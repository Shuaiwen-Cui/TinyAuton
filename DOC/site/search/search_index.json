{"config":{"lang":["en","zh"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TINYAUTON: Microcontroller-oriented Distributed Intelligence Enabling Framework","text":""},{"location":"#about-this-project","title":"ABOUT THIS PROJECT","text":"<p>This project dedicates to the development of a library for tiny agent related computing running on MCU devices to serve the multi-agent system\uff0ccovering mathematical operations, digital signal processing, and TinyML. </p> <p>About the Name</p> <p>The name \"TinyAuton\" is a combination of \"Tiny\" and \"Auton\". \"Tiny\" means the agent is designed to run on MCU devices, and \"Auton\" is short for \"Autonomous Agent\".</p>"},{"location":"#target-hardware","title":"TARGET HARDWARE","text":"<ul> <li>MCU devices (currently targeting ESP32 as the main platform)</li> </ul>"},{"location":"#scope","title":"SCOPE","text":"<ul> <li>Platform adaptation and various tools (time, communication, etc.)</li> <li>Basic Math Operations</li> <li>Digital Signal Processing</li> <li>TinyML / Edge AI</li> </ul>"},{"location":"#host-devkits","title":"HOST DEVKITS","text":"<p>Tip</p> <p>The following hardwares are for demonstration purposes only. This project is not limited to these and can be ported to other types of hardwares.</p> <ul> <li>DNESP32S3M from Alientek (ESP32-S3)</li> </ul> <p></p> <p></p> <ul> <li> <p> NexNode</p> <p>  Repo </p> <p>  Online Doc </p> </li> </ul>"},{"location":"#project-architecture","title":"PROJECT ARCHITECTURE","text":"<pre><code>+------------------------------+\n| APPLICATION                  |\n+------------------------------+\n|   - TinyAI                   | &lt;-- AI Functions\n|   - TinyDSP                  | &lt;-- DSP Functions\n|   - TinyMath                 | &lt;-- Common Math Functions\n|   - TinyToolbox              | &lt;-- Platform-specific Low-level Optimization + Various Utilities\n| MIDDLEWARE                   |\n+------------------------------+\n| DRIVERS                      |\n+------------------------------+\n| HARDWARE                     |\n+------------------------------+\n</code></pre>"},{"location":"AI/ai/","title":"ARTIFICIAL INTELLIGENCE","text":""},{"location":"ARCHITECTURE/architecture/","title":"ARCHITECTURE","text":""},{"location":"ARCHITECTURE/architecture/#layered-architecture","title":"LAYERED ARCHITECTURE","text":"<pre><code>+------------------------------+\n| AI                           | &lt;-- AI/ML Functions for Edge Devices based on Low Level Functions\n+------------------------------+\n| DSP                          | &lt;-- Digital Signal Processing Functions\n+------------------------------+\n| Math Operations              | &lt;-- Commonly Used Math Functions for Various Applications\n+------------------------------+\n| Adaptation/Toolbox Layer     | &lt;-- To Replace Functions in Standard C with Platform Optimized/Specific Functions\n+------------------------------+\n</code></pre>"},{"location":"DSP/dsp/","title":"DIGITAL SIGNAL PROCESSING","text":""},{"location":"MATH/math/","title":"MATH OPERATIONS","text":"<p>Note</p> <p>This component is designed for mathematical operations. It is a lightweight library that provides basic mathematical functions to facilitate onboard computation and AI model inference. The library is designed to be lightweight and efficient, making it suitable for edge computing applications.</p> <p>Note</p> <p>This component is a wrapper and extension of the official ESP32 digital signal processing library ESP-DSP, providing higher-level API interfaces. In simple terms, the TinyMath library corresponds to the Math, Matrix, and DotProduct modules in ESP-DSP, while the other modules in ESP-DSP correspond to the TinyDSP library.</p>"},{"location":"MATH/math/#component-dependencies","title":"COMPONENT DEPENDENCIES","text":"<pre><code>set(src_dirs\n    .\n    vec\n    mat\n)\n\nset(include_dirs\n    .\n    include\n    vec\n    mat\n)\n\nset(requires\n    tiny_toolbox\n)\n\nidf_component_register(SRC_DIRS ${src_dirs} INCLUDE_DIRS ${include_dirs} REQUIRES ${requires})\n</code></pre>"},{"location":"MATH/math/#architecture-and-directory","title":"ARCHITECTURE AND DIRECTORY","text":""},{"location":"MATH/math/#dependency-diagram","title":"Dependency Diagram","text":""},{"location":"MATH/math/#code-tree","title":"Code Tree","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 include\n    |   \u251c\u2500\u2500 tiny_error_type.h // error type header file\n    |   \u251c\u2500\u2500 tiny_constant.h // constant header file\n    |   \u251c\u2500\u2500 tiny_math_config.h // configuration header file\n    |   \u2514\u2500\u2500 tiny_math.h // main header file, include this file where you want to use the library\n    \u251c\u2500\u2500 vec\n    |   \u251c\u2500\u2500 tiny_vec.h // vector header file\n    |   \u251c\u2500\u2500 tiny_vec.c // vector source file\n    |   \u251c\u2500\u2500 tiny_vec_test.c // vector test file\n    |   \u2514\u2500\u2500 tiny_vec_test.h // vector test header file\n    \u251c\u2500\u2500 mat\n    |   \u251c\u2500\u2500 tiny_mat.h // matrix header file - c\n    |   \u251c\u2500\u2500 tiny_mat.c // matrix source file - c\n    |   \u251c\u2500\u2500 tiny_mat_test.c // matrix test file - c \n    |   \u251c\u2500\u2500 tiny_mat_test.h // matrix test header file - c\n    |   \u251c\u2500\u2500 tiny_matrix.hpp // matrix header file - cpp\n    |   \u251c\u2500\u2500 tiny_matrix.cpp // matrix source file - cpp\n    |   \u251c\u2500\u2500 tiny_matrix_test.cpp // matrix test file - cpp\n    |   \u2514\u2500\u2500 tiny_matrix_test.hpp // matrix test header file - cpp\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"MATH/ESP-DSP/esp-dsp/","title":"ESP-DSP","text":"<ul> <li> <p> ESP-DSP</p> <p>An Espressif DSP Library (esp-dsp) it\u2019s library of functions, modules and components that provides possibility to use Espressif\u2019s CPUs as DSPs in efficient way.</p> <p>  Online Doc </p> </li> </ul>"},{"location":"MATH/ESP-DSP/esp-dsp/#function-naming","title":"Function Naming","text":"<p>Naming conventions for the Library functions are similar for all covered domains. You can distinguish signal processing functions by the dsps prefix, while image and video processing functions have dspi prefix, and functions that are specific for operations on small matrices have dspm prefix in their names. Function names in Library have the following general format:</p> <pre><code>dsp&lt;data-domain&gt;_&lt;name&gt;_&lt;datatype1&gt;&lt;datatype_ext&gt;_&lt;datatype2&gt;&lt;datatype_ext&gt;[_&lt;descriptor&gt;]&lt;_impl&gt;(&lt;parameters&gt;);\n</code></pre> <p>Where:</p> <ul> <li> <p><code>&lt;data-domain&gt;</code> is the domain of the function, e.g. <code>s</code> for signal processing, <code>i</code> for image processing, <code>v</code> for video processing, and <code>m</code> for small matrix operations.</p> </li> <li> <p><code>&lt;name&gt;</code> is the name of the function.</p> </li> <li> <p><code>&lt;datatype1&gt;</code> is the type of the first input parameter.</p> </li> <li> <p><code>&lt;datatype_ext&gt;</code> is the type of the first input parameter extended with a suffix that indicates the type of the data, e.g. <code>f</code> for float, <code>i</code> for integer, <code>c</code> for complex, etc.</p> </li> <li> <p><code>&lt;datatype2&gt;</code> is the type of the second input parameter.</p> </li> <li> <p><code>&lt;descriptor&gt;</code> is an optional descriptor that provides additional information about the function.</p> </li> <li> <p><code>&lt;impl&gt;</code> is an optional implementation descriptor that provides additional information about the implementation of the function.</p> </li> <li> <p><code>&lt;parameters&gt;</code> are the parameters of the function.</p> </li> </ul>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-domain","title":"Data Domain","text":"<p>The data-domain is a single character that expresses the subset of functionality to which a given function belongs. The Library designed to supports the following data-domains:</p> <ul> <li> <p>s - for signals (expected data type is a 1D signal)</p> </li> <li> <p>i - for images and video (expected data type is a 2D image)</p> </li> <li> <p>m - for matrices (expected data type is a matrix)</p> </li> <li> <p>r - for realistic rendering functionality and 3D data processing (expected data type depends on supported rendering techniques)</p> </li> <li> <p>q - for signals of fixed length</p> </li> </ul> <p>For example, function names that begin with dspi signify that respective functions are used for image or video processing.</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#name","title":"Name","text":"<p>The name is an abbreviation for the core operation that the function really does, for example Add, Sqrt, followed in some cases by a function-specific modifier: = [_modifier]</p> <p>This modifier, if present, denotes a slight modification or variation of the given function.</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-types","title":"Data Types","text":"<p>The library supports two main data types \u2013 int16 for fixed point arithmetic and float for floating point arithmetic. The datatype described as:</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-type-suffices","title":"Data type suffices:","text":"<ul> <li> <p>s - signed</p> </li> <li> <p>u - unsigned</p> </li> <li> <p>f - float</p> </li> </ul>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-type-extensions","title":"Data type extensions:","text":"<ul> <li>c - complex</li> </ul>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-type-bits-resolution","title":"Data type Bits resolution:","text":"<ul> <li> <p>16</p> </li> <li> <p>32</p> </li> </ul> <p>For example: dsps_mac_sc16 defines that mac operation with 1d array will be made with 16 bit signed complex data.</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#implementation-type","title":"Implementation Type","text":"<p>Each function could be implemented different for different platform and could use different style and resources. That\u2019s why every implemented function will have name extension &lt;_impl&gt; that will define which kind of implementation it is. User can use universal function without extension.</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#implementation-extensions","title":"Implementation extensions:","text":"<p>By default all functions could be used without extensions. The option that select optimized/ansi can be chosen in menuconfig.</p> <p>Inside library the extensions means:</p> <ul> <li> <p>_ansi - a universal function where body of function implemented on ANSI C. This implementation not includes any hardware optimization</p> </li> <li> <p>_ae32 - written on ESP32 assembler and optimized for ESP32</p> </li> <li> <p>_aes3 - written on ESP32S3 assembler and optimized for ESP32S3</p> </li> <li> <p>_arp4 - written on ESP32P4 assembler and optimized for ESP32P4</p> </li> <li> <p>_platform - header file with definitions of available CPUs instructions for different functions</p> </li> <li> <p>others- depends on amount of supported CPUs. This list will be extended in future</p> </li> </ul>"},{"location":"MATH/ESP-DSP/examples/","title":"ESP-DSP EXAMPLES","text":""},{"location":"MATH/ESP-DSP/examples/#list-of-esp-dsp-examples","title":"List of esp-dsp Examples","text":"<p>Signal processing APIs use dsps prefix. The following modules are available:</p> <ul> <li> <p>Basic math - the example shows how to use basic vector math operations</p> </li> <li> <p>Dot-product - the example demonstrates how to use dot product functions</p> </li> <li> <p>FFT - the example demonstrates how to use FFT functionality</p> </li> <li> <p>FFT Window - the example demonstrates how to use Window and FFT functionality</p> </li> <li> <p>FFT 4 Real - the example demonstrates how to use FFT functionality for real input signals</p> </li> <li> <p>IIR - the example demonstrates how to use IIR filters functionality</p> </li> <li> <p>FIR - the example demonstrates how to use FIR filter functionality</p> </li> <li> <p>Kalman Filter - Extended Kalman Filter (EKF) example</p> </li> <li> <p>Matrix - example demonstrates how to use Mat class functionality</p> </li> </ul>"},{"location":"MATH/ESP-DSP/examples/#basic-math","title":"Basic math","text":"<p>This example demonstrates how to use basic math functions from esp-dsp library. The example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signals with 1024 samples</p> </li> <li> <p>Apply window to input signal by standard C loop.</p> </li> <li> <p>Calculate FFT for 1024 complex samples and show the result</p> </li> <li> <p>Show results on the plots</p> </li> <li> <p>Apply window to input signal by basic math functions dsps_mul_f32 and dsps_mulc_f32.</p> </li> <li> <p>Calculate FFT for 1024 complex samples</p> </li> <li> <p>Show results on the plots</p> </li> </ul> <p>For more details please look to the examples/basic_math/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#dot-product","title":"Dot-product","text":"<p>The example demonstrates how to use dotprod dsps_dotprod_f32 from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the input arrays</p> </li> <li> <p>Calculate dot product of two arrays</p> </li> <li> <p>Compare results and calculate execution time in cycles.</p> </li> </ul> <p>For more details please look to the examples/dotprod/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#fft","title":"FFT","text":"<p>This example demonstrates how to use FFT functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signals with 1024 samples: one 0 dB, second with -20 dB</p> </li> <li> <p>Combine two signals as one complex input signal and apply window to input signals paar.</p> </li> <li> <p>Calculate FFT for 1024 complex samples</p> </li> <li> <p>Apply bit reverse operation for output complex vector</p> </li> <li> <p>Split one complex FFT output spectrum to two real signal spectrums</p> </li> <li> <p>Show results on the plots</p> </li> <li> <p>Show execution time of FFT</p> </li> </ul> <p>For more details please look to the examples/fft/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#fft-window","title":"FFT Window","text":"<p>This example demonstrates how to use Window and FFT functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signals with 1024 samples</p> </li> <li> <p>Apply window to input signal.</p> </li> <li> <p>Calculate FFT for 1024 complex samples</p> </li> <li> <p>Apply bit reverse operation for output complex vector</p> </li> <li> <p>Split one complex FFT output spectrum to two real signal spectrums</p> </li> <li> <p>Show results on the plots</p> </li> </ul> <p>For more details please look to the examples/fft_window/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#fft-4-real","title":"FFT 4 Real","text":"<p>This example demonstrates how to use FFT functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signals with 1024 samples: one 0 dB, second with -20 dB</p> </li> <li> <p>Calculate FFT Radix-2 for 1024 complex samples</p> </li> <li> <p>Calculate FFT Radix-4 for 1024 complex samples</p> </li> <li> <p>Apply bit reverse operation for output complex vectors</p> </li> <li> <p>Show results on the plots</p> </li> <li> <p>Show execution time of FFTs</p> </li> </ul> <p>For more details please look to the examples/fft4real/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#iir","title":"IIR","text":"<p>This example demonstrates how to use IIR filters functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signal</p> </li> <li> <p>Show LPF filter with Q factor 1</p> <ul> <li> <p>Calculate iir filter coefficients</p> </li> <li> <p>Filter the input test signal (delta function)</p> </li> <li> <p>Shows impulse response on the plot</p> </li> <li> <p>Shows frequency response on the plot</p> </li> </ul> </li> <li> <p>Calculate execution performance</p> </li> <li> <p>The same for LPF filter with Q factor 10</p> </li> </ul> <p>For more details please look to the examples/fir/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#fir","title":"FIR","text":"<p>This example demonstrates how to use FIR filter functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the FFT library</p> </li> <li> <p>Initialize input signal</p> </li> <li> <p>Show input signal</p> </li> <li> <p>Show filtered signal</p> </li> </ul> <p>For more details please look to the examples/fir/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#kalman-filter","title":"Kalman Filter","text":"<p>This example emulate system with IMU sensors and show how to use Extended Kalman Filter (EKF), with 13 values states vector, to estimate gyroscope errors and calculate system attitude. Also, this example show how to use esp-dsp library to operate with matrices and vectors.</p> <p>In real system, the emulated sensors values should be replace by the real sensors values. Then, in real system, a calibration phase should be implemented and after the calibration phase the state vector X and covariance matrix P should be saved and restored next time, when filter called. It will save time for initial phase.</p> <p>For more details please look to the examples/kalman/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#matrix","title":"Matrix","text":"<p>This example demonstrates how to use Mat class functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize a matrix A and matirx x</p> </li> <li> <p>Calculate matrix b: b = A*x</p> </li> <li> <p>Find roots x1: A*x1 = b, with different methods</p> </li> <li> <p>Print result</p> </li> </ul>"},{"location":"MATH/HEADER-FILE/tiny_constants/","title":"CONSTANTS","text":"<p>Info</p> <p>This file contains the definition of some constants, which are used for upper-level calculations and applications. The documentation update speed is slow and may not be consistent with the actual code. Please refer to the code for accuracy.</p> <pre><code>/**\n * @file tiny_constants.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file contains the constants used in the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n// =======================================\n//  Logical Constants\n// =======================================\n#ifndef TRUE\n#define TRUE 1\n#endif\n\n#ifndef FALSE\n#define FALSE 0\n#endif\n\n#ifndef NULL\n#define NULL ((void *)0)\n#endif\n\n// =======================================\n//  Math Constants (float/double safe)\n// =======================================\n#define TINY_PI 3.14159265358979323846f\n#define TINY_TWO_PI 6.28318530717958647692f\n#define TINY_HALF_PI 1.57079632679489661923f\n#define TINY_E 2.71828182845904523536f\n#define TINY_SQRT2 1.41421356237309504880f\n#define TINY_INV_SQRT2 0.70710678118654752440f\n\n#define TINY_DEG2RAD(x) ((x) * TINY_PI / 180.0f)\n#define TINY_RAD2DEG(x) ((x) * 180.0f / TINY_PI)\n\n// =======================================\n//  Bitmask &amp; Bit Manipulation\n// =======================================\n\n// Bitwise operations\n#define TINY_BIT(n) (1U &lt;&lt; (n)) // e.g. TINY_BIT(3) = 0b00001000\n#define TINY_BIT_SET(x, n) ((x) |= TINY_BIT(n))\n#define TINY_BIT_CLEAR(x, n) ((x) &amp;= ~TINY_BIT(n))\n#define TINY_BIT_TOGGLE(x, n) ((x) ^= TINY_BIT(n))\n#define TINY_BIT_CHECK(x, n) (((x) &gt;&gt; (n)) &amp; 0x1U)\n\n// Common bit masks\n#define TINY_MASK_4BIT 0x0FU\n#define TINY_MASK_8BIT 0xFFU\n#define TINY_MASK_16BIT 0xFFFFU\n#define TINY_MASK_32BIT 0xFFFFFFFFU\n\n// =======================================\n//  Fixed-Point Scaling Factors\n// =======================================\n#define TINY_Q7_SCALE 128          // 2^7\n#define TINY_Q15_SCALE 32768       // 2^15\n#define TINY_Q31_SCALE 2147483648U // 2^31\n\n// =======================================\n//  User-Defined Constants (Optional)\n// =======================================\n#define TINY_MATH_MIN_DENOMINATOR 1e-6f         // Minimum denominator for safe division\n#define TINY_MATH_MIN_POSITIVE_INPUT_F32 1e-12f // Minimum positive input for float operations\n#define TINY_MATH_LARGE_VALUE_F32 1e38f         // Large value used to represent infinity-like results (safe for IEEE 754 float, max ~3.4e38)\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/HEADER-FILE/tiny_error_type/","title":"ERROR TYPES DEFINITION","text":"<p>Info</p> <p>This file defines some common error types in calculations to assist in determining the cause of errors. The documentation update speed is slow and may not match the actual code, please refer to the code for accuracy.</p> <pre><code>/**\n * @file tiny_error_type.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /* TYPE DEFINITIONS */\n    typedef int tiny_error_t; // Error type for the tiny_math middleware\n\n/* MACROS */\n/* Definitions for error constants. */\n#define TINY_OK 0    /*!&lt; tiny_err_t value indicating success (no error) */\n#define TINY_FAIL -1 /*!&lt; Generic tiny_err_t code indicating failure */\n\n#define TINY_ERR_NO_MEM 0x101           /*!&lt; Out of memory */\n#define TINY_ERR_INVALID_ARG 0x102      /*!&lt; Invalid argument */\n#define TINY_ERR_INVALID_STATE 0x103    /*!&lt; Invalid state */\n#define TINY_ERR_INVALID_SIZE 0x104     /*!&lt; Invalid size */\n#define TINY_ERR_NOT_FOUND 0x105        /*!&lt; Requested resource not found */\n#define TINY_ERR_NOT_SUPPORTED 0x106    /*!&lt; Operation or feature not supported */\n#define TINY_ERR_TIMEOUT 0x107          /*!&lt; Operation timed out */\n#define TINY_ERR_INVALID_RESPONSE 0x108 /*!&lt; Received response was invalid */\n#define TINY_ERR_INVALID_CRC 0x109      /*!&lt; CRC or checksum was invalid */\n#define TINY_ERR_INVALID_VERSION 0x10A  /*!&lt; Version was invalid */\n#define TINY_ERR_INVALID_MAC 0x10B      /*!&lt; MAC address was invalid */\n#define TINY_ERR_NOT_FINISHED 0x10C     /*!&lt; Operation has not fully completed */\n#define TINY_ERR_NOT_ALLOWED 0x10D      /*!&lt; Operation is not allowed */\n\n#define TINY_ERR_WIFI_BASE 0x3000      /*!&lt; Starting number of WiFi error codes */\n#define TINY_ERR_MESH_BASE 0x4000      /*!&lt; Starting number of MESH error codes */\n#define TINY_ERR_FLASH_BASE 0x6000     /*!&lt; Starting number of flash error codes */\n#define TINY_ERR_HW_CRYPTO_BASE 0xc000 /*!&lt; Starting number of HW cryptography module error codes */\n#define TINY_ERR_MEMPROT_BASE 0xd000   /*!&lt; Starting number of Memory Protection API error codes */\n\n#define TINY_ERR_MATH_BASE 0x70000\n#define TINY_ERR_MATH_INVALID_LENGTH (TINY_ERR_MATH_BASE + 1)\n#define TINY_ERR_MATH_INVALID_PARAM (TINY_ERR_MATH_BASE + 2)\n#define TINY_ERR_MATH_PARAM_OUTOFRANGE (TINY_ERR_MATH_BASE + 3)\n#define TINY_ERR_MATH_UNINITIALIZED (TINY_ERR_MATH_BASE + 4)\n#define TINY_ERR_MATH_REINITIALIZED (TINY_ERR_MATH_BASE + 5)\n#define TINY_ERR_MATH_ARRAY_NOT_ALIGNED (TINY_ERR_MATH_BASE + 6)\n#define TINY_ERR_MATH_NULL_POINTER (TINY_ERR_MATH_BASE + 7)\n#define TINY_ERR_MATH_ZERO_DIVISION (TINY_ERR_MATH_BASE + 8)\n#define TINY_ERR_MATH_NEGATIVE_SQRT (TINY_ERR_MATH_BASE + 9)\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/HEADER-FILE/tiny_math/","title":"TinyMath HEADER FILE","text":"<p>Info</p> <p>This is the main header file of the TinyMath library. It includes all necessary header files and provides a unified interface to use the functions of the library. After completing the porting of this library in the project, you can insert this header file where you want to use the relevant functions to use all functions in the library. The documentation update speed is slow and may not be consistent with the actual code, please refer to the actual code.</p> <pre><code>/**\n * @file tiny_math.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-03-26\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n\n// this layer\n#include \"tiny_math_config.h\"\n\n/* SUBMODULES */\n\n// vector operations\n#include \"tiny_vec.h\"\n\n// matrix operations\n#include \"tiny_mat.h\"\n\n// advanced matrix operations\n#ifdef __cplusplus\n\n#include \"tiny_matrix.hpp\"\n\n#endif\n\n/* TEST */ // NOTE: test files are platform specific and should not be included in the library\n\n// vector operations\n#include \"tiny_vec_test.h\"\n\n// matrix operations\n#include \"tiny_mat_test.h\"\n\n// advanced matrix operations\n#ifdef __cplusplus\n\n#include \"tiny_matrix_test.hpp\"\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/HEADER-FILE/tiny_math_config/","title":"TinyMath CONFIGURATION","text":"<p>Info</p> <p>This header file serves to configure the entire TinyMath module, and each submodule includes this header file. It defines the configuration options and macros for TinyMath, allowing users to customize settings as needed. By modifying the configuration options in this header file, users can easily adjust the behavior and functionality of TinyMath to meet specific requirements. The documentation may be updated slowly and may not match the actual code, so please refer to the code for accuracy.</p> <p>Tip</p> <p>This component includes macro definitions for selecting platforms, allowing users to choose different platforms for compilation as needed. By switching to the corresponding platform macro, users can leverage platform acceleration features to enhance performance. For example, for the ESP32 platform, TinyMath will automatically select the ESP32 DSP library for compilation, achieving more efficient mathematical operations.</p> <pre><code>/**\n * @file tiny_math_config.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-14\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* DEPENDENCIES */\n\n// ANSI C\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;math.h&gt;\n#include &lt;stdbool.h&gt;\n#include &lt;stdint.h&gt;\n\n// lower level\n#include \"tiny_toolbox.h\"\n\n// this level\n#include \"tiny_error_type.h\"\n#include \"tiny_constants.h\"\n\n/* PLATFORM SELECTION */\n\n// available platforms\n#define MCU_PLATFORM_GENERIC 0\n#define MCU_PLATFORM_ESP32 1 // here, we utilize the ESP built-in DSP library, it will automatically select the optimized version\n#define MCU_PLATFORM_STM32 2\n#define MCU_PLATFORM_RISCV 3\n\n// choose one platform\n#define MCU_PLATFORM_SELECTED MCU_PLATFORM_ESP32\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-api/","title":"MATRIX OPERATIONS - TINY_MAT","text":"<p>About tiny_mat library</p> <p>tiny_mat is a C implementation of a matrix library that provides basic matrix operation functions. It supports operations such as addition, subtraction, and multiplication of floating-point matrices. This library is suitable for embedded systems and real-time applications that require matrix calculations. The library is based on the ANSI C standard, ensuring good portability and performance, while also supporting platform acceleration through configuration files (ESP32).</p> <p>About the usage of tiny_mat library</p> <p>The functionality of tiny_mat is completely covered by tiny_matrix, which means that the functions in tiny_matrix include all the functions of tiny_mat. For simple matrix operations, you can only include the tiny_mat library; for complex matrix operations, it is recommended to use the tiny_matrix library. The tiny_matrix library is a C++ implementation of a matrix library that provides richer functionality and better performance. It supports operations such as addition, subtraction, multiplication, transposition, and inversion of floating-point and integer matrices.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#list-of-functions","title":"LIST OF FUNCTIONS","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500Vector\n    \u2514\u2500\u2500Matrix\n        \u251c\u2500\u2500 tiny_mat (c) &lt;---\n        \u2514\u2500\u2500 tiny_matrix (c++)\n</code></pre> <pre><code>// print matrix\nvoid print_matrix(const char *name, const float *mat, int rows, int cols);\n// print matrix padded (row-major)\nvoid print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n// addition\ntiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// subtraction\ntiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// multiplication\ntiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\ntiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\ntiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-api/#utility-functions","title":"UTILITY FUNCTIONS","text":""},{"location":"MATH/MATRIX/tiny-mat-api/#print-matrix","title":"Print Matrix","text":"<p><pre><code>void print_matrix(const char *name, const float *mat, int rows, int cols);\n</code></pre> Function: Print a matrix in row-major order.</p> <p>Parameters:</p> <ul> <li> <p><code>name</code>: Name of the matrix.</p> </li> <li> <p><code>mat</code>: Pointer to the matrix data.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> </ul> <p>Returns: None.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#print-padded-matrix","title":"Print Padded Matrix","text":"<p><pre><code>void print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n</code></pre> Function: Print a matrix in row-major order with padding.</p> <p>Parameters: - <code>name</code>: Name of the matrix.</p> <ul> <li> <p><code>mat</code>: Pointer to the matrix data.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> <li> <p><code>step</code>: Step size for the matrix data.</p> </li> </ul> <p>Returns: None.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#addition","title":"ADDITION","text":""},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-addition","title":"Matrix Addition","text":"<pre><code>tiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\n</code></pre> <p>Function: Add two matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>input1</code>: Pointer to the first input matrix.</p> </li> <li> <p><code>input2</code>: Pointer to the second input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrices.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrices.</p> </li> <li> <p><code>padd1</code>: Padding for the first input matrix.</p> </li> <li> <p><code>padd2</code>: Padding for the second input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step1</code>: Step size for the first input matrix.</p> </li> <li> <p><code>step2</code>: Step size for the second input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-addition-with-constant","title":"Matrix Addition with Constant","text":"<pre><code>tiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>Function: Add a constant to a matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>C</code>: Constant to add.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> <li> <p><code>padd_in</code>: Padding for the input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step_in</code>: Step size for the input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#subtraction","title":"SUBTRACTION","text":""},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-subtraction","title":"Matrix Subtraction","text":"<pre><code>tiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\n</code></pre> <p>Function: Subtract two matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>input1</code>: Pointer to the first input matrix.</p> </li> <li> <p><code>input2</code>: Pointer to the second input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrices.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrices.</p> </li> <li> <p><code>padd1</code>: Padding for the first input matrix.</p> </li> <li> <p><code>padd2</code>: Padding for the second input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step1</code>: Step size for the first input matrix.</p> </li> <li> <p><code>step2</code>: Step size for the second input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-subtraction-with-constant","title":"Matrix Subtraction with Constant","text":"<pre><code>tiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>Function: Subtract a constant from a matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>C</code>: Constant to subtract.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> <li> <p><code>padd_in</code>: Padding for the input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step_in</code>: Step size for the input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#multiplication","title":"MULTIPLICATION","text":""},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-multiplication","title":"Matrix Multiplication","text":"<pre><code>tiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\n</code></pre> <p>Function: Multiply two matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>A</code>: Pointer to the first input matrix.</p> </li> <li> <p><code>B</code>: Pointer to the second input matrix.</p> </li> <li> <p><code>C</code>: Pointer to the output matrix.</p> </li> <li> <p><code>m</code>: Number of rows in the first matrix.</p> </li> <li> <p><code>n</code>: Number of columns in the first matrix (and rows in the second matrix).</p> </li> <li> <p><code>k</code>: Number of columns in the second matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#extended-matrix-multiplication","title":"Extended Matrix Multiplication","text":"<pre><code>tiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\n</code></pre> <p>Function: Multiply two matrices with extended parameters.</p> <p>Parameters:</p> <ul> <li> <p><code>A</code>: Pointer to the first input matrix.</p> </li> <li> <p><code>B</code>: Pointer to the second input matrix.</p> </li> <li> <p><code>C</code>: Pointer to the output matrix.</p> </li> <li> <p><code>A_rows</code>: Number of rows in the first matrix.</p> </li> <li> <p><code>A_cols</code>: Number of columns in the first matrix.</p> </li> <li> <p><code>B_cols</code>: Number of columns in the second matrix.</p> </li> <li> <p><code>A_padding</code>: Padding for the first matrix.</p> </li> <li> <p><code>B_padding</code>: Padding for the second matrix.</p> </li> <li> <p><code>C_padding</code>: Padding for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-multiplication-with-constant","title":"Matrix Multiplication with Constant","text":"<pre><code>tiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>Function: Multiply a matrix by a constant.</p> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>C</code>: Constant to multiply.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> <li> <p><code>padd_in</code>: Padding for the input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step_in</code>: Step size for the input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure. ```</p>"},{"location":"MATH/MATRIX/tiny-mat-code/","title":"CODE","text":""},{"location":"MATH/MATRIX/tiny-mat-code/#tiny_math","title":"tiny_mat.h","text":"<pre><code>/**\n * @file tiny_mat.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the submodule mat (basic matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_math_config.h\"\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n// ESP32 DSP library\n#include \"dspm_matrix.h\"\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* FUNCTION PROTOTYPES */\n// print matrix\nvoid print_matrix(const char *name, const float *mat, int rows, int cols);\n// print matrix padded (row-major)\nvoid print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n// addition\ntiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// subtraction\ntiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// multiplication\ntiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\ntiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\ntiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-code/#tiny_matc","title":"tiny_mat.c","text":"<pre><code>/**\n * @file tiny_mat.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the source file for the submodule mat (basic matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_mat.h\"\n\n/* SUPPORTIVE FUNCTIONS */\n\n/**\n * @name print_matrix\n * @brief Prints a matrix to the console.\n * @param name Name of the matrix.\n * @param mat Pointer to the matrix data.\n * @param rows Number of rows in the matrix.\n * @param cols Number of columns in the matrix.\n */\nvoid print_matrix(const char *name, const float *mat, int rows, int cols)\n{\n    printf(\"%s =\\n\\r\", name);\n    for (int i = 0; i &lt; rows; i++)\n    {\n        for (int j = 0; j &lt; cols; j++)\n        {\n            printf(\"%10.6f \", mat[i * cols + j]); // padding not considered, row-major order\n        }\n        printf(\"\\n\\r\");\n    }\n    printf(\"\\n\\r\");\n}\n\n// print matrix padded\n/**\n * @name print_matrix\n * @brief Prints a matrix to the console.\n * @param name Name of the matrix.\n * @param mat Pointer to the matrix data.\n * @param rows Number of rows in the matrix.\n * @param cols Number of columns in the matrix.\n * @param step Step size (how many elements in a row) for the matrix data. row-major order.\n */\nvoid print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step)\n{\n    printf(\"%s =\\n\\r\", name);\n    for (int i = 0; i &lt; rows; i++)\n    {\n        for (int j = 0; j &lt; cols; j++)\n        {\n            printf(\"%10.6f \", mat[i * step + j]); // padding considered\n        }\n        printf(\"\\n\\r\");\n    }\n    printf(\"\\n\\r\");\n}\n\n/* ADDITION */\n\n// matrix + matrix | float\n\n/**\n * @name tiny_mat_add_f32\n * @brief Adds two matrices of type float32.\n * @param input1 Pointer to the first input matrix.\n * @param input2 Pointer to the second input matrix.\n * @param output Pointer to the output matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd1 Number of padding columns in the first input matrix.\n * @param padd2 Number of padding columns in the second input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step1 Step size for the first input matrix.\n * @param step2 Step size for the second input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix addition with the specified padding and step sizes.\n * @note The function assumes that the input matrices are in row-major order.\n */\ntiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd1 &lt; 0 || padd2 &lt; 0 || padd_out &lt; 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n\n    // pad refers to the columns that are not used in the matrix operation\n\n    /* Use explicit index math instead of mutating the caller pointers.\n       This keeps input pointers const and avoids surprises from pointer\n       arithmetic. The storage model is row-major with per-row reserved\n       length = cols + padd. Logical column c is at base + c * step. */\n    const int in1_row_stride = cols + padd1;\n    const int in2_row_stride = cols + padd2;\n    const int out_row_stride = cols + padd_out;\n\n    // If we're on ESP32 and all paddings are 0 and all steps are 1 (contiguous),\n    // prefer to call the optimized ESP-DSP implementation.\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd1 == 0 &amp;&amp; padd2 == 0 &amp;&amp; padd_out == 0 &amp;&amp; step1 == 1 &amp;&amp; step2 == 1 &amp;&amp; step_out == 1) {\n        dspm_add_f32(input1, input2, output, rows, cols, 0, 0, 0, 1, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in1 = row * in1_row_stride;\n        int base_in2 = row * in2_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in1 = base_in1 + col * step1;\n            int idx_in2 = base_in2 + col * step2;\n            int idx_out = base_out + col * step_out;\n\n            /* bounds are the caller's responsibility, but avoid undefined\n               behavior by checking indices minimally in debug builds if\n               needed (not enforced here for performance). */\n            output[idx_out] = input1[idx_in1] + input2[idx_in2];\n        }\n    }\n    return TINY_OK;\n}\n\n// matrix + constant | float\n\n/**\n * @name tiny_mat_addc_f32\n * @brief Adds a constant to each element of a matrix of type float32.\n * @param input Pointer to the input matrix.\n * @param output Pointer to the output matrix.\n * @param C Constant value to be added to each element of the matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd_in Number of padding columns in the input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step_in Step size for the input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix addition with a constant with the specified padding and step sizes.\n * @note The function assumes that the input matrix is in row-major order.\n */\ntiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd_in &lt; 0 || padd_out &lt; 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // pad refers to the columns that are not used in the matrix operation\n    // If running on ESP32 and all paddings are 0 and all steps are 1 (contiguous),\n    // prefer the optimized ESP-DSP implementation.\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd_in == 0 &amp;&amp; padd_out == 0 &amp;&amp; step_in == 1 &amp;&amp; step_out == 1) {\n        dspm_addc_f32(input, output, C, rows, cols, 0, 0, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    const int in_row_stride = cols + padd_in;\n    const int out_row_stride = cols + padd_out;\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n\n            output[idx_out] = input[idx_in] + C;\n        }\n    }\n    return TINY_OK;\n}\n\n/* SUBTRACTION */\n\n// matrix - matrix | float\n\n/**\n * @name tiny_mat_sub_f32\n * @brief Subtracts two matrices of type float32.\n * @param input1 Pointer to the first input matrix.\n * @param input2 Pointer to the second input matrix.\n * @param output Pointer to the output matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd1 Number of padding columns in the first input matrix.\n * @param padd2 Number of padding columns in the second input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step1 Step size for the first input matrix.\n * @param step2 Step size for the second input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix subtraction with the specified padding and step sizes.\n * @note The function assumes that the input matrices are in row-major order.\n */\ntiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd1 &lt; 0 || padd2 &lt; 0 || padd_out &lt; 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // pad refers to the columns that are not used in the matrix operation\n    // Prefer ESP-DSP only when all paddings are 0 and all steps are 1 (contiguous)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd1 == 0 &amp;&amp; padd2 == 0 &amp;&amp; padd_out == 0 &amp;&amp; step1 == 1 &amp;&amp; step2 == 1 &amp;&amp; step_out == 1) {\n        dspm_sub_f32(input1, input2, output, rows, cols, 0, 0, 0, 1, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    const int in1_row_stride = cols + padd1;\n    const int in2_row_stride = cols + padd2;\n    const int out_row_stride = cols + padd_out;\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in1 = row * in1_row_stride;\n        int base_in2 = row * in2_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in1 = base_in1 + col * step1;\n            int idx_in2 = base_in2 + col * step2;\n            int idx_out = base_out + col * step_out;\n\n            output[idx_out] = input1[idx_in1] - input2[idx_in2];\n        }\n    }\n    return TINY_OK;\n}\n\n// matrix - constant | float\n\n/**\n * @name tiny_mat_subc_f32\n * @brief Subtracts a constant from each element of a matrix of type float32.\n * @param input Pointer to the input matrix.\n * @param output Pointer to the output matrix.\n * @param C Constant value to be subtracted from each element of the matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd_in Number of padding columns in the input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step_in Step size for the input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix subtraction with a constant with the specified padding and step sizes.\n * @note The function assumes that the input matrix is in row-major order.\n */\ntiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd_in &lt; 0 || padd_out &lt; 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // pad refers to the columns that are not used in the matrix operation\n    // Prefer ESP-DSP only when all paddings are 0 and all steps are 1 (contiguous)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd_in == 0 &amp;&amp; padd_out == 0 &amp;&amp; step_in == 1 &amp;&amp; step_out == 1) {\n        // dspm_addc_f32 performs addition; pass -C to implement subtraction-constant\n        dspm_addc_f32(input, output, -C, rows, cols, 0, 0, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    const int in_row_stride = cols + padd_in;\n    const int out_row_stride = cols + padd_out;\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n\n            output[idx_out] = input[idx_in] - C;\n        }\n    }\n    return TINY_OK;\n}\n\n/* MULTIPLICATION */\n\n// matrix * matrix | float\n\n/**\n * @name tiny_mat_mult_f32\n * @brief Multiplies two matrices of type float32.\n * @param A Pointer to the first input matrix.\n * @param B Pointer to the second input matrix.\n * @param C Pointer to the output matrix.\n * @param m Number of rows in the first matrix.\n * @param n Number of columns in the first matrix and rows in the second matrix.\n * @param k Number of columns in the second matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix multiplication with the specified padding and step sizes.\n * @note The function assumes that the input matrices are in row-major order.\n */\ntiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k)\n{\n    if (NULL == A || NULL == B || NULL == C)\n        return TINY_ERR_MATH_NULL_POINTER;\n    if (m &lt;= 0 || n &lt;= 0 || k &lt;= 0)\n        return TINY_ERR_MATH_INVALID_PARAM;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized matrix multiplication\n    dspm_mult_f32(A, B, C, m, n, k);\n#else\n    // C[i][j] = sum_{s=0}^{n-1} A[i][s] * B[s][j]\n    for (int i = 0; i &lt; m; i++)\n    {\n        for (int j = 0; j &lt; k; j++)\n        {\n            C[i * k + j] = 0.0f;\n            for (int s = 0; s &lt; n; s++)\n            {\n                C[i * k + j] += A[i * n + s] * B[s * k + j];\n            }\n        }\n    }\n#endif\n    return TINY_OK;\n}\n\n// matrix * matrix | float with padding and step sizes\n/**\n * @name tiny_mat_mult_ex_f32\n * @brief Multiplies two matrices of type float32 with padding and step sizes.\n * @param A Pointer to the first input matrix.\n * @param B Pointer to the second input matrix.\n * @param C Pointer to the output matrix.\n * @param A_rows Number of rows in the first matrix.\n * @param A_cols Number of columns in the first matrix and rows in the second matrix.\n * @param B_cols Number of columns in the second matrix.\n * @param A_padding Number of padding columns in the first matrix.\n * @param B_padding Number of padding columns in the second matrix.\n * @param C_padding Number of padding columns in the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix multiplication with the specified padding and step sizes.\n * @note The function assumes that the input matrices are in row-major order.\n */\ntiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding)\n{\n    if (NULL == A || NULL == B || NULL == C)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (A_rows &lt;= 0 || A_cols &lt;= 0 || B_cols &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    if (A_padding &lt; 0 || B_padding &lt; 0 || C_padding &lt; 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // Prefer ESP-DSP only when paddings are zero (contiguous storage)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (A_padding == 0 &amp;&amp; B_padding == 0 &amp;&amp; C_padding == 0) {\n        dspm_mult_ex_f32(A, B, C, A_rows, A_cols, B_cols, 0, 0, 0);\n        return TINY_OK;\n    }\n#endif\n\n    // Matrix A(m,n), m - amount of rows, n - amount of columns\n    // C(m,k) = A(m,n)*B(n,k)\n    // C[i][j] = sum_{s=0}^{n-1} A[i][s] * B[s][j]\n    const int A_step = A_cols + A_padding;\n    const int B_step = B_cols + B_padding;\n    const int C_step = B_cols + C_padding;\n\n    for (int i = 0; i &lt; A_rows; i++)\n    {\n        for (int j = 0; j &lt; B_cols; j++)\n        {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; A_cols; s++)\n            {\n                sum += A[i * A_step + s] * B[s * B_step + j];\n            }\n            C[i * C_step + j] = sum;\n        }\n    }\n    return TINY_OK;\n}\n\n// matrix * constant | float\n/**\n * @name tiny_mat_multc_f32\n * @brief Multiplies a matrix by a constant of type float32.\n * @param input Pointer to the input matrix.\n * @param output Pointer to the output matrix.\n * @param C Constant value to be multiplied with each element of the matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd_in Number of padding columns in the input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step_in Step size for the input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix multiplication with a constant with the specified padding and step sizes.\n * @note The function assumes that the input matrix is in row-major order.\n */\ntiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd_in &lt; 0 || padd_out &lt; 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // pad refers to the columns that are not used in the matrix operation\n    // Prefer ESP-DSP only when all paddings are 0 and all steps are 1 (contiguous)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd_in == 0 &amp;&amp; padd_out == 0 &amp;&amp; step_in == 1 &amp;&amp; step_out == 1) {\n        dspm_mulc_f32(input, output, C, rows, cols, 0, 0, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    const int in_row_stride = cols + padd_in;\n    const int out_row_stride = cols + padd_out;\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n\n            output[idx_out] = input[idx_in] * C;\n        }\n    }\n    return TINY_OK;\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-test/","title":"TINY_MAT TEST","text":""},{"location":"MATH/MATRIX/tiny-mat-test/#test-code","title":"TEST CODE","text":""},{"location":"MATH/MATRIX/tiny-mat-test/#tiny_mat_testh","title":"tiny_mat_test.h","text":"<pre><code>/**\n * @file tiny_mat_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the test of the submodule mat (basic matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_math_config.h\"\n#include \"tiny_mat.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_mat_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-test/#tiny_mat_testc","title":"tiny_mat_test.c","text":"<pre><code>/**\n * @file tiny_mat_test.c\n * @brief Comprehensive stress tests for tiny_mat module, targeting edge cases and potential weaknesses.\n * @note Tests include: step parameters, different paddings, extreme values, boundary cases, and complex memory layouts.\n */\n\n#include \"tiny_mat_test.h\"\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\n/**\n * @brief Test tiny_mat_add_f32 with pad=0 and step=1 (contiguous memory layout)\n * \n * Test Scenario:\n *   - This test case uses contiguous memory layout (no padding, step=1)\n *   - On ESP32 platform, this should trigger ESP-DSP optimized implementation\n *   - On other platforms, uses the standard implementation\n * \n * Memory Layout:\n *   - Input1: 3x4 matrix stored contiguously in memory\n *     [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0]\n *     Logical view:\n *       1.0   2.0   3.0   4.0\n *       5.0   6.0   7.0   8.0\n *       9.0  10.0  11.0  12.0\n * \n *   - Input2: 3x4 matrix stored contiguously in memory\n *     [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5]\n *     Logical view:\n *       0.5   1.5   2.5   3.5\n *       4.5   5.5   6.5   7.5\n *       8.5   9.5  10.5  11.5\n * \n * Expected Output:\n *   - Output: 3x4 matrix, each element = input1[i][j] + input2[i][j]\n *     Expected logical view:\n *       1.5   3.5   5.5   7.5\n *       9.5  11.5  13.5  15.5\n *      17.5  19.5  21.5  23.5\n * \n * Parameters:\n *   - rows = 3, cols = 4\n *   - padd1 = 0, padd2 = 0, padd_out = 0 (no padding)\n *   - step1 = 1, step2 = 1, step_out = 1 (contiguous access)\n */\nvoid test_tiny_mat_add_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 1: tiny_mat_add_f32 - Contiguous Memory Layout (pad=0, step=1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=4, pad=0, step=1\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 4;\n\n    // Input matrices (contiguous, no padding)\n    float input1[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                        5.0f, 6.0f, 7.0f, 8.0f,\n                        9.0f, 10.0f, 11.0f, 12.0f};\n\n    float input2[12] = {0.5f, 1.5f, 2.5f, 3.5f,\n                        4.5f, 5.5f, 6.5f, 7.5f,\n                        8.5f, 9.5f, 10.5f, 11.5f};\n\n    float output[12];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input1 Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input1[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Input2 Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input2[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [4.5  5.5  6.5  7.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [8.5  9.5 10.5 11.5]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Expected Output Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input1[i] + input2[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [9.5 11.5 13.5 15.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [17.5 19.5 21.5 23.5] &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Test with pad=0, step=1 (should use ESP-DSP on ESP32)\n    tiny_error_t err = tiny_mat_add_f32(input1, input2, output, rows, cols, \n                                        0, 0, 0,  // padd1=0, padd2=0, padd_out=0\n                                        1, 1, 1); // step1=1, step2=1, step_out=1\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (12 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 12; i++) {\n            printf(\"%5.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\\n\\r\");\n        printf(\"          [9.5 11.5 13.5 15.5]  &lt;- Row 1\\n\\r\");\n        printf(\"          [17.5 19.5 21.5 23.5] &lt;- Row 2\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; rows * cols; i++) {\n            float expected = input1[i] + input2[i];\n            float tolerance = 1e-6f;\n            float diff = (output[i] &gt; expected) ? (output[i] - expected) : (expected - output[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_add_f32 with pad!=0 and step&gt;1 (non-contiguous memory layout)\n * \n * ================================================================================\n * Test Scenario:\n * ================================================================================\n * This test case demonstrates how to handle matrix addition with non-contiguous\n * memory layout. In real applications, matrix data may not be stored contiguously:\n *   1. Padding: Extra space at the end of each row\n *   2. Stride/Step: Gaps between elements\n * \n * For example, a 2x3 logical matrix with padding=2 and step=2 may have memory layout:\n *   Logical matrix:        Memory array (first 10 elements):\n *   [1.0  2.0  3.0]  [1.0, 0, 2.0, 0, 3.0, 0, 0, 0, 0, 0, ...]\n *   [4.0  5.0  6.0]  [4.0, 0, 5.0, 0, 6.0, 0, 0, 0, 0, 0, ...]\n * \n * ================================================================================\n * Index Calculation Formula:\n * ================================================================================\n * For matrix element [row][col], the memory index is calculated as:\n *   index = row * (cols + padding) + col * step\n * \n * Where:\n *   - row: Row number (starting from 0)\n *   - col: Column number (starting from 0)\n *   - cols: Number of columns in the matrix\n *   - padding: Number of padding elements at the end of each row\n *   - step: Stride between columns (element spacing)\n * \n * ================================================================================\n * Input1 Details (2x3 matrix, padding=2, step=2):\n * ================================================================================\n * Logical matrix view:\n *   [1.0  2.0  3.0]\n *   [4.0  5.0  6.0]\n * \n * Memory array (input1[20]) actual content:\n *   Index:  0    1    2    3    4    5    6    7    8    9   10   11   12   ...\n *   Value:  [1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]\n *           |---- row 0 ----|  |-- padding --|  |---- row 1 ----|  |-- padding --|\n * \n * Index calculation process:\n *   [0][0]: index = 0*(3+2) + 0*2 = 0*5 + 0 = 0  \u2192 input1[0] = 1.0\n *   [0][1]: index = 0*(3+2) + 1*2 = 0*5 + 2 = 2  \u2192 input1[2] = 2.0\n *   [0][2]: index = 0*(3+2) + 2*2 = 0*5 + 4 = 4  \u2192 input1[4] = 3.0\n *   [1][0]: index = 1*(3+2) + 0*2 = 1*5 + 0 = 5  \u2192 input1[5] = 4.0\n *   [1][1]: index = 1*(3+2) + 1*2 = 1*5 + 2 = 7  \u2192 input1[7] = 5.0\n *   [1][2]: index = 1*(3+2) + 2*2 = 1*5 + 4 = 9  \u2192 input1[9] = 6.0\n * \n * Memory layout visualization:\n *   Position: [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] ...\n *   Value:     1.0  0.0  2.0  0.0  3.0  0.0  0.0  0.0  0.0  6.0   0.0   0.0   0.0 ...\n *   Label:     R0C0      R0C1      R0C2  pad  pad  pad  pad  R1C2   pad   pad   pad ...\n * \n * ================================================================================\n * Input2 Details (2x3 matrix, padding=1, step=3):\n * ================================================================================\n * Logical matrix view:\n *   [0.5  1.5  2.5]\n *   [3.5  4.5  5.5]\n * \n * Memory array (input2[16]) actual content:\n *   Index:  0    1    2    3    4    5    6    7    8    9   10   11   ...\n *   Value:  [0.5, 0.0, 0.0, 1.5, 0.0, 0.0, 2.5, 0.0, 0.0, 0.0, 5.5, 0.0, ...]\n *           |---- row 0 ----|  |-- padding --|  |---- row 1 ----|  |-- padding --|\n * \n * Index calculation process:\n *   [0][0]: index = 0*(3+1) + 0*3 = 0*4 + 0 = 0  \u2192 input2[0] = 0.5\n *   [0][1]: index = 0*(3+1) + 1*3 = 0*4 + 3 = 3  \u2192 input2[3] = 1.5\n *   [0][2]: index = 0*(3+1) + 2*3 = 0*4 + 6 = 6  \u2192 input2[6] = 2.5\n *   [1][0]: index = 1*(3+1) + 0*3 = 1*4 + 0 = 4  \u2192 input2[4] = 3.5\n *   [1][1]: index = 1*(3+1) + 1*3 = 1*4 + 3 = 7  \u2192 input2[7] = 4.5\n *   [1][2]: index = 1*(3+1) + 2*3 = 1*4 + 6 = 10 \u2192 input2[10] = 5.5\n * \n * Memory layout visualization:\n *   Position: [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\n *   Value:     0.5  0.0  0.0  1.5  3.5  0.0  2.5  4.5  0.0  0.0  5.5   0.0 ...\n *   Label:     R0C0      R0C1      R1C0      R0C2  R1C1      R1C2   pad ...\n * \n * ================================================================================\n * Expected Output (2x3 matrix, padding=2, step=2):\n * ================================================================================\n * Logical matrix view:\n *   [1.5  3.5  5.5]\n *   [7.5  9.5 11.5]\n * \n * Calculation process:\n *   output[0][0] = input1[0][0] + input2[0][0] = 1.0 + 0.5 = 1.5\n *   output[0][1] = input1[0][1] + input2[0][1] = 2.0 + 1.5 = 3.5\n *   output[0][2] = input1[0][2] + input2[0][2] = 3.0 + 2.5 = 5.5\n *   output[1][0] = input1[1][0] + input2[1][0] = 4.0 + 3.5 = 7.5\n *   output[1][1] = input1[1][1] + input2[1][1] = 5.0 + 4.5 = 9.5\n *   output[1][2] = input1[1][2] + input2[1][2] = 6.0 + 5.5 = 11.5\n * \n * Output memory array (output[20]) expected content:\n *   Index:  0    1    2    3    4    5    6    7    8    9   10   11   12   ...\n *   Value:  [1.5, 0.0, 3.5, 0.0, 5.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]\n *           |---- row 0 ----|  |-- padding --|  |---- row 1 ----|  |-- padding --|\n * \n * ================================================================================\n * Test Parameters:\n * ================================================================================\n *   rows = 2, cols = 3\n *   padd1 = 2, padd2 = 1, padd_out = 2 (with padding)\n *   step1 = 2, step2 = 3, step_out = 2 (non-contiguous access)\n */\nvoid test_tiny_mat_add_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 2: tiny_mat_add_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd1 = 2;\n    const int padd2 = 1;\n    const int padd_out = 2;\n    const int step1 = 2;\n    const int step2 = 3;\n    const int step_out = 2;\n\n    printf(\"Parameters: rows=%d, cols=%d, pad1=%d, pad2=%d, pad_out=%d, step1=%d, step2=%d, step_out=%d\\n\\r\",\n           rows, cols, padd1, padd2, padd_out, step1, step2, step_out);\n    printf(\"Index formula: index = row * (cols + padding) + col * step\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Input1: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd1 = 3 + 2 = 5\n    // Memory index calculation: base = row * (cols + padd1), offset = col * step1\n    float input1[20] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 2, 4\n    input1[0 * 5 + 0 * 2] = 1.0f; // row 0, col 0: index = 0*5 + 0*2 = 0\n    input1[0 * 5 + 1 * 2] = 2.0f; // row 0, col 1: index = 0*5 + 1*2 = 2\n    input1[0 * 5 + 2 * 2] = 3.0f; // row 0, col 2: index = 0*5 + 2*2 = 4\n    // Row 1: elements at indices 5, 7, 9\n    input1[1 * 5 + 0 * 2] = 4.0f; // row 1, col 0: index = 1*5 + 0*2 = 5\n    input1[1 * 5 + 1 * 2] = 5.0f; // row 1, col 1: index = 1*5 + 1*2 = 7\n    input1[1 * 5 + 2 * 2] = 6.0f; // row 1, col 2: index = 1*5 + 2*2 = 9\n\n    // Input2: 2 rows, 3 cols, padding=1, step=3\n    // Row stride = cols + padd2 = 3 + 1 = 4\n    // Memory index calculation: base = row * (cols + padd2), offset = col * step2\n    float input2[16] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 3, 6\n    input2[0 * 4 + 0 * 3] = 0.5f; // row 0, col 0: index = 0*4 + 0*3 = 0\n    input2[0 * 4 + 1 * 3] = 1.5f; // row 0, col 1: index = 0*4 + 1*3 = 3\n    input2[0 * 4 + 2 * 3] = 2.5f; // row 0, col 2: index = 0*4 + 2*3 = 6\n    // Row 1: elements at indices 4, 7, 10\n    input2[1 * 4 + 0 * 3] = 3.5f; // row 1, col 0: index = 1*4 + 0*3 = 4\n    input2[1 * 4 + 1 * 3] = 4.5f; // row 1, col 1: index = 1*4 + 1*3 = 7\n    input2[1 * 4 + 2 * 3] = 5.5f; // row 1, col 2: index = 1*4 + 2*3 = 10\n\n    // Output: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_out = 3 + 2 = 5\n    float output[20] = {0}; // Allocate enough space, initialize to zero\n\n    printf(\"Input1 Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd1, step1);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", input1[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Input2 Memory Layout (16 elements, pad=%d, step=%d):\\n\\r\", padd2, step2);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%4.1f \", input2[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\\n\\r\");\n    printf(\"          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output\n    float expected_output[20] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        for (int col = 0; col &lt; cols; col++) {\n            int idx1 = row * (cols + padd1) + col * step1;\n            int idx2 = row * (cols + padd2) + col * step2;\n            int idx_out = row * (cols + padd_out) + col * step_out;\n            expected_output[idx_out] = input1[idx1] + input2[idx2];\n        }\n    }\n\n    printf(\"Expected Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", expected_output[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [1.5  X  3.5  X  5.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [7.5  X  9.5  X 11.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    tiny_error_t err = tiny_mat_add_f32(input1, input2, output, rows, cols,\n                                        padd1, padd2, padd_out,\n                                        step1, step2, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 15; i++) {\n            printf(\"%4.1f \", output[i]);\n        }\n        printf(\"...\\n\\r\");\n        printf(\"  Matrix: [1.5  X  3.5  X  5.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n        printf(\"          [7.5  X  9.5  X 11.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n        printf(\"          (X = padding/unused)\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_out = row * (cols + padd_out) + col * step_out;\n                int idx1 = row * (cols + padd1) + col * step1;\n                int idx2 = row * (cols + padd2) + col * step2;\n                float expected = input1[idx1] + input2[idx2];\n                float tolerance = 1e-6f;\n                float diff = (output[idx_out] &gt; expected) ? (output[idx_out] - expected) : (expected - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    all_correct = 0;\n                    break;\n                }\n            }\n            if (!all_correct) break;\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_addc_f32 with pad=0 and step=1 (contiguous memory layout)\n */\nvoid test_tiny_mat_addc_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 3: tiny_mat_addc_f32 - Contiguous Memory Layout (pad=0, step=1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=4, pad=0, step=1, C=2.5\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 4;\n    const float C = 2.5f;\n\n    // Input matrix (contiguous, no padding)\n    float input[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                       5.0f, 6.0f, 7.0f, 8.0f,\n                       9.0f, 10.0f, 11.0f, 12.0f};\n\n    float output[12];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C = %5.1f\\n\\r\", C);\n    printf(\"\\n\\r\");\n\n    printf(\"Expected Output Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input[i] + C);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [7.5  8.5  9.5 10.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [11.5 12.5 13.5 14.5] &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Test with pad=0, step=1 (should use ESP-DSP on ESP32)\n    tiny_error_t err = tiny_mat_addc_f32(input, output, C, rows, cols,\n                                         0, 0,  // padd_in=0, padd_out=0\n                                         1, 1); // step_in=1, step_out=1\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (12 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 12; i++) {\n            printf(\"%5.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\\n\\r\");\n        printf(\"          [7.5  8.5  9.5 10.5]  &lt;- Row 1\\n\\r\");\n        printf(\"          [11.5 12.5 13.5 14.5] &lt;- Row 2\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; rows * cols; i++) {\n            float expected = input[i] + C;\n            float tolerance = 1e-6f;\n            float diff = (output[i] &gt; expected) ? (output[i] - expected) : (expected - output[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_addc_f32 with pad!=0 and step&gt;1 (non-contiguous memory layout)\n */\nvoid test_tiny_mat_addc_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 4: tiny_mat_addc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd_in = 2;\n    const int padd_out = 2;\n    const int step_in = 2;\n    const int step_out = 2;\n    const float C = 1.5f;\n\n    printf(\"Parameters: rows=%d, cols=%d, pad_in=%d, pad_out=%d, step_in=%d, step_out=%d, C=%5.1f\\n\\r\",\n           rows, cols, padd_in, padd_out, step_in, step_out, C);\n    printf(\"Index formula: index = row * (cols + padding) + col * step\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Input: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_in = 3 + 2 = 5\n    float input[20] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 2, 4\n    input[0 * 5 + 0 * 2] = 1.0f; // row 0, col 0: index = 0*5 + 0*2 = 0\n    input[0 * 5 + 1 * 2] = 2.0f; // row 0, col 1: index = 0*5 + 1*2 = 2\n    input[0 * 5 + 2 * 2] = 3.0f; // row 0, col 2: index = 0*5 + 2*2 = 4\n    // Row 1: elements at indices 5, 7, 9\n    input[1 * 5 + 0 * 2] = 4.0f; // row 1, col 0: index = 1*5 + 0*2 = 5\n    input[1 * 5 + 1 * 2] = 5.0f; // row 1, col 1: index = 1*5 + 1*2 = 7\n    input[1 * 5 + 2 * 2] = 6.0f; // row 1, col 2: index = 1*5 + 2*2 = 9\n\n    // Output: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_out = 3 + 2 = 5\n    float output[20] = {0}; // Allocate enough space, initialize to zero\n\n    printf(\"Input Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_in, step_in);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", input[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C = %5.1f\\n\\r\", C);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output\n    float expected_output[20] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = row * (cols + padd_in) + col * step_in;\n            int idx_out = row * (cols + padd_out) + col * step_out;\n            expected_output[idx_out] = input[idx_in] + C;\n        }\n    }\n\n    printf(\"Expected Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", expected_output[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    tiny_error_t err = tiny_mat_addc_f32(input, output, C, rows, cols,\n                                         padd_in, padd_out,\n                                         step_in, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 15; i++) {\n            printf(\"%4.1f \", output[i]);\n        }\n        printf(\"...\\n\\r\");\n        printf(\"  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n        printf(\"          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n        printf(\"          (X = padding/unused)\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_in = row * (cols + padd_in) + col * step_in;\n                int idx_out = row * (cols + padd_out) + col * step_out;\n                float expected = input[idx_in] + C;\n                float tolerance = 1e-6f;\n                float diff = (output[idx_out] &gt; expected) ? (output[idx_out] - expected) : (expected - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    all_correct = 0;\n                    break;\n                }\n            }\n            if (!all_correct) break;\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_sub_f32 with pad=0 and step=1 (contiguous memory layout)\n */\nvoid test_tiny_mat_sub_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 5: tiny_mat_sub_f32 - Contiguous Memory Layout (pad=0, step=1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=4, pad=0, step=1\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 4;\n\n    // Input matrices (contiguous, no padding)\n    float input1[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                        5.0f, 6.0f, 7.0f, 8.0f,\n                        9.0f, 10.0f, 11.0f, 12.0f};\n\n    float input2[12] = {0.5f, 1.5f, 2.5f, 3.5f,\n                        4.5f, 5.5f, 6.5f, 7.5f,\n                        8.5f, 9.5f, 10.5f, 11.5f};\n\n    float output[12];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input1 Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input1[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Input2 Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input2[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [4.5  5.5  6.5  7.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [8.5  9.5 10.5 11.5]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Expected Output Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input1[i] - input2[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [0.5  0.5  0.5  0.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [0.5  0.5  0.5  0.5] &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Test with pad=0, step=1 (should use ESP-DSP on ESP32)\n    tiny_error_t err = tiny_mat_sub_f32(input1, input2, output, rows, cols, \n                                        0, 0, 0,  // padd1=0, padd2=0, padd_out=0\n                                        1, 1, 1); // step1=1, step2=1, step_out=1\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (12 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 12; i++) {\n            printf(\"%5.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\\n\\r\");\n        printf(\"          [0.5  0.5  0.5  0.5]  &lt;- Row 1\\n\\r\");\n        printf(\"          [0.5  0.5  0.5  0.5] &lt;- Row 2\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; rows * cols; i++) {\n            float expected = input1[i] - input2[i];\n            float tolerance = 1e-6f;\n            float diff = (output[i] &gt; expected) ? (output[i] - expected) : (expected - output[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_sub_f32 with pad!=0 and step&gt;1 (non-contiguous memory layout)\n */\nvoid test_tiny_mat_sub_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 6: tiny_mat_sub_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd1 = 2;\n    const int padd2 = 1;\n    const int padd_out = 2;\n    const int step1 = 2;\n    const int step2 = 3;\n    const int step_out = 2;\n\n    printf(\"Parameters: rows=%d, cols=%d, pad1=%d, pad2=%d, pad_out=%d, step1=%d, step2=%d, step_out=%d\\n\\r\",\n           rows, cols, padd1, padd2, padd_out, step1, step2, step_out);\n    printf(\"Index formula: index = row * (cols + padding) + col * step\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Input1: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd1 = 3 + 2 = 5\n    float input1[20] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 2, 4\n    input1[0 * 5 + 0 * 2] = 1.0f; // row 0, col 0: index = 0*5 + 0*2 = 0\n    input1[0 * 5 + 1 * 2] = 2.0f; // row 0, col 1: index = 0*5 + 1*2 = 2\n    input1[0 * 5 + 2 * 2] = 3.0f; // row 0, col 2: index = 0*5 + 2*2 = 4\n    // Row 1: elements at indices 5, 7, 9\n    input1[1 * 5 + 0 * 2] = 4.0f; // row 1, col 0: index = 1*5 + 0*2 = 5\n    input1[1 * 5 + 1 * 2] = 5.0f; // row 1, col 1: index = 1*5 + 1*2 = 7\n    input1[1 * 5 + 2 * 2] = 6.0f; // row 1, col 2: index = 1*5 + 2*2 = 9\n\n    // Input2: 2 rows, 3 cols, padding=1, step=3\n    // Row stride = cols + padd2 = 3 + 1 = 4\n    float input2[16] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 3, 6\n    input2[0 * 4 + 0 * 3] = 0.5f; // row 0, col 0: index = 0*4 + 0*3 = 0\n    input2[0 * 4 + 1 * 3] = 1.5f; // row 0, col 1: index = 0*4 + 1*3 = 3\n    input2[0 * 4 + 2 * 3] = 2.5f; // row 0, col 2: index = 0*4 + 2*3 = 6\n    // Row 1: elements at indices 4, 7, 10\n    input2[1 * 4 + 0 * 3] = 3.5f; // row 1, col 0: index = 1*4 + 0*3 = 4\n    input2[1 * 4 + 1 * 3] = 4.5f; // row 1, col 1: index = 1*4 + 1*3 = 7\n    input2[1 * 4 + 2 * 3] = 5.5f; // row 1, col 2: index = 1*4 + 2*3 = 10\n\n    // Output: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_out = 3 + 2 = 5\n    float output[20] = {0}; // Allocate enough space, initialize to zero\n\n    printf(\"Input1 Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd1, step1);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", input1[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Input2 Memory Layout (16 elements, pad=%d, step=%d):\\n\\r\", padd2, step2);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%4.1f \", input2[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\\n\\r\");\n    printf(\"          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output\n    float expected_output[20] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        for (int col = 0; col &lt; cols; col++) {\n            int idx1 = row * (cols + padd1) + col * step1;\n            int idx2 = row * (cols + padd2) + col * step2;\n            int idx_out = row * (cols + padd_out) + col * step_out;\n            expected_output[idx_out] = input1[idx1] - input2[idx2];\n        }\n    }\n\n    printf(\"Expected Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", expected_output[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    tiny_error_t err = tiny_mat_sub_f32(input1, input2, output, rows, cols,\n                                        padd1, padd2, padd_out,\n                                        step1, step2, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 15; i++) {\n            printf(\"%4.1f \", output[i]);\n        }\n        printf(\"...\\n\\r\");\n        printf(\"  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n        printf(\"          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n        printf(\"          (X = padding/unused)\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            for (int col = 0; col &lt; cols; col++) {\n                int idx1 = row * (cols + padd1) + col * step1;\n                int idx2 = row * (cols + padd2) + col * step2;\n                int idx_out = row * (cols + padd_out) + col * step_out;\n                float expected = input1[idx1] - input2[idx2];\n                float tolerance = 1e-6f;\n                float diff = (output[idx_out] &gt; expected) ? (output[idx_out] - expected) : (expected - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    all_correct = 0;\n                    break;\n                }\n            }\n            if (!all_correct) break;\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_subc_f32 with pad=0 and step=1 (contiguous memory layout)\n */\nvoid test_tiny_mat_subc_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 7: tiny_mat_subc_f32 - Contiguous Memory Layout (pad=0, step=1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=4, pad=0, step=1, C=2.5\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 4;\n    const float C = 2.5f;\n\n    // Input matrix (contiguous, no padding)\n    float input[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                       5.0f, 6.0f, 7.0f, 8.0f,\n                       9.0f, 10.0f, 11.0f, 12.0f};\n\n    float output[12];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C = %5.1f\\n\\r\", C);\n    printf(\"\\n\\r\");\n\n    printf(\"Expected Output Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input[i] - C);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Test with pad=0, step=1 (should use ESP-DSP on ESP32)\n    tiny_error_t err = tiny_mat_subc_f32(input, output, C, rows, cols,\n                                         0, 0,  // padd_in=0, padd_out=0\n                                         1, 1); // step_in=1, step_out=1\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (12 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 12; i++) {\n            printf(\"%5.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\\n\\r\");\n        printf(\"          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\\n\\r\");\n        printf(\"          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; rows * cols; i++) {\n            float expected = input[i] - C;\n            float tolerance = 1e-6f;\n            float diff = (output[i] &gt; expected) ? (output[i] - expected) : (expected - output[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_subc_f32 with pad!=0 and step&gt;1 (non-contiguous memory layout)\n */\nvoid test_tiny_mat_subc_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 8: tiny_mat_subc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd_in = 2;\n    const int padd_out = 2;\n    const int step_in = 2;\n    const int step_out = 2;\n    const float C = 1.5f;\n\n    printf(\"Parameters: rows=%d, cols=%d, pad_in=%d, pad_out=%d, step_in=%d, step_out=%d, C=%5.1f\\n\\r\",\n           rows, cols, padd_in, padd_out, step_in, step_out, C);\n    printf(\"Index formula: index = row * (cols + padding) + col * step\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Input: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_in = 3 + 2 = 5\n    float input[20] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 2, 4\n    input[0 * 5 + 0 * 2] = 1.0f; // row 0, col 0: index = 0*5 + 0*2 = 0\n    input[0 * 5 + 1 * 2] = 2.0f; // row 0, col 1: index = 0*5 + 1*2 = 2\n    input[0 * 5 + 2 * 2] = 3.0f; // row 0, col 2: index = 0*5 + 2*2 = 4\n    // Row 1: elements at indices 5, 7, 9\n    input[1 * 5 + 0 * 2] = 4.0f; // row 1, col 0: index = 1*5 + 0*2 = 5\n    input[1 * 5 + 1 * 2] = 5.0f; // row 1, col 1: index = 1*5 + 1*2 = 7\n    input[1 * 5 + 2 * 2] = 6.0f; // row 1, col 2: index = 1*5 + 2*2 = 9\n\n    // Output: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_out = 3 + 2 = 5\n    float output[20] = {0}; // Allocate enough space, initialize to zero\n\n    printf(\"Input Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_in, step_in);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", input[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C = %5.1f\\n\\r\", C);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output\n    float expected_output[20] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = row * (cols + padd_in) + col * step_in;\n            int idx_out = row * (cols + padd_out) + col * step_out;\n            expected_output[idx_out] = input[idx_in] - C;\n        }\n    }\n\n    printf(\"Expected Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", expected_output[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    tiny_error_t err = tiny_mat_subc_f32(input, output, C, rows, cols,\n                                         padd_in, padd_out,\n                                         step_in, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 15; i++) {\n            printf(\"%4.1f \", output[i]);\n        }\n        printf(\"...\\n\\r\");\n        printf(\"  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n        printf(\"          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n        printf(\"          (X = padding/unused)\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_in = row * (cols + padd_in) + col * step_in;\n                int idx_out = row * (cols + padd_out) + col * step_out;\n                float expected = input[idx_in] - C;\n                float tolerance = 1e-6f;\n                float diff = (output[idx_out] &gt; expected) ? (output[idx_out] - expected) : (expected - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    all_correct = 0;\n                    break;\n                }\n            }\n            if (!all_correct) break;\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_mult_f32 with basic matrix multiplication\n */\nvoid test_tiny_mat_mult_f32_basic(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 9: tiny_mat_mult_f32 - Basic Matrix Multiplication\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: m=3, n=4, k=2 (A is 3x4, B is 4x2, C is 3x2)\\n\\r\");\n    printf(\"Note: This function always uses ESP-DSP on ESP32, standard implementation otherwise\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int m = 3; // rows of A\n    const int n = 4; // cols of A and rows of B\n    const int k = 2; // cols of B\n\n    // Matrix A: 3x4\n    // Memory layout: [row0_col0, row0_col1, row0_col2, row0_col3, row1_col0, ...]\n    float A[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                    5.0f, 6.0f, 7.0f, 8.0f,\n                    9.0f, 10.0f, 11.0f, 12.0f};\n\n    // Matrix B: 4x2\n    float B[8] = {0.5f, 1.5f,\n                  2.5f, 3.5f,\n                  4.5f, 5.5f,\n                  6.5f, 7.5f};\n\n    // Matrix C: 3x2 (output)\n    float C[6];\n    memset(C, 0, sizeof(C));\n\n    printf(\"Matrix A Memory Layout (3x4, 12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", A[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Matrix B Memory Layout (4x2, 8 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 8; i++) {\n        printf(\"%5.1f \", B[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [2.5  3.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [4.5  5.5]  &lt;- Row 2\\n\\r\");\n    printf(\"          [6.5  7.5]  &lt;- Row 3\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: C = A * B\n    // C[i][j] = sum_{s=0}^{n-1} A[i][s] * B[s][j]\n    float expected_C[6] = {0};\n    for (int i = 0; i &lt; m; i++) {\n        for (int j = 0; j &lt; k; j++) {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; n; s++) {\n                sum += A[i * n + s] * B[s * k + j];\n            }\n            expected_C[i * k + j] = sum;\n        }\n    }\n\n    printf(\"Expected Output Matrix C Memory Layout (3x2, 6 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 6; i++) {\n        printf(\"%6.1f \", expected_C[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f]  &lt;- Row 0\\n\\r\", expected_C[0], expected_C[1]);\n    printf(\"          [%5.1f  %5.1f]  &lt;- Row 1\\n\\r\", expected_C[2], expected_C[3]);\n    printf(\"          [%5.1f  %5.1f] &lt;- Row 2\\n\\r\", expected_C[4], expected_C[5]);\n    printf(\"  Calculation:\\n\\r\");\n    printf(\"    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\\n\\r\");\n    printf(\"            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 = %5.1f\\n\\r\", expected_C[0]);\n    printf(\"    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1] + A[0][3]*B[3][1]\\n\\r\");\n    printf(\"            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 + 4.0*7.5 = %5.1f\\n\\r\", expected_C[1]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiplication\n    tiny_error_t err = tiny_mat_mult_f32(A, B, C, m, n, k);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix C Memory Layout (3x2, 6 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 6; i++) {\n            printf(\"%6.1f \", C[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f]  &lt;- Row 0\\n\\r\", C[0], C[1]);\n        printf(\"          [%5.1f  %5.1f]  &lt;- Row 1\\n\\r\", C[2], C[3]);\n        printf(\"          [%5.1f  %5.1f] &lt;- Row 2\\n\\r\", C[4], C[5]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; m * k; i++) {\n            float tolerance = 1e-5f;\n            float diff = (C[i] &gt; expected_C[i]) ? (C[i] - expected_C[i]) : (expected_C[i] - C[i]);\n            if (diff &gt; tolerance) {\n                int row = i / k;\n                int col = i % k;\n                printf(\"  ERROR at [%d][%d]: output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                       row, col, C[i], expected_C[i], diff);\n                all_correct = 0;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_mult_f32 with square matrices\n */\nvoid test_tiny_mat_mult_f32_square(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 10: tiny_mat_mult_f32 - Square Matrix Multiplication\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: m=3, n=3, k=3 (A is 3x3, B is 3x3, C is 3x3)\\n\\r\");\n    printf(\"Note: This function always uses ESP-DSP on ESP32, standard implementation otherwise\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int m = 3; // rows of A\n    const int n = 3; // cols of A and rows of B\n    const int k = 3; // cols of B\n\n    // Matrix A: 3x3\n    float A[9] = {1.0f, 2.0f, 3.0f,\n                  4.0f, 5.0f, 6.0f,\n                  7.0f, 8.0f, 9.0f};\n\n    // Matrix B: 3x3\n    float B[9] = {0.5f, 1.0f, 1.5f,\n                  2.0f, 2.5f, 3.0f,\n                  3.5f, 4.0f, 4.5f};\n\n    // Matrix C: 3x3 (output)\n    float C[9];\n    memset(C, 0, sizeof(C));\n\n    printf(\"Matrix A Memory Layout (3x3, 9 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%5.1f \", A[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [4.0  5.0  6.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [7.0  8.0  9.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Matrix B Memory Layout (3x3, 9 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%5.1f \", B[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.0  1.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [2.0  2.5  3.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [3.5  4.0  4.5]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: C = A * B\n    float expected_C[9] = {0};\n    for (int i = 0; i &lt; m; i++) {\n        for (int j = 0; j &lt; k; j++) {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; n; s++) {\n                sum += A[i * n + s] * B[s * k + j];\n            }\n            expected_C[i * k + j] = sum;\n        }\n    }\n\n    printf(\"Expected Output Matrix C Memory Layout (3x3, 9 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%6.1f \", expected_C[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f  %5.1f]  &lt;- Row 0\\n\\r\", expected_C[0], expected_C[1], expected_C[2]);\n    printf(\"          [%5.1f  %5.1f  %5.1f]  &lt;- Row 1\\n\\r\", expected_C[3], expected_C[4], expected_C[5]);\n    printf(\"          [%5.1f  %5.1f  %5.1f] &lt;- Row 2\\n\\r\", expected_C[6], expected_C[7], expected_C[8]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiplication\n    tiny_error_t err = tiny_mat_mult_f32(A, B, C, m, n, k);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix C Memory Layout (3x3, 9 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 9; i++) {\n            printf(\"%6.1f \", C[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f  %5.1f]  &lt;- Row 0\\n\\r\", C[0], C[1], C[2]);\n        printf(\"          [%5.1f  %5.1f  %5.1f]  &lt;- Row 1\\n\\r\", C[3], C[4], C[5]);\n        printf(\"          [%5.1f  %5.1f  %5.1f] &lt;- Row 2\\n\\r\", C[6], C[7], C[8]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; m * k; i++) {\n            float tolerance = 1e-5f;\n            float diff = (C[i] &gt; expected_C[i]) ? (C[i] - expected_C[i]) : (expected_C[i] - C[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_mult_ex_f32 with contiguous matrices (pad=0)\n */\nvoid test_tiny_mat_mult_ex_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 11: tiny_mat_mult_ex_f32 - Contiguous Matrix Multiplication\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: A_rows=3, A_cols=4, B_cols=2, A_padding=0, B_padding=0, C_padding=0\\n\\r\");\n    printf(\"Matrix dimensions: A is 3x4, B is 4x2, C is 3x2\\n\\r\");\n    printf(\"Note: This should use ESP-DSP on ESP32 when all paddings are 0\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int A_rows = 3;\n    const int A_cols = 4;\n    const int B_cols = 2;\n    const int A_padding = 0;\n    const int B_padding = 0;\n    const int C_padding = 0;\n\n    const int A_step = A_cols + A_padding; // 4\n    const int B_step = B_cols + B_padding; // 2\n    const int C_step = B_cols + C_padding; // 2\n\n    // Matrix A: 3x4 (contiguous, no padding)\n    float A[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                   5.0f, 6.0f, 7.0f, 8.0f,\n                   9.0f, 10.0f, 11.0f, 12.0f};\n\n    // Matrix B: 4x2 (contiguous, no padding)\n    float B[8] = {0.5f, 1.5f,\n                  2.5f, 3.5f,\n                  4.5f, 5.5f,\n                  6.5f, 7.5f};\n\n    // Matrix C: 3x2 (output, contiguous, no padding)\n    float C[6];\n    memset(C, 0, sizeof(C));\n\n    printf(\"Matrix A Memory Layout (3x4, 12 elements, contiguous, pad=%d):\\n\\r\", A_padding);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", A[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0 (indices: 0-3)\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1 (indices: 4-7)\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2 (indices: 8-11)\\n\\r\");\n    printf(\"  Step size: %d (A_cols + A_padding = %d + %d)\\n\\r\", A_step, A_cols, A_padding);\n    printf(\"\\n\\r\");\n\n    printf(\"Matrix B Memory Layout (4x2, 8 elements, contiguous, pad=%d):\\n\\r\", B_padding);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 8; i++) {\n        printf(\"%5.1f \", B[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5]  &lt;- Row 0 (indices: 0-1)\\n\\r\");\n    printf(\"          [2.5  3.5]  &lt;- Row 1 (indices: 2-3)\\n\\r\");\n    printf(\"          [4.5  5.5]  &lt;- Row 2 (indices: 4-5)\\n\\r\");\n    printf(\"          [6.5  7.5]  &lt;- Row 3 (indices: 6-7)\\n\\r\");\n    printf(\"  Step size: %d (B_cols + B_padding = %d + %d)\\n\\r\", B_step, B_cols, B_padding);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: C = A * B\n    // C[i][j] = sum_{s=0}^{A_cols-1} A[i][s] * B[s][j]\n    // Index calculation: A[i * A_step + s], B[s * B_step + j], C[i * C_step + j]\n    float expected_C[6] = {0};\n    for (int i = 0; i &lt; A_rows; i++) {\n        for (int j = 0; j &lt; B_cols; j++) {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; A_cols; s++) {\n                int idx_A = i * A_step + s;\n                int idx_B = s * B_step + j;\n                sum += A[idx_A] * B[idx_B];\n            }\n            expected_C[i * C_step + j] = sum;\n        }\n    }\n\n    printf(\"Expected Output Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=%d):\\n\\r\", C_padding);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 6; i++) {\n        printf(\"%6.1f \", expected_C[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f]  &lt;- Row 0 (indices: 0-1)\\n\\r\", expected_C[0], expected_C[1]);\n    printf(\"          [%5.1f  %5.1f]  &lt;- Row 1 (indices: 2-3)\\n\\r\", expected_C[2], expected_C[3]);\n    printf(\"          [%5.1f  %5.1f] &lt;- Row 2 (indices: 4-5)\\n\\r\", expected_C[4], expected_C[5]);\n    printf(\"  Step size: %d (B_cols + C_padding = %d + %d)\\n\\r\", C_step, B_cols, C_padding);\n    printf(\"  Calculation example:\\n\\r\");\n    printf(\"    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\\n\\r\");\n    printf(\"            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 = %5.1f\\n\\r\", expected_C[0]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiplication\n    tiny_error_t err = tiny_mat_mult_ex_f32(A, B, C, A_rows, A_cols, B_cols, A_padding, B_padding, C_padding);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=%d):\\n\\r\", C_padding);\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 6; i++) {\n            printf(\"%6.1f \", C[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f]  &lt;- Row 0 (indices: 0-1)\\n\\r\", C[0], C[1]);\n        printf(\"          [%5.1f  %5.1f]  &lt;- Row 1 (indices: 2-3)\\n\\r\", C[2], C[3]);\n        printf(\"          [%5.1f  %5.1f] &lt;- Row 2 (indices: 4-5)\\n\\r\", C[4], C[5]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; A_rows; i++) {\n            for (int j = 0; j &lt; B_cols; j++) {\n                int idx = i * C_step + j;\n                float tolerance = 1e-5f;\n                float diff = (C[idx] &gt; expected_C[idx]) ? (C[idx] - expected_C[idx]) : (expected_C[idx] - C[idx]);\n                if (diff &gt; tolerance) {\n                    printf(\"  ERROR at [%d][%d] (index %d): output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                           i, j, idx, C[idx], expected_C[idx], diff);\n                    all_correct = 0;\n                }\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_mult_ex_f32 with padded matrices (pad!=0)\n */\nvoid test_tiny_mat_mult_ex_f32_padded(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 12: tiny_mat_mult_ex_f32 - Padded Matrix Multiplication\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: A_rows=2, A_cols=3, B_cols=2, A_padding=2, B_padding=1, C_padding=1\\n\\r\");\n    printf(\"Matrix dimensions: A is 2x3, B is 3x2, C is 2x2\\n\\r\");\n    printf(\"Note: This should use own implementation when padding is non-zero\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int A_rows = 2;\n    const int A_cols = 3;\n    const int B_cols = 2;\n    const int A_padding = 2;\n    const int B_padding = 1;\n    const int C_padding = 1;\n\n    const int A_step = A_cols + A_padding; // 3 + 2 = 5\n    const int B_step = B_cols + B_padding; // 2 + 1 = 3\n    const int C_step = B_cols + C_padding; // 2 + 1 = 3\n\n    // Matrix A: 2x3 with padding=2, so each row has 5 elements (3 data + 2 padding)\n    // Total memory: 2 rows * 5 elements = 10 elements\n    float A[10] = {1.0f, 2.0f, 3.0f, 0.0f, 0.0f,  // Row 0: [1.0, 2.0, 3.0, X, X]\n                   4.0f, 5.0f, 6.0f, 0.0f, 0.0f}; // Row 1: [4.0, 5.0, 6.0, X, X]\n\n    // Matrix B: 3x2 with padding=1, so each row has 3 elements (2 data + 1 padding)\n    // Total memory: 3 rows * 3 elements = 9 elements\n    float B[9] = {0.5f, 1.5f, 0.0f,  // Row 0: [0.5, 1.5, X]\n                  2.5f, 3.5f, 0.0f,  // Row 1: [2.5, 3.5, X]\n                  4.5f, 5.5f, 0.0f}; // Row 2: [4.5, 5.5, X]\n\n    // Matrix C: 2x2 with padding=1, so each row has 3 elements (2 data + 1 padding)\n    // Total memory: 2 rows * 3 elements = 6 elements\n    float C[6];\n    memset(C, 0, sizeof(C));\n\n    printf(\"Matrix A Memory Layout (2x3, pad=%d, step=%d, 10 elements):\\n\\r\", A_padding, A_step);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 10; i++) {\n        printf(\"%4.1f \", A[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  X   X]  &lt;- Row 0 (indices: 0, 1, 2, 3, 4)\\n\\r\");\n    printf(\"          [4.0  5.0  6.0  X   X]  &lt;- Row 1 (indices: 5, 6, 7, 8, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"  Index calculation: A[i][j] = A[i * %d + j]\\n\\r\", A_step);\n    printf(\"    Row 0: indices 0, 1, 2 (data), 3, 4 (padding)\\n\\r\");\n    printf(\"    Row 1: indices 5, 6, 7 (data), 8, 9 (padding)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Matrix B Memory Layout (3x2, pad=%d, step=%d, 9 elements):\\n\\r\", B_padding, B_step);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%4.1f \", B[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5  X]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\");\n    printf(\"          [2.5  3.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\");\n    printf(\"          [4.5  5.5  X]  &lt;- Row 2 (indices: 6, 7, 8)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"  Index calculation: B[i][j] = B[i * %d + j]\\n\\r\", B_step);\n    printf(\"    Row 0: indices 0, 1 (data), 2 (padding)\\n\\r\");\n    printf(\"    Row 1: indices 3, 4 (data), 5 (padding)\\n\\r\");\n    printf(\"    Row 2: indices 6, 7 (data), 8 (padding)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: C = A * B\n    // C[i][j] = sum_{s=0}^{A_cols-1} A[i][s] * B[s][j]\n    // Index calculation: A[i * A_step + s], B[s * B_step + j], C[i * C_step + j]\n    float expected_C[6] = {0};\n    for (int i = 0; i &lt; A_rows; i++) {\n        for (int j = 0; j &lt; B_cols; j++) {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; A_cols; s++) {\n                int idx_A = i * A_step + s;\n                int idx_B = s * B_step + j;\n                sum += A[idx_A] * B[idx_B];\n            }\n            expected_C[i * C_step + j] = sum;\n        }\n    }\n\n    printf(\"Expected Output Matrix C Memory Layout (2x2, pad=%d, step=%d, 6 elements):\\n\\r\", C_padding, C_step);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 6; i++) {\n        printf(\"%6.1f \", expected_C[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f  X]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\", expected_C[0], expected_C[1]);\n    printf(\"          [%5.1f  %5.1f  X]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\", expected_C[3], expected_C[4]);\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"  Index calculation: C[i][j] = C[i * %d + j]\\n\\r\", C_step);\n    printf(\"  Calculation:\\n\\r\");\n    printf(\"    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0]\\n\\r\");\n    printf(\"            = A[%d]*B[%d] + A[%d]*B[%d] + A[%d]*B[%d]\\n\\r\", \n           0*A_step+0, 0*B_step+0, 0*A_step+1, 1*B_step+0, 0*A_step+2, 2*B_step+0);\n    printf(\"            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 = %5.1f\\n\\r\", expected_C[0]);\n    printf(\"    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1]\\n\\r\");\n    printf(\"            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 = %5.1f\\n\\r\", expected_C[1]);\n    printf(\"    C[1][0] = A[1][0]*B[0][0] + A[1][1]*B[1][0] + A[1][2]*B[2][0]\\n\\r\");\n    printf(\"            = 4.0*0.5 + 5.0*2.5 + 6.0*4.5 = %5.1f\\n\\r\", expected_C[3]);\n    printf(\"    C[1][1] = A[1][0]*B[0][1] + A[1][1]*B[1][1] + A[1][2]*B[2][1]\\n\\r\");\n    printf(\"            = 4.0*1.5 + 5.0*3.5 + 6.0*5.5 = %5.1f\\n\\r\", expected_C[4]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiplication\n    tiny_error_t err = tiny_mat_mult_ex_f32(A, B, C, A_rows, A_cols, B_cols, A_padding, B_padding, C_padding);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix C Memory Layout (2x2, pad=%d, step=%d, 6 elements):\\n\\r\", C_padding, C_step);\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 6; i++) {\n            printf(\"%6.1f \", C[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f  X]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\", C[0], C[1]);\n        printf(\"          [%5.1f  %5.1f  X]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\", C[3], C[4]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; A_rows; i++) {\n            for (int j = 0; j &lt; B_cols; j++) {\n                int idx = i * C_step + j;\n                float tolerance = 1e-5f;\n                float diff = (C[idx] &gt; expected_C[idx]) ? (C[idx] - expected_C[idx]) : (expected_C[idx] - C[idx]);\n                if (diff &gt; tolerance) {\n                    printf(\"  ERROR at [%d][%d] (index %d): output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                           i, j, idx, C[idx], expected_C[idx], diff);\n                    all_correct = 0;\n                }\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_multc_f32 with contiguous matrix (pad=0, step=1)\n */\nvoid test_tiny_mat_multc_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 13: tiny_mat_multc_f32 - Contiguous Matrix Multiply Constant\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=3, padd_in=0, padd_out=0, step_in=1, step_out=1\\n\\r\");\n    printf(\"Matrix dimensions: 3x3\\n\\r\");\n    printf(\"Constant C: 2.5\\n\\r\");\n    printf(\"Note: This should use ESP-DSP on ESP32 when all paddings are 0 and all steps are 1\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 3;\n    const int padd_in = 0;\n    const int padd_out = 0;\n    const int step_in = 1;\n    const int step_out = 1;\n    const float C = 2.5f;\n\n    const int in_row_stride = cols + padd_in;  // 3\n    const int out_row_stride = cols + padd_out; // 3\n\n    // Input matrix: 3x3 (contiguous, no padding)\n    float input[9] = {1.0f, 2.0f, 3.0f,\n                       4.0f, 5.0f, 6.0f,\n                       7.0f, 8.0f, 9.0f};\n\n    // Output matrix: 3x3 (contiguous, no padding)\n    float output[9];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input Matrix Memory Layout (3x3, 9 elements, contiguous, pad=%d, step=%d):\\n\\r\", padd_in, step_in);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%5.1f \", input[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\");\n    printf(\"          [4.0  5.0  6.0]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\");\n    printf(\"          [7.0  8.0  9.0]  &lt;- Row 2 (indices: 6, 7, 8)\\n\\r\");\n    printf(\"  Row stride: %d (cols + padd_in = %d + %d)\\n\\r\", in_row_stride, cols, padd_in);\n    printf(\"  Index calculation: input[i][j] = input[i * %d + j * %d]\\n\\r\", in_row_stride, step_in);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: output[i][j] = input[i][j] * C\n    float expected_output[9] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n            expected_output[idx_out] = input[idx_in] * C;\n        }\n    }\n\n    printf(\"Expected Output Matrix Memory Layout (3x3, 9 elements, contiguous, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%6.1f \", expected_output[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f  %5.1f]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\", \n           expected_output[0], expected_output[1], expected_output[2]);\n    printf(\"          [%5.1f  %5.1f  %5.1f]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\", \n           expected_output[3], expected_output[4], expected_output[5]);\n    printf(\"          [%5.1f  %5.1f  %5.1f] &lt;- Row 2 (indices: 6, 7, 8)\\n\\r\", \n           expected_output[6], expected_output[7], expected_output[8]);\n    printf(\"  Row stride: %d (cols + padd_out = %d + %d)\\n\\r\", out_row_stride, cols, padd_out);\n    printf(\"  Index calculation: output[i][j] = output[i * %d + j * %d]\\n\\r\", out_row_stride, step_out);\n    printf(\"  Calculation: output[i][j] = input[i][j] * %.1f\\n\\r\", C);\n    printf(\"    Example: output[0][0] = input[0][0] * %.1f = 1.0 * %.1f = %.1f\\n\\r\", C, C, expected_output[0]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiply constant\n    tiny_error_t err = tiny_mat_multc_f32(input, output, C, rows, cols, padd_in, padd_out, step_in, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix Memory Layout (3x3, 9 elements, contiguous, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 9; i++) {\n            printf(\"%6.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f  %5.1f]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\", \n               output[0], output[1], output[2]);\n        printf(\"          [%5.1f  %5.1f  %5.1f]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\", \n               output[3], output[4], output[5]);\n        printf(\"          [%5.1f  %5.1f  %5.1f] &lt;- Row 2 (indices: 6, 7, 8)\\n\\r\", \n               output[6], output[7], output[8]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            int base_out = row * out_row_stride;\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_out = base_out + col * step_out;\n                float tolerance = 1e-5f;\n                float diff = (output[idx_out] &gt; expected_output[idx_out]) ? \n                            (output[idx_out] - expected_output[idx_out]) : \n                            (expected_output[idx_out] - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    printf(\"  ERROR at [%d][%d] (index %d): output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                           row, col, idx_out, output[idx_out], expected_output[idx_out], diff);\n                    all_correct = 0;\n                }\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_multc_f32 with padded and strided matrix (pad!=0, step&gt;1)\n */\nvoid test_tiny_mat_multc_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 14: tiny_mat_multc_f32 - Padded and Strided Matrix Multiply Constant\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=2, cols=3, padd_in=2, padd_out=1, step_in=2, step_out=1\\n\\r\");\n    printf(\"Matrix dimensions: 2x3\\n\\r\");\n    printf(\"Constant C: 3.0\\n\\r\");\n    printf(\"Note: This should use own implementation when padding is non-zero or step &gt; 1\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd_in = 2;\n    const int padd_out = 1;\n    const int step_in = 2;\n    const int step_out = 1;\n    const float C = 3.0f;\n\n    const int in_row_stride = cols + padd_in;  // 3 + 2 = 5\n    const int out_row_stride = cols + padd_out; // 3 + 1 = 4\n\n    // Input matrix: 2x3 with padding=2, step=2\n    // Each row has 5 elements in memory, but we only use every 2nd element (step=2)\n    // Total memory: 2 rows * 5 elements = 10 elements\n    // Row 0: indices 0, 2, 4 (data), 1, 3 (unused)\n    // Row 1: indices 5, 7, 9 (data), 6, 8 (unused)\n    float input[10] = {1.0f, 0.0f, 2.0f, 0.0f, 3.0f,  // Row 0: [1.0, X, 2.0, X, 3.0]\n                       4.0f, 0.0f, 5.0f, 0.0f, 6.0f}; // Row 1: [4.0, X, 5.0, X, 6.0]\n\n    // Output matrix: 2x3 with padding=1, step=1\n    // Each row has 4 elements (3 data + 1 padding)\n    // Total memory: 2 rows * 4 elements = 8 elements\n    float output[8];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input Matrix Memory Layout (2x3, pad=%d, step=%d, 10 elements):\\n\\r\", padd_in, step_in);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 10; i++) {\n        printf(\"%4.1f \", input[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (data indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (data indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = unused/padding)\\n\\r\");\n    printf(\"  Row stride: %d (cols + padd_in = %d + %d)\\n\\r\", in_row_stride, cols, padd_in);\n    printf(\"  Index calculation: input[i][j] = input[i * %d + j * %d]\\n\\r\", in_row_stride, step_in);\n    printf(\"    Row 0: input[0][0]=input[%d]=%.1f, input[0][1]=input[%d]=%.1f, input[0][2]=input[%d]=%.1f\\n\\r\",\n           0*in_row_stride+0*step_in, input[0*in_row_stride+0*step_in],\n           0*in_row_stride+1*step_in, input[0*in_row_stride+1*step_in],\n           0*in_row_stride+2*step_in, input[0*in_row_stride+2*step_in]);\n    printf(\"    Row 1: input[1][0]=input[%d]=%.1f, input[1][1]=input[%d]=%.1f, input[1][2]=input[%d]=%.1f\\n\\r\",\n           1*in_row_stride+0*step_in, input[1*in_row_stride+0*step_in],\n           1*in_row_stride+1*step_in, input[1*in_row_stride+1*step_in],\n           1*in_row_stride+2*step_in, input[1*in_row_stride+2*step_in]);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: output[i][j] = input[i][j] * C\n    float expected_output[8] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n            expected_output[idx_out] = input[idx_in] * C;\n        }\n    }\n\n    printf(\"Expected Output Matrix Memory Layout (2x3, pad=%d, step=%d, 8 elements):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 8; i++) {\n        printf(\"%6.1f \", expected_output[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f  %5.1f  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\\n\\r\", \n           expected_output[0], expected_output[1], expected_output[2]);\n    printf(\"          [%5.1f  %5.1f  %5.1f  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\\n\\r\", \n           expected_output[4], expected_output[5], expected_output[6]);\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"  Row stride: %d (cols + padd_out = %d + %d)\\n\\r\", out_row_stride, cols, padd_out);\n    printf(\"  Index calculation: output[i][j] = output[i * %d + j * %d]\\n\\r\", out_row_stride, step_out);\n    printf(\"  Calculation: output[i][j] = input[i][j] * %.1f\\n\\r\", C);\n    printf(\"    Row 0: output[0][0] = input[0][0] * %.1f = %.1f * %.1f = %.1f (index %d)\\n\\r\",\n           C, input[0*in_row_stride+0*step_in], C, expected_output[0*out_row_stride+0*step_out], 0*out_row_stride+0*step_out);\n    printf(\"           output[0][1] = input[0][1] * %.1f = %.1f * %.1f = %.1f (index %d)\\n\\r\",\n           C, input[0*in_row_stride+1*step_in], C, expected_output[0*out_row_stride+1*step_out], 0*out_row_stride+1*step_out);\n    printf(\"           output[0][2] = input[0][2] * %.1f = %.1f * %.1f = %.1f (index %d)\\n\\r\",\n           C, input[0*in_row_stride+2*step_in], C, expected_output[0*out_row_stride+2*step_out], 0*out_row_stride+2*step_out);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiply constant\n    tiny_error_t err = tiny_mat_multc_f32(input, output, C, rows, cols, padd_in, padd_out, step_in, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix Memory Layout (2x3, pad=%d, step=%d, 8 elements):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 8; i++) {\n            printf(\"%6.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f  %5.1f  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\\n\\r\", \n               output[0], output[1], output[2]);\n        printf(\"          [%5.1f  %5.1f  %5.1f  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\\n\\r\", \n               output[4], output[5], output[6]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            int base_out = row * out_row_stride;\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_out = base_out + col * step_out;\n                float tolerance = 1e-5f;\n                float diff = (output[idx_out] &gt; expected_output[idx_out]) ? \n                            (output[idx_out] - expected_output[idx_out]) : \n                            (expected_output[idx_out] - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    printf(\"  ERROR at [%d][%d] (index %d): output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                           row, col, idx_out, output[idx_out], expected_output[idx_out], diff);\n                    all_correct = 0;\n                }\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\nvoid tiny_mat_test(void)\n{\n    printf(\"============ [tiny_mat_test] ============\\n\\r\");\n\n    // Test 1: Contiguous matrices (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_add_f32_contiguous();\n\n    // Test 2: Padded and strided matrices (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_add_f32_padded_strided();\n\n    // Test 3: Contiguous matrix add constant (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_addc_f32_contiguous();\n\n    // Test 4: Padded and strided matrix add constant (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_addc_f32_padded_strided();\n\n    // Test 5: Contiguous matrices subtraction (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_sub_f32_contiguous();\n\n    // Test 6: Padded and strided matrices subtraction (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_sub_f32_padded_strided();\n\n    // Test 7: Contiguous matrix subtract constant (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_subc_f32_contiguous();\n\n    // Test 8: Padded and strided matrix subtract constant (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_subc_f32_padded_strided();\n\n    // Test 9: Basic matrix multiplication (3x4 * 4x2 = 3x2)\n    test_tiny_mat_mult_f32_basic();\n\n    // Test 10: Square matrix multiplication (3x3 * 3x3 = 3x3)\n    test_tiny_mat_mult_f32_square();\n\n    // Test 11: Contiguous matrix multiplication with padding (pad=0) - should use ESP-DSP on ESP32\n    test_tiny_mat_mult_ex_f32_contiguous();\n\n    // Test 12: Padded matrix multiplication (pad!=0) - should use own implementation\n    test_tiny_mat_mult_ex_f32_padded();\n\n    // Test 13: Contiguous matrix multiply constant (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_multc_f32_contiguous();\n\n    // Test 14: Padded and strided matrix multiply constant (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_multc_f32_padded_strided();\n\n    printf(\"============ [test complete] ============\\n\\r\");\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-test/#maincpp","title":"main.cpp","text":"<pre><code>#include \"tiny_mat_test.hpp\"\n\nextern \"C\" void app_main(void)\n{\n    tiny_mat_test();\n}\n\n\n## TEST RESULTS\n\n```bash\n============ [tiny_mat_test] ============\n\n================================================================================\nTest Case 1: tiny_mat_add_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1\n\nInput1 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nInput2 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5 \n  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\n          [4.5  5.5  6.5  7.5]  &lt;- Row 1\n          [8.5  9.5 10.5 11.5]  &lt;- Row 2\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.5   3.5   5.5   7.5   9.5  11.5  13.5  15.5  17.5  19.5  21.5  23.5 \n  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\n          [9.5 11.5 13.5 15.5]  &lt;- Row 1\n          [17.5 19.5 21.5 23.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.5   3.5   5.5   7.5   9.5  11.5  13.5  15.5  17.5  19.5  21.5  23.5 \n  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\n          [9.5 11.5 13.5 15.5]  &lt;- Row 1\n          [17.5 19.5 21.5 23.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 2: tiny_mat_add_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad1=2, pad2=1, pad_out=2, step1=2, step2=3, step_out=2\nIndex formula: index = row * (cols + padding) + col * step\n\nInput1 Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nInput2 Memory Layout (16 elements, pad=1, step=3):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\n  Value:   0.5  0.0  0.0  1.5  3.5  0.0  2.5  4.5  0.0  0.0  5.5  0.0 ...\n  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\n          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\n          (X = padding/unused)\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.5  0.0  3.5  0.0  5.5  7.5  0.0  9.5  0.0 11.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.5  X  3.5  X  5.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [7.5  X  9.5  X 11.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.5  0.0  3.5  0.0  5.5  7.5  0.0  9.5  0.0 11.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.5  X  3.5  X  5.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [7.5  X  9.5  X 11.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 3: tiny_mat_addc_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1, C=2.5\n\nInput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nConstant C =   2.5\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5  12.5  13.5  14.5 \n  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\n          [7.5  8.5  9.5 10.5]  &lt;- Row 1\n          [11.5 12.5 13.5 14.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5  12.5  13.5  14.5 \n  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\n          [7.5  8.5  9.5 10.5]  &lt;- Row 1\n          [11.5 12.5 13.5 14.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 4: tiny_mat_addc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad_in=2, pad_out=2, step_in=2, step_out=2, C=  1.5\nIndex formula: index = row * (cols + padding) + col * step\n\nInput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nConstant C =   1.5\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   2.5  0.0  3.5  0.0  4.5  5.5  0.0  6.5  0.0  7.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   2.5  0.0  3.5  0.0  4.5  5.5  0.0  6.5  0.0  7.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 5: tiny_mat_sub_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1\n\nInput1 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nInput2 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5 \n  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\n          [4.5  5.5  6.5  7.5]  &lt;- Row 1\n          [8.5  9.5 10.5 11.5]  &lt;- Row 2\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 \n  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\n          [0.5  0.5  0.5  0.5]  &lt;- Row 1\n          [0.5  0.5  0.5  0.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 \n  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\n          [0.5  0.5  0.5  0.5]  &lt;- Row 1\n          [0.5  0.5  0.5  0.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 6: tiny_mat_sub_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad1=2, pad2=1, pad_out=2, step1=2, step2=3, step_out=2\nIndex formula: index = row * (cols + padding) + col * step\n\nInput1 Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nInput2 Memory Layout (16 elements, pad=1, step=3):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\n  Value:   0.5  0.0  0.0  1.5  3.5  0.0  2.5  4.5  0.0  0.0  5.5  0.0 ...\n  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\n          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\n          (X = padding/unused)\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   0.5  0.0  0.5  0.0  0.5  0.5  0.0  0.5  0.0  0.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   0.5  0.0  0.5  0.0  0.5  0.5  0.0  0.5  0.0  0.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 7: tiny_mat_subc_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1, C=2.5\n\nInput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nConstant C =   2.5\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:   -1.5  -0.5   0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5 \n  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\n          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\n          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:   -1.5  -0.5   0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5 \n  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\n          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\n          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 8: tiny_mat_subc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad_in=2, pad_out=2, step_in=2, step_out=2, C=  1.5\nIndex formula: index = row * (cols + padding) + col * step\n\nInput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nConstant C =   1.5\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:  -0.5  0.0  0.5  0.0  1.5  2.5  0.0  3.5  0.0  4.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:  -0.5  0.0  0.5  0.0  1.5  2.5  0.0  3.5  0.0  4.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 9: tiny_mat_mult_f32 - Basic Matrix Multiplication\n================================================================================\nParameters: m=3, n=4, k=2 (A is 3x4, B is 4x2, C is 3x2)\nNote: This function always uses ESP-DSP on ESP32, standard implementation otherwise\n\nMatrix A Memory Layout (3x4, 12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nMatrix B Memory Layout (4x2, 8 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5 \n  Matrix: [0.5  1.5]  &lt;- Row 0\n          [2.5  3.5]  &lt;- Row 1\n          [4.5  5.5]  &lt;- Row 2\n          [6.5  7.5]  &lt;- Row 3\n\nExpected Output Matrix C Memory Layout (3x2, 6 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0\n          [101.0  127.0]  &lt;- Row 1\n          [157.0  199.0] &lt;- Row 2\n  Calculation:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 =  45.0\n    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1] + A[0][3]*B[3][1]\n            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 + 4.0*7.5 =  55.0\n\nOutput Matrix C Memory Layout (3x2, 6 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0\n          [101.0  127.0]  &lt;- Row 1\n          [157.0  199.0] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 10: tiny_mat_mult_f32 - Square Matrix Multiplication\n================================================================================\nParameters: m=3, n=3, k=3 (A is 3x3, B is 3x3, C is 3x3)\nNote: This function always uses ESP-DSP on ESP32, standard implementation otherwise\n\nMatrix A Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0 \n  Matrix: [1.0  2.0  3.0]  &lt;- Row 0\n          [4.0  5.0  6.0]  &lt;- Row 1\n          [7.0  8.0  9.0]  &lt;- Row 2\n\nMatrix B Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    0.5   1.0   1.5   2.0   2.5   3.0   3.5   4.0   4.5 \n  Matrix: [0.5  1.0  1.5]  &lt;- Row 0\n          [2.0  2.5  3.0]  &lt;- Row 1\n          [3.5  4.0  4.5]  &lt;- Row 2\n\nExpected Output Matrix C Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    15.0   18.0   21.0   33.0   40.5   48.0   51.0   63.0   75.0 \n  Matrix: [ 15.0   18.0   21.0]  &lt;- Row 0\n          [ 33.0   40.5   48.0]  &lt;- Row 1\n          [ 51.0   63.0   75.0] &lt;- Row 2\n\nOutput Matrix C Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    15.0   18.0   21.0   33.0   40.5   48.0   51.0   63.0   75.0 \n  Matrix: [ 15.0   18.0   21.0]  &lt;- Row 0\n          [ 33.0   40.5   48.0]  &lt;- Row 1\n          [ 51.0   63.0   75.0] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 11: tiny_mat_mult_ex_f32 - Contiguous Matrix Multiplication\n================================================================================\nParameters: A_rows=3, A_cols=4, B_cols=2, A_padding=0, B_padding=0, C_padding=0\nMatrix dimensions: A is 3x4, B is 4x2, C is 3x2\nNote: This should use ESP-DSP on ESP32 when all paddings are 0\n\nMatrix A Memory Layout (3x4, 12 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0 (indices: 0-3)\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1 (indices: 4-7)\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2 (indices: 8-11)\n  Step size: 4 (A_cols + A_padding = 4 + 0)\n\nMatrix B Memory Layout (4x2, 8 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5 \n  Matrix: [0.5  1.5]  &lt;- Row 0 (indices: 0-1)\n          [2.5  3.5]  &lt;- Row 1 (indices: 2-3)\n          [4.5  5.5]  &lt;- Row 2 (indices: 4-5)\n          [6.5  7.5]  &lt;- Row 3 (indices: 6-7)\n  Step size: 2 (B_cols + B_padding = 2 + 0)\n\nExpected Output Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0 (indices: 0-1)\n          [101.0  127.0]  &lt;- Row 1 (indices: 2-3)\n          [157.0  199.0] &lt;- Row 2 (indices: 4-5)\n  Step size: 2 (B_cols + C_padding = 2 + 0)\n  Calculation example:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 =  45.0\n\nOutput Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0 (indices: 0-1)\n          [101.0  127.0]  &lt;- Row 1 (indices: 2-3)\n          [157.0  199.0] &lt;- Row 2 (indices: 4-5)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 12: tiny_mat_mult_ex_f32 - Padded Matrix Multiplication\n================================================================================\nParameters: A_rows=2, A_cols=3, B_cols=2, A_padding=2, B_padding=1, C_padding=1\nMatrix dimensions: A is 2x3, B is 3x2, C is 2x2\nNote: This should use own implementation when padding is non-zero\n\nMatrix A Memory Layout (2x3, pad=2, step=5, 10 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\n  Value:   1.0  2.0  3.0  0.0  0.0  4.0  5.0  6.0  0.0  0.0 \n  Matrix: [1.0  2.0  3.0  X   X]  &lt;- Row 0 (indices: 0, 1, 2, 3, 4)\n          [4.0  5.0  6.0  X   X]  &lt;- Row 1 (indices: 5, 6, 7, 8, 9)\n          (X = padding/unused)\n  Index calculation: A[i][j] = A[i * 5 + j]\n    Row 0: indices 0, 1, 2 (data), 3, 4 (padding)\n    Row 1: indices 5, 6, 7 (data), 8, 9 (padding)\n\nMatrix B Memory Layout (3x2, pad=1, step=3, 9 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:   0.5  1.5  0.0  2.5  3.5  0.0  4.5  5.5  0.0 \n  Matrix: [0.5  1.5  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [2.5  3.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n          [4.5  5.5  X]  &lt;- Row 2 (indices: 6, 7, 8)\n          (X = padding/unused)\n  Index calculation: B[i][j] = B[i * 3 + j]\n    Row 0: indices 0, 1 (data), 2 (padding)\n    Row 1: indices 3, 4 (data), 5 (padding)\n    Row 2: indices 6, 7 (data), 8 (padding)\n\nExpected Output Matrix C Memory Layout (2x2, pad=1, step=3, 6 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    19.0   25.0    0.0   41.5   56.5    0.0 \n  Matrix: [ 19.0   25.0  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 41.5   56.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n          (X = padding/unused)\n  Index calculation: C[i][j] = C[i * 3 + j]\n  Calculation:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0]\n            = A[0]*B[0] + A[1]*B[3] + A[2]*B[6]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 =  19.0\n    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1]\n            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 =  25.0\n    C[1][0] = A[1][0]*B[0][0] + A[1][1]*B[1][0] + A[1][2]*B[2][0]\n            = 4.0*0.5 + 5.0*2.5 + 6.0*4.5 =  41.5\n    C[1][1] = A[1][0]*B[0][1] + A[1][1]*B[1][1] + A[1][2]*B[2][1]\n            = 4.0*1.5 + 5.0*3.5 + 6.0*5.5 =  56.5\n\nOutput Matrix C Memory Layout (2x2, pad=1, step=3, 6 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    19.0   25.0    0.0   41.5   56.5    0.0 \n  Matrix: [ 19.0   25.0  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 41.5   56.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 13: tiny_mat_multc_f32 - Contiguous Matrix Multiply Constant\n================================================================================\nParameters: rows=3, cols=3, padd_in=0, padd_out=0, step_in=1, step_out=1\nMatrix dimensions: 3x3\nConstant C: 2.5\nNote: This should use ESP-DSP on ESP32 when all paddings are 0 and all steps are 1\n\nInput Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0 \n  Matrix: [1.0  2.0  3.0]  &lt;- Row 0 (indices: 0, 1, 2)\n          [4.0  5.0  6.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [7.0  8.0  9.0]  &lt;- Row 2 (indices: 6, 7, 8)\n  Row stride: 3 (cols + padd_in = 3 + 0)\n  Index calculation: input[i][j] = input[i * 3 + j * 1]\n\nExpected Output Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:     2.5    5.0    7.5   10.0   12.5   15.0   17.5   20.0   22.5 \n  Matrix: [  2.5    5.0    7.5]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 10.0   12.5   15.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [ 17.5   20.0   22.5] &lt;- Row 2 (indices: 6, 7, 8)\n  Row stride: 3 (cols + padd_out = 3 + 0)\n  Index calculation: output[i][j] = output[i * 3 + j * 1]\n  Calculation: output[i][j] = input[i][j] * 2.5\n    Example: output[0][0] = input[0][0] * 2.5 = 1.0 * 2.5 = 2.5\n\nOutput Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:     2.5    5.0    7.5   10.0   12.5   15.0   17.5   20.0   22.5 \n  Matrix: [  2.5    5.0    7.5]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 10.0   12.5   15.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [ 17.5   20.0   22.5] &lt;- Row 2 (indices: 6, 7, 8)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 14: tiny_mat_multc_f32 - Padded and Strided Matrix Multiply Constant\n================================================================================\nParameters: rows=2, cols=3, padd_in=2, padd_out=1, step_in=2, step_out=1\nMatrix dimensions: 2x3\nConstant C: 3.0\nNote: This should use own implementation when padding is non-zero or step &gt; 1\n\nInput Matrix Memory Layout (2x3, pad=2, step=2, 10 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0 \n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (data indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (data indices: 5, 7, 9)\n          (X = unused/padding)\n  Row stride: 5 (cols + padd_in = 3 + 2)\n  Index calculation: input[i][j] = input[i * 5 + j * 2]\n    Row 0: input[0][0]=input[0]=1.0, input[0][1]=input[2]=2.0, input[0][2]=input[4]=3.0\n    Row 1: input[1][0]=input[5]=4.0, input[1][1]=input[7]=5.0, input[1][2]=input[9]=6.0\n\nExpected Output Matrix Memory Layout (2x3, pad=1, step=1, 8 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:     3.0    6.0    9.0    0.0   12.0   15.0   18.0    0.0 \n  Matrix: [  3.0    6.0    9.0  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\n          [ 12.0   15.0   18.0  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\n          (X = padding/unused)\n  Row stride: 4 (cols + padd_out = 3 + 1)\n  Index calculation: output[i][j] = output[i * 4 + j * 1]\n  Calculation: output[i][j] = input[i][j] * 3.0\n    Row 0: output[0][0] = input[0][0] * 3.0 = 1.0 * 3.0 = 3.0 (index 0)\n           output[0][1] = input[0][1] * 3.0 = 2.0 * 3.0 = 6.0 (index 1)\n           output[0][2] = input[0][2] * 3.0 = 3.0 * 3.0 = 9.0 (index 2)\n\nOutput Matrix Memory Layout (2x3, pad=1, step=1, 8 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:     3.0    6.0    9.0    0.0   12.0   15.0   18.0    0.0 \n  Matrix: [  3.0    6.0    9.0  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\n          [ 12.0   15.0   18.0  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\n\n\u2713 Test PASSED\n================================================================================\n\n============ [test complete] ============\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-api/","title":"MATRIX OPERATIONS - TINY_MATRIX","text":"<p>TINY_MATRIX Library</p> <ul> <li>This library is a lightweight matrix computation library implemented in C++, providing basic matrix operations and linear algebra functions.</li> <li>The design goal of this library is to provide a simple and easy-to-use matrix operation interface, suitable for embedded systems and resource-constrained environments.</li> </ul> <p>Usage Scenario</p> <p>Compared to the TINY_MAT library, the TINY_MATRIX library offers richer functionality and higher flexibility, suitable for applications that require complex matrix computations. However, please note that this library is written in C++.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#list-of-functions","title":"LIST OF FUNCTIONS","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500Vector\n    \u2514\u2500\u2500Matrix\n        \u251c\u2500\u2500 tiny_mat (c)\n        \u2514\u2500\u2500 tiny_matrix (c++) &lt;---\n</code></pre> <pre><code>namespace tiny\n{\n    class Mat\n    {\n    public:\n        /* === Matrix Metadata === */\n        int row;         //&lt; number of rows\n        int col;         //&lt; number of columns\n        int pad;         //&lt; number of paddings between 2 rows\n        int stride;      //&lt; stride = (number of elements in a row) + padding\n        int element;     //&lt; number of elements = rows * cols\n        int memory;      //&lt; size of the data buffer = rows * stride\n        float *data;     //&lt; pointer to the data buffer\n        float *temp;     //&lt; pointer to the temporary data buffer\n        bool ext_buff;   //&lt; flag indicates that matrix use external buffer\n        bool sub_matrix; //&lt; flag indicates that matrix is a subset of another matrix\n\n        /* === Rectangular ROI Structure === */\n        /**\n         * @name Region of Interest (ROI) Structure\n         * @brief This is the structure for ROI\n         * \n         */\n        struct ROI\n        {\n            int pos_x;  ///&lt; starting column index\n            int pos_y;  ///&lt; starting row index\n            int width;  ///&lt; width of ROI (columns)\n            int height; ///&lt; height of ROI (rows)\n\n            // ROI constructor\n            ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n\n            // resize ROI\n            void resize_roi(int pos_x, int pos_y, int width, int height);\n\n            // calculate area of ROI\n            int area_roi(void) const;\n        };\n\n        /* === Printing Functions === */\n        // print matrix info\n        void print_info() const;\n\n        // print matrix elements, paddings optional\n        void print_matrix(bool show_padding);\n\n        /* === Constructors &amp; Destructor === */\n        // memory allocation\n        void alloc_mem(); // Allocate internal memory\n\n        // constructor\n        Mat();\n        Mat(int rows, int cols);\n        Mat(int rows, int cols, int stride);\n        Mat(float *data, int rows, int cols);\n        Mat(float *data, int rows, int cols, int stride);\n        Mat(const Mat &amp;src);\n\n        // destructor\n        ~Mat();\n\n        /* === Element Access === */\n        // access matrix elements - non const\n        inline float &amp;operator()(int row, int col) { return data[row * stride + col]; }\n\n        // access matrix elements - const             \n        inline const float &amp;operator()(int row, int col) const { return data[row * stride + col]; }\n\n        /* === Data Manipulation === */\n        // copy other matrix into this matrix as a sub-matrix\n        tiny_error_t copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n\n        // copy header of other matrix to this matrix\n        tiny_error_t copy_head(const Mat &amp;src);\n\n        // get a view (shallow copy) of sub-matrix (ROI) from this matrix\n        Mat view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n\n        // get a view (shallow copy) of sub-matrix (ROI) from this matrix using ROI structure\n        Mat view_roi(const Mat::ROI &amp;roi) const;\n\n        // get a replica (deep copy) of sub-matrix (ROI) \n        Mat copy_roi(int start_row, int start_col, int roi_rows, int roi_cols);\n\n        // get a replica (deep copy) of sub-matrix (ROI) using ROI structure\n        Mat copy_roi(const Mat::ROI &amp;roi);\n\n        // get a block of matrix\n        Mat block(int start_row, int start_col, int block_rows, int block_cols);\n\n        // swap rows\n        void swap_rows(int row1, int row2);\n\n        // clear matrix\n        void clear(void);\n\n        /* === Arithmetic Operators === */\n        Mat &amp;operator=(const Mat &amp;src);    // Copy assignment\n        Mat &amp;operator+=(const Mat &amp;A);     // Add matrix\n        Mat &amp;operator+=(float C);          // Add constant\n        Mat &amp;operator-=(const Mat &amp;A);     // Subtract matrix\n        Mat &amp;operator-=(float C);          // Subtract constant \n        Mat &amp;operator*=(const Mat &amp;A);     // Multiply matrix\n        Mat &amp;operator*=(float C);          // Multiply constant\n        Mat &amp;operator/=(const Mat &amp;B);     // Divide matrix\n        Mat &amp;operator/=(float C);          // Divide constant\n        Mat operator^(int C);              // Exponentiation\n\n        /* === Linear Algebra === */\n        Mat transpose();                   // Transpose matrix\n        Mat cofactor(int row, int col);    // cofactor matrix extraction\n        float determinant();\n        Mat adjoint(); \n        void normalize();\n        float norm() const;\n        Mat inverse_adjoint();\n        static Mat eye(int size);\n        static Mat augment(const Mat &amp;A, const Mat &amp;B);\n        static Mat ones(int rows, int cols);\n        static Mat ones(int size);\n        Mat gaussian_eliminate() const;\n        Mat row_reduce_from_gaussian();\n        Mat inverse_gje(); // Inverse using Gaussian-Jordan elimination\n        float dotprod(const Mat &amp;A, const Mat &amp;B);\n        Mat solve(const Mat &amp;A, const Mat &amp;b);\n        Mat band_solve(Mat A, Mat b, int k);\n        Mat roots(Mat A, Mat y);\n\n    protected:\n\n    private:\n\n    };\n\n    /* === Stream Operators === */\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n    std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n\n    /* === Global Arithmetic Operators === */\n    Mat operator+(const Mat &amp;A, const Mat &amp;B);\n    Mat operator+(const Mat &amp;A, float C);\n    Mat operator-(const Mat &amp;A, const Mat &amp;B);\n    Mat operator-(const Mat &amp;A, float C);\n    Mat operator*(const Mat &amp;A, const Mat &amp;B);\n    Mat operator*(const Mat &amp;A, float C);\n    Mat operator*(float C, const Mat &amp;A);\n    Mat operator/(const Mat &amp;A, float C);\n    Mat operator/(const Mat &amp;A, const Mat &amp;B);\n    bool operator==(const Mat &amp;A, const Mat &amp;B);\n\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-api/#meta-data","title":"META DATA","text":"<ul> <li> <p><code>int row</code> : Number of rows in the matrix.</p> </li> <li> <p><code>int col</code> : Number of columns in the matrix.</p> </li> <li> <p><code>int pad</code> : Number of paddings between two rows.</p> </li> <li> <p><code>int stride</code> : Stride = (number of elements in a row) + padding.</p> </li> <li> <p><code>int element</code> : Number of elements = rows * cols.</p> </li> <li> <p><code>int memory</code> : Size of the data buffer = rows * stride.</p> </li> <li> <p><code>float *data</code> : Pointer to the data buffer.</p> </li> <li> <p><code>float *temp</code> : Pointer to the temporary data buffer.</p> </li> <li> <p><code>bool ext_buff</code> : Flag indicating that the matrix uses an external buffer.</p> </li> <li> <p><code>bool sub_matrix</code> : Flag indicating that the matrix is a subset of another matrix.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-structure","title":"ROI STRUCTURE","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#metadata","title":"Metadata","text":"<ul> <li> <p><code>int pos_x</code> : Starting column index.</p> </li> <li> <p><code>int pos_y</code> : Starting row index.</p> </li> <li> <p><code>int width</code> : Width of the ROI (columns).</p> </li> <li> <p><code>int height</code> : Height of the ROI (rows).</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-constructor","title":"ROI Constructor","text":"<pre><code>Mat::ROI::ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n</code></pre> <p>Description: ROI constructor initializes the ROI with the specified position and size.</p> <p>Parameters:</p> <ul> <li> <p><code>int pos_x</code> : Starting column index.</p> </li> <li> <p><code>int pos_y</code> : Starting row index.</p> </li> <li> <p><code>int width</code> : Width of the ROI (columns).</p> </li> <li> <p><code>int height</code> : Height of the ROI (rows).</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-resize","title":"ROI RESIZE","text":"<pre><code>void Mat::ROI::resize_roi(int pos_x, int pos_y, int width, int height);\n</code></pre> <p>Description: Resizes the ROI to the specified position and size.</p> <p>Parameters:</p> <ul> <li> <p><code>int pos_x</code> : Starting column index.</p> </li> <li> <p><code>int pos_y</code> : Starting row index.</p> </li> <li> <p><code>int width</code> : Width of the ROI (columns).</p> </li> <li> <p><code>int height</code> : Height of the ROI (rows).</p> </li> </ul> <p>Returns: void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#area-roi","title":"AREA ROI","text":"<pre><code>int Mat::ROI::area_roi(void) const;\n</code></pre> <p>Description: Calculates the area of the ROI.</p> <p>Parameters: void</p> <p>Returns: int - Area of the ROI.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#print-function","title":"PRINT FUNCTION","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#print-matrix-information","title":"Print matrix information","text":"<pre><code>void print_info() const;\n</code></pre> <p>Description : Prints the matrix information including number of rows, columns, elements, paddings, stride, memory size (size of float), data buffer address, temporary buffer address, indicators whether the matrix uses an external buffer, and whether it is a sub-matrix.</p> <p>Parameters: void</p> <p>Returns: void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#print-matrix-elements","title":"Print matrix elements","text":"<pre><code>void Mat::print_matrix(bool show_padding);\n</code></pre> <p>Description: Prints the matrix elements. If <code>show_padding</code> is true, it will also print the padding values.</p> <p>Parameters: </p> <ul> <li><code>bool show_padding</code> - If true, show padding values.</li> </ul> <p>Returns: void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructors-destructor","title":"CONSTRUCTORS &amp; DESTRUCTOR","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#default-constructor","title":"Default Constructor","text":"<pre><code>Mat::Mat();\n</code></pre> <p>Description: Default constructor initializes the matrix with default values. This function will create a matrix with only one row and one column, and the only element is set to 0.</p> <p>Parameters: void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matint-rows-int-cols","title":"Constructor - Mat(int rows, int cols)","text":"<pre><code>Mat::Mat(int rows, int cols);\n</code></pre> <p>Description: Constructor initializes the matrix with the specified number of rows and columns.</p> <p>Parameters:</p> <ul> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matint-rows-int-cols-int-stride","title":"Constructor - Mat(int rows, int cols, int stride)","text":"<pre><code>Mat::Mat(int rows, int cols, int stride);\n</code></pre> <p>Description: Constructor initializes the matrix with the specified number of rows, columns, and stride.</p> <p>Parameters:</p> <ul> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> <li> <p><code>int stride</code> : Stride.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matfloat-data-int-rows-int-cols","title":"Constructor - Mat(float *data, int rows, int cols)","text":"<pre><code>Mat::Mat(float *data, int rows, int cols);\n</code></pre> <p>Description: Constructor initializes the matrix with the specified data buffer, number of rows, and columns.</p> <p>Parameters:</p> <ul> <li> <p><code>float *data</code> : Pointer to the data buffer.</p> </li> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matfloat-data-int-rows-int-cols-int-stride","title":"Constructor - Mat(float *data, int rows, int cols, int stride)","text":"<pre><code>Mat(float *data, int rows, int cols, int stride);\n</code></pre> <p>Description: Constructor initializes the matrix with the specified data buffer, number of rows, columns, and stride.</p> <p>Parameters:</p> <ul> <li> <p><code>float *data</code> : Pointer to the data buffer.</p> </li> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> <li> <p><code>int stride</code> : Stride.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matconst-mat-src","title":"Constructor - Mat(const Mat &amp;src)","text":"<pre><code>Mat::Mat(const Mat &amp;src);\n</code></pre> <p>Description: Copy constructor initializes the matrix with the specified source matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;src</code> : Source matrix.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#destructor","title":"Destructor","text":"<pre><code>Mat::~Mat();\n</code></pre> <p>Description: Destructor releases the allocated memory for the matrix.</p> <p>Parameters: void</p> <p>Note</p> <p>For constructor functions, it must has the same name as the class name, and it must not have a return type. As shown, for C++, the function name can be reloaded by changing the number and order of the parameters as long as the permutation of the parameters is different. The destructor will be automatically called when the object goes out of scope.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#element-access","title":"ELEMENT ACCESS","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#access-matrix-elements-non-const","title":"Access matrix elements - non const","text":"<pre><code>inline float &amp;operator()(int row, int col);\n</code></pre> <p>Description: Accesses the matrix elements using the specified row and column indices.</p> <p>Parameters\uff1a</p> <ul> <li> <p><code>int row</code> : Row index.</p> </li> <li> <p><code>int col</code> : Column index.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#access-matrix-elements-const","title":"Access matrix elements - const","text":"<pre><code>inline const float &amp;operator()(int row, int col) const;\n</code></pre> <p>Description: Accesses the matrix elements using the specified row and column indices (const version).</p> <p>Parameters\uff1a</p> <ul> <li> <p><code>int row</code> : Row index.</p> </li> <li> <p><code>int col</code> : Column index.</p> </li> </ul> <p>Note</p> <p>These two functions are in fact redefining the <code>()</code> operator, which allows you to access the elements of the matrix using the syntax <code>matrix(row, col)</code>.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#data-manipulation","title":"DATA MANIPULATION","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#copy-other-matrix-into-this-matrix-as-a-sub-matrix","title":"Copy other matrix into this matrix as a sub-matrix","text":"<pre><code>tiny_error_t Mat::copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n</code></pre> <p>Description: Copies the specified source matrix into this matrix as a sub-matrix starting from the specified row and column positions, not sharing the data buffer.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;src</code> : Source matrix.</p> </li> <li> <p><code>int row_pos</code> : Starting row position.</p> </li> <li> <p><code>int col_pos</code> : Starting column position.</p> </li> </ul> <p>***Returns**: tiny_error_t - Error code.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#copy-header-of-other-matrix-to-this-matrix","title":"Copy header of other matrix to this matrix","text":"<pre><code>tiny_error_t Mat::copy_head(const Mat &amp;src);\n</code></pre> <p>Description: Copies the header of the specified source matrix to this matrix, sharing the data buffer. All items copy the source matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;src</code> : Source matrix.</li> </ul> <p>Returns: tiny_error_t - Error code.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-view-shallow-copy-of-sub-matrix-roi-from-this-matrix","title":"Get a view (shallow copy) of sub-matrix (ROI) from this matrix","text":"<pre><code>Mat Mat::view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n</code></pre> <p>Description: Gets a view (shallow copy) of the sub-matrix (ROI) from this matrix starting from the specified row and column positions.</p> <p>Parameters:</p> <ul> <li> <p><code>int start_row</code> : Starting row position.</p> </li> <li> <p><code>int start_col</code> : Starting column position.</p> </li> <li> <p><code>int roi_rows</code> : Number of rows in the ROI.</p> </li> <li> <p><code>int roi_cols</code> : Number of columns in the ROI.</p> </li> </ul> <p>Warning</p> <p>Unlike ESP-DSP, view_roi does not allow to setup stride as it will automatically calculate the stride based on the number of columns and paddings. The function will also refuse illegal requests, i.e., out of bound requests. </p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-view-shallow-copy-of-sub-matrix-roi-from-this-matrix-using-roi-structure","title":"Get a view (shallow copy) of sub-matrix (ROI) from this matrix using ROI structure","text":"<pre><code>Mat Mat::view_roi(const Mat::ROI &amp;roi) const;\n</code></pre> <p>Description: Gets a view (shallow copy) of the sub-matrix (ROI) from this matrix using the specified ROI structure. This function will call the previous function in low level by passing the ROI structure to the parameters.</p> <p>Parameters:</p> <ul> <li><code>const Mat::ROI &amp;roi</code> : ROI structure.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-replica-deep-copy-of-sub-matrix-roi","title":"Get a replica (deep copy) of sub-matrix (ROI)","text":"<pre><code>Mat Mat::copy_roi(int start_row, int start_col, int roi_rows, int roi_cols);\n</code></pre> <p>Description: Gets a replica (deep copy) of the sub-matrix (ROI) from this matrix starting from the specified row and column positions. This function will return a new matrix object that does not share the data buffer with the original matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>int start_row</code> : Starting row position.</p> </li> <li> <p><code>int start_col</code> : Starting column position.</p> </li> <li> <p><code>int roi_rows</code> : Number of rows in the ROI.</p> </li> <li> <p><code>int roi_cols</code> : Number of columns in the ROI.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-replica-deep-copy-of-sub-matrix-roi-using-roi-structure","title":"Get a replica (deep copy) of sub-matrix (ROI) using ROI structure","text":"<pre><code>Mat Mat::copy_roi(const Mat::ROI &amp;roi);\n</code></pre> <p>Description: Gets a replica (deep copy) of the sub-matrix (ROI) from this matrix using the specified ROI structure. This function will call the previous function in low level by passing the ROI structure to the parameters.</p> <p>Parameters:</p> <ul> <li><code>const Mat::ROI &amp;roi</code> : ROI structure.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-block-of-matrix","title":"Get a block of matrix","text":"<pre><code>Mat Mat::block(int start_row, int start_col, int block_rows, int block_cols);\n</code></pre> <p>Description: Gets a block of the matrix starting from the specified row and column positions.</p> <p>Parameters:</p> <ul> <li> <p><code>int start_row</code> : Starting row position.</p> </li> <li> <p><code>int start_col</code> : Starting column position.</p> </li> <li> <p><code>int block_rows</code> : Number of rows in the block.</p> </li> <li> <p><code>int block_cols</code> : Number of columns in the block.</p> </li> </ul> <p>Differences between view_roi | copy_roi | block</p> <ul> <li> <p><code>view_roi</code> : Shallow copy of the sub-matrix (ROI) from this matrix.</p> </li> <li> <p><code>copy_roi</code> : Deep copy of the sub-matrix (ROI) from this matrix. Rigid and faster.</p> </li> <li> <p><code>block</code> : Deep copy of the block from this matrix. Flexible and slower.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#swap-rows","title":"Swap rows","text":"<pre><code>void Mat::swap_rows(int row1, int row2);\n</code></pre> <p>Description: Swaps the specified rows in the matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>int row1</code> : First row index.</p> </li> <li> <p><code>int row2</code> : Second row index.</p> </li> </ul> <p>Returns: void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#clear-matrix","title":"Clear matrix","text":"<pre><code>void Mat::clear(void);\n</code></pre> <p>Description: Clears the matrix by setting all elements to zero.</p> <p>Parameters: void</p> <p>Returns: void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#arithmetic-operators","title":"ARITHMETIC OPERATORS","text":"<p>Note</p> <p>This section defines the arithmetic operators that act on the current matrix itself. The operators are overloaded to perform matrix operations.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#copy-assignment","title":"Copy assignment","text":"<pre><code>Mat &amp;operator=(const Mat &amp;src);\n</code></pre> <p>Description: Copy assignment operator for the matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;src</code> : Source matrix.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#add-matrix","title":"Add matrix","text":"<pre><code>Mat &amp;operator+=(const Mat &amp;A);\n</code></pre> <p>Description: Adds the specified matrix to this matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;A</code> : Matrix to be added.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#add-constant","title":"Add constant","text":"<pre><code>Mat &amp;operator+=(float C);\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-api/#sbtract-matrix","title":"Sbtract matrix","text":"<pre><code>Mat &amp;operator-=(const Mat &amp;A);\n</code></pre> <p>Description: Subtracts the specified matrix from this matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;A</code> : Matrix to be subtracted.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#subtract-constant","title":"Subtract constant","text":"<pre><code>Mat &amp;operator-=(float C);\n</code></pre> <p>Description: Subtracts the specified constant from this matrix.</p> <p>***Parameters**:</p> <ul> <li><code>float C</code> : Constant to be subtracted.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-matrix","title":"Multiply matrix","text":"<pre><code>Mat &amp;operator*=(const Mat &amp;A);\n</code></pre> <p>Description: Multiplies this matrix by the specified matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;A</code> : Matrix to be multiplied.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-constant","title":"Multiply constant","text":"<pre><code>Mat &amp;operator*=(float C);\n</code></pre> <p>Description: Multiplies this matrix by the specified constant.</p> <p>Parameters:</p> <ul> <li><code>float C</code> : Constant to be multiplied.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#divide-matrix-element-wise","title":"Divide matrix (element-wise)","text":"<pre><code>Mat &amp;operator/=(const Mat &amp;B);\n</code></pre> <p>Description: Divides this matrix by the specified matrix element-wise.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;B</code> : Matrix to be divided by.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#divide-constant","title":"Divide constant","text":"<pre><code>Mat &amp;operator/=(float C);\n</code></pre> <p>Description: Divides this matrix by the specified constant.</p> <p>Parameters:</p> <ul> <li><code>float C</code> : Constant to be divided by.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#exponentiation","title":"Exponentiation","text":"<pre><code>Mat operator^(int C);\n</code></pre> <p>Description: Raises this matrix to the specified power.</p> <p>Parameters:</p> <ul> <li><code>int C</code> : Exponent.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#linear-algebra","title":"LINEAR ALGEBRA","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#transpose","title":"Transpose","text":"<pre><code>Mat::transpose();\n</code></pre> <p>Description: Calculates the transpose of the matrix, returning a new matrix.</p> <p>Parameters: None.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#cofactor","title":"cofactor","text":"<pre><code>Mat::cofactor(int row, int col);\n</code></pre> <p>Description: Extracts the cofactor matrix from the specified row and column.</p> <p>Parameters: </p> <ul> <li> <p><code>int row</code>: Number of the row to be excluded.</p> </li> <li> <p><code>int col</code>: Number of the column to be excluded.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#determinant","title":"Determinant","text":"<pre><code>float Mat::determinant();\n</code></pre> <p>Description: Calculates the determinant of the matrix. It is based on cofactor and adjoint matrices.</p> <p>Parameters: None.</p> <p>Returns: float - Determinant value.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#adjoint","title":"Adjoint","text":"<pre><code>Mat::adjoint();\n</code></pre> <p>Description: Calculates the adjoint of the matrix.</p> <p>Parameters: None.</p> <p>Returns: Mat - Adjoint matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#normalize","title":"Normalize","text":"<pre><code>void Mat::normalize();\n</code></pre> <p>Description: Normalizes the matrix.</p> <p>Parameters: None.</p> <p>Returns: void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#norm","title":"Norm","text":"<pre><code>float Mat::norm() const;\n</code></pre> <p>Description: Calculates the norm of the matrix.</p> <p>Parameters: None.</p> <p>Returns: float - Norm value.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#inverse-using-adjoint","title":"Inverse using Adjoint","text":"<pre><code>Mat::inverse_adjoint();\n</code></pre> <p>Description: Calculates the inverse of the matrix using the adjoint method.</p> <p>Parameters: None.</p> <p>Returns: Mat - Inverse matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#identity-matrix","title":"Identity matrix","text":"<pre><code>static Mat::eye(int size);\n</code></pre> <p>Description: Creates an identity matrix of the specified size.</p> <p>Parameters: </p> <ul> <li><code>int size</code> : Size of the identity matrix.</li> </ul> <p>Returns: Mat - Identity matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#augmentation-matrix","title":"Augmentation Matrix","text":"<pre><code>static Mat::augment(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description: Creates an augmented matrix by combining two matrices.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;A</code> : First matrix.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#identity-matrix_1","title":"identity matrix","text":"<pre><code>static Mat::ones(int rows, int cols);\n</code></pre> <p>Description: Creates a matrix filled with ones of the specified size.</p> <p>Parameters:</p> <ul> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> </ul> <p>Returns: Mat - Matrix filled with ones.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#all-ones-matrix","title":"All-Ones matrix","text":"<pre><code>static Mat::ones(int rows, int cols);\n</code></pre> <p>Description: Creates a matrix filled with ones of the specified size.</p> <p>Parameters:</p> <ul> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> </ul> <p>Returns: Mat - Matrix filled with ones.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#all-ones-matrix_1","title":"All-Ones matrix","text":"<pre><code>static Mat::ones(int size);\n</code></pre> <p>Description: Creates a square matrix filled with ones of the specified size.</p> <p>Parameters:</p> <ul> <li><code>int size</code> : Size of the square matrix.</li> </ul> <p>Returns: Mat - Square matrix filled with ones.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#gaussian-elimination","title":"Gaussian Elimination","text":"<pre><code>Mat::gaussian_eliminate() const;\n</code></pre> <p>Description: Performs Gaussian elimination on the matrix.</p> <p>Parameters: None.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#row-reduce-from-gaussian-elimination","title":"row reduce from Gaussian elimination","text":"<pre><code>Mat::row_reduce_from_gaussian();\n</code></pre> <p>Description: Performs row reduction from Gaussian elimination on the matrix.</p> <p>Parameters: None.</p> <p>Returns: Mat - Row reduced matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#inverse-using-gaussian-jordan-elimination","title":"Inverse using Gaussian-Jordan elimination","text":"<pre><code>Mat::inverse_gje();\n</code></pre> <p>Description: Calculates the inverse of the matrix using Gaussian-Jordan elimination.</p> <p>Parameters: None.</p> <p>Returns: Mat - Inverse matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#dot-product","title":"Dot Product","text":"<pre><code>float Mat::dotprod(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description: Calculates the dot product of two matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul> <p>Returns: float - Dot product value.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#solve-linear-system","title":"Solve Linear System","text":"<pre><code>Mat Mat::solve(const Mat &amp;A, const Mat &amp;b);\n</code></pre> <p>Description: Solves the linear system Ax = b.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Coefficient matrix.</p> </li> <li> <p><code>const Mat &amp;b</code> : Right-hand side matrix.</p> </li> </ul> <p>Returns: Mat - Solution matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#band-solve","title":"Band Solve","text":"<pre><code>Mat Mat::band_solve(Mat A, Mat b, int k);\n</code></pre> <p>Description: Solves a banded linear system.</p> <p>Parameters:</p> <ul> <li> <p><code>Mat A</code> : Coefficient matrix.</p> </li> <li> <p><code>Mat b</code> : Right-hand side matrix.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#band-solve_1","title":"Band Solve","text":"<pre><code>Mat Mat::band_solve(Mat A, Mat b, int k);\n</code></pre> <p>Description: Solves a banded linear system.</p> <p>Parameters:</p> <ul> <li> <p><code>Mat A</code> : Coefficient matrix.</p> </li> <li> <p><code>Mat b</code> : Right-hand side matrix.</p> </li> <li> <p><code>int k</code> : Bandwidth.</p> </li> </ul> <p>Returns: Mat - Solution matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roots","title":"Roots","text":"<pre><code>Mat Mat::roots(Mat A, Mat y);\n</code></pre> <p>Description: Calculates the roots of a polynomial represented by the matrix A.</p> <p>Parameters:</p> <ul> <li> <p><code>Mat A</code> : Coefficient matrix.</p> </li> <li> <p><code>Mat y</code> : Right-hand side matrix.</p> </li> </ul> <p>Returns: Mat - Roots matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#stream-operators","title":"STREAM OPERATORS","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-output-stream-operator","title":"Matrix output stream operator","text":"<pre><code>std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n</code></pre> <p>Description: Overloaded output stream operator for the matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>std::ostream &amp;os</code> : Output stream.</p> </li> <li> <p><code>const Mat &amp;m</code> : Matrix to be output.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-output-stream-operator","title":"ROI output stream operator","text":"<pre><code>std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n</code></pre> <p>Description: Overloaded output stream operator for the ROI structure.</p> <p>Parameters:</p> <ul> <li> <p><code>std::ostream &amp;os</code> : Output stream.</p> </li> <li> <p><code>const Mat::ROI &amp;roi</code> : ROI structure.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-input-stream-operator","title":"Matrix input stream operator","text":"<pre><code>std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n</code></pre> <p>Description: Overloaded input stream operator for the matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>std::istream &amp;is</code> : Input stream.</p> </li> <li> <p><code>Mat &amp;m</code> : Matrix to be input.</p> </li> </ul> <p>Tip</p> <p>This section is actually kind of overlapping with print function in terms of showing the matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#global-arithmetic-operators","title":"GLOBAL ARITHMETIC OPERATORS","text":"<p>Tip</p> <p>The operators in this section return a new matrix object, which is the result of the operation. The original matrices remain unchanged. Unlike the previous section, the operators are designed to perform operation acting on the current matrix itself.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#add-matrix_1","title":"Add matrix","text":"<pre><code>Mat operator+(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description: Adds the specified matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#add-constant_1","title":"Add constant","text":"<pre><code>Mat operator+(const Mat &amp;A, float C);\n</code></pre> <p>Description: Adds the specified constant to the matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Matrix to be added.</p> </li> <li> <p><code>float C</code> : Constant to be added.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#subtract-matrix","title":"Subtract matrix","text":"<pre><code>Mat operator-(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description: Subtracts the specified matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#subtract-constant_1","title":"Subtract constant","text":"<pre><code>Mat operator-(const Mat &amp;A, float C);\n</code></pre> <p>Description: Subtracts the specified constant from the matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Matrix to be subtracted.</p> </li> <li> <p><code>float C</code> : Constant to be subtracted.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-matrix_1","title":"Multiply matrix","text":"<pre><code>Mat operator*(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description: Multiplies the specified matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-constant_1","title":"Multiply constant","text":"<pre><code>Mat operator*(const Mat &amp;A, float C);\n</code></pre> <p>Description: Multiplies the specified matrix by the constant.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Matrix to be multiplied.</p> </li> <li> <p><code>float C</code> : Constant to be multiplied.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-constant_2","title":"Multiply constant","text":"<pre><code>Mat operator*(float C, const Mat &amp;A);\n</code></pre> <p>Description: Multiplies the specified matrix by the constant.</p> <p>Parameters:</p> <ul> <li> <p><code>float C</code> : Constant to be multiplied.</p> </li> <li> <p><code>const Mat &amp;A</code> : Matrix to be multiplied.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-constant-with-constant-on-the-left","title":"Multiply constant with constant on the left","text":"<pre><code>Mat operator*(float C, const Mat &amp;A);\n</code></pre> <p>Description: Multiplies the specified matrix by the constant.</p> <p>Parameters:</p> <ul> <li> <p><code>float C</code> : Constant to be multiplied.</p> </li> <li> <p><code>const Mat &amp;A</code> : Matrix to be multiplied.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#divide-matrix-by-constant","title":"Divide matrix (by constant)","text":"<pre><code>Mat operator/(const Mat &amp;A, float C);\n</code></pre> <p>Description: Divides the specified matrix by the constant element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Matrix to be divided.</p> </li> <li> <p><code>float C</code> : Constant to divide by.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#divide-matrix-element-wise_1","title":"Divide matrix (element-wise)","text":"<pre><code>Mat operator/(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description: Divides the specified matrices element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#equality-check","title":"Equality check","text":"<pre><code>bool operator==(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description: Checks if the specified matrices are equal.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul> <p>Returns: bool - true if equal, false otherwise.</p>"},{"location":"MATH/MATRIX/tiny-matrix-code/","title":"CODE","text":""},{"location":"MATH/MATRIX/tiny-matrix-code/#tiny_matrixhpp","title":"tiny_matrix.hpp","text":"<pre><code>/**\n * @file tiny_matrix.hpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @note This file is built on top of the mat.h file from the ESP-DSP library.\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// TinyMath\n#include \"tiny_math_config.h\"\n#include \"tiny_vec.h\"\n#include \"tiny_mat.h\"\n\n// Standard Libraries\n#include &lt;iostream&gt;\n#include &lt;stdint.h&gt;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n// ESP32 DSP C++ Matrix library\n#include \"mat.h\"\n#endif\n\n/* STATEMENTS */\nnamespace tiny\n{\n    class Mat\n    {\n    public:\n        /* === Matrix Metadata === */\n        int row;         //&lt; number of rows\n        int col;         //&lt; number of columns\n        int pad;         //&lt; number of paddings between 2 rows\n        int stride;      //&lt; stride = (number of elements in a row) + padding\n        int element;     //&lt; number of elements = rows * cols\n        int memory;      //&lt; size of the data buffer = rows * stride\n        float *data;     //&lt; pointer to the data buffer\n        float *temp;     //&lt; pointer to the temporary data buffer\n        bool ext_buff;   //&lt; flag indicates that matrix use external buffer\n        bool sub_matrix; //&lt; flag indicates that matrix is a subset of another matrix\n\n        /* === Rectangular ROI Structure === */\n        struct ROI\n        {\n            int pos_x;  ///&lt; starting column index\n            int pos_y;  ///&lt; starting row index\n            int width;  ///&lt; width of ROI (columns)\n            int height; ///&lt; height of ROI (rows)\n\n            // ROI constructor\n            ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n\n            // resize ROI\n            void resize_roi(int pos_x, int pos_y, int width, int height);\n\n            // calculate area of ROI\n            int area_roi(void) const;\n        };\n\n        /* === Printing Functions === */\n        // print matrix info\n        void print_info() const;\n\n        // print matrix elements, paddings optional\n        void print_matrix(bool show_padding);\n\n        /* === Constructors &amp; Destructor === */\n        // memory allocation\n        void alloc_mem(); // Allocate internal memory\n\n        // constructor\n        Mat();\n        Mat(int rows, int cols);\n        Mat(int rows, int cols, int stride);\n        Mat(float *data, int rows, int cols);\n        Mat(float *data, int rows, int cols, int stride);\n        Mat(const Mat &amp;src);\n\n        // destructor\n        ~Mat();\n\n        /* === Element Access === */\n        // access matrix elements - non const\n        inline float &amp;operator()(int row, int col) { return data[row * stride + col]; }\n\n        // access matrix elements - const             \n        inline const float &amp;operator()(int row, int col) const { return data[row * stride + col]; }\n\n        /* === Data Manipulation === */\n        // copy other matrix into this matrix as a sub-matrix\n        tiny_error_t copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n\n        // copy header of other matrix to this matrix\n        tiny_error_t copy_head(const Mat &amp;src);\n\n        // get a view (shallow copy) of sub-matrix (ROI) from this matrix\n        Mat view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n\n        // get a view (shallow copy) of sub-matrix (ROI) from this matrix using ROI structure\n        Mat view_roi(const Mat::ROI &amp;roi) const;\n\n        // get a replica (deep copy) of sub-matrix (ROI) \n        Mat copy_roi(int start_row, int start_col, int roi_rows, int roi_cols);\n\n        // get a replica (deep copy) of sub-matrix (ROI) using ROI structure\n        Mat copy_roi(const Mat::ROI &amp;roi);\n\n        // get a block of matrix\n        Mat block(int start_row, int start_col, int block_rows, int block_cols);\n\n        // swap rows\n        void swap_rows(int row1, int row2);\n\n        // clear matrix\n        void clear(void);\n\n        /* === Arithmetic Operators === */\n        Mat &amp;operator=(const Mat &amp;src);    // Copy assignment\n        Mat &amp;operator+=(const Mat &amp;A);     // Add matrix\n        Mat &amp;operator+=(float C);          // Add constant\n        Mat &amp;operator-=(const Mat &amp;A);     // Subtract matrix\n        Mat &amp;operator-=(float C);          // Subtract constant \n        Mat &amp;operator*=(const Mat &amp;A);     // Multiply matrix\n        Mat &amp;operator*=(float C);          // Multiply constant\n        Mat &amp;operator/=(const Mat &amp;B);     // Divide matrix\n        Mat &amp;operator/=(float C);          // Divide constant\n        Mat operator^(int C);              // Exponentiation\n\n        /* === Linear Algebra === */\n        Mat transpose();                   // Transpose matrix\n        Mat cofactor(int row, int col);    // cofactor matrix extraction\n        float determinant();\n        Mat adjoint(); \n        void normalize();\n        float norm() const;\n        Mat inverse_adjoint();\n        static Mat eye(int size);\n        static Mat augment(const Mat &amp;A, const Mat &amp;B);\n        static Mat ones(int rows, int cols);\n        static Mat ones(int size);\n        Mat gaussian_eliminate() const;\n        Mat row_reduce_from_gaussian();\n        Mat inverse_gje(); // Inverse using Gaussian-Jordan elimination\n        float dotprod(const Mat &amp;A, const Mat &amp;B);\n        Mat solve(const Mat &amp;A, const Mat &amp;b);\n        Mat band_solve(Mat A, Mat b, int k);\n        Mat roots(Mat A, Mat y);\n\n    protected:\n\n    private:\n\n    };\n\n    /* === Stream Operators === */\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n    std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n\n    /* === Global Arithmetic Operators === */\n    Mat operator+(const Mat &amp;A, const Mat &amp;B);\n    Mat operator+(const Mat &amp;A, float C);\n    Mat operator-(const Mat &amp;A, const Mat &amp;B);\n    Mat operator-(const Mat &amp;A, float C);\n    Mat operator*(const Mat &amp;A, const Mat &amp;B);\n    Mat operator*(const Mat &amp;A, float C);\n    Mat operator*(float C, const Mat &amp;A);\n    Mat operator/(const Mat &amp;A, float C);\n    Mat operator/(const Mat &amp;A, const Mat &amp;B);\n    bool operator==(const Mat &amp;A, const Mat &amp;B);\n\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-code/#tiny_matrixcpp","title":"tiny_matrix.cpp","text":"<pre><code>/**\n * @file tiny_matrix.cpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the source file for the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n// TinyMath\n#include \"tiny_matrix.hpp\"\n\n// Standard Libraries\n#include &lt;cstring&gt;\n#include &lt;iostream&gt;\n#include &lt;stdexcept&gt;\n#include &lt;string.h&gt;\n#include &lt;math.h&gt;\n#include &lt;cmath&gt;\n#include &lt;inttypes.h&gt;\n#include &lt;iomanip&gt;\n\n/* LIBRARIE CONTENTS */\nnamespace tiny\n{\n    /* === Rectangular ROI Structure === */\n    /**\n     * @brief Construct a new Mat:: R O I:: R O I object\n     * \n     * @param pos_x \n     * @param pos_y \n     * @param width \n     * @param height \n     */\n    Mat::ROI::ROI(int pos_x, int pos_y, int width, int height)\n    {\n        this-&gt;pos_x = pos_x;\n        this-&gt;pos_y = pos_y;\n        this-&gt;width = width;\n        this-&gt;height = height;\n    }\n\n    /**\n     * @brief resize the ROI structure\n     * \n     * @param pos_x starting column\n     * @param pos_y starting row\n     * @param width number of columns\n     * @param height number of rows\n     */\n    void Mat::ROI::resize_roi(int pos_x, int pos_y, int width, int height)\n    {\n        this-&gt;pos_x = pos_x;\n        this-&gt;pos_y = pos_y;\n        this-&gt;width = width;\n        this-&gt;height = height;\n    }\n\n    /**\n     * @brief calculate the area of the ROI structure - how many elements covered\n     * \n     * @return int \n     */\n    int Mat::ROI::area_roi(void) const\n    {\n        return this-&gt;width * this-&gt;height;\n    }\n\n    /* === Printing Functions === */\n    /**\n     * @name Mat::PrintHead()\n     * @brief Print the header of the matrix.\n     */\n    void Mat::print_info() const\n    {\n        std::cout &lt;&lt; \"Matrix Info &gt;&gt;&gt;\\n\";\n\n        // Basic matrix metadata\n        std::cout &lt;&lt; \"rows            \" &lt;&lt; this-&gt;row &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"cols            \" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"elements        \" &lt;&lt; this-&gt;element;\n\n        // Check if elements match rows * cols\n        if (this-&gt;element != this-&gt;row * this-&gt;col)\n        {\n            std::cout &lt;&lt; \"   [Warning] Mismatch! Expected: \" &lt;&lt; (this-&gt;row * this-&gt;col);\n        }\n        std::cout &lt;&lt; \"\\n\";\n\n        std::cout &lt;&lt; \"paddings        \" &lt;&lt; this-&gt;pad &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"stride          \" &lt;&lt; this-&gt;stride &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"memory          \" &lt;&lt; this-&gt;memory &lt;&lt; \"\\n\";\n\n        // Pointer information\n        std::cout &lt;&lt; \"data pointer    \" &lt;&lt; static_cast&lt;const void *&gt;(this-&gt;data) &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"temp pointer    \" &lt;&lt; static_cast&lt;const void *&gt;(this-&gt;temp) &lt;&lt; \"\\n\";\n\n        // Flags information\n        std::cout &lt;&lt; \"ext_buff        \" &lt;&lt; this-&gt;ext_buff;\n        if (this-&gt;ext_buff)\n        {\n            std::cout &lt;&lt; \"   (External buffer or View)\";\n        }\n        std::cout &lt;&lt; \"\\n\";\n\n        std::cout &lt;&lt; \"sub_matrix      \" &lt;&lt; this-&gt;sub_matrix;\n        if (this-&gt;sub_matrix)\n        {\n            std::cout &lt;&lt; \"   (This is a Sub-Matrix View)\";\n        }\n        std::cout &lt;&lt; \"\\n\";\n\n        // State warnings\n        if (this-&gt;sub_matrix &amp;&amp; !this-&gt;ext_buff)\n        {\n            std::cout &lt;&lt; \"[Warning] Sub-matrix is marked but ext_buff is false! Potential logic error.\\n\";\n        }\n\n        if (this-&gt;data == nullptr)\n        {\n            std::cout &lt;&lt; \"[Info] No data buffer assigned to this matrix.\\n\";\n        }\n\n        std::cout &lt;&lt; \"&lt;&lt;&lt; Matrix Info\\n\";\n    }\n\n    /**\n     * @name Mat::print_matrix()\n     * @brief Print the matrix elements.\n     *\n     * @param show_padding If true, print the padding elements as well.\n     */\n    void Mat::print_matrix(bool show_padding)\n    {\n        std::cout &lt;&lt; \"Matrix Elements &gt;&gt;&gt;\\n\";\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            // print the non-padding elements\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                std::cout &lt;&lt; std::setw(12) &lt;&lt; this-&gt;data[i * this-&gt;stride + j] &lt;&lt; \" \";\n            }\n\n            // if padding is enabled, print the padding elements\n            if (show_padding)\n            {\n                // print a separator first\n                std::cout &lt;&lt; \"      |\";\n\n                // print the padding elements\n                for (int j = this-&gt;col; j &lt; this-&gt;stride; ++j)\n                {\n                    if (j == this-&gt;col)\n                    {\n                        std::cout &lt;&lt; std::setw(7) &lt;&lt; this-&gt;data[i * this-&gt;stride + j] &lt;&lt; \" \";\n                    }\n                    else\n                    {\n                        // print the padding elements\n                        std::cout &lt;&lt; std::setw(12) &lt;&lt; this-&gt;data[i * this-&gt;stride + j] &lt;&lt; \" \";\n                    }\n                }\n            }\n\n            // print a new line after each row\n            std::cout &lt;&lt; \"\\n\";\n        }\n\n        std::cout &lt;&lt; \"&lt;&lt;&lt; Matrix Elements\\n\";\n        std::cout &lt;&lt; std::endl;\n    }\n\n    /* === Constructors &amp; Destructor === */\n    // memory allocation\n    /**\n     * @name Mat::allocate()\n     * @brief Allocate memory for the matrix according to the memory required.\n     */\n    void Mat::alloc_mem()\n    {\n        this-&gt;ext_buff = false;\n        this-&gt;memory = this-&gt;row * this-&gt;stride;\n        this-&gt;data = new float[this-&gt;memory];\n    }\n\n    /**\n     * @name Mat::Mat()\n     * @brief Constructor - default constructor: create a 1x1 matrix with only a zero element.\n     */\n    Mat::Mat()\n    {\n        this-&gt;row = 1;\n        this-&gt;col = 1;\n        this-&gt;pad = 0;\n        this-&gt;stride = 1;\n        this-&gt;element = 1;\n        this-&gt;memory = 1;\n        this-&gt;data = nullptr;\n        this-&gt;temp = nullptr;\n        this-&gt;ext_buff = false;\n        this-&gt;sub_matrix = false;\n        alloc_mem();\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\\n\";\n        }\n        std::memset(this-&gt;data, 0, this-&gt;memory * sizeof(float));\n    }\n\n    /**\n     * @name Mat::Mat(int rows, int cols)\n     * @brief Constructor - create a matrix with the specified number of rows and columns.\n     *\n     * @param rows Number of rows\n     * @param cols Number of columns\n     */\n    Mat::Mat(int rows, int cols)\n    {\n        this-&gt;row = rows;\n        this-&gt;col = cols;\n        this-&gt;pad = 0;\n        this-&gt;stride = cols;\n        this-&gt;element = rows * cols;\n        this-&gt;memory = rows * cols;\n        this-&gt;data = nullptr;\n        this-&gt;temp = nullptr;\n        this-&gt;ext_buff = false;\n        this-&gt;sub_matrix = false;\n        alloc_mem();\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\\n\";\n        }\n        std::memset(this-&gt;data, 0, this-&gt;memory * sizeof(float));\n    }\n    /**\n     * @name Mat::Mat(int rows, int cols, int stride)\n     * @brief Constructor - create a matrix with the specified number of rows, columns and stride.\n     *\n     * @param rows Number of rows\n     * @param cols Number of columns\n     * @param stride Stride (number of elements in a row)\n     */\n    Mat::Mat(int rows, int cols, int stride)\n    {\n        this-&gt;row = rows;\n        this-&gt;col = cols;\n        this-&gt;pad = stride - cols;\n        this-&gt;stride = stride;\n        this-&gt;element = rows * cols;\n        this-&gt;memory = rows * stride;\n        this-&gt;data = nullptr;\n        this-&gt;temp = nullptr;\n        this-&gt;ext_buff = false;\n        this-&gt;sub_matrix = false;\n        alloc_mem();\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\\n\";\n        }\n        std::memset(this-&gt;data, 0, this-&gt;memory * sizeof(float));\n    }\n\n    /**\n     * @name Mat::Mat(float *data, int rows, int cols)\n     * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n     *\n     * @param data Pointer to external data buffer\n     * @param rows Number of rows\n     * @param cols Number of columns\n     */\n    Mat::Mat(float *data, int rows, int cols)\n    {\n        this-&gt;row = rows;\n        this-&gt;col = cols;\n        this-&gt;pad = 0;\n        this-&gt;stride = cols;\n        this-&gt;element = rows * cols;\n        this-&gt;memory = rows * cols; // for external data, this item is actually not used\n        this-&gt;data = data;\n        this-&gt;temp = nullptr;\n        this-&gt;ext_buff = true;\n        this-&gt;sub_matrix = false;\n    }\n\n    /**\n     * @name Mat::Mat(float *data, int rows, int cols, int stride)\n     * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n     *\n     * @param data Pointer to external data buffer\n     * @param rows Number of rows\n     * @param cols Number of columns\n     * @param stride Stride (number of elements in a row)\n     */\n    Mat::Mat(float *data, int rows, int cols, int stride)\n    {\n        this-&gt;row = rows;\n        this-&gt;col = cols;\n        this-&gt;pad = stride - cols;\n        this-&gt;stride = stride;\n        this-&gt;element = rows * cols;\n        this-&gt;memory = rows * stride; // for external data, this item is actually not used\n        this-&gt;data = data;\n        this-&gt;temp = nullptr;\n        this-&gt;ext_buff = true;\n        this-&gt;sub_matrix = false;\n    }\n\n    /**\n     * @name Mat::Mat(const Mat &amp;src)\n     * @brief Copy constructor - create a matrix with the same properties as the source matrix.\n     *\n     * @param src Source matrix\n     */\n    Mat::Mat(const Mat &amp;src)\n    {\n        this-&gt;row = src.row;\n        this-&gt;col = src.col;\n        this-&gt;pad = src.pad;\n        this-&gt;stride = src.stride;\n        this-&gt;element = src.element;\n        this-&gt;memory = src.memory;\n\n        if (src.sub_matrix &amp;&amp; src.ext_buff)\n        {\n            // if the source is a view (submatrix), do shallow copy\n            this-&gt;data = src.data;\n            this-&gt;temp = nullptr;\n            this-&gt;ext_buff = true;\n            this-&gt;sub_matrix = true;\n        }\n        else\n        {\n            // otherwise do deep copy\n            this-&gt;data = nullptr;\n            this-&gt;temp = nullptr;\n            this-&gt;ext_buff = false;\n            this-&gt;sub_matrix = false;\n\n            if (src.data != nullptr)\n            {\n                alloc_mem();\n                if (this-&gt;data == nullptr)\n                {\n                    std::cerr &lt;&lt; \"[Error] Memory allocation failed in alloc_mem()\\n\";\n                }\n                std::memcpy(this-&gt;data, src.data, this-&gt;memory * sizeof(float));\n            }\n        }\n    }\n\n    /**\n     * @name ~Mat()\n     * @brief Destructor - free the memory allocated for the matrix.\n     */\n    Mat::~Mat()\n    {\n        if (!this-&gt;ext_buff &amp;&amp; this-&gt;data)\n        {\n            delete[] this-&gt;data;\n        }\n        if (this-&gt;temp)\n        {\n            delete[] this-&gt;temp;\n        }\n    }\n\n    /* === Element Access === */\n    // Already defined by inline functions in the header file\n\n    /* === Data Manipulation === */\n\n    /**\n     * @name Mat::copy_paste(const Mat &amp;src, int row_pos, int col_pos)\n     * @brief Copy the elements of the source matrix into the destination matrix. The dimension of the current matrix must be larger than the source matrix.\n     * @brief This one does not share memory with the source matrix.\n     *\n     * @param src Source matrix\n     * @param row_pos Start row position of the destination matrix\n     * @param col_pos Start column position of the destination matrix\n     */\n    tiny_error_t Mat::copy_paste(const Mat &amp;src, int row_pos, int col_pos)\n    {\n        if ((row_pos + src.row) &gt; this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Invalid row position \" &lt;&lt; std::endl;\n            return TINY_ERR_INVALID_ARG;\n        }\n        if ((col_pos + src.col) &gt; this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Invalid column position \" &lt;&lt; std::endl;\n            return TINY_ERR_INVALID_ARG;\n        }\n        for (size_t r = 0; r &lt; src.row; r++)\n        {\n            memcpy(&amp;this-&gt;data[(r + row_pos) * this-&gt;stride + col_pos], &amp;src.data[r * src.col], src.col * sizeof(float));\n        }\n\n        return TINY_OK;\n    }\n\n    /**\n     * @name Mat::copy_head(const Mat &amp;src)\n     * @brief Copy the header of the source matrix into the destination matrix. The data pointer is shared.\n     *\n     * @param src Source matrix\n     */\n    tiny_error_t Mat::copy_head(const Mat &amp;src)\n    {\n        if (!this-&gt;ext_buff)\n        {\n            delete[] this-&gt;data;\n        }\n        this-&gt;row = src.row;\n        this-&gt;col = src.col;\n        this-&gt;element = src.element;\n        this-&gt;pad = src.pad;\n        this-&gt;stride = src.stride;\n        this-&gt;memory = src.memory;\n        this-&gt;data = src.data;\n        this-&gt;temp = src.temp;\n        this-&gt;ext_buff = src.ext_buff;\n        this-&gt;sub_matrix = src.sub_matrix;\n\n        return TINY_OK;\n    }\n\n    /**\n     * @name Mat::view_roi(int start_row, int start_col, int roi_rows, int roi_cols)\n     * @brief Make a shallow copy of ROI matrix. | Make a view of the ROI matrix. Low level function. Unlike ESP-DSP, it is not allowed to setup stride here, stride is automatically calculated inside the function.\n     *\n     * @param start_row Start row position of source matrix to copy\n     * @param start_col Start column position of source matrix to copy\n     * @param roi_rows Size of row elements of source matrix to copy\n     * @param roi_cols Size of column elements of source matrix to copy\n     *\n     * @todo the pointer address is changing every time access, but the result is correct.\n     *\n     * @return result matrix size row_size x col_size\n     */\n    Mat Mat::view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const\n    {\n        if ((start_row + roi_rows) &gt; this-&gt;row || (start_col + roi_cols) &gt; this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Invalid ROI request.\\n\";\n            return Mat();\n        }\n\n        Mat result;\n        result.row = roi_rows;\n        result.col = roi_cols;\n        result.stride = this-&gt;stride;\n        result.pad = this-&gt;stride - roi_cols;\n        result.element = roi_rows * roi_cols;\n        result.memory = roi_rows * this-&gt;stride;\n        result.data = this-&gt;data + (start_row * this-&gt;stride + start_col);\n        result.temp = nullptr;\n        result.ext_buff = true;\n        result.sub_matrix = true;\n\n        return result;\n    }\n\n    /**\n     * @name Mat::view_roi(const Mat::ROI &amp;roi)\n     * @brief Make a shallow copy of ROI matrix. | Make a view of the ROI matrix. Using ROI structure.\n     *\n     * @param roi Rectangular area of interest\n     *\n     * @return result matrix size row_size x col_size\n     */\n    Mat Mat::view_roi(const Mat::ROI &amp;roi) const\n    {\n        return view_roi(roi.pos_y, roi.pos_x, roi.height, roi.width);\n    }\n\n    /**\n     * @name Mat::copy_roi(int start_row, int start_col, int height, int width)\n     * @brief Make a deep copy of matrix. Copared to view_roi(), this one is a deep copy, not sharing memory with the source matrix.\n     *\n     * @param start_row Start row position of source matrix to copy\n     * @param start_col Start column position of source matrix to copy\n     * @param height Size of row elements of source matrix to copy\n     * @param width Size of column elements of source matrix to copy\n     *\n     * @return result matrix size row_size x col_size\n     */\n    Mat Mat::copy_roi(int start_row, int start_col, int height, int width)\n    {\n        if ((start_row + height) &gt; this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Invalid row position \" &lt;&lt; std::endl;\n            return Mat();\n        }\n        if ((start_col + width) &gt; this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Invalid columnn position \" &lt;&lt; std::endl;\n            return Mat();\n        }\n\n        // initiate the result matrix\n        Mat result(height, width);\n\n        // deep copy the data from the source matrix\n        for (size_t r = 0; r &lt; result.row; r++)\n        {\n            memcpy(&amp;result.data[r * result.col], &amp;this-&gt;data[(r + start_row) * this-&gt;stride + start_col], result.col * sizeof(float));\n        }\n\n        // return result;\n        return result;\n    }\n\n    /**\n     * @name Mat::copy_roi(const Mat::ROI &amp;roi)\n     * @brief Make a deep copy of matrix. Using ROI structure. Copared to view_roi(), this one is a deep copy, not sharing memory with the source matrix.\n     *\n     * @param roi Rectangular area of interest\n     *\n     * @return result matrix size row_size x col_size\n     */\n    Mat Mat::copy_roi(const Mat::ROI &amp;roi)\n    {\n        return (copy_roi(roi.pos_y, roi.pos_x, roi.height, roi.width));\n    }\n\n    /**\n     * @name Mat::block(int start_row, int start_col, int block_rows, int block_cols)\n     * @brief Get a block of matrix.\n     *\n     * @param start_row\n     * @param start_col\n     * @param block_rows\n     * @param block_cols\n     * @return Mat\n     */\n    Mat Mat::block(int start_row, int start_col, int block_rows, int block_cols)\n    {\n        Mat result(block_rows, block_cols);\n        for (int i = 0; i &lt; block_rows; ++i)\n        {\n            for (int j = 0; j &lt; block_cols; ++j)\n            {\n                result(i, j) = (*this)(start_row + i, start_col + j);\n            }\n        }\n        return result;\n    }\n\n    /**\n     * @name Mat::swap_rows(int row1, int row2)\n     * @brief Swap two rows of the matrix.\n     *\n     * @param row1 The index of the first row to swap\n     * @param row2 The index of the second row to swap\n     */\n    void Mat::swap_rows(int row1, int row2)\n    {\n        if ((this-&gt;row &lt;= row1) || (this-&gt;row &lt;= row2))\n        {\n            std::cerr &lt;&lt; \"Error: row index out of range\" &lt;&lt; std::endl;\n        }\n        else\n        {\n            float *temp_row = new float[this-&gt;col];\n            memcpy(temp_row, &amp;this-&gt;data[row1 * this-&gt;stride], this-&gt;col * sizeof(float));\n            memcpy(&amp;this-&gt;data[row1 * this-&gt;stride], &amp;this-&gt;data[row2 * this-&gt;stride], this-&gt;col * sizeof(float));\n            memcpy(&amp;this-&gt;data[row2 * this-&gt;stride], temp_row, this-&gt;col * sizeof(float));\n            delete[] temp_row;\n        }\n    }\n\n    /**\n     * @name Mat::clear()\n     * @brief Clear the matrix by setting all elements to zero.\n     */\n    void Mat::clear(void)\n    {\n        for (int row = 0; row &lt; this-&gt;row; row++)\n        {\n            memset(this-&gt;data + (row * this-&gt;stride), 0, this-&gt;col * sizeof(float));\n        }\n    }\n\n    /* === Arithmetic Operators === */\n    /**\n     * @name &amp;Mat::operator=(const Mat &amp;src)\n     * @brief Copy assignment operator - copy the elements of the source matrix into the destination matrix. Compared to the copy constructor, this one is used for existing matrix to copy the elements. The copy constructor is used for the first time to create a new matrix and copy the elements at the same time.\n     *\n     * @param src\n     * @return Mat&amp;\n     */\n    Mat &amp;Mat::operator=(const Mat &amp;src)\n    {\n        // 1. Self-assignment check\n        if (this == &amp;src)\n        {\n            return *this;\n        }\n\n        // 2. Forbid assignment to sub-matrix views\n        if (this-&gt;sub_matrix)\n        {\n            std::cerr &lt;&lt; \"[Error] Assignment to a sub-matrix is not allowed.\\n\";\n            return *this;\n        }\n\n        // 3. If dimensions differ, reallocate memory\n        if (this-&gt;row != src.row || this-&gt;col != src.col)\n        {\n            if (!this-&gt;ext_buff &amp;&amp; this-&gt;data != nullptr)\n            {\n                delete[] this-&gt;data;\n            }\n\n            // Update dimensions and memory info\n            this-&gt;row = src.row;\n            this-&gt;col = src.col;\n            this-&gt;stride = src.col; // Follow source's logical stride\n            this-&gt;pad = 0;\n            this-&gt;element = this-&gt;row * this-&gt;col;\n            this-&gt;memory = this-&gt;row * this-&gt;stride;\n\n            this-&gt;ext_buff = false;\n            this-&gt;sub_matrix = false;\n\n            alloc_mem();\n        }\n\n        // 4. Data copy (row-wise)\n        for (int r = 0; r &lt; this-&gt;row; ++r)\n        {\n            std::memcpy(this-&gt;data + r * this-&gt;stride, src.data + r * src.stride, this-&gt;col * sizeof(float));\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator+=(const Mat &amp;A)\n     * @brief Element-wise addition of another matrix to this matrix.\n     *\n     * @param A The matrix to add\n     * @return Mat&amp; Reference to the current matrix\n     */\n    /**\n     * @name Mat::operator+=(const Mat &amp;A)\n     * @brief Element-wise addition of another matrix to this matrix.\n     *\n     * @param A The matrix to add\n     * @return Mat&amp; Reference to the current matrix\n     */\n    Mat &amp;Mat::operator+=(const Mat &amp;A)\n    {\n        // 1. Dimension check\n        if ((this-&gt;row != A.row) || (this-&gt;col != A.col))\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix addition failed: Dimension mismatch (\"\n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \" vs \"\n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Determine if padding handling is needed\n        bool need_padding_handling = (this-&gt;pad &gt; 0) || (A.pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware addition\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_add_f32(this-&gt;data, A.data, this-&gt;data,\n                         this-&gt;row, this-&gt;col,\n                         this-&gt;pad, A.pad, this-&gt;pad,\n                         1, 1, 1);\n#else\n            tiny_mat_add_f32(this-&gt;data, A.data, this-&gt;data,\n                             this-&gt;row, this-&gt;col,\n                             this-&gt;pad, A.pad, this-&gt;pad,\n                             1, 1, 1);\n#endif\n        }\n        else\n        {\n            // Vectorized addition for contiguous memory\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_add_f32(this-&gt;data, A.data, this-&gt;data, this-&gt;memory, 1, 1, 1);\n#else\n            tiny_vec_add_f32(this-&gt;data, A.data, this-&gt;data, this-&gt;memory, 1, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator+=(float C)\n     * @brief Element-wise addition of a constant to this matrix.\n     *\n     * @param C The constant to add\n     */\n    /**\n     * @name Mat::operator+=(float C)\n     * @brief Element-wise addition of a constant to this matrix.\n     *\n     * @param C The constant to add\n     * @return Mat&amp; Reference to the current matrix\n     */\n    Mat &amp;Mat::operator+=(float C)\n    {\n        // check whether padding is presented\n        bool need_padding_handling = (this-&gt;pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware constant addition\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_addc_f32(this-&gt;data, this-&gt;data, C,\n                          this-&gt;row, this-&gt;col,\n                          this-&gt;pad, this-&gt;pad,\n                          1, 1);\n#else\n            tiny_mat_addc_f32(this-&gt;data, this-&gt;data, C,\n                              this-&gt;row, this-&gt;col,\n                              this-&gt;pad, this-&gt;pad,\n                              1, 1);\n#endif\n        }\n        else\n        {\n            // Vectorized constant addition\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_addc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, C, 1, 1);\n#else\n            tiny_vec_addc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, C, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator-=(const Mat &amp;A)\n     * @brief Element-wise subtraction of another matrix from this matrix.\n     *\n     * @param A The matrix to subtract\n     * @return Mat&amp; Reference to the current matrix\n     */\n    /**\n     * @name Mat::operator-=(const Mat &amp;A)\n     * @brief Element-wise subtraction of another matrix from this matrix.\n     *\n     * @param A The matrix to subtract\n     * @return Mat&amp; Reference to the current matrix\n     */\n    Mat &amp;Mat::operator-=(const Mat &amp;A)\n    {\n        // 1. Dimension check\n        if ((this-&gt;row != A.row) || (this-&gt;col != A.col))\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix subtraction failed: Dimension mismatch (\"\n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \" vs \"\n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Determine if padding handling is needed\n        bool need_padding_handling = (this-&gt;pad &gt; 0) || (A.pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware subtraction\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_sub_f32(this-&gt;data, A.data, this-&gt;data,\n                         this-&gt;row, this-&gt;col,\n                         this-&gt;pad, A.pad, this-&gt;pad,\n                         1, 1, 1);\n#else\n            tiny_mat_sub_f32(this-&gt;data, A.data, this-&gt;data,\n                             this-&gt;row, this-&gt;col,\n                             this-&gt;pad, A.pad, this-&gt;pad,\n                             1, 1, 1);\n#endif\n        }\n        else\n        {\n            // Vectorized subtraction for contiguous memory\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_sub_f32(this-&gt;data, A.data, this-&gt;data, this-&gt;memory, 1, 1, 1);\n#else\n            tiny_vec_sub_f32(this-&gt;data, A.data, this-&gt;data, this-&gt;memory, 1, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator-=(float C)\n     * @brief Element-wise subtraction of a constant from this matrix.\n     *\n     * @param C The constant to subtract\n     */\n    /**\n     * @name Mat::operator-=(float C)\n     * @brief Element-wise subtraction of a constant from this matrix.\n     *\n     * @param C The constant to subtract\n     * @return Mat&amp; Reference to the current matrix\n     */\n    Mat &amp;Mat::operator-=(float C)\n    {\n        bool need_padding_handling = (this-&gt;pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware constant subtraction\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            // Note: ESP32 DSP does not provide dspm_subc_f32, using dspm_addc_f32 with -C\n            dspm_addc_f32(this-&gt;data, this-&gt;data, -C,\n                          this-&gt;row, this-&gt;col,\n                          this-&gt;pad, this-&gt;pad,\n                          1, 1);\n#else\n            tiny_mat_subc_f32(this-&gt;data, this-&gt;data, C,\n                              this-&gt;row, this-&gt;col,\n                              this-&gt;pad, this-&gt;pad,\n                              1, 1);\n#endif\n        }\n        else\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            // Note: ESP32 DSP does not provide dsps_subc_f32, using dsps_addc_f32 with -C\n            dsps_addc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, -C, 1, 1);\n#else\n            tiny_vec_subc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, C, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator*=(const Mat &amp;m)\n     * @brief Matrix multiplication: this = this * m\n     *\n     * @param m The matrix to multiply with\n     * @return Mat&amp; Reference to the current matrix\n     */\n    Mat &amp;Mat::operator*=(const Mat &amp;m)\n    {\n        // 1. Dimension check\n        if (this-&gt;col != m.row)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix multiplication failed: incompatible dimensions (\"\n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \" * \"\n                      &lt;&lt; m.row &lt;&lt; \"x\" &lt;&lt; m.col &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Prepare temp matrix (incase overwriting the original data)\n        Mat temp = this-&gt;copy_roi(0, 0, this-&gt;row, this-&gt;col);\n\n        // 3. check whether padding is present in either matrix\n        bool need_padding_handling = (this-&gt;pad &gt; 0) || (m.pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mult_ex_f32(temp.data, m.data, this-&gt;data, temp.row, temp.col, m.col, temp.pad, m.pad, this-&gt;pad);\n#else\n            tiny_mat_mult_ex_f32(temp.data, m.data, this-&gt;data, temp.row, temp.col, m.col, temp.pad, m.pad, this-&gt;pad);\n#endif\n        }\n        else\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mult_f32(temp.data, m.data, this-&gt;data, temp.row, temp.col, m.col);\n#else\n            tiny_mat_mult_f32(temp.data, m.data, this-&gt;data, temp.row, temp.col, m.col);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator*=(float num)\n     * @brief Element-wise multiplication by a constant\n     *\n     * @param num The constant multiplier\n     * @return Mat&amp; Reference to the current matrix\n     */\n    Mat &amp;Mat::operator*=(float num)\n    {\n        // check whether padding is present\n        bool need_padding_handling = (this-&gt;pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware multiplication\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mulc_f32(this-&gt;data, this-&gt;data, num,\n                          this-&gt;row, this-&gt;col,\n                          this-&gt;pad, this-&gt;pad,\n                          1, 1);\n#else\n            tiny_mat_multc_f32(this-&gt;data, this-&gt;data, num, this-&gt;row, this-&gt;col, this-&gt;pad, this-&gt;pad, 1, 1);\n#endif\n        }\n        else\n        {\n            // No padding, use vectorized multiplication\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_mulc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, num, 1, 1);\n#else\n            tiny_vec_mulc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, num, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator/=(const Mat &amp;B)\n     * @brief Element-wise division: this = this / B\n     *\n     * @param B The matrix divisor\n     * @return Mat&amp; Reference to the current matrix\n     */\n    Mat &amp;Mat::operator/=(const Mat &amp;B)\n    {\n        // 1. Dimension check\n        if ((this-&gt;row != B.row) || (this-&gt;col != B.col))\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix division failed: Dimension mismatch (\"\n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \" vs \"\n                      &lt;&lt; B.row &lt;&lt; \"x\" &lt;&lt; B.col &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Zero division check\n        bool zero_found = false;\n        for (int i = 0; i &lt; B.row; ++i)\n        {\n            for (int j = 0; j &lt; B.col; ++j)\n            {\n                if (B(i, j) == 0.0f)\n                {\n                    zero_found = true;\n                    break;\n                }\n            }\n            if (zero_found)\n                break;\n        }\n\n        if (zero_found)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix division failed: Division by zero detected.\\n\";\n            return *this;\n        }\n\n        // 3. Element-wise division\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                (*this)(i, j) /= B(i, j);\n            }\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator/=(float num)\n     * @brief Element-wise division of this matrix by a constant.\n     *\n     * @param num The constant divisor\n     * @return Mat&amp; Reference to the current matrix\n     */\n    Mat &amp;Mat::operator/=(float num)\n    {\n        // 1. Check division by zero\n        if (num == 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix division by zero is undefined.\\n\";\n            return *this;\n        }\n\n        // 2. Determine if padding handling is needed\n        bool need_padding_handling = (this-&gt;pad &gt; 0);\n\n        float inv_num = 1.0f / num;\n\n        if (need_padding_handling)\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mulc_f32(this-&gt;data, this-&gt;data, inv_num,\n                          this-&gt;row, this-&gt;col,\n                          this-&gt;pad, this-&gt;pad,\n                          1, 1);\n#else\n            tiny_mat_multc_f32(this-&gt;data, this-&gt;data, inv_num,\n                              this-&gt;row, this-&gt;col,\n                              this-&gt;pad, this-&gt;pad,\n                              1, 1);\n#endif\n        }\n        else\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_mulc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, inv_num, 1, 1);\n#else\n            tiny_vec_mulc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, inv_num, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator^(int num)\n     * @brief Element-wise integer exponentiation. Returns a new matrix where each element is raised to the given power.\n     *\n     * @param num The exponent (integer)\n     * @return Mat New matrix after exponentiation\n     */\n    Mat Mat::operator^(int num)\n    {\n        // Handle special cases\n        if (num == 0)\n        {\n            // Any number to the power of 0 is 1\n            Mat result(this-&gt;row, this-&gt;col, this-&gt;stride);\n            for (int i = 0; i &lt; this-&gt;row; ++i)\n            {\n                for (int j = 0; j &lt; this-&gt;col; ++j)\n                {\n                    result(i, j) = 1.0f;\n                }\n            }\n            return result;\n        }\n\n        if (num == 1)\n        {\n            // Return a copy of current matrix\n            return Mat(*this);\n        }\n\n        if (num &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] Negative exponent not supported in operator^.\\n\";\n            return Mat(*this); // Return a copy without modification\n        }\n\n        // General case: positive exponent &gt; 1\n        Mat result(this-&gt;row, this-&gt;col, this-&gt;stride);\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                float base = (*this)(i, j);\n                float value = 1.0f;\n                for (int k = 0; k &lt; num; ++k)\n                {\n                    value *= base;\n                }\n                result(i, j) = value;\n            }\n        }\n\n        return result;\n    }\n\n    /* === Linear Algebra === */\n    /**\n     * @name Mat::transpose\n     * @brief Transpose the matrix.\n     *\n     * @return Transposed matrix\n     */\n    Mat Mat::transpose()\n    {\n        Mat result(this-&gt;col, this-&gt;row);\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                result(j, i) = this-&gt;data[i * this-&gt;stride + j];\n            }\n        }\n        return result;\n    }\n\n    /**\n     * @brief Calculate the cofactor matrix by removing specified row and column.\n     *\n     * @param target_row Row index to remove\n     * @param target_col Column index to remove\n     * @return Mat The (n-1)x(n-1) cofactor matrix\n     */\n    Mat Mat::cofactor(int target_row, int target_col)\n    {\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Cofactor requires square matrix.\\n\";\n            return Mat();\n        }\n\n        int n = this-&gt;row;\n        Mat result(n - 1, n - 1);\n\n        for (int i = 0, res_i = 0; i &lt; n; ++i)\n        {\n            if (i == target_row)\n                continue;\n\n            for (int j = 0, res_j = 0; j &lt; n; ++j)\n            {\n                if (j == target_col)\n                    continue;\n\n                result.data[res_i * result.stride + res_j] = this-&gt;data[i * this-&gt;stride + j];\n                res_j++;\n            }\n            res_i++;\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::determinant()\n     * @brief Calculate the determinant of a square matrix using Laplace Expansion.\n     * @brief Low efficiency, only suitable for small matrices!!!\n     *\n     * @return Determinant value (float)\n     */\n    float Mat::determinant()\n    {\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Determinant can only be calculated for square matrices.\\n\";\n            return 0.0f;\n        }\n\n        int n = this-&gt;row;\n\n        // Base case: 1x1 matrix\n        if (n == 1)\n            return this-&gt;data[0];\n\n        // Base case: 2x2 matrix (optimized)\n        if (n == 2)\n            return this-&gt;data[0] * this-&gt;data[3] - this-&gt;data[1] * this-&gt;data[2];\n\n        float D = 0.0f;\n        int sign = 1;\n\n        for (int f = 0; f &lt; n; ++f)\n        {\n            Mat minor = this-&gt;cofactor(0, f);                // Get cofactor matrix\n            D += sign * (*this)(0, f) * minor.determinant(); // Recursive call to calculate determinant of the cofactor matrix\n            sign = -sign;                                    // Alternate sign\n        }\n\n        return D;\n    }\n\n    /**\n     * @name Mat::adjoint()\n     * @brief Calculate the adjoint (adjugate) matrix of a square matrix.\n     *\n     * @return Mat The adjoint matrix\n     */\n    Mat Mat::adjoint()\n    {\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Adjoint can only be computed for square matrices.\\n\";\n            return Mat();\n        }\n\n        int n = this-&gt;row;\n        Mat adj(n, n);\n\n        // Special case for 1x1 matrix\n        if (n == 1)\n        {\n            adj(0, 0) = 1.0f;\n            return adj;\n        }\n\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; n; ++j)\n            {\n                // Calculate cofactor matrix of element (i, j)\n                Mat cof = this-&gt;cofactor(i, j);\n\n                int sign = ((i + j) % 2 == 0) ? 1 : -1;\n\n                // Adjoint is transpose of cofactor matrix\n                adj(j, i) = sign * cof.determinant();\n            }\n        }\n\n        return adj;\n    }\n\n    /**\n     * @brief Normalize the matrix using L2 norm (Frobenius norm).\n     *        After normalization, ||Matrix|| = 1\n     */\n    void Mat::normalize()\n    {\n        float norm_sq = 0.0f;\n\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                float val = (*this)(i, j);\n                norm_sq += val * val;\n            }\n        }\n\n        if (norm_sq == 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Warning] Cannot normalize a zero matrix.\\n\";\n            return;\n        }\n\n        float inv_norm = 1.0f / sqrtf(norm_sq);\n        *this *= inv_norm;\n    }\n\n    /**\n     * @name Mat::norm() const\n     * @brief Calculate the Frobenius norm (L2 norm) of the matrix.\n     *\n     * @return float The computed matrix norm\n     */\n    float Mat::norm() const\n    {\n        float sum_sq = 0.0f;\n\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                float val = (*this)(i, j); // Access valid matrix element\n                sum_sq += val * val;\n            }\n        }\n\n        return sqrtf(sum_sq);\n    }\n\n    /**\n     * @name Mat::inverse_adjoint()\n     * @brief Compute the inverse of a square matrix using adjoint method.\n     *\n     * @return Mat The inverse matrix. If singular, returns a zero matrix.\n     */\n    Mat Mat::inverse_adjoint()\n    {\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Inverse can only be computed for square matrices.\\n\";\n            return Mat();\n        }\n\n        int n = this-&gt;row;\n\n        float det_val = this-&gt;determinant();\n        if (det_val == 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] Singular matrix, inverse does not exist.\\n\";\n            return Mat(n, n); // Return zero matrix\n        }\n\n        Mat adj = this-&gt;adjoint();\n\n        // Inverse = adjoint / determinant\n        Mat inv(n, n);\n        float inv_det = 1.0f / det_val;\n\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; n; ++j)\n            {\n                inv(i, j) = adj(i, j) * inv_det;\n            }\n        }\n\n        return inv;\n    }\n\n    /**\n     * @name Mat::eye(int size)\n     * @brief Generate an identity matrix of given size.\n     *\n     * @param size Dimension of the square identity matrix\n     * @return Mat Identity matrix (size x size)\n     */\n    Mat Mat::eye(int size)\n    {\n        Mat identity(size, size);\n\n        // Set diagonal elements to 1, rest are initialized as 0\n        for (int i = 0; i &lt; size; ++i)\n        {\n            identity(i, i) = 1.0f;\n        }\n\n        return identity;\n    }\n\n    /**\n     * @name Mat::augment(const Mat &amp;A, const Mat &amp;B)\n     * @brief Augment two matrices horizontally [A | B].\n     *\n     * @param A Left matrix\n     * @param B Right matrix\n     * @return Mat Augmented matrix [A B]\n     */\n    Mat Mat::augment(const Mat &amp;A, const Mat &amp;B)\n    {\n        // 1. Check if row counts match\n        if (A.row != B.row)\n        {\n            std::cerr &lt;&lt; \"[Error] Cannot augment matrices: Row counts do not match (\"\n                      &lt;&lt; A.row &lt;&lt; \" vs \" &lt;&lt; B.row &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // 2. Create new matrix with combined columns\n        Mat AB(A.row, A.col + B.col);\n\n        // 3. Copy data from A and B\n        for (int i = 0; i &lt; A.row; ++i)\n        {\n            // Copy A\n            for (int j = 0; j &lt; A.col; ++j)\n            {\n                AB(i, j) = A(i, j);\n            }\n            // Copy B\n            for (int j = 0; j &lt; B.col; ++j)\n            {\n                AB(i, A.col + j) = B(i, j);\n            }\n        }\n\n        return AB;\n    }\n\n    /**\n     * @name Mat::ones(int size)\n     * @brief Create a square matrix filled with ones.\n     *\n     * @param size Size of the square matrix (rows = cols)\n     * @return Mat Square matrix [size x size] with all elements = 1\n     */\n    Mat Mat::ones(int size)\n    {\n        return Mat::ones(size, size);\n    }\n\n    /**\n     * @name Mat::ones(int rows, int cols)\n     * @brief Create a matrix of specified size filled with ones.\n     *\n     * @param rows Number of rows\n     * @param cols Number of columns\n     * @return Mat Matrix [rows x cols] with all elements = 1\n     */\n    Mat Mat::ones(int rows, int cols)\n    {\n        Mat result(rows, cols);\n\n        for (int i = 0; i &lt; rows; ++i)\n        {\n            for (int j = 0; j &lt; cols; ++j)\n            {\n                result(i, j) = 1.0f;\n            }\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::gaussian_eliminate\n     * @brief Perform Gaussian Elimination to convert matrix to Row Echelon Form (REF).\n     *\n     * @return Mat The upper triangular matrix (REF form)\n     */\n    Mat Mat::gaussian_eliminate() const\n    {\n        Mat result(*this); // Create a copy of the original matrix\n        int rows = result.row;\n        int cols = result.col;\n\n        int lead = 0; // Leading column tracker\n\n        for (int r = 0; r &lt; rows; ++r)\n        {\n            if (lead &gt;= cols)\n                break;\n\n            int i = r;\n\n            // Find pivot row (partial pivoting)\n            while (result(i, lead) == 0)\n            {\n                i++;\n                if (i == rows)\n                {\n                    i = r;\n                    lead++;\n                    if (lead == cols)\n                        return result; // Return the result matrix (upper triangular)\n                }\n            }\n\n            // Swap rows if pivot is not in current row\n            if (i != r)\n                result.swap_rows(i, r);\n\n            // Eliminate rows below\n            for (int j = r + 1; j &lt; rows; ++j)\n            {\n                if (result(j, lead) == 0)\n                    continue;\n\n                float factor = result(j, lead) / result(r, lead);\n                for (int k = lead; k &lt; cols; ++k)\n                {\n                    result(j, k) -= factor * result(r, k);\n\n                    // Numerical precision handling (set near-zero values to zero)\n                    if (fabs(result(j, k)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                        result(j, k) = 0.0f;\n                }\n            }\n\n            lead++;\n        }\n\n        return result; // Return the upper triangular matrix\n    }\n\n    /**\n     * @name Mat::row_reduce_from_gaussian()\n     * @brief Convert a matrix (assumed in row echelon form) to Reduced Row Echelon Form (RREF).\n     *\n     * @return Mat The matrix in RREF form\n     */\n    Mat Mat::row_reduce_from_gaussian()\n    {\n        Mat R(*this); // Make a copy to preserve original matrix\n        int rows = R.row;\n        int cols = R.col;\n\n        int pivot_row = rows - 1;\n        int pivot_col = cols - 2;\n\n        while (pivot_row &gt;= 0)\n        {\n            // Locate pivot in current row\n            int current_pivot_col = -1;\n            for (int k = 0; k &lt; cols; ++k)\n            {\n                if (R(pivot_row, k) != 0)\n                {\n                    current_pivot_col = k;\n                    break;\n                }\n            }\n\n            if (current_pivot_col != -1)\n            {\n                // Normalize pivot row\n                float pivot_val = R(pivot_row, current_pivot_col);\n                for (int s = current_pivot_col; s &lt; cols; ++s)\n                {\n                    R(pivot_row, s) /= pivot_val;\n                    if (fabs(R(pivot_row, s)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    {\n                        R(pivot_row, s) = 0.0f;\n                    }\n                }\n\n                // Eliminate above pivot\n                for (int t = pivot_row - 1; t &gt;= 0; --t)\n                {\n                    float factor = R(t, current_pivot_col);\n                    for (int s = current_pivot_col; s &lt; cols; ++s)\n                    {\n                        R(t, s) -= factor * R(pivot_row, s);\n                        if (fabs(R(t, s)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                        {\n                            R(t, s) = 0.0f;\n                        }\n                    }\n                }\n            }\n\n            pivot_row--;\n        }\n\n        return R;\n    }\n\n    /**\n     * @name Mat::inverse_gje()\n     * @brief Compute the inverse of a square matrix using Gauss-Jordan elimination.\n     *\n     * @return Mat The inverse matrix if invertible, otherwise returns empty matrix.\n     */\n    Mat Mat::inverse_gje()\n    {\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Inversion requires a square matrix.\\n\";\n            return Mat();\n        }\n\n        // Step 1: Create augmented matrix [A | I]\n        Mat I = Mat::eye(this-&gt;row);            // Identity matrix\n        Mat augmented = Mat::augment(*this, I); // Augment matrix A with I\n\n        // Step 2: Apply Gauss-Jordan elimination to get [I | A_inv]\n        Mat rref = augmented.gaussian_eliminate().row_reduce_from_gaussian();\n\n        // Check if the left half is the identity matrix\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                if (fabs(rref(i, j) - I(i, j)) &gt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                {\n                    std::cerr &lt;&lt; \"[Error] Matrix is singular, cannot compute inverse.\\n\";\n                    return Mat();\n                }\n            }\n        }\n\n        // Step 3: Extract the right half as the inverse matrix\n        Mat result(this-&gt;row, this-&gt;col);\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                result(i, j) = rref(i, j + this-&gt;col); // Extract the right part\n            }\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::dotprod(const Mat &amp;A, const Mat &amp;B)\n     * @brief Calculate the dot product of two vectors (Nx1).\n     *\n     * @param[in] A Input vector A (Nx1).\n     * @param[in] B Input vector B (Nx1).\n     *\n     * @return float The computed dot product value.\n     */\n    float Mat::dotprod(const Mat &amp;A, const Mat &amp;B)\n    {\n        if (A.row != B.row || A.col != 1 || B.col != 1)\n        {\n            std::cerr &lt;&lt; \"[Error] Dot product can only be computed for two vectors of the same length.\\n\";\n            return 0.0f; // Return 0 in case of dimension mismatch\n        }\n\n        float sum = 0;\n        for (int i = 0; i &lt; A.row; ++i)\n        {\n            sum += A(i, 0) * B(i, 0);\n        }\n\n        return sum;\n    }\n\n    /**\n     * @name Mat::solve\n     * @brief Solve the linear system Ax = b using Gaussian elimination.\n     *\n     * @param A Coefficient matrix (NxN)\n     * @param b Result vector (Nx1)\n     * @return Mat Solution vector (Nx1) containing the roots of the equation Ax = b\n     */\n    Mat Mat::solve(const Mat &amp;A, const Mat &amp;b)\n    {\n        // Check if the matrix A is square\n        if (A.row != A.col)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix A must be square for solving.\\n\";\n            return Mat(); // Return empty matrix\n        }\n\n        // Check if A and b dimensions are compatible for solving\n        if (A.row != b.row || b.col != 1)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix dimensions do not match for solving.\\n\";\n            return Mat(); // Return empty matrix\n        }\n\n        // Create augmented matrix [A | b]\n        Mat augmentedMatrix(A.row, A.col + 1);\n        for (int i = 0; i &lt; A.row; ++i)\n        {\n            for (int j = 0; j &lt; A.col; ++j)\n            {\n                augmentedMatrix(i, j) = A(i, j); // Copy matrix A into augmented matrix\n            }\n            augmentedMatrix(i, A.col) = b(i, 0); // Copy vector b into augmented matrix\n        }\n\n        // Perform Gaussian elimination\n        for (int i = 0; i &lt; A.row; ++i)\n        {\n            // Find pivot and make sure it's non-zero\n            if (augmentedMatrix(i, i) == 0)\n            {\n                std::cerr &lt;&lt; \"[Error] Pivot is zero, matrix is singular.\\n\";\n                return Mat(); // Return empty matrix\n            }\n\n            // Normalize the pivot row\n            float pivot = augmentedMatrix(i, i);\n            for (int j = i; j &lt; augmentedMatrix.col; ++j)\n            {\n                augmentedMatrix(i, j) /= pivot; // Normalize the pivot row\n            }\n\n            // Eliminate the entries below the pivot\n            for (int j = i + 1; j &lt; A.row; ++j)\n            {\n                float factor = augmentedMatrix(j, i);\n                for (int k = i; k &lt; augmentedMatrix.col; ++k)\n                {\n                    augmentedMatrix(j, k) -= factor * augmentedMatrix(i, k);\n                }\n            }\n        }\n\n        // Back-substitution to find the solution\n        Mat solution(A.row, 1);\n        for (int i = A.row - 1; i &gt;= 0; --i)\n        {\n            float sum = augmentedMatrix(i, A.col);\n            for (int j = i + 1; j &lt; A.row; ++j)\n            {\n                sum -= augmentedMatrix(i, j) * solution(j, 0);\n            }\n            solution(i, 0) = sum;\n        }\n\n        return solution;\n    }\n\n    /**\n     * @name Mat::band_solve\n     * @brief Solve the system of equations Ax = b using optimized Gaussian elimination for banded matrices.\n     *\n     * @param A Coefficient matrix (NxN) - banded matrix\n     * @param b Result vector (Nx1)\n     * @param k Bandwidth of the matrix (the width of the non-zero bands)\n     * @return Mat Solution vector (Nx1) containing the roots of the equation Ax = b\n     */\n    Mat Mat::band_solve(Mat A, Mat b, int k)\n    {\n        // Dimension compatibility check\n        if (A.row != A.col) // Check if A is a square matrix\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix A must be square for solving.\\n\";\n            return Mat(); // Return an empty matrix in case of an error\n        }\n\n        if (A.row != b.row || b.col != 1) // Check if dimensions of A and b are compatible\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix dimensions are not compatible for solving.\\n\";\n            return Mat(); // Return an empty matrix in case of an error\n        }\n\n        int bandsBelow = (k - 1) / 2; // Number of bands below the main diagonal\n\n        // Perform forward elimination to reduce the matrix\n        for (int i = 0; i &lt; A.row; ++i)\n        {\n            if (A(i, i) == 0)\n            {\n                // Pivot 0 - error\n                std::cerr &lt;&lt; \"[Error] Zero pivot detected in bandSolve. Cannot proceed.\\n\";\n                Mat err_result(b.row, 1);\n                memset(err_result.data, 0, b.row * sizeof(float));\n                return err_result;\n            }\n\n            float a_ii = 1 / A(i, i); // Inverse of the pivot element\n\n            // Eliminate elements below the pivot in the current column\n            for (int j = i + 1; j &lt; A.row &amp;&amp; j &lt;= i + bandsBelow; ++j)\n            {\n                if (A(j, i) != 0)\n                {\n                    float factor = A(j, i) * a_ii;\n                    for (int k = i; k &lt; A.col; ++k)\n                    {\n                        A(j, k) -= A(i, k) * factor; // Eliminate the element\n                    }\n                    b(j, 0) -= b(i, 0) * factor; // Update the result vector\n                    A(j, i) = 0;                 // Set the element to zero as it has been eliminated\n                }\n            }\n        }\n\n        // Back substitution to solve for x\n        Mat x(b.row, 1);\n        x(x.row - 1, 0) = b(x.row - 1, 0) / A(x.row - 1, x.row - 1); // Solve the last variable\n\n        for (int i = x.row - 2; i &gt;= 0; --i)\n        {\n            float sum = 0;\n            for (int j = i + 1; j &lt; x.row; ++j)\n            {\n                sum += A(i, j) * x(j, 0); // Sum of the known terms\n            }\n            x(i, 0) = (b(i, 0) - sum) / A(i, i); // Solve for the current variable\n        }\n\n        return x; // Return the solution vector\n    }\n\n    /**\n     * @name Mat::roots(Mat A, Mat y)\n     * @brief   Solve the matrix using a different method. Another implementation of the 'solve' function, no difference in principle.\n     *\n     * This method solves the linear system A * x = y using Gaussian elimination.\n     *\n     * @param[in] A: matrix [N]x[N] with input coefficients\n     * @param[in] y: vector [N]x[1] with result values\n     *\n     * @return\n     *      - matrix [N]x[1] with roots\n     */\n    Mat Mat::roots(Mat A, Mat y)\n    {\n        int n = A.col; // Number of rows and columns in A (assuming A is square)\n\n        // Create augmented matrix [A | y]\n        Mat augmentedMatrix = Mat::augment(A, y);\n\n        // Perform Gaussian elimination\n        for (int j = 0; j &lt; n; j++)\n        {\n            // Normalize the pivot row (make pivot element equal to 1)\n            float pivot = augmentedMatrix(j, j);\n            if (pivot == 0)\n            {\n                std::cerr &lt;&lt; \"[Error] Pivot is zero, system may have no solution.\" &lt;&lt; std::endl;\n                return Mat(); // Return an empty matrix in case of an error\n            }\n\n            for (int k = 0; k &lt; augmentedMatrix.col; k++)\n            {\n                augmentedMatrix(j, k) /= pivot;\n            }\n\n            // Eliminate the column below the pivot (set other elements in the column to zero)\n            for (int i = j + 1; i &lt; n; i++)\n            {\n                float factor = augmentedMatrix(i, j);\n                for (int k = 0; k &lt; augmentedMatrix.col; k++)\n                {\n                    augmentedMatrix(i, k) -= factor * augmentedMatrix(j, k);\n                }\n            }\n        }\n\n        // Perform back-substitution\n        Mat result(n, 1);\n        for (int i = n - 1; i &gt;= 0; i--)\n        {\n            float sum = augmentedMatrix(i, n); // Right-hand side of the augmented matrix\n            for (int j = i + 1; j &lt; n; j++)\n            {\n                sum -= augmentedMatrix(i, j) * result(j, 0); // Subtract the known terms\n            }\n            result(i, 0) = sum; // Solve for the current variable\n        }\n\n        return result;\n    }\n\n    /* === Stream Operators === */\n    /**\n     * @name operator&lt;&lt;\n     * @brief Stream insertion operator for printing matrix to the output stream (e.g., std::cout).\n     *\n     * This function allows printing the contents of a matrix to an output stream.\n     * It prints each row of the matrix on a new line, with elements separated by spaces.\n     *\n     * @param os Output stream where the matrix will be printed (e.g., std::cout)\n     * @param m Matrix to be printed\n     *\n     * @return os The output stream after printing the matrix\n     */\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m)\n    {\n        for (int i = 0; i &lt; m.row; ++i)\n        {\n            os &lt;&lt; m(i, 0);\n            for (int j = 1; j &lt; m.col; ++j)\n            {\n                os &lt;&lt; \" \" &lt;&lt; m(i, j);\n            }\n            os &lt;&lt; std::endl;\n        }\n        return os;\n    }\n\n    /**\n     * @name operator&lt;&lt;\n     * @brief Stream insertion operator for printing the Rectangular ROI structure to the output stream.\n     *\n     * This function prints the details of the ROI (Region of Interest) including the start row and column,\n     * and the width and height of the rectangular region.\n     *\n     * @param os Output stream where the ROI will be printed (e.g., std::cout)\n     * @param roi The ROI structure to be printed\n     *\n     * @return os The output stream after printing the ROI details\n     */\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi)\n    {\n        os &lt;&lt; \"row start \" &lt;&lt; roi.pos_y &lt;&lt; std::endl;\n        os &lt;&lt; \"col start \" &lt;&lt; roi.pos_x &lt;&lt; std::endl;\n        os &lt;&lt; \"row count \" &lt;&lt; roi.height &lt;&lt; std::endl;\n        os &lt;&lt; \"col count \" &lt;&lt; roi.width &lt;&lt; std::endl;\n\n        return os;\n    }\n\n    /**\n     * @name operator&gt;&gt;\n     * @brief Stream extraction operator for reading matrix from the input stream (e.g., std::cin).\n     *\n     * This function reads the contents of a matrix from an input stream.\n     * The matrix elements are read row by row, with elements separated by spaces or newlines.\n     *\n     * @param is Input stream from which the matrix will be read (e.g., std::cin)\n     * @param m Matrix to store the read data\n     *\n     * @return is The input stream after reading the matrix\n     */\n    std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m)\n    {\n        for (int i = 0; i &lt; m.row; ++i)\n        {\n            for (int j = 0; j &lt; m.col; ++j)\n            {\n                is &gt;&gt; m(i, j);\n            }\n        }\n        return is;\n    }\n\n    /* === Global Arithmetic Operators === */\n    /**\n     * + operator, sum of two matrices\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *     - result matrix A+B\n     */\n    Mat operator+(const Mat &amp;m1, const Mat &amp;m2)\n    {\n        if ((m1.row != m2.row) || (m1.col != m2.col))\n        {\n            std::cerr &lt;&lt; \"operator + Error: matrices do not have equal dimensions\" &lt;&lt; std::endl;\n            Mat err_ret;\n            return err_ret;\n        }\n\n        if (m1.sub_matrix || m2.sub_matrix)\n        {\n            Mat temp(m1.row, m2.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_add_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m1.pad, m2.pad, temp.pad, 1, 1, 1);\n#else\n            tiny_mat_add_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m1.pad, m2.pad, temp.pad, 1, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m1);\n            return (temp += m2);\n        }\n    }\n\n    /**\n     * + operator, sum of matrix with constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] C: Input constant\n     *\n     * @return\n     *     - result matrix A+C\n     */\n    Mat operator+(const Mat &amp;m, float C)\n    {\n        if (m.sub_matrix)\n        {\n            Mat temp(m.row, m.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_addc_f32(m.data, temp.data, C, m.row, m.col, m.pad, temp.pad, 1, 1);\n#else\n            tiny_mat_addc_f32(m.data, temp.data, C, m.row, m.col, m.pad, temp.pad, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m);\n            return (temp += C);\n        }\n    }\n\n    /**\n     * - operator, subtraction of two matrices\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *     - result matrix A-B\n     */\n    Mat operator-(const Mat &amp;m1, const Mat &amp;m2)\n    {\n        if ((m1.row != m2.row) || (m1.col != m2.col))\n        {\n            std::cerr &lt;&lt; \"operator - Error: matrices do not have equal dimensions\" &lt;&lt; std::endl;\n            Mat err_ret;\n            return err_ret;\n        }\n\n        if (m1.sub_matrix || m2.sub_matrix)\n        {\n            Mat temp(m1.row, m1.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_sub_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m1.pad, m2.pad, temp.pad, 1, 1, 1);\n#else\n            tiny_mat_sub_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m1.pad, m2.pad, temp.pad, 1, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m1);\n            return (temp -= m2);\n        }\n    }\n\n\n    /**\n     * - operator, subtraction of matrix with constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] C: Input constant\n     *\n     * @return\n     *     - result matrix A-C\n     */\n    Mat operator-(const Mat &amp;m, float C)\n    {\n        if (m.sub_matrix)\n        {\n            Mat temp(m.row, m.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_addc_f32(m.data, temp.data, -C, m.row, m.col, m.pad, temp.pad, 1, 1);\n#else\n            tiny_mat_addc_f32(m.data, temp.data, -C, m.row, m.col, m.pad, temp.pad, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m);\n            return (temp -= C);\n        }\n    }\n\n\n    /**\n     * * operator, multiplication of two matrices.\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *     - result matrix A*B\n     */\n    Mat operator*(const Mat &amp;m1, const Mat &amp;m2)\n    {\n        if (m1.col != m2.row)\n        {\n            std::cerr &lt;&lt; \"operator * Error: matrices do not have correct dimensions\" &lt;&lt; std::endl;\n            Mat err_ret;\n            return err_ret;\n        }\n        Mat temp(m1.row, m2.col);\n\n        if (m1.sub_matrix || m2.sub_matrix)\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mult_ex_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m2.col, m1.pad, m2.pad, temp.pad);\n#else\n            tiny_mat_mult_ex_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m2.col, m1.pad, m2.pad, temp.pad);\n#endif\n        }\n        else\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mult_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m2.col);\n#else\n            tiny_mat_mult_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m2.col);\n#endif\n        }\n\n        return temp;\n    }\n\n    /**\n     * * operator, multiplication of matrix with constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] C: floating point value\n     *\n     * @return\n     *     - result matrix A*B\n     */\n    Mat operator*(const Mat &amp;m, float num)\n    {\n        if (m.sub_matrix)\n        {\n            Mat temp(m.row, m.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mulc_f32(m.data, temp.data, num, m.row, m.col, m.pad, temp.pad, 1, 1);\n#else\n            tiny_mat_multc_f32(m.data, temp.data, num, m.row, m.col, m.pad, temp.pad, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m);\n            return (temp *= num);\n        }\n    }\n\n    /**\n     * * operator, multiplication of matrix with constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] C: floating point value\n     * @param[in] A: Input matrix A\n     *\n     * @return\n     *     - result matrix C*A\n     */\n    Mat operator*(float num, const Mat &amp;m)\n    {\n        return (m * num);\n    }\n\n    /**\n     * / operator, divide of matrix by constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] C: floating point value\n     *\n     * @return\n     *     - result matrix A/C\n     */\n    Mat operator/(const Mat &amp;m, float num)\n    {\n        if (m.sub_matrix)\n        {\n            Mat temp(m.row, m.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mulc_f32(m.data, temp.data, 1 / num, m.row, m.col, m.pad, temp.pad, 1, 1);\n#else\n            tiny_mat_multc_f32(m.data, temp.data, 1 / num, m.row, m.col, m.pad, temp.pad, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m);\n            return (temp /= num);\n        }\n    }\n\n\n    /**\n     * / operator, divide matrix A by matrix B (element-wise)\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *     - result matrix C, where C[i,j] = A[i,j]/B[i,j]\n     */\n    Mat operator/(const Mat &amp;A, const Mat &amp;B)\n    {\n        if ((A.row != B.row) || (A.col != B.col))\n        {\n            std::cerr &lt;&lt; \"operator / Error: matrices do not have equal dimensions\" &lt;&lt; std::endl;\n            Mat err_ret;\n            return err_ret;\n        }\n\n        Mat temp(A.row, A.col);\n        for (int row = 0; row &lt; A.row; row++)\n        {\n            for (int col = 0; col &lt; A.col; col++)\n            {\n                temp(row, col) = A(row, col) / B(row, col);\n            }\n        }\n        return temp;\n    }\n\n\n    /**\n     * == operator, compare two matrices\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *      - true if matrices are the same\n     *      - false if matrices are different\n     */\n    bool operator==(const Mat &amp;m1, const Mat &amp;m2)\n    {\n        if ((m1.col != m2.col) || (m1.row != m2.row))\n        {\n            return false;\n        }\n\n        for (int row = 0; row &lt; m1.row; row++)\n        {\n            for (int col = 0; col &lt; m1.col; col++)\n            {\n                if (m1(row, col) != m2(row, col))\n                {\n                    std::cout &lt;&lt; \"operator == Error: \" &lt;&lt; row &lt;&lt; \" \" &lt;&lt; col &lt;&lt; \", m1.data=\" &lt;&lt; m1(row, col) &lt;&lt; \", m2.data=\" &lt;&lt; m2(row, col) &lt;&lt; std::endl;\n                    return false;\n                }\n            }\n        }\n\n        return true;\n    }\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/","title":"TEST","text":"<p>Tip</p> <p>The following code for testing also serves as tutorial codes.</p>"},{"location":"MATH/MATRIX/tiny-matrix-test/#tiny_matrix_testhpp","title":"tiny_matrix_test.hpp","text":"<pre><code>/**\n * @file tiny_matrix_test.hpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the test of the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_matrix.hpp\" // TinyMatrix Header\n\n/* STATEMENTS */\nvoid tiny_matrix_test();  // C-compatible test entry\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#tiny_matrix_testcpp","title":"tiny_matrix_test.cpp","text":"<pre><code>/**\n * @file tiny_matrix_test.cpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the source file for the test of the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_matrix_test.hpp\" // TinyMatrix Test Header\n\n#include &lt;iostream&gt;\n#include &lt;iomanip&gt;\n\n// Group 1: constructor &amp; destructor\nvoid test_constructor_destructor()\n{\n    std::cout &lt;&lt; \"\\n--- Test: Constructor &amp; Destructor ---\\n\";\n\n    // test1: default constructor\n    std::cout &lt;&lt; \"[Test1: Default Constructor]\\n\";\n    tiny::Mat mat1;\n    mat1.print_info();\n    mat1.print_matrix(true);\n\n    // test2: constructor with rows and cols, using internal allocation\n    std::cout &lt;&lt; \"[Test2: Constructor with Rows and Cols]\\n\";\n    tiny::Mat mat2(3, 4);\n    mat2.print_info();\n    mat2.print_matrix(true);\n\n    // test3: constructor with rows and cols, specifying stride, using internal allocation\n    std::cout &lt;&lt; \"[Test3: Constructor with Rows, Cols and Stride]\\n\";\n    tiny::Mat mat3(3, 4, 5);\n    mat3.print_info();\n    mat3.print_matrix(true);\n\n    // test4: constructor with external data\n    std::cout &lt;&lt; \"[Test4: Constructor with External Data]\\n\";\n    float data[12] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11};\n    tiny::Mat mat4(data, 3, 4);\n    mat4.print_info();\n    mat4.print_matrix(true);\n\n    // test5: constructor with external data and stride\n    std::cout &lt;&lt; \"[Test5: Constructor with External Data and Stride]\\n\";\n    float data_stride[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n    tiny::Mat mat5(data_stride, 3, 4, 5);\n    mat5.print_info();\n    mat5.print_matrix(true);\n\n    // test6: copy constructor\n    std::cout &lt;&lt; \"[Test6: Copy Constructor]\\n\";\n    tiny::Mat mat6(mat5);\n    mat6.print_info();\n    mat6.print_matrix(true);\n}\n\n// Group 2: element access\nvoid test_element_access()\n{\n    std::cout &lt;&lt; \"\\n--- Test: Element Access ---\\n\";\n    tiny::Mat mat(2, 3);\n\n    // Test 1: non-const access\n    std::cout &lt;&lt; \"[Test1: Non-const Access]\\n\";\n    mat(0, 0) = 1.1f;\n    mat(0, 1) = 2.2f;\n    mat(0, 2) = 3.3f;\n    mat(1, 0) = 4.4f;\n    mat(1, 1) = 5.5f;\n    mat(1, 2) = 6.6f;\n    mat.print_info();\n    mat.print_matrix(true);\n\n    // Test 2: const access\n    std::cout &lt;&lt; \"[Test2: Const Access]\\n\";\n    const tiny::Mat const_mat = mat;\n    std::cout &lt;&lt; \"const_mat(0, 0): \" &lt;&lt; const_mat(0, 0) &lt;&lt; \"\\n\";\n}\n\n// Group 3: data manipulation\nvoid test_roi_operations()\n{\n    std::cout &lt;&lt; \"\\n--- Test: Data Manipulation ---\\n\";\n\n    // Material Matrices\n    tiny::Mat matA(2, 3);\n    for (int i = 0; i &lt; 2; ++i)\n    {\n        for (int j = 0; j &lt; 3; ++j)\n        {\n            matA(i, j) = i * 3 + j + 1;\n            matA(i, j) = matA(i, j) / 10;\n        }\n    }\n\n    float data[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n    tiny::Mat matB(data, 3, 4, 5);\n\n    tiny::Mat matC;\n\n    std::cout &lt;&lt; \"[Material Matrices]\\n\";\n    std::cout &lt;&lt; \"matA:\\n\";\n    matA.print_info();\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"matB:\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"matC:\\n\";\n    matC.print_info();\n    matC.print_matrix(true);\n\n    // Test 1: Copy ROI\n    std::cout &lt;&lt; \"[Test1: Copy ROI - over range case]\\n\";\n    matB.copy_paste(matA, 1, 2);\n    std::cout &lt;&lt; \"matB after copy_paste matA at (1, 2):\\n\";\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"nothing changed.\\n\";\n\n    std::cout &lt;&lt; \"[Test1: Copy ROI - suitable range case]\\n\";\n    matB.copy_paste(matA, 1, 1);\n    std::cout &lt;&lt; \"matB after copy_paste matA at (1, 1):\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"successfully copied.\\n\";\n\n    // Test 2: Copy Head\n    std::cout &lt;&lt; \"[Test2: Copy Head]\\n\";\n    matC.copy_head(matB);\n    std::cout &lt;&lt; \"matC after copy_head matB:\\n\";\n    matC.print_info();\n    matC.print_matrix(true);\n\n    std::cout &lt;&lt; \"[Test2: Copy Head - memory sharing check]\\n\"; // matB and matC share the same data pointer\n    matB(0, 0) = 99.99f;\n    std::cout &lt;&lt; \"matB(0, 0) = 99.99f\\n\";\n    std::cout &lt;&lt; \"matC:\\n\";\n    matC.print_info();\n    matC.print_matrix(true);\n\n    // Test 3: Get a View of ROI - low level function\n    std::cout &lt;&lt; \"[Test3: Get a View of ROI - low level function]\\n\";\n    std::cout &lt;&lt; \"get a view of ROI with overrange dimensions - rows:\\n\";\n    tiny::Mat roi1 = matB.view_roi(1, 1, 3, 2); // note here, C++ will use the copy constructor, which will copy according to the case (submatrix - shallow copy | normal - deep copy)\n    std::cout &lt;&lt; \"get a view of ROI with overrange dimensions - cols:\\n\";\n    tiny::Mat roi2 = matB.view_roi(1, 1, 2, 4); // note here, C++ will use the copy constructor, which will copy according to the case (submatrix - shallow copy | normal - deep copy)\n    std::cout &lt;&lt; \"get a view of ROI with suitable dimensions:\\n\";\n    tiny::Mat roi3 = matB.view_roi(1, 1, 2, 2); // note here, C++ will use the copy constructor, which will copy according to the case (submatrix - shallow copy | normal - deep copy)\n    std::cout &lt;&lt; \"roi3:\\n\";\n    roi3.print_info();\n    roi3.print_matrix(true);\n\n    // Test 4: Get a View of ROI - using ROI structure\n    std::cout &lt;&lt; \"[Test4: Get a View of ROI - using ROI structure]\\n\";\n    tiny::Mat::ROI roi_struct(1, 1, 2, 2);\n    tiny::Mat roi4 = matB.view_roi(roi_struct);\n    roi4.print_info();\n    roi4.print_matrix(true);\n\n    // Test 5: Copy ROI - low level function\n    std::cout &lt;&lt; \"[Test5: Copy ROI - low level function]\\n\";\n    tiny::Mat mat_deep_copy = matB.copy_roi(1, 1, 2, 2);\n    mat_deep_copy.print_info();\n    mat_deep_copy.print_matrix(true);\n\n    // Test 6: Copy ROI - using ROI structure\n    std::cout &lt;&lt; \"[Test6: Copy ROI - using ROI structure]\\n\";\n    TinyTimeMark_t tic1 = tiny_get_running_time();\n    tiny::Mat::ROI roi_struct2(1, 1, 2, 2);\n    tiny::Mat mat_deep_copy2 = matB.copy_roi(roi_struct2);\n    TinyTimeMark_t toc1 = tiny_get_running_time();\n    TinyTimeMark_t copy_roi_time = toc1 - tic1;\n    std::cout &lt;&lt; \"time for copy_roi using ROI structure: \" &lt;&lt; copy_roi_time &lt;&lt; \" ms\\n\";\n    mat_deep_copy2.print_info();\n    mat_deep_copy2.print_matrix(true);\n\n    // Test 7: Block\n    std::cout &lt;&lt; \"[Test7: Block]\\n\";\n    TinyTimeMark_t tic2 = tiny_get_running_time();\n    tiny::Mat mat_block = matB.block(1, 1, 2, 2);\n    TinyTimeMark_t toc2 = tiny_get_running_time();\n    TinyTimeMark_t block_roi_time = toc2 - tic2;\n    std::cout &lt;&lt; \"time for block: \" &lt;&lt; block_roi_time &lt;&lt; \" ms\\n\";\n    mat_block.print_info();\n    mat_block.print_matrix(true);\n\n    // swap rows\n    std::cout &lt;&lt; \"[Test7: Swap Rows]\\n\";\n    std::cout &lt;&lt; \"matB before swap:\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"matB after swap:\\n\";\n    matB.swap_rows(0, 2);\n    matB.print_info();\n    matB.print_matrix(true);\n\n    // clear function\n    std::cout &lt;&lt; \"[Test8: Clear]\\n\";\n    std::cout &lt;&lt; \"matB before clear:\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"matB after clear:\\n\";\n    matB.clear();\n    matB.print_info();\n    matB.print_matrix(true);\n}\n\n// Group 4: arithmetic operators\n// void test_arithmetic_operators()\n// {\n//     std::cout &lt;&lt; \"\\n[Arithmetic Operators Test Start]\\n\";\n\n//     /*** Test1: Assignment Operator ***/\n//     std::cout &lt;&lt; \"\\n[Test 1.1] Assignment (Same Dimensions)\\n\";\n//     tiny::Mat assignMat_1_1_dst(2, 3);\n//     tiny::Mat assignMat_1_1_src(2, 3);\n//     for (int i = 0; i &lt; 2; ++i)\n//         for (int j = 0; j &lt; 3; ++j)\n//             assignMat_1_1_src(i, j) = static_cast&lt;float&gt;(i * 3 + j + 1);\n//     assignMat_1_1_dst = assignMat_1_1_src;\n//     assignMat_1_1_dst.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 1.2] Assignment (Different Dimensions)\\n\";\n//     tiny::Mat assignMat_1_2_dst(4, 2);\n//     assignMat_1_2_dst = assignMat_1_1_src;\n//     assignMat_1_2_dst.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 1.3] Assignment to Sub-Matrix (Expect Error)\\n\";\n//     float data_1_3[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n//     tiny::Mat baseMat_1_3(data_1_3, 3, 4, 5);\n//     tiny::Mat subView_1_3 = baseMat_1_3.view_roi(1, 1, 2, 2);\n//     subView_1_3 = assignMat_1_1_src;\n//     subView_1_3.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 1.4] Self-Assignment\\n\";\n//     assignMat_1_1_src = assignMat_1_1_src;\n//     assignMat_1_1_src.print_matrix(true);\n\n//     /*** Test2: Matrix Addition ***/\n//     std::cout &lt;&lt; \"\\n[Test 2.1] Matrix Addition (Same Dimensions)\\n\";\n//     tiny::Mat addMat_2_1_A(2, 3);\n//     tiny::Mat addMat_2_1_B(2, 3);\n//     for (int i = 0; i &lt; 2; ++i)\n//         for (int j = 0; j &lt; 3; ++j)\n//         {\n//             addMat_2_1_A(i, j) = static_cast&lt;float&gt;(i * 3 + j + 1);\n//             addMat_2_1_B(i, j) = 1.0f;\n//         }\n//     addMat_2_1_A += addMat_2_1_B;\n//     addMat_2_1_A.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 2.2] Sub-Matrix Addition\\n\";\n//     float data_2_2[20] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0, 12, 13, 14, 15, 0};\n//     tiny::Mat baseMat_2_2(data_2_2, 4, 4, 5);\n//     tiny::Mat subView_2_2_A = baseMat_2_2.view_roi(1, 1, 2, 2);\n//     tiny::Mat subView_2_2_B = baseMat_2_2.view_roi(1, 1, 2, 2);\n//     subView_2_2_A += subView_2_2_B;\n//     subView_2_2_A.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 2.3] Full Matrix + Sub-Matrix Addition\\n\";\n//     tiny::Mat addMat_2_3(2, 2);\n//     for (int i = 0; i &lt; 2; ++i)\n//         for (int j = 0; j &lt; 2; ++j)\n//             addMat_2_3(i, j) = 2.0f;\n//     addMat_2_3 += subView_2_2_B;\n//     addMat_2_3.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 2.4] Addition Dimension Mismatch (Expect Error)\\n\";\n//     tiny::Mat addMat_2_4_wrongDim(3, 3);\n//     addMat_2_3 += addMat_2_4_wrongDim;\n\n//     /*** Test3: Constant Addition ***/\n//     std::cout &lt;&lt; \"\\n[Test 3.1] Full Matrix + Constant\\n\";\n//     tiny::Mat addConstMat_3_1(2, 3);\n//     for (int i = 0; i &lt; 2; ++i)\n//         for (int j = 0; j &lt; 3; ++j)\n//             addConstMat_3_1(i, j) = static_cast&lt;float&gt;(i * 3 + j);\n//     addConstMat_3_1 += 5.0f;\n//     addConstMat_3_1.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 3.2] Sub-Matrix + Constant\\n\";\n//     float data_3_2[20] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0, 12, 13, 14, 15, 0};\n//     tiny::Mat baseMat_3_2(data_3_2, 4, 4, 5);\n//     tiny::Mat subView_3_2 = baseMat_3_2.view_roi(1, 1, 2, 2);\n//     subView_3_2 += 3.0f;\n//     subView_3_2.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 3.3] Add Zero to Matrix\\n\";\n//     tiny::Mat addConstMat_3_3(2, 2);\n//     addConstMat_3_3(0, 0) = 1;\n//     addConstMat_3_3(0, 1) = 2;\n//     addConstMat_3_3(1, 0) = 3;\n//     addConstMat_3_3(1, 1) = 4;\n//     addConstMat_3_3 += 0.0f;\n//     addConstMat_3_3.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 3.4] Add Negative Constant\\n\";\n//     tiny::Mat addConstMat_3_4(2, 2);\n//     addConstMat_3_4(0, 0) = 10;\n//     addConstMat_3_4(0, 1) = 20;\n//     addConstMat_3_4(1, 0) = 30;\n//     addConstMat_3_4(1, 1) = 40;\n//     addConstMat_3_4 += -15.0f;\n//     addConstMat_3_4.print_matrix(true);\n\n//     /*** Test4: Matrix Subtraction ***/\n//     std::cout &lt;&lt; \"\\n[Test 4.1] Matrix Subtraction\\n\";\n//     tiny::Mat subMat_4_1_A(2, 2);\n//     tiny::Mat subMat_4_1_B(2, 2);\n//     subMat_4_1_A(0, 0) = 5;\n//     subMat_4_1_A(0, 1) = 7;\n//     subMat_4_1_A(1, 0) = 9;\n//     subMat_4_1_A(1, 1) = 11;\n//     subMat_4_1_B(0, 0) = 1;\n//     subMat_4_1_B(0, 1) = 2;\n//     subMat_4_1_B(1, 0) = 3;\n//     subMat_4_1_B(1, 1) = 4;\n//     subMat_4_1_A -= subMat_4_1_B;\n//     subMat_4_1_A.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 4.2] Subtraction Dimension Mismatch (Expect Error)\\n\";\n//     tiny::Mat subMat_4_2_wrong(3, 3);\n//     subMat_4_1_A -= subMat_4_2_wrong;\n\n//     /*** Test5: Constant Subtraction ***/\n//     std::cout &lt;&lt; \"\\n[Test 5.1] Full Matrix - Constant\\n\";\n//     tiny::Mat subConstMat_5_1(2, 3);\n//     for (int i = 0; i &lt; 2; ++i)\n//         for (int j = 0; j &lt; 3; ++j)\n//             subConstMat_5_1(i, j) = static_cast&lt;float&gt;(i * 3 + j + 1);\n//     subConstMat_5_1 -= 2.0f;\n//     subConstMat_5_1.print_matrix(true);\n\n//     std::cout &lt;&lt; \"\\n[Test 5.2] Sub-Matrix - Constant\\n\";\n//     float data_5_2[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n//     tiny::Mat baseMat_5_2(data_5_2, 3, 4, 5);\n//     tiny::Mat subView_5_2 = baseMat_5_2.view_roi(1, 1, 2, 2);\n//     subView_5_2 -= 1.5f;\n//     subView_5_2.print_matrix(true);\n\n//     /*** Test6: Matrix Element-wise Division ***/\n//     std::cout &lt;&lt; \"\\n[Test6: Operator /= (Matrix)]\\n\";\n\n//     // Test 6.1: Standard element-wise division\n//     std::cout &lt;&lt; \"\\n[Test 6.1] Element-wise division (no zero, same dimensions)\\n\";\n//     tiny::Mat divMat_6_1_A(2, 2);\n//     tiny::Mat divMat_6_1_B(2, 2);\n\n//     // Initialize matrices\n//     divMat_6_1_A(0, 0) = 10;\n//     divMat_6_1_A(0, 1) = 20;\n//     divMat_6_1_A(1, 0) = 30;\n//     divMat_6_1_A(1, 1) = 40;\n\n//     divMat_6_1_B(0, 0) = 2;\n//     divMat_6_1_B(0, 1) = 4;\n//     divMat_6_1_B(1, 0) = 5;\n//     divMat_6_1_B(1, 1) = 8;\n\n//     divMat_6_1_A /= divMat_6_1_B;\n//     divMat_6_1_A.print_matrix(true);\n\n//     // Test 6.2: Dimension mismatch\n//     std::cout &lt;&lt; \"\\n[Test 6.2] Division with dimension mismatch (expect error)\\n\";\n//     tiny::Mat divMat_6_2_wrong(3, 3);\n//     divMat_6_1_A /= divMat_6_2_wrong;\n\n//     // Test 6.3: Division by zero detection\n//     std::cout &lt;&lt; \"\\n[Test 6.3] Division by matrix containing zero (expect error)\\n\";\n//     tiny::Mat divMat_6_3_A(2, 2);\n//     tiny::Mat divMat_6_3_B(2, 2);\n\n//     divMat_6_3_A(0, 0) = 5;\n//     divMat_6_3_A(0, 1) = 10;\n//     divMat_6_3_A(1, 0) = 15;\n//     divMat_6_3_A(1, 1) = 20;\n\n//     divMat_6_3_B(0, 0) = 1;\n//     divMat_6_3_B(0, 1) = 0; // Contains zero\n//     divMat_6_3_B(1, 0) = 3;\n//     divMat_6_3_B(1, 1) = 4;\n\n//     divMat_6_3_A /= divMat_6_3_B;\n//     divMat_6_3_A.print_matrix(true); // Should remain unchanged\n\n//     /*** Test7: Matrix Division by Constant ***/\n//     std::cout &lt;&lt; \"\\n[Test7: Operator /= (Constant)]\\n\";\n\n//     // Test 7.1: Standard division by positive constant\n//     std::cout &lt;&lt; \"\\n[Test 7.1] Divide full matrix by positive constant\\n\";\n//     tiny::Mat divConstMat_7_1(2, 3);\n//     for (int i = 0; i &lt; 2; ++i)\n//         for (int j = 0; j &lt; 3; ++j)\n//             divConstMat_7_1(i, j) = static_cast&lt;float&gt;((i * 3 + j + 2)); // Avoid zero\n\n//     divConstMat_7_1 /= 2.0f;\n//     divConstMat_7_1.print_matrix(true);\n\n//     // Test 7.2: Division by negative constant\n//     std::cout &lt;&lt; \"\\n[Test 7.2] Divide matrix by negative constant\\n\";\n//     tiny::Mat divConstMat_7_2(2, 2);\n//     divConstMat_7_2(0, 0) = 6;\n//     divConstMat_7_2(0, 1) = 12;\n//     divConstMat_7_2(1, 0) = 18;\n//     divConstMat_7_2(1, 1) = 24;\n\n//     divConstMat_7_2 /= -3.0f;\n//     divConstMat_7_2.print_matrix(true);\n\n//     // Test 7.3: Division by zero (expect error)\n//     std::cout &lt;&lt; \"\\n[Test 7.3] Division by zero constant (expect error)\\n\";\n//     tiny::Mat divConstMat_7_3(2, 2);\n//     divConstMat_7_3(0, 0) = 1;\n//     divConstMat_7_3(0, 1) = 2;\n//     divConstMat_7_3(1, 0) = 3;\n//     divConstMat_7_3(1, 1) = 4;\n\n//     divConstMat_7_3 /= 0.0f;\n//     divConstMat_7_3.print_matrix(true); // Should remain unchanged\n\n//     /*** Test8: Matrix Element-wise Exponentiation ***/\n//     std::cout &lt;&lt; \"\\n[Test8: Operator ^ (Element-wise Exponentiation)]\\n\";\n\n//     // Test 8.1: Positive exponent (Square)\n//     std::cout &lt;&lt; \"\\n[Test 8.1] Raise each element to power of 2\\n\";\n//     tiny::Mat expMat_8_1(2, 2);\n//     expMat_8_1(0, 0) = 2;\n//     expMat_8_1(0, 1) = 3;\n//     expMat_8_1(1, 0) = 4;\n//     expMat_8_1(1, 1) = 5;\n\n//     tiny::Mat result_8_1 = expMat_8_1 ^ 2;\n//     result_8_1.print_matrix(true);\n\n//     // Test 8.2: Exponent = 0\n//     std::cout &lt;&lt; \"\\n[Test 8.2] Raise each element to power of 0\\n\";\n//     tiny::Mat expMat_8_2(2, 2);\n//     expMat_8_2(0, 0) = 7;\n//     expMat_8_2(0, 1) = -3;\n//     expMat_8_2(1, 0) = 0.5f;\n//     expMat_8_2(1, 1) = 10;\n\n//     tiny::Mat result_8_2 = expMat_8_2 ^ 0;\n//     result_8_2.print_matrix(true); // Expected: all 1\n\n//     // Test 8.3: Exponent = 1\n//     std::cout &lt;&lt; \"\\n[Test 8.3] Raise each element to power of 1\\n\";\n//     tiny::Mat expMat_8_3(2, 2);\n//     expMat_8_3(0, 0) = 9;\n//     expMat_8_3(0, 1) = 8;\n//     expMat_8_3(1, 0) = 7;\n//     expMat_8_3(1, 1) = 6;\n\n//     tiny::Mat result_8_3 = expMat_8_3 ^ 1;\n//     result_8_3.print_matrix(true); // Expected: same as original\n\n//     // Test 8.4: Negative exponent (if supported)\n//     std::cout &lt;&lt; \"\\n[Test 8.4] Raise each element to power of -1 (Expect reciprocal if supported)\\n\";\n//     tiny::Mat expMat_8_4(2, 2);\n//     expMat_8_4(0, 0) = 1;\n//     expMat_8_4(0, 1) = 2;\n//     expMat_8_4(1, 0) = 4;\n//     expMat_8_4(1, 1) = 5;\n\n//     tiny::Mat result_8_4 = expMat_8_4 ^ -1;\n//     result_8_4.print_matrix(true); // Depends on expHelper behavior\n\n//     // Test 8.5: Matrix contains zero, exponent = 3\n//     std::cout &lt;&lt; \"\\n[Test 8.5] Raise matrix containing zero to power of 3\\n\";\n//     tiny::Mat expMat_8_5(2, 2);\n//     expMat_8_5(0, 0) = 0;\n//     expMat_8_5(0, 1) = 2;\n//     expMat_8_5(1, 0) = -1;\n//     expMat_8_5(1, 1) = 3;\n\n//     tiny::Mat result_8_5 = expMat_8_5 ^ 3;\n//     result_8_5.print_matrix(true); // Expected: 0^3=0, others normal\n\n//     std::cout &lt;&lt; \"\\n[Arithmetic Operators Test End]\\n\";\n// }\n\n// Test 4.1\nvoid test_assignment_operator()\n{\n    std::cout &lt;&lt; \"\\n[Assignment Operator Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[Test 1.1] Assignment (Same Dimensions)\\n\";\n    tiny::Mat dst(2, 3), src(2, 3);\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            src(i, j) = static_cast&lt;float&gt;(i * 3 + j + 1);\n    dst = src;\n    dst.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 1.2] Assignment (Different Dimensions)\\n\";\n    tiny::Mat dst2(4, 2);\n    dst2 = src;\n    dst2.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 1.3] Assignment to Sub-Matrix (Expect Error)\\n\";\n    float data[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n    tiny::Mat base(data, 3, 4, 5);\n    tiny::Mat subView = base.view_roi(1, 1, 2, 2);\n    subView = src;\n    subView.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 1.4] Self-Assignment\\n\";\n    src = src;\n    src.print_matrix(true);\n}\n\n// Test 4.2\nvoid test_matrix_addition()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Addition Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[Test 2.1] Matrix Addition (Same Dimensions)\\n\";\n    tiny::Mat A(2, 3), B(2, 3);\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n        {\n            A(i, j) = static_cast&lt;float&gt;(i * 3 + j + 1);\n            B(i, j) = 1.0f;\n        }\n    A += B;\n    A.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 2.2] Sub-Matrix Addition\\n\";\n    float data[20] = {0,1,2,3,0,4,5,6,7,0,8,9,10,11,0,12,13,14,15,0};\n    tiny::Mat base(data, 4, 4, 5);\n    tiny::Mat subA = base.view_roi(1,1,2,2);\n    tiny::Mat subB = base.view_roi(1,1,2,2);\n    subA += subB;\n    subA.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 2.3] Full Matrix + Sub-Matrix Addition\\n\";\n    tiny::Mat full(2,2);\n    for(int i=0;i&lt;2;++i) for(int j=0;j&lt;2;++j) full(i,j)=2.0f;\n    full += subB;\n    full.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 2.4] Addition Dimension Mismatch (Expect Error)\\n\";\n    tiny::Mat wrongDim(3,3);\n    full += wrongDim;\n}\n\n// Test 4.3\nvoid test_constant_addition()\n{\n    std::cout &lt;&lt; \"\\n[Constant Addition Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[Test 3.1] Full Matrix + Constant\\n\";\n    tiny::Mat mat1(2,3);\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat1(i,j) = static_cast&lt;float&gt;(i*3 + j);\n    mat1 += 5.0f;\n    mat1.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 3.2] Sub-Matrix + Constant\\n\";\n    float data[20] = {0,1,2,3,0,4,5,6,7,0,8,9,10,11,0,12,13,14,15,0};\n    tiny::Mat base(data,4,4,5);\n    tiny::Mat sub = base.view_roi(1,1,2,2);\n    sub += 3.0f;\n    sub.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 3.3] Add Zero\\n\";\n    tiny::Mat mat2(2,2);\n    mat2(0,0)=1; mat2(0,1)=2; mat2(1,0)=3; mat2(1,1)=4;\n    mat2 += 0.0f;\n    mat2.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 3.4] Add Negative Constant\\n\";\n    tiny::Mat mat3(2,2);\n    mat3(0,0)=10; mat3(0,1)=20; mat3(1,0)=30; mat3(1,1)=40;\n    mat3 += -15.0f;\n    mat3.print_matrix(true);\n}\n\n// Test 4.4\nvoid test_matrix_subtraction()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Subtraction Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[Test 4.1] Matrix Subtraction\\n\";\n    tiny::Mat A(2,2), B(2,2);\n    A(0,0)=5; A(0,1)=7; A(1,0)=9; A(1,1)=11;\n    B(0,0)=1; B(0,1)=2; B(1,0)=3; B(1,1)=4;\n    A -= B;\n    A.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 4.2] Subtraction Dimension Mismatch\\n\";\n    tiny::Mat wrong(3,3);\n    A -= wrong;\n}\n\n// Test 4.5\nvoid test_constant_subtraction()\n{\n    std::cout &lt;&lt; \"\\n[Constant Subtraction Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[Test 5.1] Full Matrix - Constant\\n\";\n    tiny::Mat mat(2,3);\n    for (int i=0;i&lt;2;++i) for(int j=0;j&lt;3;++j) mat(i,j) = i*3+j+1;\n    mat -= 2.0f;\n    mat.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 5.2] Sub-Matrix - Constant\\n\";\n    float data[15] = {0,1,2,3,0,4,5,6,7,0,8,9,10,11,0};\n    tiny::Mat base(data,3,4,5);\n    tiny::Mat sub = base.view_roi(1,1,2,2);\n    sub -= 1.5f;\n    sub.print_matrix(true);\n}\n\n// Test 4.6\nvoid test_matrix_division()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Element-wise Division Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[Test 6.1] Element-wise division (same dimensions, no zero)\\n\";\n    tiny::Mat A(2, 2), B(2, 2);\n    A(0,0) = 10; A(0,1) = 20; A(1,0) = 30; A(1,1) = 40;\n    B(0,0) = 2;  B(0,1) = 4;  B(1,0) = 5;  B(1,1) = 8;\n    A /= B;\n    A.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 6.2] Dimension mismatch (expect error)\\n\";\n    tiny::Mat wrongDim(3, 3);\n    A /= wrongDim;\n\n    std::cout &lt;&lt; \"\\n[Test 6.3] Division by matrix containing zero (expect error)\\n\";\n    tiny::Mat C(2, 2), D(2, 2);\n    C(0,0)=5; C(0,1)=10; C(1,0)=15; C(1,1)=20;\n    D(0,0)=1; D(0,1)=0;  D(1,0)=3;  D(1,1)=4;  // Contains zero\n    C /= D;\n    C.print_matrix(true);  // Should remain unchanged\n}\n\n// Test 4.7\nvoid test_constant_division()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Division by Constant Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[Test 7.1] Divide full matrix by positive constant\\n\";\n    tiny::Mat mat1(2, 3);\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat1(i, j) = static_cast&lt;float&gt;(i * 3 + j + 2);  // Avoid zero\n    mat1 /= 2.0f;\n    mat1.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 7.2] Divide matrix by negative constant\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0,0)=6; mat2(0,1)=12; mat2(1,0)=18; mat2(1,1)=24;\n    mat2 /= -3.0f;\n    mat2.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 7.3] Division by zero constant (expect error)\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0,0)=1; mat3(0,1)=2; mat3(1,0)=3; mat3(1,1)=4;\n    mat3 /= 0.0f;\n    mat3.print_matrix(true);  // Should remain unchanged\n}\n\n// Test 4.8\nvoid test_matrix_exponentiation()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Exponentiation Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[Test 8.1] Raise each element to power of 2\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0,0)=2; mat1(0,1)=3; mat1(1,0)=4; mat1(1,1)=5;\n    tiny::Mat result1 = mat1 ^ 2;\n    result1.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 8.2] Raise each element to power of 0\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0,0)=7; mat2(0,1)=-3; mat2(1,0)=0.5f; mat2(1,1)=10;\n    tiny::Mat result2 = mat2 ^ 0;\n    result2.print_matrix(true);  // Expect all 1\n\n    std::cout &lt;&lt; \"\\n[Test 8.3] Raise each element to power of 1\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0,0)=9; mat3(0,1)=8; mat3(1,0)=7; mat3(1,1)=6;\n    tiny::Mat result3 = mat3 ^ 1;\n    result3.print_matrix(true);  // Expect same as original\n\n    std::cout &lt;&lt; \"\\n[Test 8.4] Raise each element to power of -1 (expect error or warning)\\n\";\n    tiny::Mat mat4(2, 2);\n    mat4(0,0)=1; mat4(0,1)=2; mat4(1,0)=4; mat4(1,1)=5;\n    tiny::Mat result4 = mat4 ^ -1;\n    result4.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[Test 8.5] Raise matrix containing zero to power of 3\\n\";\n    tiny::Mat mat5(2, 2);\n    mat5(0,0)=0; mat5(0,1)=2; mat5(1,0)=-1; mat5(1,1)=3;\n    tiny::Mat result5 = mat5 ^ 3;\n    result5.print_matrix(true);\n}\n\n// Group 5: Linear Algebra\n// Test 5.1 Transpose\nvoid test_matrix_transpose()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Transpose Test]\\n\";\n\n    // Test 1: Basic 2x3 matrix transpose\n    std::cout &lt;&lt; \"\\n[Test 1] Transpose of 2x3 Matrix\\n\";\n    tiny::Mat mat1(2, 3);\n    int val = 1;\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat1(i, j) = val++;\n\n    std::cout &lt;&lt; \"Original 2x3 Matrix:\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat transposed1 = mat1.transpose();\n    std::cout &lt;&lt; \"Transposed 3x2 Matrix:\\n\";\n    transposed1.print_matrix(true);\n\n    // Test 2: Square matrix transpose (3x3)\n    std::cout &lt;&lt; \"\\n[Test 2] Transpose of 3x3 Square Matrix\\n\";\n    tiny::Mat mat2(3, 3);\n    val = 1;\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat2(i, j) = val++;\n\n    std::cout &lt;&lt; \"Original 3x3 Matrix:\\n\";\n    mat2.print_matrix(true);\n\n    tiny::Mat transposed2 = mat2.transpose();\n    std::cout &lt;&lt; \"Transposed 3x3 Matrix:\\n\";\n    transposed2.print_matrix(true);\n\n    // Test 3: Matrix with padding (4x2, stride=3)\n    std::cout &lt;&lt; \"\\n[Test 3] Transpose of Matrix with Padding\\n\";\n    float data[12] = {1, 2, 0, 3, 4, 0, 5, 6, 0, 7, 8, 0};  // stride=3, 4 rows\n    tiny::Mat mat3(data, 4, 2, 3);\n    std::cout &lt;&lt; \"Original 4x2 Matrix (with padding):\\n\";\n    mat3.print_matrix(true);\n\n    tiny::Mat transposed3 = mat3.transpose();\n    std::cout &lt;&lt; \"Transposed 2x4 Matrix:\\n\";\n    transposed3.print_matrix(true);\n\n    // Test 4: Transpose of empty matrix\n    std::cout &lt;&lt; \"\\n[Test 4] Transpose of Empty Matrix\\n\";\n    tiny::Mat mat4;\n    mat4.print_matrix(true);\n\n    tiny::Mat transposed4 = mat4.transpose();\n    transposed4.print_matrix(true);\n}\n\n// Test 5.2 cofactor calculation - prepare the matrix for cofactor calculation\nvoid test_matrix_cofactor()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Cofactor Test]\\n\";\n\n    // Test 1: 3x3 Matrix - Standard Case\n    std::cout &lt;&lt; \"\\n[Test 1] Cofactor of 3x3 Matrix (remove row 1, col 1)\\n\";\n    tiny::Mat mat1(3, 3);\n    int val = 1;\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat1(i, j) = val++;\n\n    std::cout &lt;&lt; \"Original 3x3 Matrix:\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat cof1 = mat1.cofactor(1, 1);\n    std::cout &lt;&lt; \"Cofactor Matrix (remove row 1, col 1):\\n\";\n    cof1.print_matrix(true);  // Expected: [[1,3],[7,9]]\n\n    // Test 2: Remove first row and first column\n    std::cout &lt;&lt; \"\\n[Test 2] Remove row 0, col 0\\n\";\n    tiny::Mat cof2 = mat1.cofactor(0, 0);\n    cof2.print_matrix(true);  // Expected: [[5,6],[8,9]]\n\n    // Test 3: Remove last row and last column\n    std::cout &lt;&lt; \"\\n[Test 3] Remove row 2, col 2\\n\";\n    tiny::Mat cof3 = mat1.cofactor(2, 2);\n    cof3.print_matrix(true);  // Expected: [[1,2],[4,5]]\n\n    // Test 4: 4x4 Matrix Example\n    std::cout &lt;&lt; \"\\n[Test 4] Cofactor of 4x4 Matrix (remove row 2, col 1)\\n\";\n    tiny::Mat mat4(4, 4);\n    val = 1;\n    for (int i = 0; i &lt; 4; ++i)\n        for (int j = 0; j &lt; 4; ++j)\n            mat4(i, j) = val++;\n\n    mat4.print_matrix(true);\n    tiny::Mat cof4 = mat4.cofactor(2, 1);\n    std::cout &lt;&lt; \"Cofactor Matrix:\\n\";\n    cof4.print_matrix(true);\n\n    // Test 5: Non-square Matrix (Expect Error)\n    std::cout &lt;&lt; \"\\n[Test 5] Non-square Matrix (Expect Error)\\n\";\n    tiny::Mat rectMat(3, 4);\n    rectMat.cofactor(1, 1).print_matrix(true);  // Should trigger error and return empty matrix\n}\n\n// Test 5.3 determinant calculation\nvoid test_matrix_determinant()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Determinant Test Start]\\n\";\n\n    /*** Test 1: 1x1 Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 1] 1x1 Matrix Determinant\\n\";\n    tiny::Mat mat1(1, 1);\n    mat1(0, 0) = 7;\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; mat1.determinant() &lt;&lt; \"  (Expected: 7)\\n\";\n\n    /*** Test 2: 2x2 Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 2] 2x2 Matrix Determinant\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0, 0) = 3; mat2(0, 1) = 8;\n    mat2(1, 0) = 4; mat2(1, 1) = 6;\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; mat2.determinant() &lt;&lt; \"  (Expected: -14)\\n\";\n\n    /*** Test 3: 3x3 Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 3] 3x3 Matrix Determinant\\n\";\n    tiny::Mat mat3(3, 3);\n    mat3(0,0) = 1; mat3(0,1) = 2; mat3(0,2) = 3;\n    mat3(1,0) = 0; mat3(1,1) = 4; mat3(1,2) = 5;\n    mat3(2,0) = 1; mat3(2,1) = 0; mat3(2,2) = 6;\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; mat3.determinant() &lt;&lt; \"  (Expected: 22)\\n\";\n\n    /*** Test 4: 4x4 Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 4] 4x4 Matrix Determinant\\n\";\n    tiny::Mat mat4(4, 4);\n    int val = 1;\n    for (int i = 0; i &lt; 4; ++i)\n        for (int j = 0; j &lt; 4; ++j)\n            mat4(i, j) = val++;\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; mat4.determinant() &lt;&lt; \"  (Expected: 0)\\n\";  \n\n    /*** Test 5: Non-square Matrix (Expect Error) ***/\n    std::cout &lt;&lt; \"\\n[Test 5] Non-square Matrix (Expect Error)\\n\";\n    tiny::Mat rectMat(3, 4);\n    float det_rect = rectMat.determinant();  // should trigger error\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; det_rect &lt;&lt; \"  (Expected: 0 with error message)\\n\";\n\n    std::cout &lt;&lt; \"\\n[Matrix Determinant Test End]\\n\";\n}\n\n// Test 5.4 adjoint calculation\nvoid test_matrix_adjoint()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Adjoint Test Start]\\n\";\n\n    /*** Test 1: 1x1 Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 1] Adjoint of 1x1 Matrix\\n\";\n    tiny::Mat mat1(1, 1);\n    mat1(0, 0) = 5;\n    tiny::Mat adj1 = mat1.adjoint();\n    adj1.print_matrix(true);  // Expected: [1]\n\n    /*** Test 2: 2x2 Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 2] Adjoint of 2x2 Matrix\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0, 0) = 1; mat2(0, 1) = 2;\n    mat2(1, 0) = 3; mat2(1, 1) = 4;\n    tiny::Mat adj2 = mat2.adjoint();\n    adj2.print_matrix(true);  // Expected: [4, -2; -3, 1]\n\n    /*** Test 3: 3x3 Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 3] Adjoint of 3x3 Matrix\\n\";\n    tiny::Mat mat3(3, 3);\n    mat3(0,0) = 1; mat3(0,1) = 2; mat3(0,2) = 3;\n    mat3(1,0) = 0; mat3(1,1) = 4; mat3(1,2) = 5;\n    mat3(2,0) = 1; mat3(2,1) = 0; mat3(2,2) = 6;\n    tiny::Mat adj3 = mat3.adjoint();\n    adj3.print_matrix(true);\n    // No simple expected value, but should compute correctly\n\n    /*** Test 4: Non-Square Matrix (Expect Error) ***/\n    std::cout &lt;&lt; \"\\n[Test 4] Adjoint of Non-Square Matrix (Expect Error)\\n\";\n    tiny::Mat rectMat(2, 3);\n    tiny::Mat adjRect = rectMat.adjoint();\n    adjRect.print_matrix(true);  // Should be empty or default matrix\n\n    std::cout &lt;&lt; \"\\n[Matrix Adjoint Test End]\\n\";\n}\n\n// Test 5.5 normalization function\nvoid test_matrix_normalize()\n{\n    std::cout &lt;&lt; \"\\n[Test: Matrix Normalization]\\n\";\n\n    /*** Test 1: Standard normalization ***/\n    std::cout &lt;&lt; \"\\n[Test 1] Normalize a standard 2x2 matrix\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0, 0) = 3.0f; mat1(0, 1) = 4.0f;\n    mat1(1, 0) = 3.0f; mat1(1, 1) = 4.0f;\n\n    std::cout &lt;&lt; \"Before normalization:\\n\";\n    mat1.print_matrix(true);\n\n    mat1.normalize();\n\n    std::cout &lt;&lt; \"After normalization (Expected L2 norm = 1):\\n\";\n    mat1.print_matrix(true);\n\n    /*** Test 2: Matrix with padding ***/\n    std::cout &lt;&lt; \"\\n[Test 2] Normalize a 2x2 matrix with stride=4 (Padding Test)\\n\";\n    float data_with_padding[8] = {3.0f, 4.0f, 0.0f, 0.0f, 3.0f, 4.0f, 0.0f, 0.0f};\n    tiny::Mat mat2(data_with_padding, 2, 2, 4);  // 2x2 matrix, stride 4\n\n    std::cout &lt;&lt; \"Before normalization:\\n\";\n    mat2.print_matrix(true);\n\n    mat2.normalize();\n\n    std::cout &lt;&lt; \"After normalization:\\n\";\n    mat2.print_matrix(true);\n\n    /*** Test 3: Zero matrix normalization ***/\n    std::cout &lt;&lt; \"\\n[Test 3] Normalize a zero matrix (Expect warning)\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3.clear();  // Assuming clear() sets all elements to zero\n\n    mat3.print_matrix(true);\n    mat3.normalize();  // Should trigger warning\n}\n\n// Test 5.6: Matrix Norm Calculation\nvoid test_matrix_norm()\n{\n    std::cout &lt;&lt; \"\\n[Test: Matrix Norm Calculation]\\n\";\n\n    /*** Test 1: Simple 2x2 Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 1] 2x2 Matrix Norm (Expect 5.0)\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0, 0) = 3.0f; mat1(0, 1) = 4.0f;\n    mat1(1, 0) = 0.0f; mat1(1, 1) = 0.0f;\n    float norm1 = mat1.norm();\n    std::cout &lt;&lt; \"Calculated Norm: \" &lt;&lt; norm1 &lt;&lt; \"\\n\";\n\n    /*** Test 2: Zero Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 2] Zero Matrix Norm (Expect 0.0)\\n\";\n    tiny::Mat mat2(3, 3);\n    mat2.clear();  // Assuming clear() sets all elements to zero\n    float norm2 = mat2.norm();\n    std::cout &lt;&lt; \"Calculated Norm: \" &lt;&lt; norm2 &lt;&lt; \"\\n\";\n\n    /*** Test 3: Matrix with Negative Values ***/\n    std::cout &lt;&lt; \"\\n[Test 3] Matrix with Negative Values\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0, 0) = -1.0f; mat3(0, 1) = -2.0f;\n    mat3(1, 0) = -3.0f; mat3(1, 1) = -4.0f;\n    float norm3 = mat3.norm();\n    std::cout &lt;&lt; \"Calculated Norm: \" &lt;&lt; norm3 &lt;&lt; \"  (Expect sqrt(30) \u2248 5.477)\\n\";\n\n    /*** Test 4: Matrix with Padding ***/\n    std::cout &lt;&lt; \"\\n[Test 4] 2x2 Matrix with Stride=4 (Padding Test)\\n\";\n    float data4[8] = {1.0f, 2.0f, 0.0f, 0.0f, 3.0f, 4.0f, 0.0f, 0.0f};\n    tiny::Mat mat4(data4, 2, 2, 4);  // 2x2 matrix, stride 4\n    float norm4 = mat4.norm();\n    std::cout &lt;&lt; \"Calculated Norm: \" &lt;&lt; norm4 &lt;&lt; \"  (Expect sqrt(30) \u2248 5.477)\\n\";\n}\n\n// Test 5.7: Matrix Inversion\nvoid test_inverse_adjoint_adjoint()\n{\n    std::cout &lt;&lt; \"\\n[Test: Matrix Inverse Calculation]\\n\";\n\n    /*** Test 1: 2x2 Regular Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 1] Inverse of 2x2 Matrix\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0, 0) = 4;  mat1(0, 1) = 7;\n    mat1(1, 0) = 2;  mat1(1, 1) = 6;\n\n    mat1.print_matrix(true);\n    tiny::Mat inv1 = mat1.inverse_adjoint();\n    std::cout &lt;&lt; \"Inverse Matrix:\\n\";\n    inv1.print_matrix(true);\n    std::cout &lt;&lt; \"Expected Approx:\\n[ 0.6  -0.7 ]\\n[ -0.2  0.4 ]\\n\";\n\n    /*** Test 2: Singular Matrix (Determinant = 0) ***/\n    std::cout &lt;&lt; \"\\n[Test 2] Singular Matrix (Expect Error)\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0, 0) = 1;  mat2(0, 1) = 2;\n    mat2(1, 0) = 2;  mat2(1, 1) = 4;   // Rank-deficient, det = 0\n\n    mat2.print_matrix(true);\n    tiny::Mat inv2 = mat2.inverse_adjoint();\n    std::cout &lt;&lt; \"Inverse Matrix (Should be zero matrix):\\n\";\n    inv2.print_matrix(true);\n\n    /*** Test 3: 3x3 Regular Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 3] Inverse of 3x3 Matrix\\n\";\n    tiny::Mat mat3(3, 3);\n    mat3(0,0) = 3; mat3(0,1) = 0; mat3(0,2) = 2;\n    mat3(1,0) = 2; mat3(1,1) = 0; mat3(1,2) = -2;\n    mat3(2,0) = 0; mat3(2,1) = 1; mat3(2,2) = 1;\n\n    mat3.print_matrix(true);\n    tiny::Mat inv3 = mat3.inverse_adjoint();\n    std::cout &lt;&lt; \"Inverse Matrix:\\n\";\n    inv3.print_matrix(true);\n\n    /*** Test 4: Non-Square Matrix (Expect Error) ***/\n    std::cout &lt;&lt; \"\\n[Test 4] Non-Square Matrix (Expect Error)\\n\";\n    tiny::Mat mat4(2, 3);\n    tiny::Mat inv4 = mat4.inverse_adjoint();\n    inv4.print_matrix(true);\n}\n\n// Test 5.8: Matrix Utilities\nvoid test_matrix_utilities()\n{\n    std::cout &lt;&lt; \"\\n[Matrix Utilities Test Start]\\n\";\n\n    /*** Test 1: Identity Matrix (eye) ***/\n    std::cout &lt;&lt; \"\\n[Test 1] Generate Identity Matrix (eye)\\n\";\n    tiny::Mat I3 = tiny::Mat::eye(3);\n    std::cout &lt;&lt; \"3x3 Identity Matrix:\\n\";\n    I3.print_matrix(true);\n\n    tiny::Mat I5 = tiny::Mat::eye(5);\n    std::cout &lt;&lt; \"5x5 Identity Matrix:\\n\";\n    I5.print_matrix(true);\n\n    /*** Test 2: Ones Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 2] Generate Ones Matrix\\n\";\n    tiny::Mat ones_3x4 = tiny::Mat::ones(3, 4);\n    std::cout &lt;&lt; \"3x4 Ones Matrix:\\n\";\n    ones_3x4.print_matrix(true);\n\n    tiny::Mat ones_4x4 = tiny::Mat::ones(4);\n    std::cout &lt;&lt; \"4x4 Ones Matrix (Square):\\n\";\n    ones_4x4.print_matrix(true);\n\n    /*** Test 3: Matrix Augmentation ***/\n    std::cout &lt;&lt; \"\\n[Test 3] Augment Two Matrices Horizontally [A | B]\\n\";\n\n    // Prepare matrices A (2x2) and B (2x3)\n    tiny::Mat A(2, 2);\n    A(0,0) = 1;  A(0,1) = 2;\n    A(1,0) = 3;  A(1,1) = 4;\n\n    tiny::Mat B(2, 3);\n    B(0,0) = 5;  B(0,1) = 6;  B(0,2) = 7;\n    B(1,0) = 8;  B(1,1) = 9;  B(1,2) = 10;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix B:\\n\";\n    B.print_matrix(true);\n\n    tiny::Mat AB = tiny::Mat::augment(A, B);\n    std::cout &lt;&lt; \"Augmented Matrix [A | B]:\\n\";\n    AB.print_matrix(true);\n\n    // Test 3.2: Row mismatch case\n    std::cout &lt;&lt; \"\\n[Test 3.2] Augment with Row Mismatch (Expect Error)\\n\";\n    tiny::Mat C(3, 2);  // 3x2 matrix\n    tiny::Mat invalidAug = tiny::Mat::augment(A, C);\n    invalidAug.print_info();  // Should show empty matrix due to error\n\n    std::cout &lt;&lt; \"\\n[Matrix Utilities Test End]\\n\";\n}\n\n// Test 5.9: Gaussian Elimination\nvoid test_gaussian_eliminate()\n{\n    std::cout &lt;&lt; \"\\n[Gaussian Elimination Test]\\n\";\n\n    /*** Test 1: Simple 3x3 System ***/\n    std::cout &lt;&lt; \"\\n[Test 1] 3x3 Matrix (Simple Upper Triangular)\\n\";\n    tiny::Mat mat1(3, 3);\n    mat1(0,0) = 2; mat1(0,1) = 1; mat1(0,2) = -1;\n    mat1(1,0) = -3; mat1(1,1) = -1; mat1(1,2) = 2;\n    mat1(2,0) = -2; mat1(2,1) = 1; mat1(2,2) = 2;\n\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat result1 = mat1.gaussian_eliminate();\n\n    std::cout &lt;&lt; \"After Gaussian Elimination (Should be upper triangular):\\n\";\n    result1.print_matrix(true);\n\n    /*** Test 2: 3x4 Augmented Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 2] 3x4 Augmented Matrix (Linear System Ax = b)\\n\";\n    tiny::Mat mat2(3, 4);\n    mat2(0,0) = 1; mat2(0,1) = 2; mat2(0,2) = -1; mat2(0,3) =  8;\n    mat2(1,0) = -3; mat2(1,1) = -1; mat2(1,2) = 2; mat2(1,3) = -11;\n    mat2(2,0) = -2; mat2(2,1) = 1; mat2(2,2) = 2; mat2(2,3) = -3;\n\n    std::cout &lt;&lt; \"Original Augmented Matrix [A | b]:\\n\";\n    mat2.print_matrix(true);\n\n    tiny::Mat result2 = mat2.gaussian_eliminate();\n\n    std::cout &lt;&lt; \"After Gaussian Elimination (Row Echelon Form):\\n\";\n    result2.print_matrix(true);\n\n    /*** Test 3: Singular Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 3] Singular Matrix (No unique solution)\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0,0) = 1; mat3(0,1) = 2;\n    mat3(1,0) = 2; mat3(1,1) = 4;  // Linearly dependent rows\n\n    std::cout &lt;&lt; \"Original Singular Matrix:\\n\";\n    mat3.print_matrix(true);\n\n    tiny::Mat result3 = mat3.gaussian_eliminate();\n    std::cout &lt;&lt; \"After Gaussian Elimination (Should show rows of zeros):\\n\";\n    result3.print_matrix(true);\n\n    /*** Test 4: Zero Matrix ***/\n    std::cout &lt;&lt; \"\\n[Test 4] Zero Matrix\\n\";\n    tiny::Mat mat4(3, 3);\n    mat4.clear();  // Assuming clear() sets all elements to zero\n    mat4.print_matrix(true);\n\n    tiny::Mat result4 = mat4.gaussian_eliminate();\n    std::cout &lt;&lt; \"After Gaussian Elimination (Should be a zero matrix):\\n\";\n    result4.print_matrix(true);\n}\n\n\n// Test 5.10: Row Reduce from Gaussian (RREF Calculation)\nvoid test_row_reduce_from_gaussian()\n{\n    std::cout &lt;&lt; \"\\n[Test] Row Reduce From Gaussian (RREF Calculation)\\n\";\n\n    // Example 1: Simple 3x4 augmented matrix (representing a system of equations)\n    std::cout &lt;&lt; \"\\n[Test 1] 3x4 Augmented Matrix\\n\";\n    tiny::Mat mat1(3, 4);\n\n    // Matrix:\n    // [ 1  2 -1  -4 ]\n    // [ 2  3 -1 -11 ]\n    // [-2  0 -3  22 ]\n    mat1(0,0) = 1;  mat1(0,1) = 2;  mat1(0,2) = -1; mat1(0,3) = -4;\n    mat1(1,0) = 2;  mat1(1,1) = 3;  mat1(1,2) = -1; mat1(1,3) = -11;\n    mat1(2,0) = -2; mat1(2,1) = 0;  mat1(2,2) = -3; mat1(2,3) = 22;\n\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat rref1 = mat1.gaussian_eliminate().row_reduce_from_gaussian();\n    std::cout &lt;&lt; \"RREF Result:\\n\";\n    rref1.print_matrix(true);\n\n    // Example 2: 2x3 Matrix\n    std::cout &lt;&lt; \"\\n[Test 2] 2x3 Matrix\\n\";\n    tiny::Mat mat2(2, 3);\n    mat2(0,0) = 1; mat2(0,1) = 2;  mat2(0,2) = 3;\n    mat2(1,0) = 4; mat2(1,1) = 5;  mat2(1,2) = 6;\n\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat2.print_matrix(true);\n\n    tiny::Mat rref2 = mat2.gaussian_eliminate().row_reduce_from_gaussian();\n    std::cout &lt;&lt; \"RREF Result:\\n\";\n    rref2.print_matrix(true);\n\n    // Example 3: Already reduced matrix (should remain the same)\n    std::cout &lt;&lt; \"\\n[Test 3] Already Reduced Matrix\\n\";\n    tiny::Mat mat3(2, 3);\n    mat3(0,0) = 1; mat3(0,1) = 0; mat3(0,2) = 2;\n    mat3(1,0) = 0; mat3(1,1) = 1; mat3(1,2) = 3;\n\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat3.print_matrix(true);\n\n    tiny::Mat rref3 = mat3.row_reduce_from_gaussian();\n    std::cout &lt;&lt; \"RREF Result:\\n\";\n    rref3.print_matrix(true);\n}\n\n// Test 5.11 gaussian inverse\nvoid test_inverse_gje()\n{\n    std::cout &lt;&lt; \"\\n--- Test: Gaussian Inverse ---\\n\";\n\n    /*** Test1: Regular 2x2 Matrix ***/\n    std::cout &lt;&lt; \"[Test 1: 2x2 Matrix Inverse]\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0, 0) = 4; mat1(0, 1) = 7;\n    mat1(1, 0) = 2; mat1(1, 1) = 6;\n    std::cout &lt;&lt; \"Original matrix (mat1):\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat invMat1 = mat1.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (mat1):\\n\";\n    invMat1.print_matrix(true);\n\n    /*** Test2: Identity Matrix (should return identity matrix) ***/\n    std::cout &lt;&lt; \"[Test 2: Identity Matrix Inverse]\\n\";\n    tiny::Mat mat2 = tiny::Mat::eye(3);\n    std::cout &lt;&lt; \"Original matrix (Identity):\\n\";\n    mat2.print_matrix(true);\n\n    tiny::Mat invMat2 = mat2.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (Identity):\\n\";\n    invMat2.print_matrix(true); // Expected: Identity matrix\n\n    /*** Test3: Singular Matrix (should return empty matrix or indicate error) ***/\n    std::cout &lt;&lt; \"[Test 3: Singular Matrix (Expected: No Inverse)]\\n\";\n    tiny::Mat mat3(3, 3);\n    mat3(0, 0) = 1; mat3(0, 1) = 2; mat3(0, 2) = 3;\n    mat3(1, 0) = 4; mat3(1, 1) = 5; mat3(1, 2) = 6;\n    mat3(2, 0) = 7; mat3(2, 1) = 8; mat3(2, 2) = 9;  // Determinant is 0\n    std::cout &lt;&lt; \"Original matrix (singular):\\n\";\n    mat3.print_matrix(true);\n\n    tiny::Mat invMat3 = mat3.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (singular):\\n\";\n    invMat3.print_matrix(true); // Expected: empty matrix or error message\n\n    /*** Test4: 3x3 Matrix with a valid inverse ***/\n    std::cout &lt;&lt; \"[Test 4: 3x3 Matrix Inverse]\\n\";\n    tiny::Mat mat4(3, 3);\n    mat4(0, 0) = 4; mat4(0, 1) = 7; mat4(0, 2) = 2;\n    mat4(1, 0) = 3; mat4(1, 1) = 5; mat4(1, 2) = 1;\n    mat4(2, 0) = 8; mat4(2, 1) = 6; mat4(2, 2) = 9;\n    std::cout &lt;&lt; \"Original matrix (mat4):\\n\";\n    mat4.print_matrix(true);\n\n    tiny::Mat invMat4 = mat4.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (mat4):\\n\";\n    invMat4.print_matrix(true); // Check that the inverse is calculated correctly\n\n    /*** Test5: Non-square Matrix (should return error or empty matrix) ***/\n    std::cout &lt;&lt; \"[Test 5: Non-square Matrix Inverse (Expected Error)]\\n\";\n    tiny::Mat mat5(2, 3);\n    mat5(0, 0) = 1; mat5(0, 1) = 2; mat5(0, 2) = 3;\n    mat5(1, 0) = 4; mat5(1, 1) = 5; mat5(1, 2) = 6;\n    std::cout &lt;&lt; \"Original matrix (non-square):\\n\";\n    mat5.print_matrix(true);\n\n    tiny::Mat invMat5 = mat5.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (non-square):\\n\";\n    invMat5.print_matrix(true); // Expected: Error message or empty matrix\n}\n\n// Test 5.12: Dot Product\nvoid test_dotprod()\n{\n    std::cout &lt;&lt; \"\\n--- Test: Dot Product ---\\n\";\n\n    // Test 1: Valid Dot Product Calculation (Same Length Vectors)\n    std::cout &lt;&lt; \"[Test 1] Valid Dot Product (Same Length Vectors)\\n\";\n    tiny::Mat vectorA(3, 1);  // Create a 3x1 vector\n    tiny::Mat vectorB(3, 1);  // Create a 3x1 vector\n\n    // Initialize vectors\n    vectorA(0, 0) = 1.0f;\n    vectorA(1, 0) = 2.0f;\n    vectorA(2, 0) = 3.0f;\n\n    vectorB(0, 0) = 4.0f;\n    vectorB(1, 0) = 5.0f;\n    vectorB(2, 0) = 6.0f;\n\n    // Compute the dot product\n    float result = vectorA.dotprod(vectorA, vectorB);\n    std::cout &lt;&lt; \"Dot product of vectorA and vectorB: \" &lt;&lt; result &lt;&lt; std::endl;  // Expected result: 1*4 + 2*5 + 3*6 = 32\n\n    // Test 2: Dot Product with Dimension Mismatch (Different Length Vectors)\n    std::cout &lt;&lt; \"[Test 2] Invalid Dot Product (Dimension Mismatch)\\n\";\n    tiny::Mat vectorC(2, 1);  // Create a 2x1 vector (different size)\n    vectorC(0, 0) = 1.0f;\n    vectorC(1, 0) = 2.0f;\n\n    float invalidResult = vectorA.dotprod(vectorA, vectorC);  // Should print an error and return 0\n    std::cout &lt;&lt; \"Dot product (dimension mismatch): \" &lt;&lt; invalidResult &lt;&lt; std::endl;  // Expected: 0 and error message\n\n    // Test 3: Dot Product of Zero Vectors\n    std::cout &lt;&lt; \"[Test 3] Dot Product of Zero Vectors\\n\";\n    tiny::Mat zeroVectorA(3, 1);  // Create a 3x1 zero vector\n    tiny::Mat zeroVectorB(3, 1);  // Create a 3x1 zero vector\n\n    // Initialize vectors\n    zeroVectorA(0, 0) = 0.0f;\n    zeroVectorA(1, 0) = 0.0f;\n    zeroVectorA(2, 0) = 0.0f;\n\n    zeroVectorB(0, 0) = 0.0f;\n    zeroVectorB(1, 0) = 0.0f;\n    zeroVectorB(2, 0) = 0.0f;\n\n    float zeroResult = zeroVectorA.dotprod(zeroVectorA, zeroVectorB);\n    std::cout &lt;&lt; \"Dot product of zero vectors: \" &lt;&lt; zeroResult &lt;&lt; std::endl;  // Expected: 0\n\n    std::cout &lt;&lt; \"[Dot Product Test End]\\n\";\n}\n\n// Test 5.13: Solve Linear System\nvoid test_solve()\n{\n    std::cout &lt;&lt; \"\\n[Test: Solve Linear System Ax = b]\\n\";\n\n    // Test 1: Solving a simple 2x2 system\n    std::cout &lt;&lt; \"[Test1] Solving a simple 2x2 system Ax = b\\n\";\n    tiny::Mat A(2, 2);\n    tiny::Mat b(2, 1);\n\n    A(0, 0) = 2; A(0, 1) = 1;\n    A(1, 0) = 1; A(1, 1) = 3;\n\n    b(0, 0) = 5;\n    b(1, 0) = 6;\n\n    tiny::Mat solution = A.solve(A, b);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution.print_matrix(true);\n\n    // Test 2: Solving a 3x3 system\n    std::cout &lt;&lt; \"[Test2] Solving a 3x3 system Ax = b\\n\";\n    tiny::Mat A2(3, 3);\n    tiny::Mat b2(3, 1);\n\n    A2(0, 0) = 1; A2(0, 1) = 2; A2(0, 2) = 1;\n    A2(1, 0) = 2; A2(1, 1) = 0; A2(1, 2) = 3;\n    A2(2, 0) = 3; A2(2, 1) = 2; A2(2, 2) = 1;\n\n    b2(0, 0) = 9;\n    b2(1, 0) = 8;\n    b2(2, 0) = 7;\n\n    tiny::Mat solution2 = A2.solve(A2, b2);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution2.print_matrix(true);\n\n    // Test 3: Solving a system where one row is all zeros\n    std::cout &lt;&lt; \"[Test3] Solving a system where one row is all zeros (expect failure or infinite solutions)\\n\";\n    tiny::Mat A3(3, 3);\n    tiny::Mat b3(3, 1);\n\n    A3(0, 0) = 1; A3(0, 1) = 2; A3(0, 2) = 3;\n    A3(1, 0) = 0; A3(1, 1) = 0; A3(1, 2) = 0; // Zero row\n    A3(2, 0) = 4; A3(2, 1) = 5; A3(2, 2) = 6;\n\n    b3(0, 0) = 9;\n    b3(1, 0) = 0; // Inconsistent, no solution should be possible\n    b3(2, 0) = 15;\n\n    tiny::Mat solution3 = A3.solve(A3, b3);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution3.print_matrix(true);\n\n    // Test 4: Solving a system with zero determinant (singular matrix)\n    std::cout &lt;&lt; \"[Test4] Solving a system with zero determinant (singular matrix)\\n\";\n    tiny::Mat A4(3, 3);\n    tiny::Mat b4(3, 1);\n\n    A4(0, 0) = 2; A4(0, 1) = 4; A4(0, 2) = 1;\n    A4(1, 0) = 1; A4(1, 1) = 2; A4(1, 2) = 3;\n    A4(2, 0) = 3; A4(2, 1) = 6; A4(2, 2) = 2; // The matrix is singular (row 2 = 2 * row 1)\n\n    b4(0, 0) = 5;\n    b4(1, 0) = 6;\n    b4(2, 0) = 7;\n\n    tiny::Mat solution4 = A4.solve(A4, b4);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution4.print_matrix(true); // Expect no solution or an error message\n\n    // Test 5: Solving a system with linearly dependent rows\n    std::cout &lt;&lt; \"[Test5] Solving a system with linearly dependent rows (expect failure or infinite solutions)\\n\";\n    tiny::Mat A5(3, 3);\n    tiny::Mat b5(3, 1);\n\n    A5(0, 0) = 1; A5(0, 1) = 1; A5(0, 2) = 1;\n    A5(1, 0) = 2; A5(1, 1) = 2; A5(1, 2) = 2;\n    A5(2, 0) = 3; A5(2, 1) = 3; A5(2, 2) = 3; // All rows are linearly dependent\n\n    b5(0, 0) = 6;\n    b5(1, 0) = 12;\n    b5(2, 0) = 18;\n\n    tiny::Mat solution5 = A5.solve(A5, b5);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution5.print_matrix(true); // Expect an error message or infinite solutions\n\n    // Test 6: Solving a larger 4x4 system\n    std::cout &lt;&lt; \"[Test6] Solving a larger 4x4 system Ax = b\\n\";\n    tiny::Mat A6(4, 4);\n    tiny::Mat b6(4, 1);\n\n    A6(0, 0) = 4; A6(0, 1) = 2; A6(0, 2) = 3; A6(0, 3) = 1;\n    A6(1, 0) = 2; A6(1, 1) = 5; A6(1, 2) = 1; A6(1, 3) = 2;\n    A6(2, 0) = 3; A6(2, 1) = 1; A6(2, 2) = 6; A6(2, 3) = 3;\n    A6(3, 0) = 1; A6(3, 1) = 2; A6(3, 2) = 3; A6(3, 3) = 4;\n\n    b6(0, 0) = 10;\n    b6(1, 0) = 12;\n    b6(2, 0) = 14;\n    b6(3, 0) = 16;\n\n    tiny::Mat solution6 = A6.solve(A6, b6);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution6.print_matrix(true); // Should print the solution vector\n\n    std::cout &lt;&lt; \"[Test end]\\n\";\n}\n\n// Test 5.14: Band Solve\nvoid test_band_solve()\n{\n    std::cout &lt;&lt; \"\\n[band_solve Test]\\n\";\n\n    /*** Test 1: Simple 3x3 Band Matrix ***/\n    std::cout &lt;&lt; \"[Test 1] Simple 3x3 Band Matrix\\n\";\n    tiny::Mat A1(3, 3);\n    tiny::Mat b1(3, 1);\n\n    // Define the matrix A and vector b for the system Ax = b\n    A1(0, 0) = 2; A1(0, 1) = 1; A1(0, 2) = 0;\n    A1(1, 0) = 1; A1(1, 1) = 3; A1(1, 2) = 2;\n    A1(2, 0) = 0; A1(2, 1) = 1; A1(2, 2) = 4;\n\n    b1(0, 0) = 5;\n    b1(1, 0) = 6;\n    b1(2, 0) = 7;\n\n    // Solve Ax = b using band_solve\n    tiny::Mat solution1 = A1.band_solve(A1, b1, 3);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution1.print_matrix(true);\n\n    /*** Test 2: 4x4 Band Matrix with different right-hand side vector ***/\n    std::cout &lt;&lt; \"[Test 2] 4x4 Band Matrix\\n\";\n    tiny::Mat A2(4, 4);\n    tiny::Mat b2(4, 1);\n\n    // Define the matrix A and vector b\n    A2(0, 0) = 2; A2(0, 1) = 1; A2(0, 2) = 0; A2(0, 3) = 0;\n    A2(1, 0) = 1; A2(1, 1) = 3; A2(1, 2) = 2; A2(1, 3) = 0;\n    A2(2, 0) = 0; A2(2, 1) = 1; A2(2, 2) = 4; A2(2, 3) = 2;\n    A2(3, 0) = 0; A2(3, 1) = 0; A2(3, 2) = 1; A2(3, 3) = 5;\n\n    b2(0, 0) = 8;\n    b2(1, 0) = 9;\n    b2(2, 0) = 10;\n    b2(3, 0) = 11;\n\n    // Solve Ax = b using band_solve\n    tiny::Mat solution2 = A2.band_solve(A2, b2, 3);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution2.print_matrix(true);\n\n    /*** Test 3: Incompatible dimensions (expect error) ***/\n    std::cout &lt;&lt; \"[Test 3] Incompatible Dimensions (Expect Error)\\n\";\n    tiny::Mat A3(3, 3);\n    tiny::Mat b3(2, 1);  // Incompatible dimension\n\n    A3(0, 0) = 1; A3(0, 1) = 2; A3(0, 2) = 3;\n    A3(1, 0) = 4; A3(1, 1) = 5; A3(1, 2) = 6;\n    A3(2, 0) = 7; A3(2, 1) = 8; A3(2, 2) = 9;\n\n    b3(0, 0) = 10;\n    b3(1, 0) = 11;\n\n    // This should print an error because of incompatible dimensions\n    tiny::Mat solution3 = A3.band_solve(A3, b3, 3);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution3.print_matrix(true);\n\n    /*** Test 4: Singular Matrix (Should fail) ***/\n    std::cout &lt;&lt; \"[Test 4] Singular Matrix (No unique solution)\\n\";\n    tiny::Mat A4(3, 3);\n    tiny::Mat b4(3, 1);\n\n    // Define a singular matrix (linearly dependent rows)\n    A4(0, 0) = 1; A4(0, 1) = 2; A4(0, 2) = 3;\n    A4(1, 0) = 2; A4(1, 1) = 4; A4(1, 2) = 6;\n    A4(2, 0) = 3; A4(2, 1) = 6; A4(2, 2) = 9;\n\n    b4(0, 0) = 10;\n    b4(1, 0) = 20;\n    b4(2, 0) = 30;\n\n    // This should print an error as the matrix is singular and does not have a unique solution\n    tiny::Mat solution4 = A4.band_solve(A4, b4, 3);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution4.print_matrix(true);\n}\n\n// Test 5.15: Roots\nvoid test_roots()\n{\n    std::cout &lt;&lt; \"\\n[Roots Test]\\n\";\n\n    /*** Test 1: Simple 2x2 System ***/\n    std::cout &lt;&lt; \"[Test 1] Solving a simple 2x2 system Ax = b\\n\";\n    tiny::Mat A1(2, 2);\n    tiny::Mat b1(2, 1);\n\n    // Define the matrix A and vector b for the system Ax = b\n    A1(0, 0) = 2; A1(0, 1) = 1;\n    A1(1, 0) = 1; A1(1, 1) = 3;\n\n    b1(0, 0) = 5;\n    b1(1, 0) = 6;\n\n    // Solve Ax = b using roots\n    tiny::Mat solution1 = A1.roots(A1, b1);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution1.print_matrix(true);\n\n    /*** Test 2: 3x3 System ***/\n    std::cout &lt;&lt; \"[Test 2] Solving a 3x3 system Ax = b\\n\";\n    tiny::Mat A2(3, 3);\n    tiny::Mat b2(3, 1);\n\n    A2(0, 0) = 1; A2(0, 1) = 2; A2(0, 2) = 1;\n    A2(1, 0) = 2; A2(1, 1) = 0; A2(1, 2) = 3;\n    A2(2, 0) = 3; A2(2, 1) = 2; A2(2, 2) = 1;\n\n    b2(0, 0) = 9;\n    b2(1, 0) = 8;\n    b2(2, 0) = 7;\n\n    // Solve Ax = b using roots\n    tiny::Mat solution2 = A2.roots(A2, b2);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution2.print_matrix(true);\n\n    /*** Test 3: Singular Matrix ***/\n    std::cout &lt;&lt; \"[Test 3] Singular Matrix (No unique solution)\\n\";\n    tiny::Mat A3(2, 2);\n    tiny::Mat b3(2, 1);\n\n    // Define a singular matrix (linearly dependent rows)\n    A3(0, 0) = 1; A3(0, 1) = 2;\n    A3(1, 0) = 2; A3(1, 1) = 4;\n\n    b3(0, 0) = 5;\n    b3(1, 0) = 6;\n\n    // This should print an error as the matrix is singular and does not have a unique solution\n    tiny::Mat solution3 = A3.roots(A3, b3);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution3.print_matrix(true);\n\n    /*** Test 4: Incompatible Dimensions (Expect Error) ***/\n    std::cout &lt;&lt; \"[Test 4] Incompatible Dimensions (Expect Error)\\n\";\n    tiny::Mat A4(3, 3);\n    tiny::Mat b4(2, 1);  // Incompatible dimension\n\n    A4(0, 0) = 1; A4(0, 1) = 2; A4(0, 2) = 3;\n    A4(1, 0) = 4; A4(1, 1) = 5; A4(1, 2) = 6;\n    A4(2, 0) = 7; A4(2, 1) = 8; A4(2, 2) = 9;\n\n    b4(0, 0) = 10;\n    b4(1, 0) = 11;\n\n    // This should print an error because of incompatible dimensions\n    tiny::Mat solution4 = A4.roots(A4, b4);\n    std::cout &lt;&lt; \"Solution: \\n\";\n    solution4.print_matrix(true);\n}\n\n// Group 6: Stream Operators\nvoid test_stream_operators()\n{\n    std::cout &lt;&lt; \"\\n[Test: Stream Operators]\\n\";\n\n    // Test 1: Test stream insertion operator (&lt;&lt;) for Mat\n    std::cout &lt;&lt; \"[Test 1] Stream Insertion Operator (&lt;&lt;) for Mat\\n\";\n    tiny::Mat mat1(3, 3);\n    mat1(0, 0) = 1; mat1(0, 1) = 2; mat1(0, 2) = 3;\n    mat1(1, 0) = 4; mat1(1, 1) = 5; mat1(1, 2) = 6;\n    mat1(2, 0) = 7; mat1(2, 1) = 8; mat1(2, 2) = 9;\n\n    std::cout &lt;&lt; \"Matrix mat1:\\n\";\n    std::cout &lt;&lt; mat1 &lt;&lt; std::endl; // Use the &lt;&lt; operator to print mat1\n\n    // Test 2: Test stream insertion operator (&lt;&lt;) for Mat::ROI\n    std::cout &lt;&lt; \"[Test 2] Stream Insertion Operator (&lt;&lt;) for Mat::ROI\\n\";\n    tiny::Mat::ROI roi(1, 2, 3, 4);\n    std::cout &lt;&lt; \"ROI roi:\\n\";\n    std::cout &lt;&lt; roi &lt;&lt; std::endl; // Use the &lt;&lt; operator to print roi\n\n    // Test 3: Test stream extraction operator (&gt;&gt;) for Mat\n    std::cout &lt;&lt; \"[Test 3] Stream Extraction Operator (&gt;&gt;) for Mat\\n\";\n    tiny::Mat mat2(2, 2);\n    std::cout &lt;&lt; \"Please enter 4 elements for a 2x2 matrix:\\n\";\n    std::cin &gt;&gt; mat2; // Use the &gt;&gt; operator to input mat2\n    std::cout &lt;&lt; \"Matrix mat2 after input:\\n\";\n    std::cout &lt;&lt; mat2 &lt;&lt; std::endl; // Use the &lt;&lt; operator to print mat2\n\n    // Test 4: Test stream extraction operator (&gt;&gt;) for Mat (with invalid input)\n    std::cout &lt;&lt; \"[Test 4] Stream Extraction Operator (&gt;&gt;) for Mat with invalid input\\n\";\n    tiny::Mat mat3(2, 3);\n    std::cout &lt;&lt; \"Please enter 6 elements for a 2x3 matrix:\\n\";\n    std::cin &gt;&gt; mat3; // Use the &gt;&gt; operator to input mat3\n    std::cout &lt;&lt; \"Matrix mat3 after input:\\n\";\n    std::cout &lt;&lt; mat3 &lt;&lt; std::endl; // Use the &lt;&lt; operator to print mat3\n}\n\n// Group 7: Global Arithmetic Operators\n\nvoid test_matrix_operations()\n{\n    std::cout &lt;&lt; \"\\n[Test: Matrix Operations]\\n\";\n\n    /*** Test 1: Matrix Addition (operator+) ***/\n    std::cout &lt;&lt; \"\\n[Test 1] Matrix Addition (operator+)\\n\";\n    tiny::Mat matA(2, 2);\n    tiny::Mat matB(2, 2);\n\n    matA(0, 0) = 1; matA(0, 1) = 2;\n    matA(1, 0) = 3; matA(1, 1) = 4;\n\n    matB(0, 0) = 5; matB(0, 1) = 6;\n    matB(1, 0) = 7; matB(1, 1) = 8;\n\n    tiny::Mat resultAdd = matA + matB;\n    std::cout &lt;&lt; \"matA + matB:\\n\";\n    std::cout &lt;&lt; resultAdd &lt;&lt; std::endl;  // Expected: [6, 8], [10, 12]\n\n    /*** Test 2: Matrix Addition with Constant (operator+) ***/\n    std::cout &lt;&lt; \"\\n[Test 2] Matrix Addition with Constant (operator+)\\n\";\n    tiny::Mat resultAddConst = matA + 5.0f;\n    std::cout &lt;&lt; \"matA + 5.0f:\\n\";\n    std::cout &lt;&lt; resultAddConst &lt;&lt; std::endl;  // Expected: [6, 7], [8, 9]\n\n    /*** Test 3: Matrix Subtraction (operator-) ***/\n    std::cout &lt;&lt; \"\\n[Test 3] Matrix Subtraction (operator-)\\n\";\n    tiny::Mat resultSub = matA - matB;\n    std::cout &lt;&lt; \"matA - matB:\\n\";\n    std::cout &lt;&lt; resultSub &lt;&lt; std::endl;  // Expected: [-4, -4], [-4, -4]\n\n    /*** Test 4: Matrix Subtraction with Constant (operator-) ***/\n    std::cout &lt;&lt; \"\\n[Test 4] Matrix Subtraction with Constant (operator-)\\n\";\n    tiny::Mat resultSubConst = matA - 2.0f;\n    std::cout &lt;&lt; \"matA - 2.0f:\\n\";\n    std::cout &lt;&lt; resultSubConst &lt;&lt; std::endl;  // Expected: [-1, 0], [1, 2]\n\n    /*** Test 5: Matrix Multiplication (operator*) ***/\n    std::cout &lt;&lt; \"\\n[Test 5] Matrix Multiplication (operator*)\\n\";\n    tiny::Mat matC(2, 3);\n    tiny::Mat matD(3, 2);\n\n    matC(0, 0) = 1; matC(0, 1) = 2; matC(0, 2) = 3;\n    matC(1, 0) = 4; matC(1, 1) = 5; matC(1, 2) = 6;\n\n    matD(0, 0) = 7; matD(0, 1) = 8;\n    matD(1, 0) = 9; matD(1, 1) = 10;\n    matD(2, 0) = 11; matD(2, 1) = 12;\n\n    tiny::Mat resultMul = matC * matD;\n    std::cout &lt;&lt; \"matC * matD:\\n\";\n    std::cout &lt;&lt; resultMul &lt;&lt; std::endl;  // Expected: [58, 64], [139, 154]\n\n    /*** Test 6: Matrix Multiplication with Constant (operator*) ***/\n    std::cout &lt;&lt; \"\\n[Test 6] Matrix Multiplication with Constant (operator*)\\n\";\n    tiny::Mat resultMulConst = matA * 2.0f;\n    std::cout &lt;&lt; \"matA * 2.0f:\\n\";\n    std::cout &lt;&lt; resultMulConst &lt;&lt; std::endl;  // Expected: [2, 4], [6, 8]\n\n    /*** Test 7: Matrix Division (operator/) ***/\n    std::cout &lt;&lt; \"\\n[Test 7] Matrix Division (operator/)\\n\";\n    tiny::Mat resultDiv = matA / 2.0f;\n    std::cout &lt;&lt; \"matA / 2.0f:\\n\";\n    std::cout &lt;&lt; resultDiv &lt;&lt; std::endl;  // Expected: [0.5, 1], [1.5, 2]\n\n    /*** Test 8: Matrix Division Element-wise (operator/) ***/\n    std::cout &lt;&lt; \"\\n[Test 8] Matrix Division Element-wise (operator/)\\n\";\n    tiny::Mat resultDivElem = matA / matB;\n    std::cout &lt;&lt; \"matA / matB:\\n\";\n    std::cout &lt;&lt; resultDivElem &lt;&lt; std::endl;  // Expected: [0.2, 0.333], [0.428, 0.5]\n\n    /*** Test 9: Matrix Comparison (operator==) ***/\n    std::cout &lt;&lt; \"\\n[Test 9] Matrix Comparison (operator==)\\n\";\n    tiny::Mat matE(2, 2);\n    matE(0, 0) = 1; matE(0, 1) = 2;\n    matE(1, 0) = 3; matE(1, 1) = 4;\n\n    tiny::Mat matF(2, 2);\n    matF(0, 0) = 1; matF(0, 1) = 2;\n    matF(1, 0) = 3; matF(1, 1) = 4;\n\n    bool isEqual = (matE == matF);\n    std::cout &lt;&lt; \"matE == matF: \" &lt;&lt; (isEqual ? \"True\" : \"False\") &lt;&lt; std::endl;  // Expected: True\n\n    matF(0, 0) = 5;  // Modify matF\n    isEqual = (matE == matF);\n    std::cout &lt;&lt; \"matE == matF after modification: \" &lt;&lt; (isEqual ? \"True\" : \"False\") &lt;&lt; std::endl;  // Expected: False\n}\n\nvoid tiny_matrix_test()\n{\n    std::cout &lt;&lt; \"============ [tiny_matrix_test start] ============\\n\";\n\n    // Group 1: constructor &amp; destructor\n    test_constructor_destructor();\n\n    // Group 2: element access\n    // test_element_access();\n\n    // Group 3: ROI operations\n    // test_roi_operations();\n\n    // Group 4: arithmetic operators\n    // test_assignment_operator();\n    // test_matrix_addition();\n    // test_constant_addition();\n    // test_matrix_subtraction();\n    // test_constant_subtraction();\n    // test_matrix_division();\n    // test_constant_division();\n    // test_matrix_exponentiation();\n\n    // Group 5: Linear algebra tests\n    // test_matrix_transpose();\n    // test_matrix_cofactor();\n    // test_matrix_determinant();\n    // test_matrix_adjoint();\n    // test_matrix_normalize();\n    // test_matrix_norm();\n    // test_inverse_adjoint();\n    // test_matrix_utilities();\n    // test_gaussian_eliminate();\n    // test_row_reduce_from_gaussian();\n    // test_inverse_gje();\n    // test_dotprod();\n    // test_solve();\n    // test_band_solve();\n    // test_roots();\n\n    // Group 6: Stream operators\n    // test_stream_operators();\n    // test_matrix_operations();\n\n    std::cout &lt;&lt; \"============ [tiny_matrix_test end] ============\\n\";\n}\n</code></pre>"},{"location":"MATH/USAGE/usage/","title":"USAGE INSTRUCTIONS","text":"<p>Usage Instructions</p> <p>This document provides usage instructions for the <code>math</code> module in Python.  It includes examples and explanations of various functions and methods available in the module.</p>"},{"location":"MATH/USAGE/usage/#import-tinymath-as-a-whole","title":"Import TinyMath as a Whole","text":"<p>Info</p> <p>Suitable for C projects or projects with a simple structure in C++.</p> <pre><code>#include \"tiny_math.h\"\n</code></pre>"},{"location":"MATH/USAGE/usage/#import-tinymath-by-module","title":"Import TinyMath by Module","text":"<p>Info</p> <p>Suitable for projects that require precise control over module imports or complex C++ projects.</p> <pre><code>#include \"tiny_vec.h\" // Import vector module\n#include \"tiny_mat.h\" // Import matrix module\n</code></pre> <pre><code>#include \"tiny_matrix.hpp\" // Import advanced matrix module\n</code></pre> <p>Note</p> <ul> <li> <p><code>tiny_vec.h</code> and <code>tiny_mat.h</code> are header files for the C language version, suitable for C programming.</p> </li> <li> <p><code>tiny_matrix.hpp</code> is a header file for the C++ language version, suitable for C++ programming.</p> </li> </ul> <p>In simple terms, C language projects can only use <code>tiny_vec.h</code> and <code>tiny_mat.h</code>, while C++ projects can use <code>tiny_vec.h</code>, <code>tiny_mat.h</code>, and <code>tiny_matrix.hpp</code>.</p> <p>Tip</p> <p>For specific usage methods, please refer to the test code.</p>"},{"location":"MATH/VECTOR/api/","title":"VECTOR OPERATIONS","text":""},{"location":"MATH/VECTOR/api/#list-of-functions","title":"LIST OF FUNCTIONS","text":"<pre><code>// Addition\ntiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Subtraction\ntiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Multiplication\ntiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Division\ntiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\ntiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\n// Square root\ntiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\n// Dot product\ntiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\ntiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n</code></pre>"},{"location":"MATH/VECTOR/api/#addition","title":"ADDITION","text":""},{"location":"MATH/VECTOR/api/#addition-of-two-vectors","title":"Addition of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>Function: Computes the element-wise addition of two vectors.</p> <p>Parameters:</p> <ul> <li><code>input1</code>: Pointer to the first input vector.</li> <li><code>input2</code>: Pointer to the second input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#addition-of-a-vector-and-a-constant","title":"Addition of a Vector and a Constant","text":"<pre><code>tiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>Function: Computes the element-wise addition of a vector and a constant.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> <li><code>C</code>: Constant value to be added.</li> <li><code>step_in</code>: Step size for the input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#subtraction","title":"SUBTRACTION","text":""},{"location":"MATH/VECTOR/api/#subtraction-of-two-vectors","title":"Subtraction of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>Function: Computes the element-wise subtraction of two vectors.</p> <p>Parameters:</p> <ul> <li><code>input1</code>: Pointer to the first input vector.</li> <li><code>input2</code>: Pointer to the second input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#subtraction-of-a-vector-and-a-constant","title":"Subtraction of a Vector and a Constant","text":"<pre><code>tiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>Function: Computes the element-wise subtraction of a vector and a constant.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> <li><code>C</code>: Constant value to be subtracted.</li> <li><code>step_in</code>: Step size for the input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#multiplication","title":"MULTIPLICATION","text":""},{"location":"MATH/VECTOR/api/#multiplication-of-two-vectors","title":"Multiplication of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>Function: Computes the element-wise multiplication of two vectors.</p> <p>Parameters:</p> <ul> <li><code>input1</code>: Pointer to the first input vector.</li> <li><code>input2</code>: Pointer to the second input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#multiplication-of-a-vector-and-a-constant","title":"Multiplication of a Vector and a Constant","text":"<pre><code>tiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>Function: Computes the element-wise multiplication of a vector and a constant.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> <li><code>C</code>: Constant value to be multiplied.</li> <li><code>step_in</code>: Step size for the input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#division","title":"DIVISION","text":""},{"location":"MATH/VECTOR/api/#division-of-two-vectors","title":"Division of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\n</code></pre> <p>Function: Computes the element-wise division of two vectors.</p> <p>Parameters:</p> <ul> <li><code>input1</code>: Pointer to the first input vector.</li> <li><code>input2</code>: Pointer to the second input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> <li><code>allow_divide_by_zero</code>: Flag to allow division by zero (true or false).</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#division-of-a-vector-and-a-constant","title":"Division of a Vector and a Constant","text":"<pre><code>tiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\n</code></pre> <p>Function: Computes the element-wise division of a vector and a constant.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> <li><code>C</code>: Constant value to be divided.</li> <li><code>step_in</code>: Step size for the input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> <li><code>allow_divide_by_zero</code>: Flag to allow division by zero (true or false).</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#square-root","title":"SQUARE ROOT","text":""},{"location":"MATH/VECTOR/api/#square-root-of-a-vector","title":"Square Root of a Vector","text":"<pre><code>tiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\n</code></pre> <p>Function: Computes the element-wise square root of a vector.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#square-root-of-a-vector-fast","title":"Square Root of a Vector (Fast)","text":"<pre><code>tiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\n</code></pre> <p>Function: Computes the element-wise square root of a vector (fast version).</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#inverse-square-root-of-a-vector","title":"Inverse Square Root of a Vector","text":"<pre><code>tiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\n</code></pre> <p>Function: Computes the element-wise inverse square root of a vector.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#inverse-square-root-of-a-vector-fast","title":"Inverse Square Root of a Vector (Fast)","text":"<pre><code>tiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\n</code></pre> <p>Function: Computes the element-wise inverse square root of a vector (fast version).</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#dot-product","title":"DOT PRODUCT","text":""},{"location":"MATH/VECTOR/api/#dot-product-of-two-vectors","title":"Dot Product of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\n</code></pre> <p>Function: Computes the dot product of two vectors.</p> <p>Parameters:</p> <ul> <li><code>src1</code>: Pointer to the first input vector.</li> <li><code>src2</code>: Pointer to the second input vector.</li> <li><code>dest</code>: Pointer to the output scalar value.</li> <li><code>len</code>: Length of the vectors.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#dot-product-of-two-vectors-with-different-steps","title":"Dot Product of Two Vectors with Different Steps","text":"<pre><code>tiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n</code></pre> <p>Function: Computes the dot product of two vectors with different step sizes.</p> <p>Parameters:</p> <ul> <li><code>src1</code>: Pointer to the first input vector.</li> <li><code>src2</code>: Pointer to the second input vector.</li> <li><code>dest</code>: Pointer to the output scalar value.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/code/","title":"CODE","text":""},{"location":"MATH/VECTOR/code/#tiny_vech","title":"tiny_vec.h","text":"<pre><code>/**\n * @file tiny_vec.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the submodule vec of the tiny_math middleware. This module is correspondign to the math &amp; dotprod functions in the ESP-DSP library.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_math_config.h\"\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n\n#include \"dsps_math.h\" // math operations\n#include \"dsps_dotprod.h\" // dot product\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* FUNCTION PROTOTYPES */\ntiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\ntiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\ntiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\ntiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\ntiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\ntiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\ntiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/VECTOR/code/#tiny_vecc","title":"tiny_vec.c","text":"<pre><code>/**\n * @file tiny_vec.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the source file for the submodule vec of the tiny_math middleware. This module is correspondign to the math &amp; dotprod functions in the ESP-DSP library.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n *\n * @note IMPORTANT: Buffer Overflow Prevention\n *       When using step parameters, ensure that array bounds are respected:\n *       - For input arrays: (len-1) * step &lt; array_size\n *       - For output arrays: (len-1) * step_out &lt; array_size\n *       Example: If array has 10 elements and step=2, max safe len is 5.\n *       The library does not perform runtime bounds checking for performance reasons.\n *       Users must ensure valid array sizes before calling these functions.\n */\n\n#include \"tiny_vec.h\"\n\n// #ifdef __cplusplus\n\n/* ADDITION */\n\n// vector + vector | float\n\n/**\n * @name tiny_vec_add_f32\n * @brief Adds two vectors element-wise.\n * @param input1 Pointer to the first input vector.\n * @param input2 Pointer to the second input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param step1 Step size for the first input vector.\n * @param step2 Step size for the second input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function performs element-wise addition of two vectors with specified step sizes, and the output is also specified with a step size.\n */\ntiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector addition\n    dsps_add_f32(input1, input2, output, len, step1, step2, step_out);\n#else\n    // Fallback to a simple loop for vector addition\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input1[i * step1] + input2[i * step2];\n    }\n\n#endif\n\n    return TINY_OK;\n}\n\n// vector + constant | float\n/**\n * @name tiny_vec_addc_f32\n * @brief Adds a constant to each element of a vector.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param C Constant value to be added.\n * @param step_in Step size for the input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function adds a constant value to each element of the input vector, with specified step sizes for both input and output vectors.\n */\ntiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector addition\n    dsps_addc_f32(input, output, len, C, step_in, step_out);\n#else\n    // Fallback to a simple loop for vector addition\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input[i * step_in] + C;\n    }\n#endif\n    return TINY_OK;\n}\n\n/* SUBTRACTION */\n\n// vector - vector | float\n/**\n * @name tiny_vec_sub_f32\n * @brief Subtracts two vectors element-wise.\n * @param input1 Pointer to the first input vector.\n * @param input2 Pointer to the second input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param step1 Step size for the first input vector.\n * @param step2 Step size for the second input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function performs element-wise subtraction of two vectors with specified step sizes, and the output is also specified with a step size.\n */\ntiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector subtraction\n    dsps_sub_f32(input1, input2, output, len, step1, step2, step_out);\n#else\n    // Fallback to a simple loop for vector subtraction\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input1[i * step1] - input2[i * step2];\n    }\n#endif\n    return TINY_OK;\n}\n\n// vector - constant (add -c) | float\n/**\n * @name tiny_vec_subc_f32\n * @brief Subtracts a constant from each element of a vector.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param C Constant value to be subtracted.\n * @param step_in Step size for the input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function subtracts a constant value from each element of the input vector, with specified step sizes for both input and output vectors.\n */\ntiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector subtraction\n    dsps_addc_f32(input, output, len, -C, step_in, step_out);\n#else\n    // Fallback to a simple loop for vector subtraction\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input[i * step_in] - C;\n    }\n#endif\n    return TINY_OK;\n}\n\n/* MULTIPLICATION */\n\n// vector * vector (elementwise) | float\n/**\n * @name tiny_vec_mul_f32\n * @brief Multiplies two vectors element-wise.\n * @param input1 Pointer to the first input vector.\n * @param input2 Pointer to the second input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param step1 Step size for the first input vector.\n * @param step2 Step size for the second input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function performs element-wise multiplication of two vectors with specified step sizes, and the output is also specified with a step size.\n */\ntiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector multiplication\n    dsps_mul_f32(input1, input2, output, len, step1, step2, step_out);\n#else\n    // Fallback to a simple loop for vector multiplication\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input1[i * step1] * input2[i * step2];\n    }\n#endif\n    return TINY_OK;\n}\n\n// vector * constant | float\n/**\n * @name tiny_vec_mulc_f32\n * @brief Multiplies each element of a vector by a constant.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param C Constant value to be multiplied.\n * @param step_in Step size for the input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function multiplies each element of the input vector by a constant value, with specified step sizes for both input and output vectors.\n */\ntiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector multiplication\n    dsps_mulc_f32(input, output, len, C, step_in, step_out);\n#else\n    // Fallback to a simple loop for vector multiplication\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input[i * step_in] * C;\n    }\n#endif\n    return TINY_OK;\n}\n\n/* DIVISION */\n\n// vector / vector (elementwise) | float\n/**\n * @name tiny_vec_div_f32\n * @brief Divides one vector by another element-wise.\n * @param input1 Pointer to the numerator vector.\n * @param input2 Pointer to the denominator vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param step1 Step size for the numerator vector.\n * @param step2 Step size for the denominator vector.\n * @param step_out Step size for the output vector.\n * @param allow_divide_by_zero Whether to safely handle zero denominators (true: set output to 0; false: return error if any zero is found).\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function performs element-wise division with specified step sizes.\n *       If allow_divide_by_zero is false, the function will first scan for zero denominators and return an error immediately if any are found.\n */\ntiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    const float epsilon = TINY_MATH_MIN_DENOMINATOR;\n\n    // Step 1: Pre-check for zero denominators if not allowed\n    if (!allow_divide_by_zero)\n    {\n        for (int i = 0; i &lt; len; i++)\n        {\n            if (fabsf(input2[i * step2]) &lt; epsilon)\n            {\n                return TINY_ERR_MATH_ZERO_DIVISION;\n            }\n        }\n    }\n\n    // Step 2: Perform element-wise division\n    // Note: If allow_divide_by_zero=false, pre-check already passed, but we double-check for safety\n    for (int i = 0; i &lt; len; i++)\n    {\n        float denom = input2[i * step2];\n        float numer = input1[i * step1];\n\n        if (fabsf(denom) &lt; epsilon)\n        {\n            if (allow_divide_by_zero)\n            {\n                // Handle division by near-zero: mathematically correct behavior\n                if (fabsf(numer) &lt; epsilon)\n                {\n                    // 0/0 case: undefined, return 0.0f as safe fallback\n                    output[i * step_out] = 0.0f;\n                }\n                else\n                {\n                    // Non-zero divided by near-zero: return signed infinity\n                    // Use large number instead of INFINITY for compatibility\n                    output[i * step_out] = (numer &gt; 0.0f) ? TINY_MATH_LARGE_VALUE_F32 : -TINY_MATH_LARGE_VALUE_F32;\n                }\n            }\n            else\n            {\n                // This should not happen if pre-check passed, but return error for safety\n                return TINY_ERR_MATH_ZERO_DIVISION;\n            }\n        }\n        else\n        {\n            output[i * step_out] = numer / denom;\n        }\n    }\n\n    return TINY_OK;\n}\n\n// vector / constant | float\n/**\n * @name tiny_vec_divc_f32\n * @brief Divides each element of a vector by a constant using multiplication for performance.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param C Constant value to divide by.\n * @param step_in Step size for the input vector.\n * @param step_out Step size for the output vector.\n * @param allow_divide_by_zero Whether to safely handle zero constant (true: set output to 0; false: return error if C is near zero).\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function divides each element of the input vector by a constant using multiplication for performance.\n *       If allow_divide_by_zero is false and C is near zero, the function returns an error.\n *       Otherwise, 1/C is precomputed and used as a multiplier.\n */\ntiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    const float epsilon = TINY_MATH_MIN_DENOMINATOR;\n\n    // Step 1: Handle constant C\n    if (fabsf(C) &lt; epsilon)\n    {\n        if (!allow_divide_by_zero)\n        {\n            return TINY_ERR_MATH_ZERO_DIVISION;\n        }\n\n        // Handle division by near-zero constant: mathematically correct behavior\n        // For vector / near-zero, each element should approach infinity\n        for (int i = 0; i &lt; len; i++)\n        {\n            float val = input[i * step_in];\n            if (fabsf(val) &lt; epsilon)\n            {\n                // 0 / near-zero: undefined, return 0.0f as safe fallback\n                output[i * step_out] = 0.0f;\n            }\n            else\n            {\n                // Non-zero divided by near-zero: return signed large value\n                output[i * step_out] = (val &gt; 0.0f) ? TINY_MATH_LARGE_VALUE_F32 : -TINY_MATH_LARGE_VALUE_F32;\n            }\n        }\n        return TINY_OK;\n    }\n\n    // Step 2: Use 1/C for performance\n    float invC = 1.0f / C;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_mulc_f32(input, output, len, invC, step_in, step_out);\n#else\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input[i * step_in] * invC;\n    }\n#endif\n\n    return TINY_OK;\n}\n\n/* SQUARE ROOT */\n\n// vector ^ 0.5 (sqrt-based)| float\n/**\n * @name tiny_vec_sqrt_f32\n * @brief Computes the square root of each element in a vector using standard library sqrtf.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function provides accurate results using math library sqrtf().\n *       It returns TINY_ERR_MATH_NEGATIVE_SQRT immediately if any element is negative.\n */\ntiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    // Pre-check: validate all inputs before processing to avoid partial results\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (input[i] &lt; 0.0f)\n        {\n            return TINY_ERR_MATH_NEGATIVE_SQRT;\n        }\n    }\n\n    // All inputs validated, now perform computation\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = sqrtf(input[i]);  // high-precision sqrt\n    }\n\n    return TINY_OK;\n}\n\n// single value sqrt\n/**\n * @name tiny_sqrtf_f32\n * @brief Computes the square root of a single float value using bit manipulation.\n * @param f Input float value.\n * @return Square root of the input value.\n * @note This function uses bit manipulation to compute the square root of a float value.\n *       It returns 0.0f for negative inputs to prevent sqrt of negative values.\n *       WARNING: This is a fast approximation algorithm. Typical relative error is &lt; 1%.\n *       For high-precision applications, use tiny_vec_sqrt_f32() instead.\n */\ninline float tiny_sqrtf_f32(float f)\n{\n    if (f &lt; 0.0f) {\n        return 0.0f;  // Prevent sqrt of negative values\n    }\n\n    // Use union to avoid strict aliasing violation\n    union {\n        float f;\n        uint32_t i;\n    } input_conv = {f};\n\n    union {\n        float f;\n        uint32_t i;\n    } result_conv;\n\n    result_conv.i = 0x1fbb4000 + (input_conv.i &gt;&gt; 1);\n    return result_conv.f;\n}\n\n// vector ^ 0.5 (sqrtf-based)| float\n/**\n * @name tiny_vec_sqrtf_f32\n * @brief Computes the square root of each element in a vector using fast approximation.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function computes the square root of each element using fast bit manipulation.\n *       It returns TINY_ERR_MATH_NEGATIVE_SQRT immediately if any element is negative.\n *       WARNING: This is a fast approximation. Typical relative error is &lt; 1%.\n *       For high-precision applications, use tiny_vec_sqrt_f32() instead.\n *       NOTE: Ensure input/output arrays have sufficient size: at least len elements.\n *       When using step parameters, ensure: (len-1)*step &lt; array_size to avoid buffer overflow.\n */\ntiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    // Pre-check: validate all inputs before processing to avoid partial results\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (input[i] &lt; 0.0f)\n        {\n            return TINY_ERR_MATH_NEGATIVE_SQRT;\n        }\n    }\n\n    // All inputs validated, now perform computation\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = tiny_sqrtf_f32(input[i]);\n    }\n\n    return TINY_OK;\n}\n\n// vector ^ -0.5 (sqrt-based) | float\n/**\n * @name tiny_vec_inv_sqrt_f32\n * @brief Computes the inverse square root of each element in a vector using standard sqrtf().\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function provides accurate inverse square root results using 1.0f / sqrtf(x).\n *       It returns TINY_ERR_NOT_ALLOWED immediately if any element is less than TINY_MATH_MIN_POSITIVE_INPUT_F32.\n */\ntiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    // Pre-check: validate all inputs before processing to avoid partial results\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (input[i] &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            return TINY_ERR_NOT_ALLOWED;\n        }\n    }\n\n    // All inputs validated, now perform computation\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = 1.0f / sqrtf(input[i]);  // Accurate inverse square root\n    }\n\n    return TINY_OK;\n}\n\n\n// single value inv sqrt\n/**\n * @name tiny_inverted_sqrtf_f32\n * @brief Computes the inverse square root of a single float value using bit manipulation (Quake algorithm).\n * @param data Input float value.\n * @return Inverse square root of the input value.\n * @note This function uses the famous Quake III fast inverse square root algorithm.\n *       It returns 0.0f for negative or near-zero inputs to prevent division by zero.\n *       WARNING: This is a fast approximation. Typical relative error is &lt; 0.2%.\n *       For high-precision applications, use tiny_vec_inv_sqrt_f32() instead.\n */\nfloat tiny_inverted_sqrtf_f32(float data)\n{\n    if (data &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32) {\n        return 0.0f;  // Avoid division by near-zero or zero\n    }\n\n    const float x2 = data * 0.5F;\n    const float threehalfs = 1.5F;\n\n    union {\n        float f;\n        uint32_t i;\n    } conv = {data};\n\n    conv.i  = 0x5f3759df - (conv.i &gt;&gt; 1);\n    conv.f  = conv.f * (threehalfs - (x2 * conv.f * conv.f));\n\n    return conv.f;\n}\n\n// vector ^ -0.5 (sqrtf-based) | float\n/**\n * @name tiny_vec_inv_sqrtf_f32\n * @brief Computes the inverse square root of each element in a vector using fast approximation.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function computes the inverse square root using the Quake III fast algorithm.\n *       If any element is less than TINY_MATH_MIN_POSITIVE_INPUT_F32, the function returns TINY_ERR_NOT_ALLOWED.\n *       WARNING: This is a fast approximation. Typical relative error is &lt; 0.2%.\n *       For high-precision applications, use tiny_vec_inv_sqrt_f32() instead.\n *       NOTE: Ensure input/output arrays have sufficient size: at least len elements.\n *       When using step parameters, ensure: (len-1)*step &lt; array_size to avoid buffer overflow.\n */\ntiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    // Pre-check: validate all inputs before processing to avoid partial results\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (input[i] &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            return TINY_ERR_NOT_ALLOWED;\n        }\n    }\n\n    // All inputs validated, now perform computation\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = tiny_inverted_sqrtf_f32(input[i]);\n    }\n\n    return TINY_OK;\n}\n\n/* DOT PRODUCT */\n\n// vector * vector (dot product) | float\n/**\n * @name tiny_vec_dotprod_f32\n * @brief Computes the dot product of two vectors.\n * @param src1 Pointer to the first input vector.\n * @param src2 Pointer to the second input vector.\n * @param dest Pointer to the output scalar result.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function computes the dot product of two vectors and stores the result in a single float value.\n *       It returns TINY_ERR_MATH_NULL_POINTER if any pointer is NULL.\n *       The function uses the ESP-DSP library for optimized computation.\n */\ntiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len)\n{\n    if (NULL == src1 || NULL == src2 || NULL == dest)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized dot product\n    dsps_dotprod_f32(src1, src2, dest, len);\n#else\n    // Fallback to a simple loop for dot product\n    float acc = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        acc += src1[i] * src2[i];\n    }\n    *dest = acc;\n#endif\n    return TINY_OK;\n}\n\n// vector * vector (dot product - step support) | float\n/**\n * @name tiny_vec_dotprode_f32\n * @brief Computes the dot product of two vectors with step support.\n * @param src1 Pointer to the first input vector.\n * @param src2 Pointer to the second input vector.\n * @param dest Pointer to the output scalar result.\n * @param len Length of the vectors.\n * @param step1 Step size for the first input vector.\n * @param step2 Step size for the second input vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function computes the dot product of two vectors with specified step sizes and stores the result in a single float value.\n */\ntiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2)\n{\n    if (NULL == src1 || NULL == src2 || NULL == dest)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized dot product with step support\n    dsps_dotprode_f32(src1, src2, dest, len, step1, step2);\n#else\n    // Fallback to a simple loop for dot product with step support\n    float acc = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        acc += src1[i * step1] * src2[i * step2];\n    }\n    *dest = acc;\n#endif\n    return TINY_OK;\n}\n</code></pre>"},{"location":"MATH/VECTOR/test/","title":"VECTOR OPERATIONS TEST","text":"<p>Vector Operations Test</p> <p>This test is designed to evaluate the performance of vector-related functions.</p>"},{"location":"MATH/VECTOR/test/#test-code","title":"Test Code","text":""},{"location":"MATH/VECTOR/test/#tiny_vec_testh","title":"tiny_vec_test.h","text":"<pre><code>/**\n * @file tiny_vec_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the test header file for the submodule vec of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n */\n\n#pragma once\n\n#include \"tiny_math_config.h\"\n#include \"tiny_vec.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @name tiny_vec_test\n     * @brief Run unit tests and timing benchmarks for the tiny_vec module.\n     */\n    void tiny_vec_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/VECTOR/test/#tiny_vec_testc","title":"tiny_vec_test.c","text":"<pre><code>/**\n * @file tiny_vec_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file implements test functions for the submodule vec of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n */\n\n#include \"tiny_vec_test.h\"\n\n#define LEN 6\n#define ITERATIONS 10000 // Number of iterations for performance benchmarking\n\n#define RUN_VEC_TEST(FUNC, ...)                                                \\\n    do                                                                         \\\n    {                                                                          \\\n        tiny_error_t err = TINY_OK;                                            \\\n        int actual_iter = 0;                                                   \\\n        TinyTimeMark_t t0 = tiny_get_running_time();                           \\\n        for (int iter = 0; iter &lt; ITERATIONS; iter++)                          \\\n        {                                                                      \\\n            err = FUNC(__VA_ARGS__);                                           \\\n            actual_iter++;                                                     \\\n            if (err != TINY_OK)                                                \\\n                break;                                                         \\\n        }                                                                      \\\n        TinyTimeMark_t t1 = tiny_get_running_time();                           \\\n        double dt_total = (double)(t1 - t0);                                   \\\n        double dt_avg = (actual_iter &gt; 0) ? dt_total / actual_iter : 0.0;     \\\n        printf(\"%-24s | Output: \", #FUNC);                                     \\\n        for (int i = 0; i &lt; LEN; i++)                                          \\\n        {                                                                      \\\n            printf(\"%10.6f \", out[i]);                                         \\\n        }                                                                      \\\n        printf(\"| Total: %8.2f us | Avg: %6.2f us | Iter: %d | Error: %d\\n\\r\", \\\n               dt_total, dt_avg, actual_iter, err);                            \\\n    } while (0)\n\nvoid tiny_vec_test(void)\n{\n    float a[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f};\n    float b[] = {6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f};\n    float out[LEN];\n    float C = 2.0f;\n    float dot_result = 0.0f;\n\n    printf(\"============ [tiny_vec_test] ============\\n\\r\");\n    printf(\"Benchmark Settings: %d iterations per test\\n\\r\", ITERATIONS);\n\n    printf(\"Input Vector a:        \");\n    for (int i = 0; i &lt; LEN; i++)\n        printf(\"%10.6f \", a[i]);\n    printf(\"\\n\\r\");\n\n    printf(\"Input Vector b:        \");\n    for (int i = 0; i &lt; LEN; i++)\n        printf(\"%10.6f \", b[i]);\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C:            %10.6f\\n\\r\\n\\r\", C);\n\n    RUN_VEC_TEST(tiny_vec_add_f32, a, b, out, LEN, 1, 1, 1);\n    RUN_VEC_TEST(tiny_vec_addc_f32, a, out, LEN, C, 1, 1);\n    RUN_VEC_TEST(tiny_vec_sub_f32, a, b, out, LEN, 1, 1, 1);\n    RUN_VEC_TEST(tiny_vec_subc_f32, a, out, LEN, C, 1, 1);\n    RUN_VEC_TEST(tiny_vec_mul_f32, a, b, out, LEN, 1, 1, 1);\n    RUN_VEC_TEST(tiny_vec_mulc_f32, a, out, LEN, C, 1, 1);\n    RUN_VEC_TEST(tiny_vec_div_f32, a, b, out, LEN, 1, 1, 1, true);\n    RUN_VEC_TEST(tiny_vec_divc_f32, a, out, LEN, C, 1, 1, true);\n    RUN_VEC_TEST(tiny_vec_sqrt_f32, a, out, LEN);\n    RUN_VEC_TEST(tiny_vec_sqrtf_f32, a, out, LEN);\n    RUN_VEC_TEST(tiny_vec_inv_sqrt_f32, a, out, LEN);\n    RUN_VEC_TEST(tiny_vec_inv_sqrtf_f32, a, out, LEN);\n\n    // Dot product (non-strided)\n    {\n        tiny_error_t err = TINY_OK;\n        int actual_iter = 0;\n        TinyTimeMark_t t0 = tiny_get_running_time();\n        for (int iter = 0; iter &lt; ITERATIONS; iter++)\n        {\n            err = tiny_vec_dotprod_f32(a, b, &amp;dot_result, LEN);\n            actual_iter++;\n            if (err != TINY_OK)\n                break;\n        }\n        TinyTimeMark_t t1 = tiny_get_running_time();\n        double dt_total = (double)(t1 - t0);\n        double dt_avg = (actual_iter &gt; 0) ? dt_total / actual_iter : 0.0;\n        printf(\"%-24s | Output: %10.6f | Total: %8.2f us | Avg: %6.2f us | Iter: %d | Error: %d\\n\\r\",\n               \"tiny_vec_dotprod_f32\", dot_result, dt_total, dt_avg, actual_iter, err);\n    }\n\n    // Dot product (strided)\n    {\n        tiny_error_t err = TINY_OK;\n        int actual_iter = 0;\n        TinyTimeMark_t t0 = tiny_get_running_time();\n        for (int iter = 0; iter &lt; ITERATIONS; iter++)\n        {\n            err = tiny_vec_dotprode_f32(a, b, &amp;dot_result, LEN, 1, 1);\n            actual_iter++;\n            if (err != TINY_OK)\n                break;\n        }\n        TinyTimeMark_t t1 = tiny_get_running_time();\n        double dt_total = (double)(t1 - t0);\n        double dt_avg = (actual_iter &gt; 0) ? dt_total / actual_iter : 0.0;\n        printf(\"%-24s | Output: %10.6f | Total: %8.2f us | Avg: %6.2f us | Iter: %d | Error: %d\\n\\r\",\n               \"tiny_vec_dotprode_f32\", dot_result, dt_total, dt_avg, actual_iter, err);\n    }\n\n    printf(\"============ [test complete] ============\\n\\r\");\n}\n</code></pre>"},{"location":"MATH/VECTOR/test/#maincpp","title":"main.cpp","text":"<pre><code>#include \"tiny_vec_test.h\"\n\nextern \"C\" void app_main(void)\n{\n    tiny_vec_test();\n}\n</code></pre>"},{"location":"MATH/VECTOR/test/#test-output","title":"Test Output","text":"<p>Basic C computation results</p> <p></p> <p>ESP-DSP accelerated results</p> <p></p> <p>You can see that with ESP-DSP acceleration enabled, the performance of vector operations is significantly improved.</p>"},{"location":"PREREQUISITE/prerequisite/","title":"PREREQUISITES","text":""},{"location":"PREREQUISITE/prerequisite/#hardware-and-software-requirements","title":"HARDWARE AND SOFTWARE REQUIREMENTS","text":"<p>ESP32 development board, please refer to the following projects for details:</p> <ul> <li> <p> NexNode</p> <p>  Repo </p> <p>  Online Doc </p> </li> </ul> <p>We will build upon the code in this project for further development.</p>"},{"location":"PREREQUISITE/prerequisite/#dependency-components","title":"DEPENDENCY COMPONENTS","text":"<p>To enhance the computational efficiency of our framework, we first introduce the ESP-DSP library and ESP-DL library, which provide efficient implementations for digital signal processing and deep learning respectively.</p> <p>Tip</p> <p>Note that these two libraries seem to be developed by different teams, so many of their functions overlap.</p> <pre><code>- espressif__esp-dsp\n- espressif__esp-dl\n   - espressif__dl_fft\n   - espressif__esp_new_jpeg\n</code></pre> <p>We can find and download these components from the ESP-REGISTRY into our project. In this project, I moved the downloaded components and their dependencies into the <code>middleware</code> folder and removed the configuration files to avoid version locking and network dependencies.</p>"},{"location":"TOOLBOX/toolbox/","title":"TOOLBOX","text":"<p>tiny_toolbox</p> <p>tiny_toolbox is a library designed for platform adaptation and optimization, providing various practical tools to serve edge computing and application development. Note that the adaptation and tools are included in the same library because many tools utilize the functions provided by the platform at a lower level. Therefore, placing platform adaptation and various tools together facilitates usage and maintenance.</p> <p>Warning</p> <p>Currently, development is based on ESP32, and migration to platforms like STM32 requires some modifications to the adaptation layer.</p>"},{"location":"TOOLBOX/toolbox/#architecture-and-function-directory","title":"ARCHITECTURE AND FUNCTION DIRECTORY","text":"<pre><code>    tiny_toolbox\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 tiny_toolbox.h // serves as a directory, integrating all submodules\n    \u251c\u2500\u2500 time\n    \u2502   \u251c\u2500\u2500 tiny_time.h // submodule for time management - header file\n    \u2502   \u251c\u2500\u2500 tiny_time.c // submodule for time management - source file\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"TOOLBOX/toolbox/#time","title":"TIME","text":"<ul> <li>Get Running Time: <code>tiny_get_running_time()</code></li> <li>SNTP Time Synchronization: <code>sync_time_with_timezone(\"CST-8\")</code></li> <li>Get World Time: <code>tiny_get_current_datetime(1)</code></li> </ul> <p>TODO:</p> <ul> <li>Local Time Synchronization for Wireless Sensor Networks - Microsecond Level</li> </ul>"},{"location":"TOOLBOX/toolbox/#code","title":"CODE","text":"<p>Tip</p> <p>tiny_toolbox.h serves merely as a directory, integrating all submodules. The specific functionalities are implemented in each submodule. tiny_toolbox.c is just a formal source file without specific functionality.</p>"},{"location":"TOOLBOX/toolbox/#cmakeliststxt","title":"CMakeLists.txt","text":"<pre><code>set(src_dirs\n    .\n    time\n)\n\nset(include_dirs\n    .\n    time\n)\n\nset(requires\n    esp_timer\n    node_rtc\n    espressif__esp-dsp\n    espressif__esp_new_jpeg\n    espressif__dl_fft\n    espressif__esp-dl\n)\n\nidf_component_register(SRC_DIRS ${src_dirs} INCLUDE_DIRS ${include_dirs} REQUIRES ${requires})\n</code></pre>"},{"location":"TOOLBOX/toolbox/#tiny_toolboxh","title":"tiny_toolbox.h","text":"<pre><code>/**\n * @file tiny_toolbox.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the tiny_toolbox middleware.\n * @version 1.0\n * @date 2025-03-26\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* DEPENDENCIES */\n// system\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"esp_log.h\"\n#include \"esp_timer.h\"\n#include \"esp_heap_caps.h\"\n\n// customized drivers\n#include \"node_rtc.h\"\n\n/* SUBMODULES */\n#include \"tiny_time.h\" // Time\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"TOOLBOX/TIME/code/","title":"TIME","text":""},{"location":"TOOLBOX/TIME/code/#tiny_timeh","title":"tiny_time.h","text":"<pre><code>/**\n * @file tiny_time.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief Submodule for TinyToolbox - header file\n * @version 1.0\n * @date 2025-04-10\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* CONFIGURATIONS */\n\n/* ================================ DEPENDENCIES ================================ */\n#include &lt;stdbool.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;time.h&gt;\n#include &lt;sys/time.h&gt;\n#include \"esp_log.h\"\n#include \"esp_timer.h\"\n#include \"esp_sntp.h\"\n// customized drivers\n#include \"node_rtc.h\"\n\n    /* ================================ DEFINITIONS ================================= */\n    // Use int64_t to match esp_timer_get_time() return type and avoid overflow\n    // esp_timer_get_time() returns microseconds since boot (int64_t)\n    typedef int64_t TinyTimeMark_t;\n\n    /**\n     * @brief Structure to hold date and time\n     */\n    typedef struct TinyDateTime_t\n    {\n        int year;\n        int month;\n        int day;\n        int hour;\n        int minute;\n        int second;\n        int32_t microsecond; // Microseconds (0-999999), using int32_t for portability\n    } TinyDateTime_t;\n\n    /* ================================ FUNCTIONS =================================== */\n    /* LOCAL RUNNING TIME IN MICROSECONDS */\n    /**\n     * @brief Get the running time in microseconds\n     * @return TinyTimeMark_t\n     */\n    TinyTimeMark_t tiny_get_running_time(void);\n\n    /* WORLD CURRENT TIME - SNTP */\n    /**\n     * @brief Obtain the current time with timezone\n     * @param timezone_str Timezone string (e.g., \"CST-8\" or \"GMT+8\")\n     * @note The timezone string format should be compatible with POSIX TZ format (e.g., \"CST-8\", \"GMT+8\")\n     * @note To use this function, in application, after internet connection, call sync_time_with_timezone(\"CST-8\")\n     * @return None\n     */\n    void sync_time_with_timezone(const char *timezone_str);\n\n    /* WORLD CURRENT TIME - GET TIME */\n    /**\n     * @name tiny_get_current_datetime\n     * @brief Get the current time as a TinyDateTime_t struct\n     * @param print_flag Flag to indicate whether to print the time\n     * @return TinyDateTime_t structure containing the current date and time\n     */\n    TinyDateTime_t tiny_get_current_datetime(bool print_flag);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"TOOLBOX/TIME/code/#tiny_timec","title":"tiny_time.c","text":"<pre><code>/**\n * @file tiny_time.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief Submodule for TinyToolbox - source file\n * @version 1.0\n * @date 2025-04-10\n * @copyright Copyright (c) 2025\n *\n */\n\n/* ================================ DEPENDENCIES\n * ================================ */\n#include \"tiny_time.h\" // Time\n\n/* ================================ DEFINITIONS\n * ================================= */\n/* CONFIGURATIONS */\n#define MIN_VALID_YEAR_OFFSET \\\n    (2020 - 1900) // Minimum valid year offset (year 2020)\n\n/* TAGS */\nstatic const char *TAG_SNTP = \"NTP_SYNC\";\nstatic const char *TAG_TIME = \"TIME\";\n\n/* ================================ FUNCTIONS\n * =================================== */\n/* LOCAL RUNNING TIME IN MICROSECONDS */\n/**\n * @brief Get the running time in microseconds\n * @return TinyTimeMark_t\n */\nTinyTimeMark_t tiny_get_running_time(void) { return esp_timer_get_time(); }\n\n/* WORLD CURRENT TIME - SNTP */\n/**\n * @brief Callback function for time synchronization notification\n * @param tv Pointer to the timeval structure containing the synchronized time\n * @return None\n */\nstatic void time_sync_notification_cb(struct timeval *tv)\n{\n    ESP_LOGI(TAG_SNTP, \"Time synchronized!\");\n}\n\n/**\n * @brief Initialize SNTP\n * @note This function can be called multiple times if needed\n * @return None\n */\nstatic void initialize_sntp(void)\n{\n    ESP_LOGI(TAG_SNTP, \"Initializing SNTP\");\n    esp_sntp_setoperatingmode(SNTP_OPMODE_POLL);\n    esp_sntp_setservername(0, \"pool.ntp.org\"); // NTP server // pool.ntp.org // ntp.aliyun.com\n    esp_sntp_set_time_sync_notification_cb(time_sync_notification_cb);\n    esp_sntp_init();\n}\n\n/**\n * @brief Obtain the current time with timezone\n * @param timezone_str Timezone string (e.g., \"CST-8\" or \"GMT+8\")\n * @note The timezone string format should be compatible with POSIX TZ format\n * (e.g., \"CST-8\", \"GMT+8\")\n * @note To use this function, in application, after internet connection, call\n * sync_time_with_timezone(\"CST-8\")\n * @return None\n */\nvoid sync_time_with_timezone(const char *timezone_str)\n{\n    // Validate input parameter\n    if (timezone_str == NULL)\n    {\n        ESP_LOGE(TAG_SNTP, \"timezone_str is NULL\");\n        return;\n    }\n\n    // Set system timezone\n    if (setenv(\"TZ\", timezone_str, 1) != 0)\n    {\n        ESP_LOGE(TAG_SNTP, \"Failed to set timezone environment variable\");\n        return;\n    }\n    tzset();\n\n    // Initialize SNTP and start time sync\n    initialize_sntp();\n\n    // Wait for system time to be set\n    time_t now = 0;\n    struct tm timeinfo = {0};\n    int retry = 0;\n    const int retry_count = 15;\n\n    while (timeinfo.tm_year &lt; MIN_VALID_YEAR_OFFSET &amp;&amp; ++retry &lt; retry_count)\n    {\n        ESP_LOGI(TAG_SNTP, \"Waiting for system time to be set... (%d/%d)\", retry,\n                 retry_count);\n        vTaskDelay(2000 / portTICK_PERIOD_MS);\n        time(&amp;now);\n        if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n        {\n            ESP_LOGW(TAG_SNTP, \"Failed to convert time to local time\");\n            continue;\n        }\n    }\n\n    if (timeinfo.tm_year &gt;= MIN_VALID_YEAR_OFFSET)\n    {\n        rtc_set_time(timeinfo.tm_year + 1900, timeinfo.tm_mon + 1, timeinfo.tm_mday,\n                     timeinfo.tm_hour, timeinfo.tm_min,\n                     timeinfo.tm_sec); // defined in esp_rtc.c\n        ESP_LOGI(TAG_SNTP, \"System time is set.\");\n    }\n    else\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to sync time.\");\n        return;\n    }\n\n    // Log current local time (using thread-safe formatting)\n    char time_str[64];\n    if (strftime(time_str, sizeof(time_str), \"%a %b %d %H:%M:%S %Y\", &amp;timeinfo) ==\n        0)\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to format time string\");\n    }\n    else\n    {\n        ESP_LOGI(TAG_SNTP, \"Current time: %s\", time_str);\n    }\n\n    // vTaskDelay(10000 / portTICK_PERIOD_MS); // Wait for 10 second\n    // rtc_get_time(); // uncomment to check the RTC time\n    // ESP_LOGI(TAG_SNTP, \"Current RTC time: %04d-%02d-%02d %02d:%02d:%02d\",\n    //          calendar.year, calendar.month, calendar.date,\n    //          calendar.hour, calendar.min, calendar.sec); // uncomment to check\n    //          the RTC time\n}\n\n/* WORLD CURRENT TIME - GET TIME */\n/**\n * @name tiny_get_current_datetime\n * @brief Get the current time as a TinyDateTime_t struct\n * @param print_flag Flag to indicate whether to print the time\n * @return TinyDateTime_t structure containing the current date and time\n */\nTinyDateTime_t tiny_get_current_datetime(bool print_flag)\n{\n    TinyDateTime_t result = {0}; // Initialize to zero\n    struct timeval tv;\n\n    // Get current time (seconds + microseconds)\n    if (gettimeofday(&amp;tv, NULL) != 0)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to get time of day\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    time_t now = tv.tv_sec;\n    struct tm timeinfo;\n    if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to convert time to local time\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    result.year = timeinfo.tm_year + 1900;\n    result.month = timeinfo.tm_mon + 1;\n    result.day = timeinfo.tm_mday;\n    result.hour = timeinfo.tm_hour;\n    result.minute = timeinfo.tm_min;\n    result.second = timeinfo.tm_sec;\n    result.microsecond = (int32_t)tv.tv_usec; // Explicit cast for portability\n\n    if (print_flag)\n    {\n        ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06d\",\n                 result.year, result.month, result.day, result.hour, result.minute,\n                 result.second, result.microsecond);\n    }\n\n    return result;\n}\n</code></pre>"},{"location":"TOOLBOX/TIME/code/#maincpp","title":"main.cpp","text":"<pre><code>/**\n * @file main.cpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief Main program for testing tiny_time module\n * @version 1.0\n * @date 2025-10-22\n * \n * @copyright Copyright (c) 2024\n * \n */\n\n/* DEPENDENCIES */\n// ESP\n#include \"nvs_flash.h\"\n#include \"esp_log.h\"\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n// FreeRTOS (must be inside extern \"C\" for C++ files)\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"freertos/event_groups.h\"\n#include \"freertos/semphr.h\"\n\n// ESP Timer (high-precision timer)\n#include \"esp_timer.h\"\n\n// WiFi (required for time sync)\n#include \"node_wifi.h\"\n\n// TinyToolbox\n#include \"tiny_time.h\"\n\n/* Variables */\nconst char *TAG = \"tiny_time_test\";\n\n/* Timer precision test variables */\n#define TIMESTAMP_COUNT 15\nstatic TinyTimeMark_t s_timestamps[TIMESTAMP_COUNT] = {0};\nstatic int s_timestamp_index = 0;\nstatic bool s_timer_test_complete = false;\nstatic esp_timer_handle_t s_timer_handle = NULL;\nstatic SemaphoreHandle_t s_timer_mutex = NULL;\n\n/**\n * @brief Timer callback function - records timestamp at the very beginning\n * @param arg Timer argument (not used)\n * @return None\n */\nstatic void timer_precision_callback(void *arg)\n{\n    // CRITICAL: Get timestamp IMMEDIATELY at the start of callback\n    // to avoid any execution overhead affecting the measurement\n    TinyTimeMark_t timestamp = tiny_get_running_time();\n\n    // Store timestamp in array (thread-safe access)\n    if (xSemaphoreTake(s_timer_mutex, portMAX_DELAY) == pdTRUE)\n    {\n        if (s_timestamp_index &lt; TIMESTAMP_COUNT)\n        {\n            s_timestamps[s_timestamp_index++] = timestamp;\n\n            // Stop timer when we have collected all timestamps\n            if (s_timestamp_index &gt;= TIMESTAMP_COUNT)\n            {\n                s_timer_test_complete = true;\n                esp_timer_stop(s_timer_handle);\n            }\n        }\n        xSemaphoreGive(s_timer_mutex);\n    }\n}\n\n/**\n * @brief Entry point of the program - Testing tiny_time module\n * @param None\n * @retval None\n */\nvoid app_main(void)\n{\n    esp_err_t ret;\n\n    // Initialize NVS (required for WiFi)\n    ret = nvs_flash_init();\n    if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND)\n    {\n        ESP_ERROR_CHECK(nvs_flash_erase());\n        ret = nvs_flash_init();\n    }\n    ESP_ERROR_CHECK(ret);\n\n    ESP_LOGI(TAG, \"========================================\");\n    ESP_LOGI(TAG, \"  tiny_time Module Test Program\");\n    ESP_LOGI(TAG, \"========================================\");\n\n    // Initialize WiFi (required for time synchronization)\n    ESP_LOGI(TAG, \"Initializing WiFi...\");\n    ret = wifi_sta_wpa2_init();\n    if (ret != ESP_OK)\n    {\n        ESP_LOGE(TAG, \"WiFi initialization failed!\");\n        return;\n    }\n    ESP_LOGI(TAG, \"WiFi initialized successfully\");\n\n    // Wait for WiFi connection\n    ESP_LOGI(TAG, \"Waiting for WiFi connection...\");\n    EventBits_t ev = xEventGroupWaitBits(wifi_event_group, CONNECTED_BIT, \n                                         pdTRUE, pdFALSE, portMAX_DELAY);\n    if (ev &amp; CONNECTED_BIT)\n    {\n        ESP_LOGI(TAG, \"WiFi connected!\");\n\n        // ============================================================\n        // Test 1: Get running time (microseconds since boot)\n        // ============================================================\n        ESP_LOGI(TAG, \"\\n--- Test 1: Get Running Time ---\");\n        TinyTimeMark_t start_time = tiny_get_running_time();\n        ESP_LOGI(TAG, \"Running time: %lld microseconds\", start_time);\n        ESP_LOGI(TAG, \"Running time: %.3f seconds\", start_time / 1000000.0);\n\n        // ============================================================\n        // Test 2: Sync time with timezone\n        // ============================================================\n        ESP_LOGI(TAG, \"\\n--- Test 2: Sync Time with Timezone ---\");\n        ESP_LOGI(TAG, \"Syncing time with timezone CST-8...\");\n        sync_time_with_timezone(\"CST-8\");\n\n        // Wait for time synchronization (SNTP may take a few seconds)\n        ESP_LOGI(TAG, \"Waiting for time synchronization...\");\n        vTaskDelay(5000 / portTICK_PERIOD_MS);\n\n        // ============================================================\n        // Test 3: Get current datetime\n        // ============================================================\n        ESP_LOGI(TAG, \"\\n--- Test 3: Get Current DateTime ---\");\n        (void)tiny_get_current_datetime(true);  // Function prints internally\n\n        // ============================================================\n        // Test 4: Measure time elapsed\n        // ============================================================\n        ESP_LOGI(TAG, \"\\n--- Test 4: Measure Time Elapsed ---\");\n        TinyTimeMark_t end_time = tiny_get_running_time();\n        TinyTimeMark_t elapsed = end_time - start_time;\n        ESP_LOGI(TAG, \"Time elapsed: %lld microseconds\", elapsed);\n        ESP_LOGI(TAG, \"Time elapsed: %.3f seconds\", elapsed / 1000000.0);\n\n        ESP_LOGI(TAG, \"\\n========================================\");\n        ESP_LOGI(TAG, \"  Initial Tests Completed\");\n        ESP_LOGI(TAG, \"========================================\\n\");\n    }\n    else\n    {\n        ESP_LOGE(TAG, \"WiFi connection failed!\");\n        return;\n    }\n\n    // ============================================================\n    // Timer precision test: Record 15 timestamps at 2-second intervals\n    // ============================================================\n    ESP_LOGI(TAG, \"\\n========================================\");\n    ESP_LOGI(TAG, \"  Timer Precision Test\");\n    ESP_LOGI(TAG, \"========================================\");\n    ESP_LOGI(TAG, \"Recording 15 timestamps at 2-second intervals...\");\n    ESP_LOGI(TAG, \"No printing during recording to avoid timing overhead.\\n\");\n\n    // Create mutex for thread-safe access to timestamp array\n    s_timer_mutex = xSemaphoreCreateMutex();\n    if (s_timer_mutex == NULL)\n    {\n        ESP_LOGE(TAG, \"Failed to create mutex!\");\n        return;\n    }\n\n    // Initialize timer\n    const uint64_t TIMER_PERIOD_US = 2000000;  // 2 seconds in microseconds\n    esp_timer_create_args_t timer_args;\n    timer_args.callback = &amp;timer_precision_callback;\n    timer_args.arg = NULL;\n    timer_args.dispatch_method = ESP_TIMER_TASK;  // Execute callback in timer task\n    timer_args.name = \"precision_timer\";\n    timer_args.skip_unhandled_events = false;  // Don't skip events\n\n    ret = esp_timer_create(&amp;timer_args, &amp;s_timer_handle);\n    if (ret != ESP_OK)\n    {\n        ESP_LOGE(TAG, \"Failed to create timer: %s\", esp_err_to_name(ret));\n        vSemaphoreDelete(s_timer_mutex);\n        return;\n    }\n\n    // Start periodic timer\n    ret = esp_timer_start_periodic(s_timer_handle, TIMER_PERIOD_US);\n    if (ret != ESP_OK)\n    {\n        ESP_LOGE(TAG, \"Failed to start timer: %s\", esp_err_to_name(ret));\n        esp_timer_delete(s_timer_handle);\n        vSemaphoreDelete(s_timer_mutex);\n        return;\n    }\n\n    // Wait for all timestamps to be collected\n    ESP_LOGI(TAG, \"Timer started. Waiting for %d timestamps...\", TIMESTAMP_COUNT);\n    while (!s_timer_test_complete)\n    {\n        vTaskDelay(100 / portTICK_PERIOD_MS);  // Check every 100ms\n    }\n\n    // Wait a bit more to ensure timer has stopped\n    vTaskDelay(100 / portTICK_PERIOD_MS);\n\n    // Print all results\n    ESP_LOGI(TAG, \"\\n========================================\");\n    ESP_LOGI(TAG, \"  Timer Precision Test Results\");\n    ESP_LOGI(TAG, \"========================================\");\n    ESP_LOGI(TAG, \"Expected interval: 2000000 microseconds (2.000000 seconds)\\n\");\n\n    for (int i = 0; i &lt; TIMESTAMP_COUNT; i++)\n    {\n        if (i == 0)\n        {\n            // First timestamp - show absolute time\n            ESP_LOGI(TAG, \"Timestamp #%2d: %lld microseconds (%.6f seconds) [baseline]\",\n                     i + 1, s_timestamps[i], s_timestamps[i] / 1000000.0);\n        }\n        else\n        {\n            // Calculate interval from previous timestamp\n            TinyTimeMark_t interval = s_timestamps[i] - s_timestamps[i - 1];\n            int64_t error = interval - 2000000;  // Expected 2 seconds = 2000000 microseconds\n            double error_ms = error / 1000.0;\n\n            ESP_LOGI(TAG, \"Timestamp #%2d: %lld microseconds (%.6f seconds) | \"\n                     \"Interval: %lld us (%.6f s) | Error: %lld us (%.3f ms)\",\n                     i + 1, \n                     s_timestamps[i], \n                     s_timestamps[i] / 1000000.0,\n                     interval,\n                     interval / 1000000.0,\n                     error,\n                     error_ms);\n        }\n    }\n\n    // Calculate statistics\n    ESP_LOGI(TAG, \"\\n--- Statistics ---\");\n    int64_t total_interval = s_timestamps[TIMESTAMP_COUNT - 1] - s_timestamps[0];\n    int64_t expected_total = 2000000 * (TIMESTAMP_COUNT - 1);\n    int64_t total_error = total_interval - expected_total;\n\n    ESP_LOGI(TAG, \"Total time: %lld microseconds (%.6f seconds)\", \n             total_interval, total_interval / 1000000.0);\n    ESP_LOGI(TAG, \"Expected total: %lld microseconds (%.6f seconds)\", \n             expected_total, expected_total / 1000000.0);\n    ESP_LOGI(TAG, \"Total error: %lld microseconds (%.3f milliseconds)\", \n             total_error, total_error / 1000.0);\n\n    // Calculate average interval\n    double avg_interval = (double)total_interval / (TIMESTAMP_COUNT - 1);\n    ESP_LOGI(TAG, \"Average interval: %.6f seconds (%.3f microseconds)\", \n             avg_interval / 1000000.0, avg_interval);\n\n    // Cleanup\n    esp_timer_delete(s_timer_handle);\n    vSemaphoreDelete(s_timer_mutex);\n\n    ESP_LOGI(TAG, \"\\n========================================\");\n    ESP_LOGI(TAG, \"  Test Complete\");\n    ESP_LOGI(TAG, \"========================================\\n\");\n\n    // Main loop: Keep running\n    while (1)\n    {\n        vTaskDelay(10000 / portTICK_PERIOD_MS);\n    }\n}\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"TOOLBOX/TIME/code/#output","title":"output","text":"<pre><code>I (25) boot: ESP-IDF v6.0-dev-1833-g758939caec 2nd stage bootloader\nI (25) boot: compile time Nov  4 2025 23:13:16\nI (25) boot: Multicore bootloader\nI (27) boot: chip revision: v0.2\nI (30) boot: efuse block revision: v1.3\nI (33) qio_mode: Enabling default flash chip QIO\nI (38) boot.esp32s3: Boot SPI Speed : 80MHz\nI (41) boot.esp32s3: SPI Mode       : QIO\nI (45) boot.esp32s3: SPI Flash Size : 16MB\nI (49) boot: Enabling RNG early entropy source...\nI (54) boot: Partition Table:\nI (56) boot: ## Label            Usage          Type ST Offset   Length\nI (62) boot:  0 nvs              WiFi data        01 02 00009000 00006000\nI (69) boot:  1 phy_init         RF data          01 01 0000f000 00001000\nI (75) boot:  2 factory          factory app      00 00 00010000 001f0000\nI (82) boot:  3 vfs              Unknown data     01 81 00200000 00a00000\nI (89) boot:  4 storage          Unknown data     01 82 00c00000 00400000\nI (95) boot: End of partition table\nI (98) esp_image: segment 0: paddr=00010020 vaddr=3c0b0020 size=1df80h (122752) map\nI (124) esp_image: segment 1: paddr=0002dfa8 vaddr=3fc99300 size=02070h (  8304) load\nI (126) esp_image: segment 2: paddr=00030020 vaddr=42000020 size=a26fch (665340) map\nI (227) esp_image: segment 3: paddr=000d2724 vaddr=3fc9b370 size=030e0h ( 12512) load\nI (229) esp_image: segment 4: paddr=000d580c vaddr=40374000 size=152ech ( 86764) load\nI (247) esp_image: segment 5: paddr=000eab00 vaddr=50000000 size=00020h (    32) load\nI (256) boot: Loaded app from partition at offset 0x10000\nI (256) boot: Disabling RNG early entropy source...\nI (266) octal_psram: vendor id    : 0x0d (AP)\nI (267) octal_psram: dev id       : 0x02 (generation 3)\nI (267) octal_psram: density      : 0x03 (64 Mbit)\nI (269) octal_psram: good-die     : 0x01 (Pass)\nI (273) octal_psram: Latency      : 0x01 (Fixed)\nI (277) octal_psram: VCC          : 0x01 (3V)\nI (281) octal_psram: SRF          : 0x01 (Fast Refresh)\nI (286) octal_psram: BurstType    : 0x01 (Hybrid Wrap)\nI (291) octal_psram: BurstLen     : 0x01 (32 Byte)\nI (296) octal_psram: Readlatency  : 0x02 (10 cycles@Fixed)\nI (301) octal_psram: DriveStrength: 0x00 (1/1)\nI (306) MSPI Timing: PSRAM timing tuning index: 5\nI (310) esp_psram: Found 8MB PSRAM device\nI (313) esp_psram: Speed: 80MHz\nI (316) cpu_start: Multicore app\nI (752) esp_psram: SPI SRAM memory test OK\nI (760) cpu_start: GPIO 44 and 43 are used as console UART I/O pins\nI (761) cpu_start: Pro cpu start user code\nI (761) cpu_start: cpu freq: 240000000 Hz\nI (762) app_init: Application information:\nI (766) app_init: Project name:     AIoTNode\nI (770) app_init: App version:      0a79117-dirty\nI (775) app_init: Compile time:     Nov  4 2025 23:13:38\nI (780) app_init: ELF file SHA256:  a5e0090b4...\nI (784) app_init: ESP-IDF:          v6.0-dev-1833-g758939caec\nI (789) efuse_init: Min chip rev:     v0.0\nI (793) efuse_init: Max chip rev:     v0.99 \nI (797) efuse_init: Chip rev:         v0.2\nI (801) heap_init: Initializing. RAM available for dynamic allocation:\nI (807) heap_init: At 3FCA2918 len 00046DF8 (283 KiB): RAM\nI (812) heap_init: At 3FCE9710 len 00005724 (21 KiB): RAM\nI (818) heap_init: At 3FCF0000 len 00008000 (32 KiB): DRAM\nI (823) heap_init: At 600FE000 len 00001FE8 (7 KiB): RTCRAM\nI (828) esp_psram: Adding pool of 8192K of PSRAM memory to heap allocator\nI (835) spi_flash: detected chip: boya\nI (838) spi_flash: flash io: qio\nI (841) sleep_gpio: Configure to isolate all GPIO pins in sleep state\nI (847) sleep_gpio: Enable automatic switching of GPIO sleep configuration\nI (854) main_task: Started on CPU0\nI (878) esp_psram: Reserving pool of 32K of internal memory for DMA/internal allocations\nI (878) main_task: Calling app_main()\nI (883) tiny_time_test: ========================================\nI (884) tiny_time_test:   tiny_time Module Test Program\nI (889) tiny_time_test: ========================================\nI (895) tiny_time_test: Initializing WiFi...\nI (900) pp: pp rom version: e7ae62f\nI (902) net80211: net80211 rom version: e7ae62f\nI (907) wifi:wifi driver task: 3fcaf644, prio:23, stack:6656, core=0\nI (915) wifi:wifi firmware version: 14da9b7\nI (916) wifi:wifi certification version: v7.0\nI (920) wifi:config NVS flash: enabled\nI (924) wifi:config nano formatting: disabled\nI (928) wifi:Init data frame dynamic rx buffer num: 32\nI (933) wifi:Init static rx mgmt buffer num: 5\nI (937) wifi:Init management short buffer num: 32\nI (941) wifi:Init dynamic tx buffer num: 32\nI (945) wifi:Init static tx FG buffer num: 2\nI (949) wifi:Init static rx buffer size: 1600\nI (953) wifi:Init static rx buffer num: 10\nI (957) wifi:Init dynamic rx buffer num: 32\nI (961) wifi_init: rx ba win: 6\nI (964) wifi_init: accept mbox: 6\nI (967) wifi_init: tcpip mbox: 32\nI (970) wifi_init: udp mbox: 6\nI (973) wifi_init: tcp mbox: 6\nI (975) wifi_init: tcp tx win: 5760\nI (979) wifi_init: tcp rx win: 5760\nI (982) wifi_init: tcp mss: 1440\nI (985) wifi_init: WiFi IRAM OP enabled\nI (988) wifi_init: WiFi RX IRAM OP enabled\nI (992) NODE-WIFI: Setting WiFi configuration SSID NTUSECURE...\nI (999) phy_init: phy_version 701,f4f1da3a,Mar  3 2025,15:50:10\nI (1037) wifi:mode : sta (cc:ba:97:09:a7:50)\nI (1038) wifi:enable tsf\nI (1039) tiny_time_test: WiFi initialized successfully\nI (1040) tiny_time_test: Waiting for WiFi connection...\nI (1107) wifi:new:&lt;1,0&gt;, old:&lt;1,0&gt;, ap:&lt;255,255&gt;, sta:&lt;1,0&gt;, prof:1, snd_ch_cfg:0x0\nI (1108) wifi:state: init -&gt; auth (0xb0)\nI (1111) wifi:state: auth -&gt; assoc (0x0)\nI (1115) wifi:state: assoc -&gt; run (0x10)\nI (1430) wifi:connected with NTUSECURE, aid = 2, channel 1, BW20, bssid = a8:9d:21:3c:12:b1\nI (1430) wifi:security: WPA2-ENT, phy: bgn, rssi: -66\nI (1432) wifi:pm start, type: 1\n\nI (1435) wifi:dp: 1, bi: 104448, li: 2, scale listen interval from 307200 us to 208896 us\nI (1443) wifi:set rx beacon pti, rx_bcn_pti: 0, bcn_timeout: 25000, mt_pti: 0, mt_time: 10000\nI (1459) wifi:&lt;ba-add&gt;idx:0 (ifx:0, a8:9d:21:3c:12:b1), tid:0, ssn:1200, winSize:64\nI (1488) wifi:AP's beacon interval = 104448 us, DTIM period = 1\nI (2467) esp_netif_handlers: sta ip: 10.91.180.236, mask: 255.255.0.0, gw: 10.91.255.254\nI (2467) tiny_time_test: WiFi connected!\nI (2467) tiny_time_test: \n--- Test 1: Get Running Time ---\nI (2473) tiny_time_test: Running time: 1644833 microseconds\nI (2478) tiny_time_test: Running time: 1.645 seconds\nI (2483) tiny_time_test: \n--- Test 2: Sync Time with Timezone ---\nI (2489) tiny_time_test: Syncing time with timezone CST-8...\nI (2494) NTP_SYNC: Initializing SNTP\nI (2498) NTP_SYNC: Waiting for system time to be set... (1/15)\nI (4503) NTP_SYNC: Waiting for system time to be set... (2/15)\nI (4715) NTP_SYNC: Time synchronized!\nI (6503) NTP_SYNC: System time is set.\nI (6503) NTP_SYNC: Current time: Tue Nov 04 23:15:34 2025\nI (6503) tiny_time_test: Waiting for time synchronization...\nI (11506) tiny_time_test: \n--- Test 3: Get Current DateTime ---\nI (11506) TIME: Current Time: 2025-11-04 23:15:39.003179\nI (11506) tiny_time_test: \n--- Test 4: Measure Time Elapsed ---\nI (11511) tiny_time_test: Time elapsed: 9038406 microseconds\nI (11517) tiny_time_test: Time elapsed: 9.038 seconds\nI (11521) tiny_time_test: \n========================================\nI (11527) tiny_time_test:   Initial Tests Completed\nI (11532) tiny_time_test: ========================================\n\nI (11538) tiny_time_test: \n========================================\nI (11544) tiny_time_test:   Timer Precision Test\nI (11548) tiny_time_test: ========================================\nI (11554) tiny_time_test: Recording 15 timestamps at 2-second intervals...\nI (11561) tiny_time_test: No printing during recording to avoid timing overhead.\n\nI (11568) tiny_time_test: Timer started. Waiting for 15 timestamps...\nI (41674) tiny_time_test: \n========================================\nI (41674) tiny_time_test:   Timer Precision Test Results\nI (41674) tiny_time_test: ========================================\nI (41680) tiny_time_test: Expected interval: 2000000 microseconds (2.000000 seconds)\n\nI (41687) tiny_time_test: Timestamp # 1: 12740383 microseconds (12.740383 seconds) [baseline]\nI (41696) tiny_time_test: Timestamp # 2: 14740381 microseconds (14.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41708) tiny_time_test: Timestamp # 3: 16740383 microseconds (16.740383 seconds) | Interval: 2000002 us (2.000002 s) | Error: 2 us (0.002 ms)\nI (41721) tiny_time_test: Timestamp # 4: 18740383 microseconds (18.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41733) tiny_time_test: Timestamp # 5: 20740383 microseconds (20.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41746) tiny_time_test: Timestamp # 6: 22740383 microseconds (22.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41759) tiny_time_test: Timestamp # 7: 24740382 microseconds (24.740382 seconds) | Interval: 1999999 us (1.999999 s) | Error: -1 us (-0.001 ms)\nI (41771) tiny_time_test: Timestamp # 8: 26740383 microseconds (26.740383 seconds) | Interval: 2000001 us (2.000001 s) | Error: 1 us (0.001 ms)\nI (41784) tiny_time_test: Timestamp # 9: 28740383 microseconds (28.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41797) tiny_time_test: Timestamp #10: 30740383 microseconds (30.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41809) tiny_time_test: Timestamp #11: 32740383 microseconds (32.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41822) tiny_time_test: Timestamp #12: 34740381 microseconds (34.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41834) tiny_time_test: Timestamp #13: 36740383 microseconds (36.740383 seconds) | Interval: 2000002 us (2.000002 s) | Error: 2 us (0.002 ms)\nI (41847) tiny_time_test: Timestamp #14: 38740383 microseconds (38.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41860) tiny_time_test: Timestamp #15: 40740381 microseconds (40.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41872) tiny_time_test: \n--- Statistics ---\nI (41877) tiny_time_test: Total time: 27999998 microseconds (27.999998 seconds)\nI (41884) tiny_time_test: Expected total: 28000000 microseconds (28.000000 seconds)\nI (41891) tiny_time_test: Total error: -2 microseconds (-0.002 milliseconds)\nI (41898) tiny_time_test: Average interval: 2.000000 seconds (1999999.857 microseconds)\nI (41906) tiny_time_test: \n========================================\nI (41912) tiny_time_test:   Test Complete\nI (41915) tiny_time_test: ========================================\n</code></pre>"},{"location":"TOOLBOX/TIME/log/","title":"LOG","text":"<p>2025-04-10</p> <ul> <li>Get Running Time: <code>tiny_get_running_time()</code></li> <li>SNTP Time Synchronization: <code>sync_time_with_timezone(\"CST-8\")</code></li> <li>Get World Time: <code>tiny_get_current_datetime(1)</code></li> </ul> <p>TODO:</p> <ul> <li>Local Time Synchronization for Wireless Sensor Networks - Microsecond Level</li> </ul>"},{"location":"TOOLBOX/TIME/notes/","title":"TIME","text":"<p>Time</p> <p>Time related functions are of vital importance for MCU devices. This section provides a series of time related definitions and functions for developers to use.</p> <p>In MCU, time can be divided into the following types:</p> <ul> <li> <p>Running Time: The time from the power-on of the MCU to now.</p> </li> <li> <p>World Time: The time of the time zone where the MCU is located. World time can be represented by standard year, month, day, hour, minute, and second, or it can be represented as a UNIX timestamp.</p> </li> </ul>"},{"location":"TOOLBOX/TIME/notes/#running-time","title":"RUNNING TIME","text":"<p>ESP has its own function to get the running time, <code>esp_timer_get_time</code>, which depends on the <code>esp_timer</code> library. This function returns the time from power-on to now, in microseconds.</p> <p>To facilitate usage, TinyToolbox redefines the data type <code>TinyTimeMark_t</code> and provides a function <code>tiny_get_running_time</code> to get the running time. The time returned by this function is in the unit of int64_t, which is long enough to avoid overflow.</p> <pre><code>typedef int64_t TinyTimeMark_t;\n</code></pre> <pre><code>/**\n * @brief Get the running time in microseconds\n * @return TinyTimeMark_t\n */\nTinyTimeMark_t tiny_get_running_time(void) { return esp_timer_get_time(); }\n</code></pre> <p>Usage reference:</p> <pre><code>void app_main(void)\n{\n    // Get running time\n    TinyTimeMark_t running_time = tiny_get_running_time();\n    ESP_LOGI(TAG_TIME, \"Running Time: %lld us\", running_time);\n}\n</code></pre>"},{"location":"TOOLBOX/TIME/notes/#world-time","title":"WORLD TIME","text":"<p>Warning</p> <p>Note that obtaining world time requires a successful network connection. In other words, the function to obtain world time needs to be called after the network connection is successfully established.</p>"},{"location":"TOOLBOX/TIME/notes/#ntp-time-synchronization","title":"NTP TIME SYNCHRONIZATION","text":"<p>NTP Time Synchronization</p> <p>NTP (Network Time Protocol) is a protocol used to synchronize time in computer networks. It can obtain accurate time information through the Internet or local area network. NTP protocol uses UDP for communication, with the default port being 123. NTP servers periodically send time information to clients, and clients adjust their system time based on this information.</p> <pre><code>    Client                      Server\n      |-------------------&gt;      |     T1\uff1aRequest sent\n      |                          |\n      |         &lt;--------------- |     T2/T3\uff1aServer received &amp; replied\n      |                          |\n      |-------------------&gt;      |     T4\uff1aClient received response\n</code></pre> <p>NTP Time Synchronization Principle</p> <p>NTP time synchronization is based on four timestamps: 1. Timestamp T1 when the client sends the request 2. Timestamp T2 when the server receives the request 3. Timestamp T3 when the server sends the response 4. Timestamp T4 when the client receives the response. Based on these four timestamps, we can calculate Network Delay Delay = (T4 - T1) - (T3 - T2), and Time Offset Offset = ((T2 - T1) + (T3 - T4)) / 2.</p> <p>ESP32 SNTP Time Synchronization</p> <p>In ESP32, SNTP (Simple Network Time Protocol) is used. SNTP is a simplified version of NTP, suitable for scenarios where time accuracy is not critical. The time synchronization in ESP32 relies on the <code>esp_sntp</code> library. The working principle of SNTP is similar to that of NTP, but the implementation of SNTP is relatively simple, making it suitable for embedded devices. Its accuracy is usually at the millisecond level, which is sufficient for most application scenarios.</p> <p>First, define a callback function to receive time synchronization notifications:</p> <pre><code>/* WORLD CURRENT TIME - SNTP */\n/**\n * @brief Callback function for time synchronization notification\n * @param tv Pointer to the timeval structure containing the synchronized time\n * @return None\n */\nstatic void time_sync_notification_cb(struct timeval *tv)\n{\n    ESP_LOGI(TAG_SNTP, \"Time synchronized!\");\n}\n</code></pre> <p>Next is the SNTP initialization function, which is also the core function of time synchronization. It is usually called when the system is initialized and the network is connected. Note that the time synchronization server address can be modified as needed. After the time synchronization is completed, ESP32 will set the local time at the bottom layer.</p> <pre><code>/**\n * @brief Initialize SNTP\n * @note This function can be called multiple times if needed\n * @return None\n */\nstatic void initialize_sntp(void)\n{\n    ESP_LOGI(TAG_SNTP, \"Initializing SNTP\");\n    esp_sntp_setoperatingmode(SNTP_OPMODE_POLL);\n    esp_sntp_setservername(0, \"pool.ntp.org\"); // NTP server // pool.ntp.org // ntp.aliyun.com\n    esp_sntp_set_time_sync_notification_cb(time_sync_notification_cb);\n    esp_sntp_init();\n}\n</code></pre> <p>Next is a further encapsulation of the above functions, including time zone settings. Note that the following function includes the RTC setting <code>rtc_set_time</code>, which depends on the RTC driver at the driver layer. Here I use my custom rtc driver, if there is no related function, you can comment it out directly.</p> <pre><code>/**\n * @brief Obtain the current time with timezone\n * @param timezone_str Timezone string (e.g., \"CST-8\" or \"GMT+8\")\n * @note The timezone string format should be compatible with POSIX TZ format\n * (e.g., \"CST-8\", \"GMT+8\")\n * @note To use this function, in application, after internet connection, call\n * sync_time_with_timezone(\"CST-8\")\n * @return None\n */\nvoid sync_time_with_timezone(const char *timezone_str)\n{\n    // Validate input parameter\n    if (timezone_str == NULL)\n    {\n        ESP_LOGE(TAG_SNTP, \"timezone_str is NULL\");\n        return;\n    }\n\n    // Set system timezone\n    if (setenv(\"TZ\", timezone_str, 1) != 0)\n    {\n        ESP_LOGE(TAG_SNTP, \"Failed to set timezone environment variable\");\n        return;\n    }\n    tzset();\n\n    // Initialize SNTP and start time sync\n    initialize_sntp();\n\n    // Wait for system time to be set\n    time_t now = 0;\n    struct tm timeinfo = {0};\n    int retry = 0;\n    const int retry_count = 15;\n\n    while (timeinfo.tm_year &lt; MIN_VALID_YEAR_OFFSET &amp;&amp; ++retry &lt; retry_count)\n    {\n        ESP_LOGI(TAG_SNTP, \"Waiting for system time to be set... (%d/%d)\", retry,\n                 retry_count);\n        vTaskDelay(2000 / portTICK_PERIOD_MS);\n        time(&amp;now);\n        if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n        {\n            ESP_LOGW(TAG_SNTP, \"Failed to convert time to local time\");\n            continue;\n        }\n    }\n\n    if (timeinfo.tm_year &gt;= MIN_VALID_YEAR_OFFSET)\n    {\n        rtc_set_time(timeinfo.tm_year + 1900, timeinfo.tm_mon + 1, timeinfo.tm_mday,\n                     timeinfo.tm_hour, timeinfo.tm_min,\n                     timeinfo.tm_sec); // defined in esp_rtc.c\n        ESP_LOGI(TAG_SNTP, \"System time is set.\");\n    }\n    else\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to sync time.\");\n        return;\n    }\n\n    // Log current local time (using thread-safe formatting)\n    char time_str[64];\n    if (strftime(time_str, sizeof(time_str), \"%a %b %d %H:%M:%S %Y\", &amp;timeinfo) ==\n        0)\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to format time string\");\n    }\n    else\n    {\n        ESP_LOGI(TAG_SNTP, \"Current time: %s\", time_str);\n    }\n\n    // vTaskDelay(10000 / portTICK_PERIOD_MS); // Wait for 10 second\n    // rtc_get_time(); // uncomment to check the RTC time\n    // ESP_LOGI(TAG_SNTP, \"Current RTC time: %04d-%02d-%02d %02d:%02d:%02d\",\n    //          calendar.year, calendar.month, calendar.date,\n    //          calendar.hour, calendar.min, calendar.sec); // uncomment to check\n    //          the RTC time\n}\n</code></pre>"},{"location":"TOOLBOX/TIME/notes/#world-time-getting","title":"WORLD TIME GETTING","text":"<p>In order to facilitate the acquisition of world time, we first define a data structure <code>DateTime_t</code> to store information such as year, month, day, hour, minute, and second. Then we define a function <code>tiny_get_current_datetime</code> to obtain the current world time. This function returns a <code>DateTime_t</code> structure, which contains the current year, month, day, hour, minute, and second information. When using it, pass in a Boolean value <code>print_flag</code> to control whether to print the current time.</p> <pre><code>/**\n * @brief Structure to hold date and time\n */\ntypedef struct TinyDateTime_t\n{\n    int year;\n    int month;\n    int day;\n    int hour;\n    int minute;\n    int second;\n    long microsecond;\n} TinyDateTime_t; \n</code></pre> <pre><code>/* WORLD CURRENT TIME - GET TIME */\n/**\n * @name tiny_get_current_datetime\n * @brief Get the current time as a TinyDateTime_t struct\n * @param print_flag Flag to indicate whether to print the time\n * @return TinyDateTime_t structure containing the current date and time\n */\nTinyDateTime_t tiny_get_current_datetime(bool print_flag)\n{\n    TinyDateTime_t result = {0}; // Initialize to zero\n    struct timeval tv;\n\n    // Get current time (seconds + microseconds)\n    if (gettimeofday(&amp;tv, NULL) != 0)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to get time of day\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    time_t now = tv.tv_sec;\n    struct tm timeinfo;\n    if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to convert time to local time\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    result.year = timeinfo.tm_year + 1900;\n    result.month = timeinfo.tm_mon + 1;\n    result.day = timeinfo.tm_mday;\n    result.hour = timeinfo.tm_hour;\n    result.minute = timeinfo.tm_min;\n    result.second = timeinfo.tm_sec;\n    result.microsecond = (int32_t)tv.tv_usec; // Explicit cast for portability\n\n    if (print_flag)\n    {\n        ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06d\",\n                 result.year, result.month, result.day, result.hour, result.minute,\n                 result.second, result.microsecond);\n    }\n\n    return result;\n}\n</code></pre> <p>Usage</p> <pre><code>void app_main(void)\n{\n    // Initialize SNTP and sync time\n    sync_time_with_timezone(\"CST-8\");\n\n    // Get current time\n    TinyDateTime_t current_time = tiny_get_current_datetime(true);\n\n    // Print current time\n    ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06ld\",\n             current_time.year, current_time.month, current_time.day,\n             current_time.hour, current_time.minute, current_time.second, current_time.microsecond);\n}\n</code></pre> <p>Example Output</p> <p></p> <p>Danger</p> <p>The SNTP accuracy when syncing to RTC is at the second level, so the microsecond part when obtaining world time may not be accurate and is for reference only.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"zh/","title":"TINYAUTON: \u9762\u5411\u5fae\u63a7\u5236\u5668\u7684\u5206\u5e03\u5f0f\u667a\u80fd\u8d4b\u80fd\u6846\u67b6","text":""},{"location":"zh/#_1","title":"\u5173\u4e8e\u672c\u9879\u76ee","text":"<p>\u8fd9\u4e2a\u9879\u76ee\u81f4\u529b\u4e8e\u5f00\u53d1\u4e00\u4e2a\u8fd0\u884c\u5728 MCU \u8bbe\u5907\u4e0a\u7684\u5c0f\u578b\u667a\u80fd\u4f53\u76f8\u5173\u7684\u8ba1\u7b97\u5e93\uff0c\u4ee5\u670d\u52a1\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6db5\u76d6\u6570\u5b66\u8fd0\u7b97\u3001\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u548c TinyML\u3002</p> <p>\u540d\u5b57\u7684\u7531\u6765</p> <p>\"TinyAuton\" \u662f \"Tiny\" \u548c \"Auton\" \u7684\u7ec4\u5408\u3002\"Tiny\" \u610f\u5473\u7740\u667a\u80fd\u4f53\u88ab\u8bbe\u8ba1\u4e3a\u8fd0\u884c\u5728 MCU \u8bbe\u5907\u4e0a\uff0c\u800c \"Auton\" \u662f \"Autonomous Agent\" \u7684\u7f29\u5199\u3002</p>"},{"location":"zh/#_2","title":"\u76ee\u6807\u786c\u4ef6","text":"<ul> <li>MCU \u8bbe\u5907\uff08\u76ee\u524d\u4ee5 ESP32 \u4e3a\u4e3b\u8981\u76ee\u6807\uff09</li> </ul>"},{"location":"zh/#_3","title":"\u8986\u76d6\u8303\u56f4","text":"<ul> <li>\u5e73\u53f0\u9002\u914d\u4e0e\u5404\u7c7b\u5404\u7c7b\u5de5\u5177\uff08\u65f6\u95f4\u3001\u901a\u8baf\u7b49\uff09</li> <li>\u57fa\u672c\u6570\u5b66\u8fd0\u7b97</li> <li>\u6570\u5b57\u4fe1\u53f7\u5904\u7406</li> <li>TinyML / \u8fb9\u7f18\u4eba\u5de5\u667a\u80fd</li> </ul>"},{"location":"zh/#_4","title":"\u5f00\u53d1\u8f7d\u4f53","text":"<p>Tip</p> <p>\u4ee5\u4e0b\u786c\u4ef6\u4ec5\u505a\u5c55\u793a\u7528\u9014\uff0c\u672c\u9879\u76ee\u5e76\u4e0d\u5c40\u9650\u4e8e\u6b64\uff0c\u53ef\u4ee5\u79fb\u690d\u5230\u5176\u4ed6\u7c7b\u578b\u7684\u786c\u4ef6\u4e0a\u3002</p> <ul> <li>Alientek \u7684 DNESP32S3M\uff08ESP32-S3\uff09</li> </ul> <p></p> <p></p> <ul> <li> <p> NexNode</p> <p>  \u4ee3\u7801 </p> <p>  \u6587\u6863 </p> </li> </ul>"},{"location":"zh/#_5","title":"\u9879\u76ee\u67b6\u6784","text":"<pre><code>+------------------------------+\n| \u5e94\u7528\u5c42                        |\n+------------------------------+\n|   - TinyAI                   | &lt;-- AI \u51fd\u6570\n|   - TinyDSP                  | &lt;-- DSP \u51fd\u6570\n|   - TinyMath                 | &lt;-- \u5e38\u7528\u6570\u5b66\u51fd\u6570\n|   - TinyToolbox              | &lt;-- \u5e73\u53f0\u5e95\u5c42\u4f18\u5316 + \u5404\u79cd\u5de5\u5177\n| \u4e2d\u95f4\u4ef6                        |\n+------------------------------+\n| \u9a71\u52a8\u5c42                        |\n+------------------------------+\n| \u786c\u4ef6\u5c42                        |\n+------------------------------+\n</code></pre>"},{"location":"zh/AI/ai/","title":"\u4eba\u5de5\u667a\u80fd","text":""},{"location":"zh/ARCHITECTURE/architecture/","title":"\u67b6\u6784","text":""},{"location":"zh/ARCHITECTURE/architecture/#_2","title":"\u5206\u5c42\u67b6\u6784","text":"<pre><code>+------------------------------+\n| AI                           | &lt;-- \u57fa\u4e8e\u4f4e\u7ea7\u51fd\u6570\u7684\u8fb9\u7f18\u8bbe\u5907 AI/ML \u51fd\u6570\n+------------------------------+\n| DSP                          | &lt;-- \u6570\u5b57\u4fe1\u53f7\u5904\u7406\u51fd\u6570\n+------------------------------+\n| Math Operations              | &lt;-- \u5404\u79cd\u5e94\u7528\u7684\u5e38\u7528\u6570\u5b66\u51fd\u6570\n+------------------------------+\n| Adaptation/Toolbox Layer     | &lt;-- \u7528\u5e73\u53f0\u4f18\u5316/\u7279\u5b9a\u51fd\u6570\u66ff\u6362\u6807\u51c6 C \u4e2d\u7684\u51fd\u6570\n+------------------------------+\n</code></pre>"},{"location":"zh/DSP/dsp/","title":"\u6570\u5b57\u4fe1\u53f7\u5904\u7406","text":""},{"location":"zh/MATH/math/","title":"\u6570\u5b66\u8fd0\u7b97","text":"<p>Note</p> <p>\u8be5\u7ec4\u4ef6\u7528\u4e8e \u6570\u5b66\u8fd0\u7b97 \uff0c\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5e93\uff0c\u63d0\u4f9b\u57fa\u672c\u7684\u6570\u5b66\u51fd\u6570\uff0c\u4ee5\u4fbf\u4e8e\u677f\u8f7d\u8ba1\u7b97\u548cAI\u6a21\u578b\u63a8\u7406\u3002\u8be5\u5e93\u8bbe\u8ba1\u4e3a \u8f7b\u91cf\u9ad8\u6548 \uff0c\u9002\u5408\u8fb9\u7f18\u8ba1\u7b97\u5e94\u7528\u3002</p> <p>Note</p> <p>\u8be5\u7ec4\u4ef6\u57fa\u4e8eESP32\u5b98\u65b9\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u5e93 ESP-DSP \u8fdb\u884c\u5c01\u88c5\u548c\u6269\u5c55\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u5c42\u6b21\u7684API\u63a5\u53e3\u3002\u7b80\u5355\u6765\u8bf4\uff0cTinyMath\u5e93\u5bf9\u5e94ESP-DSP\u4e2d\u7684Math, Matrix, DotProduct\u6a21\u5757\uff0cESP-DSP\u4e2d\u7684\u5176\u4f59\u6a21\u5757\u5bf9\u5e94TinyDSP\u5e93\u3002</p>"},{"location":"zh/MATH/math/#_2","title":"\u7ec4\u4ef6\u4f9d\u8d56","text":"<pre><code>set(src_dirs\n    .\n    vec\n    mat\n)\n\nset(include_dirs\n    .\n    include\n    vec\n    mat\n)\n\nset(requires\n    tiny_toolbox\n)\n\nidf_component_register(SRC_DIRS ${src_dirs} INCLUDE_DIRS ${include_dirs} REQUIRES ${requires})\n</code></pre>"},{"location":"zh/MATH/math/#_3","title":"\u67b6\u6784\u4e0e\u529f\u80fd\u76ee\u5f55","text":""},{"location":"zh/MATH/math/#_4","title":"\u4f9d\u8d56\u5173\u7cfb\u793a\u610f\u56fe","text":""},{"location":"zh/MATH/math/#_5","title":"\u4ee3\u7801\u6811","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 include\n    |   \u251c\u2500\u2500 tiny_error_type.h // error type header file\n    |   \u251c\u2500\u2500 tiny_constant.h // constant header file\n    |   \u251c\u2500\u2500 tiny_math_config.h // configuration header file\n    |   \u2514\u2500\u2500 tiny_math.h // main header file, include this file where you want to use the library\n    \u251c\u2500\u2500 vec\n    |   \u251c\u2500\u2500 tiny_vec.h // vector header file\n    |   \u251c\u2500\u2500 tiny_vec.c // vector source file\n    |   \u251c\u2500\u2500 tiny_vec_test.c // vector test file\n    |   \u2514\u2500\u2500 tiny_vec_test.h // vector test header file\n    \u251c\u2500\u2500 mat\n    |   \u251c\u2500\u2500 tiny_mat.h // matrix header file - c\n    |   \u251c\u2500\u2500 tiny_mat.c // matrix source file - c\n    |   \u251c\u2500\u2500 tiny_mat_test.c // matrix test file - c \n    |   \u251c\u2500\u2500 tiny_mat_test.h // matrix test header file - c\n    |   \u251c\u2500\u2500 tiny_matrix.hpp // matrix header file - cpp\n    |   \u251c\u2500\u2500 tiny_matrix.cpp // matrix source file - cpp\n    |   \u251c\u2500\u2500 tiny_matrix_test.cpp // matrix test file - cpp\n    |   \u2514\u2500\u2500 tiny_matrix_test.hpp // matrix test header file - cpp\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/","title":"ESP-DSP \u6570\u5b57\u4fe1\u53f7\u5904\u7406\u5e93","text":"<ul> <li> <p> ESP-DSP</p> <p>\u4e00\u4e2a Espressif DSP \u5e93 (esp-dsp)\uff0c\u5b83\u662f\u4e00\u4e2a\u51fd\u6570\u3001\u6a21\u5757\u548c\u7ec4\u4ef6\u7684\u5e93\uff0c\u63d0\u4f9b\u4e86\u4ee5\u9ad8\u6548\u7684\u65b9\u5f0f\u4f7f\u7528 Espressif \u7684 CPU \u4f5c\u4e3a DSP \u7684\u53ef\u80fd\u6027\u3002</p> <p>  \u5728\u7ebf\u6587\u6863 </p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_1","title":"\u51fd\u6570\u547d\u540d","text":"<p>\u547d\u540d\u7ea6\u5b9a\u9002\u7528\u4e8e\u6240\u6709\u8986\u76d6\u7684\u9886\u57df\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7 dsps \u524d\u7f00\u533a\u5206\u4fe1\u53f7\u5904\u7406\u51fd\u6570\uff0c\u800c\u56fe\u50cf\u548c\u89c6\u9891\u5904\u7406\u51fd\u6570\u5177\u6709 dspi \u524d\u7f00\uff0c\u7279\u5b9a\u4e8e\u5c0f\u77e9\u9635\u64cd\u4f5c\u7684\u51fd\u6570\u5728\u5176\u540d\u79f0\u4e2d\u5177\u6709 dspm \u524d\u7f00\u3002\u5e93\u4e2d\u7684\u51fd\u6570\u540d\u79f0\u5177\u6709\u4ee5\u4e0b\u901a\u7528\u683c\u5f0f\uff1a</p> <pre><code>dsp&lt;data-domain&gt;_&lt;name&gt;_&lt;datatype1&gt;&lt;datatype_ext&gt;_&lt;datatype2&gt;&lt;datatype_ext&gt;[_&lt;descriptor&gt;]&lt;_impl&gt;(&lt;parameters&gt;);\n</code></pre> <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p><code>&lt;data-domain&gt;</code> \u662f\u51fd\u6570\u7684\u57df\uff0c\u4f8b\u5982 <code>s</code> \u8868\u793a\u4fe1\u53f7\u5904\u7406\uff0c<code>i</code> \u8868\u793a\u56fe\u50cf\u5904\u7406\uff0c<code>v</code> \u8868\u793a\u89c6\u9891\u5904\u7406\uff0c<code>m</code> \u8868\u793a\u5c0f\u77e9\u9635\u64cd\u4f5c\u3002</p> </li> <li> <p><code>&lt;name&gt;</code> \u662f\u51fd\u6570\u7684\u540d\u79f0\u3002</p> </li> <li> <p><code>&lt;datatype1&gt;</code> \u662f\u7b2c\u4e00\u4e2a\u8f93\u5165\u53c2\u6570\u7684\u7c7b\u578b\u3002</p> </li> <li> <p><code>&lt;datatype_ext&gt;</code> \u662f\u7b2c\u4e00\u4e2a\u8f93\u5165\u53c2\u6570\u7684\u7c7b\u578b\uff0c\u540e\u7f00\u8868\u793a\u6570\u636e\u7684\u7c7b\u578b\uff0c\u4f8b\u5982 <code>f</code> \u8868\u793a\u6d6e\u70b9\u6570\uff0c<code>i</code> \u8868\u793a\u6574\u6570\uff0c<code>c</code> \u8868\u793a\u590d\u6570\u7b49\u3002</p> </li> <li> <p><code>&lt;datatype2&gt;</code> \u662f\u7b2c\u4e8c\u4e2a\u8f93\u5165\u53c2\u6570\u7684\u7c7b\u578b\u3002</p> </li> <li> <p><code>&lt;descriptor&gt;</code> \u662f\u4e00\u4e2a\u53ef\u9009\u63cf\u8ff0\u7b26\uff0c\u63d0\u4f9b\u6709\u5173\u51fd\u6570\u7684\u9644\u52a0\u4fe1\u606f\u3002</p> </li> <li> <p><code>&lt;impl&gt;</code> \u662f\u4e00\u4e2a\u53ef\u9009\u5b9e\u73b0\u63cf\u8ff0\u7b26\uff0c\u63d0\u4f9b\u6709\u5173\u51fd\u6570\u5b9e\u73b0\u7684\u9644\u52a0\u4fe1\u606f\u3002</p> </li> <li> <p><code>&lt;parameters&gt;</code> \u662f\u51fd\u6570\u7684\u53c2\u6570\u3002</p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_2","title":"\u6570\u636e\u57df","text":"<p>\u6570\u636e\u57df\u662f\u4e00\u4e2a\u5355\u5b57\u7b26\uff0c\u8868\u793a\u7ed9\u5b9a\u51fd\u6570\u6240\u5c5e\u7684\u529f\u80fd\u5b50\u96c6\u3002\u5e93\u8bbe\u8ba1\u4e3a\u652f\u6301\u4ee5\u4e0b\u6570\u636e\u57df\uff1a</p> <ul> <li> <p>s - \u4fe1\u53f7\uff08\u9884\u671f\u6570\u636e\u7c7b\u578b\u4e3a 1D \u4fe1\u53f7\uff09</p> </li> <li> <p>i - \u56fe\u50cf\u548c\u89c6\u9891\uff08\u9884\u671f\u6570\u636e\u7c7b\u578b\u4e3a 2D \u56fe\u50cf\uff09</p> </li> <li> <p>m - \u77e9\u9635\uff08\u9884\u671f\u6570\u636e\u7c7b\u578b\u4e3a\u77e9\u9635\uff09</p> </li> <li> <p>r - \u903c\u771f\u6e32\u67d3\u529f\u80fd\u548c 3D \u6570\u636e\u5904\u7406\uff08\u9884\u671f\u6570\u636e\u7c7b\u578b\u53d6\u51b3\u4e8e\u652f\u6301\u7684\u6e32\u67d3\u6280\u672f\uff09</p> </li> <li> <p>q - \u56fa\u5b9a\u957f\u5ea6\u4fe1\u53f7</p> </li> </ul> <p>\u4f8b\u5982\uff0c\u4ee5 dspi \u5f00\u5934\u7684\u51fd\u6570\u540d\u79f0\u8868\u793a\u76f8\u5e94\u7684\u51fd\u6570\u7528\u4e8e\u56fe\u50cf\u6216\u89c6\u9891\u5904\u7406\u3002</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_3","title":"\u540d\u79f0","text":"<p>\u51fd\u6570\u540d\u79f0\u662f\u51fd\u6570\u5b9e\u9645\u6267\u884c\u7684\u6838\u5fc3\u64cd\u4f5c\u7684\u7f29\u5199\uff0c\u4f8b\u5982 Add\u3001Sqrt\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f1a\u540e\u8ddf\u51fd\u6570\u7279\u5b9a\u7684\u4fee\u9970\u7b26\uff1a= [_modifier]</p> <p>\u5982\u679c\u5b58\u5728\u6b64\u4fee\u9970\u7b26\uff0c\u5219\u8868\u793a\u5bf9\u7ed9\u5b9a\u51fd\u6570\u8fdb\u884c\u4e86\u7ec6\u5fae\u7684\u4fee\u6539\u6216\u53d8\u4f53\u3002</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_4","title":"\u6570\u636e\u7c7b\u578b","text":"<p>\u8be5\u5e93\u652f\u6301\u4e24\u79cd\u4e3b\u8981\u6570\u636e\u7c7b\u578b\uff1a\u7528\u4e8e\u5b9a\u70b9\u8fd0\u7b97\u7684 int16 \u548c\u7528\u4e8e\u6d6e\u70b9\u8fd0\u7b97\u7684 float\u3002\u6570\u636e\u7c7b\u578b\u63cf\u8ff0\u5982\u4e0b\uff1a</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_5","title":"\u6570\u636e\u7c7b\u578b\u540e\u7f00","text":"<ul> <li> <p>s - \u6709\u7b26\u53f7</p> </li> <li> <p>u - \u65e0\u7b26\u53f7</p> </li> <li> <p>f - \u6d6e\u70b9\u6570</p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_6","title":"\u6570\u636e\u7c7b\u578b\u6269\u5c55","text":"<ul> <li>c - \u590d\u6570</li> </ul>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_7","title":"\u6570\u636e\u7c7b\u578b\u6bd4\u7279\u5206\u8fa8\u7387","text":"<ul> <li> <p>16</p> </li> <li> <p>32</p> </li> </ul> <p>\u4f8b\u5982\uff1adsps_mac_sc16 \u5b9a\u4e49\u5c06\u4f7f\u7528 16 \u4f4d\u6709\u7b26\u53f7\u590d\u6570\u6570\u636e\u5bf9 1d \u6570\u7ec4\u8fdb\u884c m\u200b\u200bac \u8fd0\u7b97\u3002</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_8","title":"\u5b9e\u73b0\u65b9\u5f0f\u7c7b\u578b","text":"<p>\u6bcf\u4e2a\u51fd\u6570\u53ef\u4ee5\u9488\u5bf9\u4e0d\u540c\u7684\u5e73\u53f0\u8fdb\u884c\u4e0d\u540c\u7684\u5b9e\u73b0\uff0c\u5e76\u4e14\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u6837\u5f0f\u548c\u8d44\u6e90\u3002\u56e0\u6b64\uff0c\u6bcf\u4e2a\u5b9e\u73b0\u7684\u51fd\u6570\u90fd\u4f1a\u6709\u4e00\u4e2a\u6269\u5c55\u540d &lt;_impl&gt;\uff0c\u7528\u4e8e\u5b9a\u4e49\u5176\u5b9e\u73b0\u7c7b\u578b\u3002\u7528\u6237\u65e0\u9700\u6269\u5c55\u540d\u5373\u53ef\u4f7f\u7528\u901a\u7528\u51fd\u6570\u3002</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_9","title":"\u5b9e\u73b0\u65b9\u5f0f\u7c7b\u578b\u540e\u7f00","text":"<p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u51fd\u6570\u65e0\u9700\u6269\u5c55\u5373\u53ef\u4f7f\u7528\u3002\u60a8\u53ef\u4ee5\u5728 menuconfig \u4e2d\u9009\u62e9\u201coptimized/ansi\u201d\u9009\u9879\u3002</p> <p>\u5e93\u4e2d\u7684\u6269\u5c55\u5305\u62ec\uff1a</p> <ul> <li> <p>_ansi - \u901a\u7528\u51fd\u6570\uff0c\u5176\u51fd\u6570\u4f53\u4f7f\u7528 ANSI C \u5b9e\u73b0\u3002\u6b64\u5b9e\u73b0\u4e0d\u5305\u542b\u4efb\u4f55\u786c\u4ef6\u4f18\u5316\u3002</p> </li> <li> <p>_ae32 - \u4f7f\u7528 ESP32 \u6c47\u7f16\u5668\u7f16\u5199\uff0c\u5e76\u9488\u5bf9 ESP32 \u8fdb\u884c\u4e86\u4f18\u5316\u3002</p> </li> <li> <p>_aes3 - \u4f7f\u7528 ESP32S3 \u6c47\u7f16\u5668\u7f16\u5199\uff0c\u5e76\u9488\u5bf9 ESP32S3 \u8fdb\u884c\u4e86\u4f18\u5316\u3002</p> </li> <li> <p>_arp4 - \u4f7f\u7528 ESP32P4 \u6c47\u7f16\u5668\u7f16\u5199\uff0c\u5e76\u9488\u5bf9 ESP32P4 \u8fdb\u884c\u4e86\u4f18\u5316\u3002</p> </li> <li> <p>_platform - \u5934\u6587\u4ef6\uff0c\u5176\u4e2d\u5305\u542b\u9488\u5bf9\u4e0d\u540c\u51fd\u6570\u7684\u53ef\u7528 CPU \u6307\u4ee4\u5b9a\u4e49\u3002</p> </li> <li> <p>\u5176\u4ed6 - \u53d6\u51b3\u4e8e\u652f\u6301\u7684 CPU \u6570\u91cf\u3002\u6b64\u5217\u8868\u672a\u6765\u5c06\u4e0d\u65ad\u6269\u5c55\u3002</p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/examples/","title":"ESP-DSP \u6848\u4f8b","text":""},{"location":"zh/MATH/ESP-DSP/examples/#esp-dsp_1","title":"esp-dsp \u793a\u4f8b\u5217\u8868","text":"<p>\u4fe1\u53f7\u5904\u7406 API \u4f7f\u7528 dsps \u524d\u7f00\u3002\u4ee5\u4e0b\u6a21\u5757\u53ef\u7528\uff1a</p> <ul> <li> <p>\u57fa\u7840\u6570\u5b66 - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528\u57fa\u672c\u5411\u91cf\u6570\u5b66\u8fd0\u7b97</p> </li> <li> <p>\u70b9\u79ef - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528\u70b9\u79ef\u51fd\u6570</p> </li> <li> <p>\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362 - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 FFT \u529f\u80fd</p> </li> <li> <p>\u7a97\u53e3 FFT - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528\u7a97\u53e3\u548c FFT \u529f\u80fd</p> </li> <li> <p>\u5b9e\u6570 FFT - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 FFT \u529f\u80fd\u5904\u7406\u5b9e\u6570\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u65e0\u9650\u8109\u51b2\u54cd\u5e94 (IIR) - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 IIR \u6ee4\u6ce2\u5668\u529f\u80fd</p> </li> <li> <p>\u6709\u9650\u8109\u51b2\u54cd\u5e94 (FIR) - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 FIR \u6ee4\u6ce2\u5668\u529f\u80fd</p> </li> <li> <p>\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668 - \u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668 (EKF) \u793a\u4f8b</p> </li> <li> <p>\u77e9\u9635 - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Mat \u7c7b\u529f\u80fd</p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/examples/#_1","title":"\u57fa\u7840\u6570\u5b66","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u4e2d\u7684\u57fa\u672c\u6570\u5b66\u51fd\u6570\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u7528 1024 \u4e2a\u6837\u672c\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u4f7f\u7528\u6807\u51c6 C \u5faa\u73af\u5bf9\u8f93\u5165\u4fe1\u53f7\u52a0\u7a97\u3002</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT \u5e76\u663e\u793a\u7ed3\u679c</p> </li> <li> <p>\u5728\u56fe\u8868\u4e0a\u663e\u793a\u7ed3\u679c</p> </li> <li> <p>\u4f7f\u7528\u57fa\u672c\u6570\u5b66\u51fd\u6570 dsps_mul_f32 \u548c dsps_mulc_f32 \u5bf9\u8f93\u5165\u4fe1\u53f7\u52a0\u7a97\u3002</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT</p> </li> <li> <p>\u5728\u56fe\u8868\u4e0a\u663e\u793a\u7ed3\u679c</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/basic_math/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#_2","title":"\u70b9\u79ef","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u4e2d\u7684 dotprod dsps_dotprod_f32 \u51fd\u6570\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u8f93\u5165\u6570\u7ec4</p> </li> <li> <p>\u8ba1\u7b97\u4e24\u4e2a\u6570\u7ec4\u7684\u70b9\u79ef</p> </li> <li> <p>\u6bd4\u8f83\u7ed3\u679c\u5e76\u8ba1\u7b97\u6267\u884c\u65f6\u95f4\uff08\u4ee5\u5468\u671f\u4e3a\u5355\u4f4d\uff09\u3002</p> </li> </ul> <p>\u66f4\u591a\u8be6\u60c5\uff0c\u8bf7\u53c2\u9605 examples/dotprod/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#fft","title":"FFT","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 ESP-DSP \u5e93\u4e2d\u7684 FFT \u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u7528 1024 \u4e2a\u6837\u672c\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7\uff1a\u7b2c\u4e00\u4e2a 0 dB\uff0c\u7b2c\u4e8c\u4e2a -20 dB</p> </li> <li> <p>\u5c06\u4e24\u4e2a\u4fe1\u53f7\u5408\u5e76\u4e3a\u4e00\u4e2a\u590d\u6570\u8f93\u5165\u4fe1\u53f7\uff0c\u5e76\u5bf9\u8f93\u5165\u4fe1\u53f7\u5bf9\u5e94\u7528\u7a97\u53e3\u3002</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT</p> </li> <li> <p>\u5bf9\u8f93\u51fa\u590d\u6570\u5411\u91cf\u5e94\u7528\u4f4d\u53cd\u8f6c\u64cd\u4f5c</p> </li> <li> <p>\u5c06\u4e00\u4e2a\u590d\u6570 FFT \u8f93\u51fa\u9891\u8c31\u62c6\u5206\u4e3a\u4e24\u4e2a\u5b9e\u6570\u4fe1\u53f7\u9891\u8c31</p> </li> <li> <p>\u5728\u56fe\u8868\u4e0a\u663e\u793a\u7ed3\u679c</p> </li> <li> <p>\u663e\u793a FFT \u7684\u6267\u884c\u65f6\u95f4</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fft/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#fft_1","title":"FFT \u7a97\u53e3","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u4e2d\u7684\u7a97\u53e3\u548c FFT \u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u7528 1024 \u4e2a\u6837\u672c\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u5bf9\u8f93\u5165\u4fe1\u53f7\u5e94\u7528\u7a97\u53e3\u3002</p> </li> <li> <p>\u5bf9 1024 \u4e2a\u590d\u6570\u6837\u672c\u8ba1\u7b97 FFT</p> </li> <li> <p>\u5bf9\u8f93\u51fa\u590d\u6570\u5411\u91cf\u5e94\u7528\u4f4d\u53cd\u8f6c\u64cd\u4f5c</p> </li> <li> <p>\u5c06\u4e00\u4e2a\u590d\u6570 FFT \u8f93\u51fa\u9891\u8c31\u62c6\u5206\u4e3a\u4e24\u4e2a\u5b9e\u6570\u4fe1\u53f7\u9891\u8c31</p> </li> <li> <p>\u5728\u56fe\u8868\u4e0a\u663e\u793a\u7ed3\u679c</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fft_window/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#fft-4-real","title":"FFT 4 Real","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 ESP-DSP \u5e93\u4e2d\u7684 FFT \u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u7528 1024 \u4e2a\u6837\u672c\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7\uff1a\u7b2c\u4e00\u4e2a 0 dB\uff0c\u7b2c\u4e8c\u4e2a -20 dB</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT \u57fa\u6570 2</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT \u57fa\u6570 4</p> </li> <li> <p>\u5bf9\u8f93\u51fa\u590d\u6570\u5411\u91cf\u5e94\u7528\u4f4d\u53cd\u8f6c\u8fd0\u7b97</p> </li> <li> <p>\u7ed8\u56fe\u663e\u793a\u7ed3\u679c</p> </li> <li> <p>\u663e\u793a FFT \u6267\u884c\u65f6\u95f4</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fft4real/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#iir","title":"IIR","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 ESP-DSP \u5e93\u4e2d\u7684 IIR \u6ee4\u6ce2\u5668\u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u663e\u793a Q \u56e0\u5b50\u4e3a 1 \u7684\u4f4e\u901a\u6ee4\u6ce2\u5668 (LPF)</p> </li> <li> <p>\u8ba1\u7b97 IIR \u6ee4\u6ce2\u5668\u7cfb\u6570</p> </li> <li> <p>\u6ee4\u6ce2\u8f93\u5165\u6d4b\u8bd5\u4fe1\u53f7\uff08Delta \u51fd\u6570\uff09</p> </li> <li> <p>\u5728\u56fe\u4e2d\u663e\u793a\u8109\u51b2\u54cd\u5e94</p> </li> <li> <p>\u5728\u56fe\u4e2d\u663e\u793a\u9891\u7387\u54cd\u5e94</p> </li> <li> <p>\u8ba1\u7b97\u6267\u884c\u6027\u80fd</p> </li> <li> <p>\u5bf9\u4e8e Q \u56e0\u5b50\u4e3a 10 \u7684\u4f4e\u901a\u6ee4\u6ce2\u5668\uff0c\u540c\u6837\u5982\u6b64</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fir/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#fir","title":"FIR","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 ESP-DSP \u5e93\u4e2d\u7684 FIR \u6ee4\u6ce2\u5668\u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316 FFT \u5e93</p> </li> <li> <p>\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u663e\u793a\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u663e\u793a\u6ee4\u6ce2\u540e\u7684\u4fe1\u53f7</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fir/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#_3","title":"\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668","text":"<p>\u672c\u793a\u4f8b\u6a21\u62df\u4e86\u5e26\u6709 IMU \u4f20\u611f\u5668\u7684\u7cfb\u7edf\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u5177\u6709 13 \u4e2a\u72b6\u6001\u5411\u91cf\u7684\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668 (EKF) \u6765\u4f30\u8ba1\u9640\u87ba\u4eea\u8bef\u5dee\u5e76\u8ba1\u7b97\u7cfb\u7edf\u59ff\u6001\u3002\u6b64\u5916\uff0c\u672c\u793a\u4f8b\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u5bf9\u77e9\u9635\u548c\u5411\u91cf\u8fdb\u884c\u8fd0\u7b97\u3002</p> <p>\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\uff0c\u5e94\u5c06\u6a21\u62df\u4f20\u611f\u5668\u503c\u66ff\u6362\u4e3a\u5b9e\u9645\u4f20\u611f\u5668\u503c\u3002\u7136\u540e\uff0c\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\uff0c\u5e94\u6267\u884c\u6821\u51c6\u9636\u6bb5\u3002\u6821\u51c6\u9636\u6bb5\u7ed3\u675f\u540e\uff0c\u5e94\u4fdd\u5b58\u72b6\u6001\u5411\u91cf X \u548c\u534f\u65b9\u5dee\u77e9\u9635 P\uff0c\u5e76\u5728\u4e0b\u6b21\u8c03\u7528\u6ee4\u6ce2\u5668\u65f6\u6062\u590d\u3002\u8fd9\u5c06\u8282\u7701\u521d\u59cb\u9636\u6bb5\u7684\u65f6\u95f4\u3002</p> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/kalman/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#_4","title":"\u77e9\u9635","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u4e2d\u7684 Mat \u7c7b\u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u77e9\u9635 A \u548c \u77e9\u9635 x</p> </li> <li> <p>\u8ba1\u7b97\u77e9\u9635 b\uff1ab = A*x</p> </li> <li> <p>\u4f7f\u7528\u4e0d\u540c\u65b9\u6cd5\u6c42 x1 \u7684\u6839\uff1aA*x1 = b</p> </li> <li> <p>\u6253\u5370\u7ed3\u679c</p> </li> </ul>"},{"location":"zh/MATH/HEADER-FILE/tiny_constants/","title":"\u5e38\u91cf\u5b9a\u4e49","text":"<p>Info</p> <p>\u8be5\u6587\u4ef6\u5305\u542b\u4e86\u4e00\u4e9b\u5e38\u91cf\u7684\u5b9a\u4e49\u7528\u4e8e\u4e0a\u5c42\u8ba1\u7b97\u548c\u5e94\u7528\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bf7\u4ee5\u4ee3\u7801\u4e3a\u51c6\u3002</p> <pre><code>/**\n * @file tiny_constants.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file contains the constants used in the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n// =======================================\n//  Logical Constants\n// =======================================\n#ifndef TRUE\n#define TRUE 1\n#endif\n\n#ifndef FALSE\n#define FALSE 0\n#endif\n\n#ifndef NULL\n#define NULL ((void *)0)\n#endif\n\n// =======================================\n//  Math Constants (float/double safe)\n// =======================================\n#define TINY_PI 3.14159265358979323846f\n#define TINY_TWO_PI 6.28318530717958647692f\n#define TINY_HALF_PI 1.57079632679489661923f\n#define TINY_E 2.71828182845904523536f\n#define TINY_SQRT2 1.41421356237309504880f\n#define TINY_INV_SQRT2 0.70710678118654752440f\n\n#define TINY_DEG2RAD(x) ((x) * TINY_PI / 180.0f)\n#define TINY_RAD2DEG(x) ((x) * 180.0f / TINY_PI)\n\n// =======================================\n//  Bitmask &amp; Bit Manipulation\n// =======================================\n\n// Bitwise operations\n#define TINY_BIT(n) (1U &lt;&lt; (n)) // e.g. TINY_BIT(3) = 0b00001000\n#define TINY_BIT_SET(x, n) ((x) |= TINY_BIT(n))\n#define TINY_BIT_CLEAR(x, n) ((x) &amp;= ~TINY_BIT(n))\n#define TINY_BIT_TOGGLE(x, n) ((x) ^= TINY_BIT(n))\n#define TINY_BIT_CHECK(x, n) (((x) &gt;&gt; (n)) &amp; 0x1U)\n\n// Common bit masks\n#define TINY_MASK_4BIT 0x0FU\n#define TINY_MASK_8BIT 0xFFU\n#define TINY_MASK_16BIT 0xFFFFU\n#define TINY_MASK_32BIT 0xFFFFFFFFU\n\n// =======================================\n//  Fixed-Point Scaling Factors\n// =======================================\n#define TINY_Q7_SCALE 128          // 2^7\n#define TINY_Q15_SCALE 32768       // 2^15\n#define TINY_Q31_SCALE 2147483648U // 2^31\n\n// =======================================\n//  User-Defined Constants (Optional)\n// =======================================\n#define TINY_MATH_MIN_DENOMINATOR 1e-6f         // Minimum denominator for safe division\n#define TINY_MATH_MIN_POSITIVE_INPUT_F32 1e-12f // Minimum positive input for float operations\n#define TINY_MATH_LARGE_VALUE_F32 1e38f         // Large value used to represent infinity-like results (safe for IEEE 754 float, max ~3.4e38)\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/MATH/HEADER-FILE/tiny_error_type/","title":"\u9519\u8bef\u7c7b\u578b\u5b9a\u4e49","text":"<p>Info</p> <p>\u8be5\u6587\u4ef6\u5b9a\u4e49\u4e86\u4e00\u4e9b\u8ba1\u7b97\u4e2d\u5e38\u89c1\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u7528\u4e8e\u8f85\u52a9\u5224\u65ad\u9519\u8bef\u539f\u56e0\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u7b26\uff0c\u8bf7\u4ee5\u4ee3\u7801\u4e3a\u51c6\u3002</p> <pre><code>/**\n * @file tiny_error_type.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /* TYPE DEFINITIONS */\n    typedef int tiny_error_t; // Error type for the tiny_math middleware\n\n/* MACROS */\n/* Definitions for error constants. */\n#define TINY_OK 0    /*!&lt; tiny_err_t value indicating success (no error) */\n#define TINY_FAIL -1 /*!&lt; Generic tiny_err_t code indicating failure */\n\n#define TINY_ERR_NO_MEM 0x101           /*!&lt; Out of memory */\n#define TINY_ERR_INVALID_ARG 0x102      /*!&lt; Invalid argument */\n#define TINY_ERR_INVALID_STATE 0x103    /*!&lt; Invalid state */\n#define TINY_ERR_INVALID_SIZE 0x104     /*!&lt; Invalid size */\n#define TINY_ERR_NOT_FOUND 0x105        /*!&lt; Requested resource not found */\n#define TINY_ERR_NOT_SUPPORTED 0x106    /*!&lt; Operation or feature not supported */\n#define TINY_ERR_TIMEOUT 0x107          /*!&lt; Operation timed out */\n#define TINY_ERR_INVALID_RESPONSE 0x108 /*!&lt; Received response was invalid */\n#define TINY_ERR_INVALID_CRC 0x109      /*!&lt; CRC or checksum was invalid */\n#define TINY_ERR_INVALID_VERSION 0x10A  /*!&lt; Version was invalid */\n#define TINY_ERR_INVALID_MAC 0x10B      /*!&lt; MAC address was invalid */\n#define TINY_ERR_NOT_FINISHED 0x10C     /*!&lt; Operation has not fully completed */\n#define TINY_ERR_NOT_ALLOWED 0x10D      /*!&lt; Operation is not allowed */\n\n#define TINY_ERR_WIFI_BASE 0x3000      /*!&lt; Starting number of WiFi error codes */\n#define TINY_ERR_MESH_BASE 0x4000      /*!&lt; Starting number of MESH error codes */\n#define TINY_ERR_FLASH_BASE 0x6000     /*!&lt; Starting number of flash error codes */\n#define TINY_ERR_HW_CRYPTO_BASE 0xc000 /*!&lt; Starting number of HW cryptography module error codes */\n#define TINY_ERR_MEMPROT_BASE 0xd000   /*!&lt; Starting number of Memory Protection API error codes */\n\n#define TINY_ERR_MATH_BASE 0x70000\n#define TINY_ERR_MATH_INVALID_LENGTH (TINY_ERR_MATH_BASE + 1)\n#define TINY_ERR_MATH_INVALID_PARAM (TINY_ERR_MATH_BASE + 2)\n#define TINY_ERR_MATH_PARAM_OUTOFRANGE (TINY_ERR_MATH_BASE + 3)\n#define TINY_ERR_MATH_UNINITIALIZED (TINY_ERR_MATH_BASE + 4)\n#define TINY_ERR_MATH_REINITIALIZED (TINY_ERR_MATH_BASE + 5)\n#define TINY_ERR_MATH_ARRAY_NOT_ALIGNED (TINY_ERR_MATH_BASE + 6)\n#define TINY_ERR_MATH_NULL_POINTER (TINY_ERR_MATH_BASE + 7)\n#define TINY_ERR_MATH_ZERO_DIVISION (TINY_ERR_MATH_BASE + 8)\n#define TINY_ERR_MATH_NEGATIVE_SQRT (TINY_ERR_MATH_BASE + 9)\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/MATH/HEADER-FILE/tiny_math/","title":"TinyMath\u5934\u6587\u4ef6","text":"<p>Info</p> <p>\u8fd9\u662fTinyMath\u5e93\u7684\u4e3b\u5934\u6587\u4ef6\u3002\u5b83\u5305\u542b\u6240\u6709\u5fc5\u8981\u7684\u5934\u6587\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u63a5\u53e3\u6765\u4f7f\u7528\u5e93\u7684\u529f\u80fd\u3002\u5728\u9879\u76ee\u4e2d\u5b8c\u6210\u8be5\u5e93\u7684\u79fb\u690d\u540e\uff0c\u5728\u9700\u8981\u4f7f\u7528\u76f8\u5173\u51fd\u6570\u7684\u5730\u65b9\u63d2\u5165\u8be5\u5934\u6587\u4ef6\u5373\u53ef\u4f7f\u7528\u5e93\u5185\u7684\u6240\u6709\u51fd\u6570\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bf7\u4ee5\u5b9e\u9645\u4ee3\u7801\u4e3a\u51c6\u3002</p> <pre><code>/**\n * @file tiny_math.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-03-26\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n\n// this layer\n#include \"tiny_math_config.h\"\n\n/* SUBMODULES */\n\n// vector operations\n#include \"tiny_vec.h\"\n\n// matrix operations\n#include \"tiny_mat.h\"\n\n// advanced matrix operations\n#ifdef __cplusplus\n\n#include \"tiny_matrix.hpp\"\n\n#endif\n\n/* TEST */ // NOTE: test files are platform specific and should not be included in the library\n\n// vector operations\n#include \"tiny_vec_test.h\"\n\n// matrix operations\n#include \"tiny_mat_test.h\"\n\n// advanced matrix operations\n#ifdef __cplusplus\n\n#include \"tiny_matrix_test.hpp\"\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/MATH/HEADER-FILE/tiny_math_config/","title":"TinyMath \u914d\u7f6e","text":"<p>Info</p> <p>\u8fd9\u4e2a\u5934\u6587\u4ef6\u8d77\u5230\u914d\u7f6e\u6574\u4e2aTinyMath\u6a21\u5757\u7684\u4f5c\u7528\uff0c\u6bcf\u4e2a\u5b50\u6a21\u5757\u90fd\u5305\u542b\u4e86\u6b64\u5934\u6587\u4ef6\u3002\u5b83\u5b9a\u4e49\u4e86TinyMath\u7684\u914d\u7f6e\u9009\u9879\u548c\u5b8f\uff0c\u5141\u8bb8\u7528\u6237\u6839\u636e\u9700\u8981\u8fdb\u884c\u81ea\u5b9a\u4e49\u8bbe\u7f6e\u3002\u901a\u8fc7\u4fee\u6539\u8fd9\u4e2a\u5934\u6587\u4ef6\u4e2d\u7684\u914d\u7f6e\u9009\u9879\uff0c\u7528\u6237\u53ef\u4ee5\u8f7b\u677e\u5730\u8c03\u6574TinyMath\u7684\u884c\u4e3a\u548c\u529f\u80fd\uff0c\u4ee5\u6ee1\u8db3\u7279\u5b9a\u7684\u9700\u6c42\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4f1a\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bf7\u4ee5\u4ee3\u7801\u4e3a\u51c6\u3002</p> <p>Tip</p> <p>\u8be5\u7ec4\u4ef6\u5185\u5305\u62ec\u9009\u62e9\u5e73\u53f0\u7684\u5b8f\u5b9a\u4e49\uff0c\u7528\u6237\u53ef\u4ee5\u6839\u636e\u9700\u8981\u9009\u62e9\u4e0d\u540c\u7684\u5e73\u53f0\u8fdb\u884c\u7f16\u8bd1\u3002\u5207\u6362\u5230\u5bf9\u5e94\u5e73\u53f0\u7684\u5b8f\u540e\uff0c\u53ef\u4ee5\u5229\u7528\u5e73\u53f0\u52a0\u901f\u7684\u7279\u6027\u6765\u63d0\u5347\u6027\u80fd\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8eESP32\u5e73\u53f0\uff0cTinyMath\u4f1a\u81ea\u52a8\u9009\u62e9ESP32\u7684DSP\u5e93\u8fdb\u884c\u7f16\u8bd1\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6570\u5b66\u8fd0\u7b97\u3002</p> <pre><code>/**\n * @file tiny_math_config.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-14\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* DEPENDENCIES */\n\n// ANSI C\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;math.h&gt;\n#include &lt;stdbool.h&gt;\n#include &lt;stdint.h&gt;\n\n// lower level\n#include \"tiny_toolbox.h\"\n\n// this level\n#include \"tiny_error_type.h\"\n#include \"tiny_constants.h\"\n\n/* PLATFORM SELECTION */\n\n// available platforms\n#define MCU_PLATFORM_GENERIC 0\n#define MCU_PLATFORM_ESP32 1 // here, we utilize the ESP built-in DSP library, it will automatically select the optimized version\n#define MCU_PLATFORM_STM32 2\n#define MCU_PLATFORM_RISCV 3\n\n// choose one platform\n#define MCU_PLATFORM_SELECTED MCU_PLATFORM_ESP32\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/","title":"\u77e9\u9635\u64cd\u4f5c - TINY_MAT","text":"<p>\u5173\u4e8etiny_mat\u5e93</p> <p>tiny_mat\u662f\u4e00\u4e2aC\u8bed\u8a00\u5b9e\u73b0\u7684\u77e9\u9635\u5e93\uff0c\u63d0\u4f9b\u4e86\u57fa\u672c\u7684\u77e9\u9635\u64cd\u4f5c\u51fd\u6570\u3002\u5b83\u652f\u6301\u6d6e\u70b9\u6570\u77e9\u9635\u7684\u52a0\u6cd5\u3001\u51cf\u6cd5\u548c\u4e58\u6cd5\u7b49\u64cd\u4f5c\u3002\u8be5\u5e93\u9002\u7528\u4e8e\u9700\u8981\u8fdb\u884c\u77e9\u9635\u8ba1\u7b97\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u5b9e\u65f6\u5e94\u7528\u3002\u8be5\u5e93\u57fa\u4e8eANSIC C\u6807\u51c6\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u79fb\u690d\u6027\u548c\u6027\u80fd,\u540c\u65f6\u53c8\u652f\u6301\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u8fdb\u884c\u914d\u7f6e\u4ece\u800c\u652f\u6301\u5e73\u53f0\u52a0\u901f\uff08ESP32\uff09\u3002</p> <p>\u5173\u4e8etiny_mat\u5e93\u7684\u4f7f\u7528</p> <p>tiny_mat\u7684\u529f\u80fd\u88abtiny_matrix\u5b8c\u5168\u8986\u76d6\uff0c\u4e5f\u5c31\u662f\u8bf4\u5728tiny_matrix\u4e2d\u7684\u529f\u80fd\u5305\u542b\u4e86tiny_mat\u7684\u6240\u6709\u529f\u80fd\u3002\u5bf9\u4e8e\u7b80\u5355\u7684\u77e9\u9635\u64cd\u4f5c\uff0c\u53ef\u4ee5\u4ec5\u5f15\u5165tiny_mat\u5e93\uff1b\u5bf9\u4e8e\u590d\u6742\u7684\u77e9\u9635\u64cd\u4f5c\uff0c\u5efa\u8bae\u4f7f\u7528tiny_matrix\u5e93\u3002tiny_matrix\u5e93\u662f\u4e00\u4e2aC++\u5b9e\u73b0\u7684\u77e9\u9635\u5e93\uff0c\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u529f\u80fd\u548c\u66f4\u597d\u7684\u6027\u80fd\u3002\u5b83\u652f\u6301\u6d6e\u70b9\u6570\u548c\u6574\u6570\u77e9\u9635\u7684\u52a0\u6cd5\u3001\u51cf\u6cd5\u3001\u4e58\u6cd5\u3001\u8f6c\u7f6e\u3001\u6c42\u9006\u7b49\u64cd\u4f5c\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_1","title":"\u76ee\u5f55","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500Vector\n    \u2514\u2500\u2500Matrix\n        \u251c\u2500\u2500 tiny_mat (c) &lt;---\n        \u2514\u2500\u2500 tiny_matrix (c++)\n</code></pre> <pre><code>// print matrix\nvoid print_matrix(const char *name, const float *mat, int rows, int cols);\n// print matrix padded (row-major)\nvoid print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n// addition\ntiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// subtraction\ntiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// multiplication\ntiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\ntiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\ntiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_2","title":"\u5de5\u5177\u51fd\u6570","text":""},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_3","title":"\u6253\u5370\u77e9\u9635","text":"<pre><code>void print_matrix(const char *name, const float *mat, int rows, int cols);\n</code></pre> <p>\u51fd\u6570: \u4ee5\u884c\u4e3b\u5e8f\u6253\u5370\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>name</code>: \u77e9\u9635\u540d\u79f0\u3002</p> </li> <li> <p><code>mat</code>: \u77e9\u9635\u6570\u636e\u6307\u9488\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u65e0\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_4","title":"\u6253\u5370\u5e26\u586b\u5145\u7684\u77e9\u9635","text":"<pre><code>void print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n</code></pre> <p>\u51fd\u6570: \u4ee5\u884c\u4e3b\u5e8f\u6253\u5370\u5e26\u586b\u5145\u7684\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>name</code>: \u77e9\u9635\u540d\u79f0\u3002</p> </li> <li> <p><code>mat</code>: \u77e9\u9635\u6570\u636e\u6307\u9488\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>step</code>: \u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u65e0\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_5","title":"\u77e9\u9635\u52a0\u6cd5","text":"<pre><code>tiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u52a0\u6cd5\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input1</code>: \u8f93\u5165\u77e9\u96351\u3002</p> </li> <li> <p><code>input2</code>: \u8f93\u5165\u77e9\u96352\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd1</code>: \u8f93\u5165\u77e9\u96351\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd2</code>: \u8f93\u5165\u77e9\u96352\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step1</code>: \u8f93\u5165\u77e9\u96351\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step2</code>: \u8f93\u5165\u77e9\u96352\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_6","title":"\u77e9\u9635\u52a0\u5e38\u6570","text":"<pre><code>tiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u52a0\u5e38\u6570\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u77e9\u9635\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>C</code>: \u5e38\u6570\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_7","title":"\u77e9\u9635\u51cf\u6cd5","text":"<pre><code>tiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u51cf\u6cd5\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input1</code>: \u8f93\u5165\u77e9\u96351\u3002</p> </li> <li> <p><code>input2</code>: \u8f93\u5165\u77e9\u96352\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd1</code>: \u8f93\u5165\u77e9\u96351\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd2</code>: \u8f93\u5165\u77e9\u96352\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step1</code>: \u8f93\u5165\u77e9\u96351\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step2</code>: \u8f93\u5165\u77e9\u96352\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_8","title":"\u77e9\u9635\u51cf\u5e38\u6570","text":"<pre><code>tiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u51cf\u5e38\u6570\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u77e9\u9635\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>C</code>: \u5e38\u6570\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_9","title":"\u77e9\u9635\u4e58\u6cd5","text":"<pre><code>tiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u4e58\u6cd5\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>A</code>: \u8f93\u5165\u77e9\u9635A\u3002</p> </li> <li> <p><code>B</code>: \u8f93\u5165\u77e9\u9635B\u3002</p> </li> <li> <p><code>C</code>: \u8f93\u51fa\u77e9\u9635C\u3002</p> </li> <li> <p><code>m</code>: \u77e9\u9635A\u7684\u884c\u6570\u3002</p> </li> <li> <p><code>n</code>: \u77e9\u9635A\u7684\u5217\u6570\u3002</p> </li> <li> <p><code>k</code>: \u77e9\u9635B\u7684\u5217\u6570\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_10","title":"\u6269\u5c55\u77e9\u9635\u4e58\u6cd5","text":"<pre><code>tiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\n</code></pre> <p>\u51fd\u6570: \u6269\u5c55\u77e9\u9635\u4e58\u6cd5\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>A</code>: \u8f93\u5165\u77e9\u9635A\u3002</p> </li> <li> <p><code>B</code>: \u8f93\u5165\u77e9\u9635B\u3002</p> </li> <li> <p><code>C</code>: \u8f93\u51fa\u77e9\u9635C\u3002</p> </li> <li> <p><code>A_rows</code>: \u77e9\u9635A\u7684\u884c\u6570\u3002</p> </li> <li> <p><code>A_cols</code>: \u77e9\u9635A\u7684\u5217\u6570\u3002</p> </li> <li> <p><code>B_cols</code>: \u77e9\u9635B\u7684\u5217\u6570\u3002</p> </li> <li> <p><code>A_padding</code>: \u77e9\u9635A\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>B_padding</code>: \u77e9\u9635B\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>C_padding</code>: \u77e9\u9635C\u7684\u586b\u5145\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_11","title":"\u77e9\u9635\u4e58\u5e38\u6570","text":"<pre><code>tiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u4e58\u5e38\u6570\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u77e9\u9635\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>C</code>: \u5e38\u6570\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-code/","title":"\u4ee3\u7801","text":""},{"location":"zh/MATH/MATRIX/tiny-mat-test/","title":"TINY_MAT \u6d4b\u8bd5","text":""},{"location":"zh/MATH/MATRIX/tiny-mat-test/#_1","title":"\u6d4b\u8bd5\u4ee3\u7801","text":""},{"location":"zh/MATH/MATRIX/tiny-mat-test/#maincpp","title":"main.cpp","text":"<pre><code>#include \"tiny_mat_test.hpp\"\n\nextern \"C\" void app_main(void)\n{\n    tiny_mat_test();\n}\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-mat-test/#_2","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<pre><code>============ [tiny_mat_test] ============\n\n================================================================================\nTest Case 1: tiny_mat_add_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1\n\nInput1 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nInput2 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5 \n  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\n          [4.5  5.5  6.5  7.5]  &lt;- Row 1\n          [8.5  9.5 10.5 11.5]  &lt;- Row 2\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.5   3.5   5.5   7.5   9.5  11.5  13.5  15.5  17.5  19.5  21.5  23.5 \n  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\n          [9.5 11.5 13.5 15.5]  &lt;- Row 1\n          [17.5 19.5 21.5 23.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.5   3.5   5.5   7.5   9.5  11.5  13.5  15.5  17.5  19.5  21.5  23.5 \n  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\n          [9.5 11.5 13.5 15.5]  &lt;- Row 1\n          [17.5 19.5 21.5 23.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 2: tiny_mat_add_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad1=2, pad2=1, pad_out=2, step1=2, step2=3, step_out=2\nIndex formula: index = row * (cols + padding) + col * step\n\nInput1 Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nInput2 Memory Layout (16 elements, pad=1, step=3):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\n  Value:   0.5  0.0  0.0  1.5  3.5  0.0  2.5  4.5  0.0  0.0  5.5  0.0 ...\n  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\n          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\n          (X = padding/unused)\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.5  0.0  3.5  0.0  5.5  7.5  0.0  9.5  0.0 11.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.5  X  3.5  X  5.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [7.5  X  9.5  X 11.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.5  0.0  3.5  0.0  5.5  7.5  0.0  9.5  0.0 11.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.5  X  3.5  X  5.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [7.5  X  9.5  X 11.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 3: tiny_mat_addc_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1, C=2.5\n\nInput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nConstant C =   2.5\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5  12.5  13.5  14.5 \n  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\n          [7.5  8.5  9.5 10.5]  &lt;- Row 1\n          [11.5 12.5 13.5 14.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5  12.5  13.5  14.5 \n  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\n          [7.5  8.5  9.5 10.5]  &lt;- Row 1\n          [11.5 12.5 13.5 14.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 4: tiny_mat_addc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad_in=2, pad_out=2, step_in=2, step_out=2, C=  1.5\nIndex formula: index = row * (cols + padding) + col * step\n\nInput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nConstant C =   1.5\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   2.5  0.0  3.5  0.0  4.5  5.5  0.0  6.5  0.0  7.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   2.5  0.0  3.5  0.0  4.5  5.5  0.0  6.5  0.0  7.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 5: tiny_mat_sub_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1\n\nInput1 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nInput2 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5 \n  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\n          [4.5  5.5  6.5  7.5]  &lt;- Row 1\n          [8.5  9.5 10.5 11.5]  &lt;- Row 2\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 \n  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\n          [0.5  0.5  0.5  0.5]  &lt;- Row 1\n          [0.5  0.5  0.5  0.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 \n  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\n          [0.5  0.5  0.5  0.5]  &lt;- Row 1\n          [0.5  0.5  0.5  0.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 6: tiny_mat_sub_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad1=2, pad2=1, pad_out=2, step1=2, step2=3, step_out=2\nIndex formula: index = row * (cols + padding) + col * step\n\nInput1 Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nInput2 Memory Layout (16 elements, pad=1, step=3):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\n  Value:   0.5  0.0  0.0  1.5  3.5  0.0  2.5  4.5  0.0  0.0  5.5  0.0 ...\n  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\n          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\n          (X = padding/unused)\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   0.5  0.0  0.5  0.0  0.5  0.5  0.0  0.5  0.0  0.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   0.5  0.0  0.5  0.0  0.5  0.5  0.0  0.5  0.0  0.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 7: tiny_mat_subc_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1, C=2.5\n\nInput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nConstant C =   2.5\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:   -1.5  -0.5   0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5 \n  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\n          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\n          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:   -1.5  -0.5   0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5 \n  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\n          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\n          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 8: tiny_mat_subc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad_in=2, pad_out=2, step_in=2, step_out=2, C=  1.5\nIndex formula: index = row * (cols + padding) + col * step\n\nInput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nConstant C =   1.5\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:  -0.5  0.0  0.5  0.0  1.5  2.5  0.0  3.5  0.0  4.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:  -0.5  0.0  0.5  0.0  1.5  2.5  0.0  3.5  0.0  4.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 9: tiny_mat_mult_f32 - Basic Matrix Multiplication\n================================================================================\nParameters: m=3, n=4, k=2 (A is 3x4, B is 4x2, C is 3x2)\nNote: This function always uses ESP-DSP on ESP32, standard implementation otherwise\n\nMatrix A Memory Layout (3x4, 12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nMatrix B Memory Layout (4x2, 8 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5 \n  Matrix: [0.5  1.5]  &lt;- Row 0\n          [2.5  3.5]  &lt;- Row 1\n          [4.5  5.5]  &lt;- Row 2\n          [6.5  7.5]  &lt;- Row 3\n\nExpected Output Matrix C Memory Layout (3x2, 6 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0\n          [101.0  127.0]  &lt;- Row 1\n          [157.0  199.0] &lt;- Row 2\n  Calculation:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 =  45.0\n    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1] + A[0][3]*B[3][1]\n            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 + 4.0*7.5 =  55.0\n\nOutput Matrix C Memory Layout (3x2, 6 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0\n          [101.0  127.0]  &lt;- Row 1\n          [157.0  199.0] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 10: tiny_mat_mult_f32 - Square Matrix Multiplication\n================================================================================\nParameters: m=3, n=3, k=3 (A is 3x3, B is 3x3, C is 3x3)\nNote: This function always uses ESP-DSP on ESP32, standard implementation otherwise\n\nMatrix A Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0 \n  Matrix: [1.0  2.0  3.0]  &lt;- Row 0\n          [4.0  5.0  6.0]  &lt;- Row 1\n          [7.0  8.0  9.0]  &lt;- Row 2\n\nMatrix B Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    0.5   1.0   1.5   2.0   2.5   3.0   3.5   4.0   4.5 \n  Matrix: [0.5  1.0  1.5]  &lt;- Row 0\n          [2.0  2.5  3.0]  &lt;- Row 1\n          [3.5  4.0  4.5]  &lt;- Row 2\n\nExpected Output Matrix C Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    15.0   18.0   21.0   33.0   40.5   48.0   51.0   63.0   75.0 \n  Matrix: [ 15.0   18.0   21.0]  &lt;- Row 0\n          [ 33.0   40.5   48.0]  &lt;- Row 1\n          [ 51.0   63.0   75.0] &lt;- Row 2\n\nOutput Matrix C Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    15.0   18.0   21.0   33.0   40.5   48.0   51.0   63.0   75.0 \n  Matrix: [ 15.0   18.0   21.0]  &lt;- Row 0\n          [ 33.0   40.5   48.0]  &lt;- Row 1\n          [ 51.0   63.0   75.0] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 11: tiny_mat_mult_ex_f32 - Contiguous Matrix Multiplication\n================================================================================\nParameters: A_rows=3, A_cols=4, B_cols=2, A_padding=0, B_padding=0, C_padding=0\nMatrix dimensions: A is 3x4, B is 4x2, C is 3x2\nNote: This should use ESP-DSP on ESP32 when all paddings are 0\n\nMatrix A Memory Layout (3x4, 12 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0 (indices: 0-3)\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1 (indices: 4-7)\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2 (indices: 8-11)\n  Step size: 4 (A_cols + A_padding = 4 + 0)\n\nMatrix B Memory Layout (4x2, 8 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5 \n  Matrix: [0.5  1.5]  &lt;- Row 0 (indices: 0-1)\n          [2.5  3.5]  &lt;- Row 1 (indices: 2-3)\n          [4.5  5.5]  &lt;- Row 2 (indices: 4-5)\n          [6.5  7.5]  &lt;- Row 3 (indices: 6-7)\n  Step size: 2 (B_cols + B_padding = 2 + 0)\n\nExpected Output Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0 (indices: 0-1)\n          [101.0  127.0]  &lt;- Row 1 (indices: 2-3)\n          [157.0  199.0] &lt;- Row 2 (indices: 4-5)\n  Step size: 2 (B_cols + C_padding = 2 + 0)\n  Calculation example:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 =  45.0\n\nOutput Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0 (indices: 0-1)\n          [101.0  127.0]  &lt;- Row 1 (indices: 2-3)\n          [157.0  199.0] &lt;- Row 2 (indices: 4-5)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 12: tiny_mat_mult_ex_f32 - Padded Matrix Multiplication\n================================================================================\nParameters: A_rows=2, A_cols=3, B_cols=2, A_padding=2, B_padding=1, C_padding=1\nMatrix dimensions: A is 2x3, B is 3x2, C is 2x2\nNote: This should use own implementation when padding is non-zero\n\nMatrix A Memory Layout (2x3, pad=2, step=5, 10 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\n  Value:   1.0  2.0  3.0  0.0  0.0  4.0  5.0  6.0  0.0  0.0 \n  Matrix: [1.0  2.0  3.0  X   X]  &lt;- Row 0 (indices: 0, 1, 2, 3, 4)\n          [4.0  5.0  6.0  X   X]  &lt;- Row 1 (indices: 5, 6, 7, 8, 9)\n          (X = padding/unused)\n  Index calculation: A[i][j] = A[i * 5 + j]\n    Row 0: indices 0, 1, 2 (data), 3, 4 (padding)\n    Row 1: indices 5, 6, 7 (data), 8, 9 (padding)\n\nMatrix B Memory Layout (3x2, pad=1, step=3, 9 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:   0.5  1.5  0.0  2.5  3.5  0.0  4.5  5.5  0.0 \n  Matrix: [0.5  1.5  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [2.5  3.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n          [4.5  5.5  X]  &lt;- Row 2 (indices: 6, 7, 8)\n          (X = padding/unused)\n  Index calculation: B[i][j] = B[i * 3 + j]\n    Row 0: indices 0, 1 (data), 2 (padding)\n    Row 1: indices 3, 4 (data), 5 (padding)\n    Row 2: indices 6, 7 (data), 8 (padding)\n\nExpected Output Matrix C Memory Layout (2x2, pad=1, step=3, 6 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    19.0   25.0    0.0   41.5   56.5    0.0 \n  Matrix: [ 19.0   25.0  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 41.5   56.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n          (X = padding/unused)\n  Index calculation: C[i][j] = C[i * 3 + j]\n  Calculation:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0]\n            = A[0]*B[0] + A[1]*B[3] + A[2]*B[6]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 =  19.0\n    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1]\n            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 =  25.0\n    C[1][0] = A[1][0]*B[0][0] + A[1][1]*B[1][0] + A[1][2]*B[2][0]\n            = 4.0*0.5 + 5.0*2.5 + 6.0*4.5 =  41.5\n    C[1][1] = A[1][0]*B[0][1] + A[1][1]*B[1][1] + A[1][2]*B[2][1]\n            = 4.0*1.5 + 5.0*3.5 + 6.0*5.5 =  56.5\n\nOutput Matrix C Memory Layout (2x2, pad=1, step=3, 6 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    19.0   25.0    0.0   41.5   56.5    0.0 \n  Matrix: [ 19.0   25.0  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 41.5   56.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 13: tiny_mat_multc_f32 - Contiguous Matrix Multiply Constant\n================================================================================\nParameters: rows=3, cols=3, padd_in=0, padd_out=0, step_in=1, step_out=1\nMatrix dimensions: 3x3\nConstant C: 2.5\nNote: This should use ESP-DSP on ESP32 when all paddings are 0 and all steps are 1\n\nInput Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0 \n  Matrix: [1.0  2.0  3.0]  &lt;- Row 0 (indices: 0, 1, 2)\n          [4.0  5.0  6.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [7.0  8.0  9.0]  &lt;- Row 2 (indices: 6, 7, 8)\n  Row stride: 3 (cols + padd_in = 3 + 0)\n  Index calculation: input[i][j] = input[i * 3 + j * 1]\n\nExpected Output Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:     2.5    5.0    7.5   10.0   12.5   15.0   17.5   20.0   22.5 \n  Matrix: [  2.5    5.0    7.5]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 10.0   12.5   15.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [ 17.5   20.0   22.5] &lt;- Row 2 (indices: 6, 7, 8)\n  Row stride: 3 (cols + padd_out = 3 + 0)\n  Index calculation: output[i][j] = output[i * 3 + j * 1]\n  Calculation: output[i][j] = input[i][j] * 2.5\n    Example: output[0][0] = input[0][0] * 2.5 = 1.0 * 2.5 = 2.5\n\nOutput Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:     2.5    5.0    7.5   10.0   12.5   15.0   17.5   20.0   22.5 \n  Matrix: [  2.5    5.0    7.5]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 10.0   12.5   15.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [ 17.5   20.0   22.5] &lt;- Row 2 (indices: 6, 7, 8)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 14: tiny_mat_multc_f32 - Padded and Strided Matrix Multiply Constant\n================================================================================\nParameters: rows=2, cols=3, padd_in=2, padd_out=1, step_in=2, step_out=1\nMatrix dimensions: 2x3\nConstant C: 3.0\nNote: This should use own implementation when padding is non-zero or step &gt; 1\n\nInput Matrix Memory Layout (2x3, pad=2, step=2, 10 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0 \n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (data indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (data indices: 5, 7, 9)\n          (X = unused/padding)\n  Row stride: 5 (cols + padd_in = 3 + 2)\n  Index calculation: input[i][j] = input[i * 5 + j * 2]\n    Row 0: input[0][0]=input[0]=1.0, input[0][1]=input[2]=2.0, input[0][2]=input[4]=3.0\n    Row 1: input[1][0]=input[5]=4.0, input[1][1]=input[7]=5.0, input[1][2]=input[9]=6.0\n\nExpected Output Matrix Memory Layout (2x3, pad=1, step=1, 8 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:     3.0    6.0    9.0    0.0   12.0   15.0   18.0    0.0 \n  Matrix: [  3.0    6.0    9.0  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\n          [ 12.0   15.0   18.0  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\n          (X = padding/unused)\n  Row stride: 4 (cols + padd_out = 3 + 1)\n  Index calculation: output[i][j] = output[i * 4 + j * 1]\n  Calculation: output[i][j] = input[i][j] * 3.0\n    Row 0: output[0][0] = input[0][0] * 3.0 = 1.0 * 3.0 = 3.0 (index 0)\n           output[0][1] = input[0][1] * 3.0 = 2.0 * 3.0 = 6.0 (index 1)\n           output[0][2] = input[0][2] * 3.0 = 3.0 * 3.0 = 9.0 (index 2)\n\nOutput Matrix Memory Layout (2x3, pad=1, step=1, 8 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:     3.0    6.0    9.0    0.0   12.0   15.0   18.0    0.0 \n  Matrix: [  3.0    6.0    9.0  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\n          [ 12.0   15.0   18.0  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\n\n\u2713 Test PASSED\n================================================================================\n\n============ [test complete] ============\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/","title":"\u77e9\u9635\u64cd\u4f5c - TINY_MATRIX","text":"<p>TINY_MATRIX\u5e93</p> <ul> <li>\u8be5\u5e93\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u77e9\u9635\u8fd0\u7b97\u5e93\uff0c\u57fa\u4e8eC++\u5b9e\u73b0\uff0c\u63d0\u4f9b\u4e86\u57fa\u672c\u7684\u77e9\u9635\u64cd\u4f5c\u548c\u7ebf\u6027\u4ee3\u6570\u529f\u80fd\u3002</li> <li>\u8be5\u5e93\u7684\u8bbe\u8ba1\u76ee\u6807\u662f\u63d0\u4f9b\u7b80\u5355\u6613\u7528\u7684\u77e9\u9635\u64cd\u4f5c\u63a5\u53e3\uff0c\u9002\u5408\u4e8e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u3002</li> </ul> <p>\u4f7f\u7528\u573a\u666f</p> <p>\u76f8\u5bf9\u4e8eTINY_MAT\u5e93\u800c\u8a00\uff0cTINY_MATRIX\u5e93\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u529f\u80fd\u548c\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\uff0c\u9002\u5408\u4e8e\u9700\u8981\u8fdb\u884c\u590d\u6742\u77e9\u9635\u8fd0\u7b97\u7684\u5e94\u7528\u573a\u666f\u3002\u4f46\u662f\u8bf7\u6ce8\u610f\uff0c\u8be5\u5e93\u57fa\u4e8eC++\u7f16\u5199\uff0c</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_1","title":"\u76ee\u5f55","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500Vector\n    \u2514\u2500\u2500Matrix\n        \u251c\u2500\u2500 tiny_mat (c)\n        \u2514\u2500\u2500 tiny_matrix (c++) &lt;---\n</code></pre> <pre><code>namespace tiny\n{\n    class Mat\n    {\n    public:\n        /* === Matrix Metadata === */\n        int row;         //&lt; number of rows\n        int col;         //&lt; number of columns\n        int pad;         //&lt; number of paddings between 2 rows\n        int stride;      //&lt; stride = (number of elements in a row) + padding\n        int element;     //&lt; number of elements = rows * cols\n        int memory;      //&lt; size of the data buffer = rows * stride\n        float *data;     //&lt; pointer to the data buffer\n        float *temp;     //&lt; pointer to the temporary data buffer\n        bool ext_buff;   //&lt; flag indicates that matrix use external buffer\n        bool sub_matrix; //&lt; flag indicates that matrix is a subset of another matrix\n\n        /* === Rectangular ROI Structure === */\n        /**\n         * @name Region of Interest (ROI) Structure\n         * @brief This is the structure for ROI\n         * \n         */\n        struct ROI\n        {\n            int pos_x;  ///&lt; starting column index\n            int pos_y;  ///&lt; starting row index\n            int width;  ///&lt; width of ROI (columns)\n            int height; ///&lt; height of ROI (rows)\n\n            // ROI constructor\n            ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n\n            // resize ROI\n            void resize_roi(int pos_x, int pos_y, int width, int height);\n\n            // calculate area of ROI\n            int area_roi(void) const;\n        };\n\n        /* === Printing Functions === */\n        // print matrix info\n        void print_info() const;\n\n        // print matrix elements, paddings optional\n        void print_matrix(bool show_padding);\n\n        /* === Constructors &amp; Destructor === */\n        // memory allocation\n        void alloc_mem(); // Allocate internal memory\n\n        // constructor\n        Mat();\n        Mat(int rows, int cols);\n        Mat(int rows, int cols, int stride);\n        Mat(float *data, int rows, int cols);\n        Mat(float *data, int rows, int cols, int stride);\n        Mat(const Mat &amp;src);\n\n        // destructor\n        ~Mat();\n\n        /* === Element Access === */\n        // access matrix elements - non const\n        inline float &amp;operator()(int row, int col) { return data[row * stride + col]; }\n\n        // access matrix elements - const             \n        inline const float &amp;operator()(int row, int col) const { return data[row * stride + col]; }\n\n        /* === Data Manipulation === */\n        // copy other matrix into this matrix as a sub-matrix\n        tiny_error_t copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n\n        // copy header of other matrix to this matrix\n        tiny_error_t copy_head(const Mat &amp;src);\n\n        // get a view (shallow copy) of sub-matrix (ROI) from this matrix\n        Mat view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n\n        // get a view (shallow copy) of sub-matrix (ROI) from this matrix using ROI structure\n        Mat view_roi(const Mat::ROI &amp;roi) const;\n\n        // get a replica (deep copy) of sub-matrix (ROI) \n        Mat copy_roi(int start_row, int start_col, int roi_rows, int roi_cols);\n\n        // get a replica (deep copy) of sub-matrix (ROI) using ROI structure\n        Mat copy_roi(const Mat::ROI &amp;roi);\n\n        // get a block of matrix\n        Mat block(int start_row, int start_col, int block_rows, int block_cols);\n\n        // swap rows\n        void swap_rows(int row1, int row2);\n\n        // clear matrix\n        void clear(void);\n\n        /* === Arithmetic Operators === */\n        Mat &amp;operator=(const Mat &amp;src);    // Copy assignment\n        Mat &amp;operator+=(const Mat &amp;A);     // Add matrix\n        Mat &amp;operator+=(float C);          // Add constant\n        Mat &amp;operator-=(const Mat &amp;A);     // Subtract matrix\n        Mat &amp;operator-=(float C);          // Subtract constant \n        Mat &amp;operator*=(const Mat &amp;A);     // Multiply matrix\n        Mat &amp;operator*=(float C);          // Multiply constant\n        Mat &amp;operator/=(const Mat &amp;B);     // Divide matrix\n        Mat &amp;operator/=(float C);          // Divide constant\n        Mat operator^(int C);              // Exponentiation\n\n        /* === Linear Algebra === */\n        Mat transpose();                   // Transpose matrix\n        Mat cofactor(int row, int col);    // cofactor matrix extraction\n        float determinant();\n        Mat adjoint(); \n        void normalize();\n        float norm() const;\n        Mat inverse_adjoint();\n        static Mat eye(int size);\n        static Mat augment(const Mat &amp;A, const Mat &amp;B);\n        static Mat ones(int rows, int cols);\n        static Mat ones(int size);\n        Mat gaussian_eliminate() const;\n        Mat row_reduce_from_gaussian();\n        Mat inverse_gje(); // Inverse using Gaussian-Jordan elimination\n        float dotprod(const Mat &amp;A, const Mat &amp;B);\n        Mat solve(const Mat &amp;A, const Mat &amp;b);\n        Mat band_solve(Mat A, Mat b, int k);\n        Mat roots(Mat A, Mat y);\n\n    protected:\n\n    private:\n\n    };\n\n    /* === Stream Operators === */\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n    std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n\n    /* === Global Arithmetic Operators === */\n    Mat operator+(const Mat &amp;A, const Mat &amp;B);\n    Mat operator+(const Mat &amp;A, float C);\n    Mat operator-(const Mat &amp;A, const Mat &amp;B);\n    Mat operator-(const Mat &amp;A, float C);\n    Mat operator*(const Mat &amp;A, const Mat &amp;B);\n    Mat operator*(const Mat &amp;A, float C);\n    Mat operator*(float C, const Mat &amp;A);\n    Mat operator/(const Mat &amp;A, float C);\n    Mat operator/(const Mat &amp;A, const Mat &amp;B);\n    bool operator==(const Mat &amp;A, const Mat &amp;B);\n\n}\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_2","title":"\u5143\u6570\u636e","text":"<ul> <li> <p><code>int row</code>: \u884c\u6570</p> </li> <li> <p><code>int col</code>: \u5217\u6570</p> </li> <li> <p><code>int pad</code>: \u884c\u95f4\u586b\u5145\u6570</p> </li> <li> <p><code>int stride</code>: \u884c\u5185\u5143\u7d20\u6570 + \u586b\u5145\u6570</p> </li> <li> <p><code>int element</code>: \u5143\u7d20\u6570</p> </li> <li> <p><code>int memory</code>: \u6570\u636e\u7f13\u51b2\u533a\u5927\u5c0f = \u884c\u6570 * \u6b65\u5e45</p> </li> <li> <p><code>float *data</code>: \u6570\u636e\u7f13\u51b2\u533a\u6307\u9488</p> </li> <li> <p><code>float *temp</code>: \u4e34\u65f6\u6570\u636e\u7f13\u51b2\u533a\u6307\u9488</p> </li> <li> <p><code>bool ext_buff</code>: \u6807\u5fd7\u77e9\u9635\u662f\u5426\u4f7f\u7528\u5916\u90e8\u7f13\u51b2\u533a</p> </li> <li> <p><code>bool sub_matrix</code>: \u6807\u5fd7\u77e9\u9635\u662f\u5426\u4e3a\u53e6\u4e00\u4e2a\u77e9\u9635\u7684\u5b50\u96c6</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi","title":"ROI \u7ed3\u6784","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_3","title":"\u5143\u6570\u636e","text":"<ul> <li> <p><code>int pos_x</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int pos_y</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int width</code>: ROI \u7684\u5bbd\u5ea6\uff08\u5217\u6570\uff09</p> </li> <li> <p><code>int height</code>: ROI \u7684\u9ad8\u5ea6\uff08\u884c\u6570\uff09</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi_1","title":"ROI \u6784\u9020\u51fd\u6570","text":"<pre><code>Mat::ROI::ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n</code></pre> <p>\u63cf\u8ff0: \u6784\u9020\u4e00\u4e2a ROI \u5bf9\u8c61\uff0c\u9ed8\u8ba4\u503c\u4e3a (0, 0, 0, 0)\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int pos_x</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int pos_y</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int width</code>: ROI \u7684\u5bbd\u5ea6\uff08\u5217\u6570\uff09</p> </li> <li> <p><code>int height</code>: ROI \u7684\u9ad8\u5ea6\uff08\u884c\u6570\uff09</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi_2","title":"ROI \u91cd\u7f6e\u51fd\u6570","text":"<pre><code>void Mat::ROI::resize_roi(int pos_x, int pos_y, int width, int height);\n</code></pre> <p>\u63cf\u8ff0: \u91cd\u7f6e ROI \u7684\u4f4d\u7f6e\u548c\u5927\u5c0f\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int pos_x</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int pos_y</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int width</code>: ROI \u7684\u5bbd\u5ea6\uff08\u5217\u6570\uff09</p> </li> <li> <p><code>int height</code>: ROI \u7684\u9ad8\u5ea6\uff08\u884c\u6570\uff09</p> </li> </ul> <p>\u8fd4\u56de\u503c: void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi_3","title":"ROI \u9762\u79ef\u51fd\u6570","text":"<pre><code>int Mat::ROI::area_roi(void) const;\n</code></pre> <p>\u63cf\u8ff0: \u8ba1\u7b97 ROI \u7684\u9762\u79ef\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: \u6574\u6570\u7c7b\u578b ROI \u7684\u9762\u79ef</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_4","title":"\u6253\u5370\u51fd\u6570","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_5","title":"\u6253\u5370\u77e9\u9635\u4fe1\u606f","text":"<pre><code>void Mat::print_info() const\n</code></pre> <p>\u63cf\u8ff0: \u6253\u5370\u77e9\u9635\u7684\u57fa\u672c\u4fe1\u606f\uff0c\u5305\u62ec\u884c\u6570\u3001\u5217\u6570\u3001\u5143\u7d20\u6570\u3001\u586b\u5145\u6570\u3001\u6b65\u5e45\u6570\u3001\u5185\u5b58\u5927\u5c0f\u3001\u6570\u636e\u7f13\u51b2\u533a\u6307\u9488\u3001\u4e34\u65f6\u6570\u636e\u7f13\u51b2\u533a\u6307\u9488\u3001\u5916\u90e8\u7f13\u51b2\u533a\u6807\u5fd7\u3001\u5b50\u77e9\u9635\u6807\u5fd7\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_6","title":"\u6253\u5370\u77e9\u9635\u5143\u7d20","text":"<pre><code>void Mat::print_matrix(bool show_padding);\n</code></pre> <p>\u63cf\u8ff0: \u6253\u5370\u77e9\u9635\u7684\u5143\u7d20\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>bool show_padding</code>: \u662f\u5426\u663e\u793a\u586b\u5145\u533a\u5143\u7d20\uff0c true \u663e\u793a\uff0cfalse \u4e0d\u663e\u793a</li> </ul> <p>\u8fd4\u56de\u503c: void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_7","title":"\u6784\u9020\u4e0e\u6790\u6784\u51fd\u6570","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_8","title":"\u9ed8\u8ba4\u6784\u9020\u51fd\u6570","text":"<pre><code>Mat::Mat();\n</code></pre> <p>\u63cf\u8ff0: \u9ed8\u8ba4\u6784\u9020\u51fd\u6570\u5c06\u4f7f\u7528\u9ed8\u8ba4\u503c\u521d\u59cb\u5316\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61\u3002\u8fd9\u4e2a\u51fd\u6570\u4f1a\u521b\u5efa\u4e00\u4e2a\u4e00\u884c\u4e00\u5217\u7684\u77e9\u9635\uff0c\u552f\u4e00\u7684\u5143\u7d20\u662f0\u3002</p> <p>\u53c2\u6570: void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matint-rows-int-cols","title":"\u6784\u9020\u51fd\u6570 - Mat(int rows, int cols)","text":"<pre><code>Mat::Mat(int rows, int cols);\n</code></pre> <p>\u63cf\u8ff0: \u6784\u9020\u4e00\u4e2a\u6307\u5b9a\u884c\u6570\u548c\u5217\u6570\u7684\u77e9\u9635\u5bf9\u8c61\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int rows</code>: \u884c\u6570</p> </li> <li> <p><code>int cols</code>: \u5217\u6570</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matint-rows-int-cols-int-stride","title":"\u6784\u9020\u51fd\u6570 - Mat(int rows, int cols, int stride)","text":"<pre><code>Mat::Mat(int rows, int cols, int stride);\n</code></pre> <p>\u63cf\u8ff0: \u6784\u9020\u4e00\u4e2a\u6307\u5b9a\u884c\u6570\u3001\u5217\u6570\u548c\u6b65\u5e45\u7684\u77e9\u9635\u5bf9\u8c61\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int rows</code>: \u884c\u6570</p> </li> <li> <p><code>int cols</code>: \u5217\u6570</p> </li> <li> <p><code>int stride</code>: \u6b65\u5e45</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matfloat-data-int-rows-int-cols","title":"\u6784\u9020\u51fd\u6570 - Mat(float *data, int rows, int cols)","text":"<pre><code>Mat::Mat(float *data, int rows, int cols);\n</code></pre> <p>\u63cf\u8ff0: \u6784\u9020\u4e00\u4e2a\u6307\u5b9a\u884c\u6570\u548c\u5217\u6570\u7684\u77e9\u9635\u5bf9\u8c61\uff0c\u5e76\u4f7f\u7528\u7ed9\u5b9a\u7684\u6570\u636e\u7f13\u51b2\u533a\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>float *data</code>: \u6570\u636e\u7f13\u51b2\u533a\u6307\u9488</p> </li> <li> <p><code>int rows</code>: \u884c\u6570</p> </li> <li> <p><code>int cols</code>: \u5217\u6570</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matfloat-data-int-rows-int-cols-int-stride","title":"\u6784\u9020\u51fd\u6570 - Mat(float *data, int rows, int cols, int stride)","text":"<pre><code>Mat::Mat(float *data, int rows, int cols, int stride);\n</code></pre> <p>\u63cf\u8ff0: \u6784\u9020\u4e00\u4e2a\u6307\u5b9a\u884c\u6570\u3001\u5217\u6570\u548c\u6b65\u5e45\u7684\u77e9\u9635\u5bf9\u8c61\uff0c\u5e76\u4f7f\u7528\u7ed9\u5b9a\u7684\u6570\u636e\u7f13\u51b2\u533a\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>float *data</code>: \u6570\u636e\u7f13\u51b2\u533a\u6307\u9488</p> </li> <li> <p><code>int rows</code>: \u884c\u6570</p> </li> <li> <p><code>int cols</code>: \u5217\u6570</p> </li> <li> <p><code>int stride</code>: \u6b65\u5e45</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matconst-mat-src","title":"\u6784\u9020\u51fd\u6570 - Mat(const Mat &amp;src)","text":"<pre><code>Mat::Mat(const Mat &amp;src);\n</code></pre> <p>\u63cf\u8ff0: \u6784\u9020\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61\uff0c\u5e76\u4f7f\u7528\u7ed9\u5b9a\u7684\u77e9\u9635\u5bf9\u8c61\u7684\u5934\u90e8\u4fe1\u606f\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;src</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_9","title":"\u6790\u6784\u51fd\u6570","text":"<pre><code>Mat::~Mat();\n</code></pre> <p>\u63cf\u8ff0: \u6790\u6784\u51fd\u6570\u91ca\u653e\u77e9\u9635\u5bf9\u8c61\u7684\u5185\u5b58\u3002</p> <p>\u53c2\u6570: void</p> <p>Note</p> <p>\u5bf9\u4e8e\u6784\u9020\u51fd\u6570\uff0c\u5176\u540d\u79f0\u5fc5\u987b\u4e0e\u7c7b\u540d\u76f8\u540c\uff0c\u5e76\u4e14\u4e0d\u80fd\u6709\u8fd4\u56de\u7c7b\u578b\u3002\u5982\u4e0a\u6240\u8ff0\uff0c\u5bf9\u4e8e C++\uff0c\u53ea\u8981\u53c2\u6570\u7684\u6392\u5217\u987a\u5e8f\u4e0d\u540c\uff0c\u5c31\u53ef\u4ee5\u901a\u8fc7\u66f4\u6539\u53c2\u6570\u7684\u6570\u91cf\u548c\u987a\u5e8f\u6765\u91cd\u65b0\u52a0\u8f7d\u51fd\u6570\u540d\u79f0\u3002\u5f53\u5bf9\u8c61\u8d85\u51fa\u8303\u56f4\u65f6\uff0c\u6790\u6784\u51fd\u6570\u5c06\u81ea\u52a8\u8c03\u7528\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_10","title":"\u5143\u7d20\u8bbf\u95ee","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_11","title":"\u975e\u5e38\u91cf\u8bbf\u95ee","text":"<pre><code>inline float &amp;operator()(int row, int col);\n</code></pre> <p>\u63cf\u8ff0: \u8bbf\u95ee\u77e9\u9635\u5143\u7d20\uff0c\u8fd4\u56de\u5bf9\u6307\u5b9a\u884c\u548c\u5217\u7684\u5f15\u7528\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int row</code>: \u884c\u7d22\u5f15</p> </li> <li> <p><code>int col</code>: \u5217\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20 float\u7c7b\u578b</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_12","title":"\u5e38\u91cf\u8bbf\u95ee","text":"<pre><code>inline const float &amp;operator()(int row, int col) const;\n</code></pre> <p>\u63cf\u8ff0: \u8bbf\u95ee\u77e9\u9635\u5143\u7d20\uff0c\u8fd4\u56de\u5bf9\u6307\u5b9a\u884c\u548c\u5217\u7684\u5e38\u91cf\u5f15\u7528\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int row</code>: \u884c\u7d22\u5f15</p> </li> <li> <p><code>int col</code>: \u5217\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20 float\u7c7b\u578b</p> <p>\u6ce8\u610f</p> <p>\u8fd9\u4e24\u4e2a\u51fd\u6570\u5b9e\u9645\u4e0a\u662f\u91cd\u65b0\u5b9a\u4e49\u4e86 <code>()</code> \u8fd0\u7b97\u7b26\uff0c\u5b83\u5141\u8bb8\u4f60\u4f7f\u7528 <code>matrix(row, col)</code> \u8bed\u6cd5\u8bbf\u95ee\u77e9\u9635\u7684\u5143\u7d20\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_13","title":"\u6570\u636e\u64cd\u4f5c","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_14","title":"\u590d\u5236\u5176\u4ed6\u77e9\u9635\u5230\u5f53\u524d\u77e9\u9635","text":"<pre><code>tiny_error_t copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n</code></pre> <p>\u63cf\u8ff0: \u5c06\u6e90\u77e9\u9635\u7684\u5143\u7d20\u590d\u5236\u5230\u5f53\u524d\u77e9\u9635\u7684\u6307\u5b9a\u4f4d\u7f6e\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;src</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>int row_pos</code>: \u76ee\u6807\u77e9\u9635\u7684\u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int col_pos</code>: \u76ee\u6807\u77e9\u9635\u7684\u8d77\u59cb\u5217\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u9519\u8bef\u4ee3\u7801</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_15","title":"\u590d\u5236\u77e9\u9635\u5934\u90e8","text":"<pre><code>tiny_error_t copy_head(const Mat &amp;src);\n</code></pre> <p>\u63cf\u8ff0: \u5c06\u6e90\u77e9\u9635\u7684\u5934\u90e8\u4fe1\u606f\u590d\u5236\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;src</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul> <p>\u8fd4\u56de\u503c: \u9519\u8bef\u4ee3\u7801</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_16","title":"\u83b7\u53d6\u5b50\u77e9\u9635\u89c6\u56fe","text":"<pre><code>Mat view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n</code></pre> <p>\u63cf\u8ff0: \u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5b50\u77e9\u9635\u89c6\u56fe\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int start_row</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int start_col</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int roi_rows</code>: \u5b50\u77e9\u9635\u7684\u884c\u6570</p> </li> <li> <p><code>int roi_cols</code>: \u5b50\u77e9\u9635\u7684\u5217\u6570</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u5b50\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-roi","title":"\u83b7\u53d6\u5b50\u77e9\u9635\u89c6\u56fe - \u4f7f\u7528 ROI \u7ed3\u6784","text":"<pre><code>Mat view_roi(const Mat::ROI &amp;roi) const;\n</code></pre> <p>\u63cf\u8ff0: \u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5b50\u77e9\u9635\u89c6\u56fe\uff0c\u4f7f\u7528 ROI \u7ed3\u6784\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat::ROI &amp;roi</code>: ROI \u7ed3\u6784\u5bf9\u8c61</li> </ul> <p>\u8fd4\u56de\u503c: \u5b50\u77e9\u9635\u5bf9\u8c61</p> <p>\u8b66\u544a</p> <p>\u4e0e ESP-DSP \u4e0d\u540c\uff0cview_roi \u4e0d\u5141\u8bb8\u8bbe\u7f6e\u6b65\u957f\uff0c\u56e0\u4e3a\u5b83\u4f1a\u6839\u636e\u5217\u6570\u548c\u586b\u5145\u6570\u81ea\u52a8\u8ba1\u7b97\u6b65\u957f\u3002\u8be5\u51fd\u6570\u8fd8\u4f1a\u62d2\u7edd\u975e\u6cd5\u8bf7\u6c42\uff0c\u5373\u8d85\u51fa\u8303\u56f4\u7684\u8bf7\u6c42\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_17","title":"\u83b7\u53d6\u5b50\u77e9\u9635\u526f\u672c","text":"<pre><code>Mat copy_roi(int start_row, int start_col, int roi_rows, int roi_cols);\n</code></pre> <p>\u63cf\u8ff0: \u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5b50\u77e9\u9635\u526f\u672c\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int start_row</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int start_col</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int roi_rows</code>: \u5b50\u77e9\u9635\u7684\u884c\u6570</p> </li> <li> <p><code>int roi_cols</code>: \u5b50\u77e9\u9635\u7684\u5217\u6570</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u5b50\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-roi_1","title":"\u83b7\u53d6\u5b50\u77e9\u9635\u526f\u672c - \u4f7f\u7528 ROI \u7ed3\u6784","text":"<pre><code>Mat copy_roi(const Mat::ROI &amp;roi);\n</code></pre> <p>\u63cf\u8ff0: \u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5b50\u77e9\u9635\u526f\u672c\uff0c\u4f7f\u7528 ROI \u7ed3\u6784\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat::ROI &amp;roi</code>: ROI \u7ed3\u6784\u5bf9\u8c61</li> </ul> <p>\u8fd4\u56de\u503c: \u5b50\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_18","title":"\u83b7\u53d6\u77e9\u9635\u5757","text":"<pre><code>Mat block(int start_row, int start_col, int block_rows, int block_cols);\n</code></pre> <p>\u63cf\u8ff0: \u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5757\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int start_row</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int start_col</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int block_rows</code>: \u5757\u7684\u884c\u6570</p> </li> <li> <p><code>int block_cols</code>: \u5757\u7684\u5217\u6570</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u5757\u5bf9\u8c61</p> <p>!!! tip \u201cview_roi | copy_roi | block \u4e4b\u95f4\u7684\u533a\u522b\u201d</p> <ul> <li> <p><code>view_roi</code>\uff1a\u4ece\u8be5\u77e9\u9635\u6d45\u62f7\u8d1d\u5b50\u77e9\u9635 (ROI)\u3002</p> </li> <li> <p><code>copy_roi</code>\uff1a\u4ece\u8be5\u77e9\u9635\u6df1\u62f7\u8d1d\u5b50\u77e9\u9635 (ROI)\u3002\u521a\u6027\u62f7\u8d1d\uff0c\u901f\u5ea6\u66f4\u5feb\u3002</p> </li> <li> <p><code>block</code>\uff1a\u4ece\u8be5\u77e9\u9635\u6df1\u62f7\u8d1d\u5757\u3002\u67d4\u6027\u62f7\u8d1d\uff0c\u901f\u5ea6\u66f4\u6162\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_19","title":"\u4ea4\u6362\u884c","text":"<pre><code>void swap_rows(int row1, int row2);\n</code></pre> <p>\u63cf\u8ff0: \u4ea4\u6362\u5f53\u524d\u77e9\u9635\u7684\u4e24\u884c\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int row1</code>: \u7b2c\u4e00\u884c\u7d22\u5f15</p> </li> <li> <p><code>int row2</code>: \u7b2c\u4e8c\u884c\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c: void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_20","title":"\u6e05\u9664\u77e9\u9635","text":"<pre><code>void clear(void);\n</code></pre> <p>\u63cf\u8ff0: \u6e05\u9664\u5f53\u524d\u77e9\u9635\u7684\u5143\u7d20\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_21","title":"\u7b97\u672f\u8fd0\u7b97\u7b26","text":"<p>\u6ce8\u610f</p> <p>\u672c\u8282\u5b9a\u4e49\u4e86\u4f5c\u7528\u4e8e\u5f53\u524d\u77e9\u9635\u672c\u8eab\u7684\u7b97\u672f\u8fd0\u7b97\u7b26\u3002\u8fd9\u4e9b\u8fd0\u7b97\u7b26\u5df2\u88ab\u91cd\u8f7d\u4ee5\u6267\u884c\u77e9\u9635\u8fd0\u7b97\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_22","title":"\u8d4b\u503c\u8fd0\u7b97\u7b26","text":"<pre><code>Mat &amp;operator=(const Mat &amp;src);\n</code></pre> <p>\u63cf\u8ff0: \u8d4b\u503c\u8fd0\u7b97\u7b26\uff0c\u5c06\u6e90\u77e9\u9635\u7684\u5143\u7d20\u590d\u5236\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;src</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_23","title":"\u52a0\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat &amp;operator+=(const Mat &amp;A);\n</code></pre> <p>\u63cf\u8ff0: \u52a0\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u6e90\u77e9\u9635\u7684\u5143\u7d20\u52a0\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;A</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-","title":"\u52a0\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat &amp;operator+=(float C);\n</code></pre> <p>\u63cf\u8ff0: \u52a0\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u5e38\u91cf\u52a0\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float C</code>: \u5e38\u91cf</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_24","title":"\u51cf\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat &amp;operator-=(const Mat &amp;A);\n</code></pre> <p>\u63cf\u8ff0: \u51cf\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u6e90\u77e9\u9635\u7684\u5143\u7d20\u4ece\u5f53\u524d\u77e9\u9635\u4e2d\u51cf\u53bb\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;A</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_1","title":"\u51cf\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat &amp;operator-=(float C);\n</code></pre> <p>\u63cf\u8ff0: \u51cf\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u5e38\u91cf\u4ece\u5f53\u524d\u77e9\u9635\u4e2d\u51cf\u53bb\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float C</code>: \u5e38\u91cf</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_25","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat &amp;operator*=(const Mat &amp;A);\n</code></pre> <p>\u63cf\u8ff0: \u4e58\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u6e90\u77e9\u9635\u7684\u5143\u7d20\u4e58\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;A</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_2","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat &amp;operator*=(float C);\n</code></pre> <p>\u63cf\u8ff0: \u4e58\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u5e38\u91cf\u4e58\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float C</code>: \u5e38\u91cf</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_26","title":"\u9664\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat &amp;operator/=(const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0: \u9664\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u5f53\u524d\u77e9\u9635\u9664\u4ee5\u6e90\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;B</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_3","title":"\u9664\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat &amp;operator/=(float C);\n</code></pre> <p>\u63cf\u8ff0: \u9664\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u5f53\u524d\u77e9\u9635\u9664\u4ee5\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float C</code>: \u5e38\u91cf</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_27","title":"\u5e42\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator^(int C);\n</code></pre> <p>\u63cf\u8ff0: \u5e42\u8fd0\u7b97\u7b26\uff0c\u5c06\u5f53\u524d\u77e9\u9635\u7684\u5143\u7d20\u8fdb\u884c\u5e42\u8fd0\u7b97\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>int C</code>: \u5e42\u6307\u6570</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_28","title":"\u7ebf\u6027\u4ee3\u6570","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_29","title":"\u8f6c\u7f6e\u77e9\u9635","text":"<pre><code>Mat::transpose();\n</code></pre> <p>\u63cf\u8ff0: \u8f6c\u7f6e\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: \u8f6c\u7f6e\u540e\u7684\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_30","title":"\u4f59\u5b50\u5f0f\u77e9\u9635","text":"<pre><code>Mat::cofactor(int row, int col);\n</code></pre> <p>\u63cf\u8ff0: \u63d0\u53d6\u5f53\u524d\u77e9\u9635\u7684\u4f59\u5b50\u5f0f\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int row</code>: \u884c\u7d22\u5f15</p> </li> <li> <p><code>int col</code>: \u5217\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u4f59\u5b50\u5f0f\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_31","title":"\u884c\u5217\u5f0f","text":"<pre><code>float Mat::determinant();\n</code></pre> <p>\u63cf\u8ff0: \u8ba1\u7b97\u5f53\u524d\u77e9\u9635\u7684\u884c\u5217\u5f0f\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: \u884c\u5217\u5f0f\u7684\u503c</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_32","title":"\u4f34\u968f\u77e9\u9635","text":"<pre><code>Mat::adjoint();\n</code></pre> <p>\u63cf\u8ff0: \u8ba1\u7b97\u5f53\u524d\u77e9\u9635\u7684\u4f34\u968f\u77e9\u9635\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: \u4f34\u968f\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_33","title":"\u5f52\u4e00\u5316","text":"<pre><code>void Mat::normalize();\n</code></pre> <p>\u63cf\u8ff0: \u5f52\u4e00\u5316\u5f53\u524d\u77e9\u9635\u7684\u5143\u7d20\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_34","title":"\u8303\u6570","text":"<pre><code>float Mat::norm() const;\n</code></pre> <p>\u63cf\u8ff0: \u8ba1\u7b97\u5f53\u524d\u77e9\u9635\u7684\u8303\u6570\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: \u8303\u6570\u7684\u503c</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_4","title":"\u77e9\u9635\u6c42\u9006 -- \u57fa\u4e8e\u4f34\u968f\u77e9\u9635","text":"<pre><code>Mat::inverse_adjoint();\n</code></pre> <p>\u63cf\u8ff0: \u8ba1\u7b97\u5f53\u524d\u77e9\u9635\u7684\u9006\u77e9\u9635\uff0c\u57fa\u4e8e\u4f34\u968f\u77e9\u9635\u6cd5\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: \u9006\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_35","title":"\u5355\u4f4d\u77e9\u9635","text":"<pre><code>Mat::eye(int size);\n</code></pre> <p>\u63cf\u8ff0: \u521b\u5efa\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>int size</code>: \u77e9\u9635\u7684\u5927\u5c0f</li> </ul> <p>\u8fd4\u56de\u503c: \u5355\u4f4d\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_36","title":"\u589e\u5e7f\u77e9\u9635","text":"<pre><code>Mat::augment(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0: \u521b\u5efa\u4e00\u4e2a\u589e\u5e7f\u77e9\u9635\uff0c\u5c06\u4e24\u4e2a\u77e9\u9635\u8fde\u63a5\u5728\u4e00\u8d77\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_37","title":"\u5355\u4f4d\u77e9\u9635","text":"<pre><code>Mat::ones(int rows, int cols);\n</code></pre> <p>\u63cf\u8ff0: \u521b\u5efa\u4e00\u4e2a\u5168\u4e3a1\u7684\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int rows</code>: \u884c\u6570</p> </li> <li> <p><code>int cols</code>: \u5217\u6570</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#1","title":"\u51681\u7684\u77e9\u9635","text":"<pre><code>Mat::ones(int size);\n</code></pre> <p>\u63cf\u8ff0: \u521b\u5efa\u4e00\u4e2a\u5168\u4e3a1\u7684\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>int size</code>: \u77e9\u9635\u7684\u5927\u5c0f</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_38","title":"\u9ad8\u65af\u6d88\u5143\u6cd5","text":"<pre><code>Mat::gaussian_eliminate() const;\n</code></pre> <p>\u63cf\u8ff0: \u4f7f\u7528\u9ad8\u65af\u6d88\u5143\u6cd5\u5bf9\u5f53\u524d\u77e9\u9635\u8fdb\u884c\u53d8\u6362\u3002</p> <p>\u53c2\u6570: void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_39","title":"\u9ad8\u65af\u6d88\u5143\u6cd5\u4e0b\u884c\u6700\u7b80\u5f62\u5f0f","text":"<pre><code>Mat::row_reduce_from_gaussian();\n</code></pre> <p>\u63cf\u8ff0: \u4f7f\u7528\u9ad8\u65af\u6d88\u5143\u6cd5\u5c06\u5f53\u524d\u77e9\u9635\u8f6c\u6362\u4e3a\u4e0b\u884c\u6700\u7b80\u5f62\u5f0f\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: \u4e0b\u884c\u6700\u7b80\u5f62\u5f0f\u7684\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_5","title":"\u9ad8\u65af-\u7ea6\u65e6\u6d88\u5143\u6cd5\u6c42\u9006","text":"<pre><code>Mat::inverse_gje();\n</code></pre> <p>\u63cf\u8ff0: \u4f7f\u7528\u9ad8\u65af-\u7ea6\u65e6\u6d88\u5143\u6cd5\u8ba1\u7b97\u5f53\u524d\u77e9\u9635\u7684\u9006\u77e9\u9635\u3002</p> <p>\u53c2\u6570: void</p> <p>\u8fd4\u56de\u503c: \u9006\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_40","title":"\u70b9\u79ef","text":"<pre><code>float Mat::dotprod(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0: \u8ba1\u7b97\u4e24\u4e2a\u77e9\u9635\u7684\u70b9\u79ef\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u70b9\u79ef\u7684\u503c</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_41","title":"\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4","text":"<pre><code>Mat::solve(const Mat &amp;A, const Mat &amp;b);\n</code></pre> <p>\u63cf\u8ff0: \u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4 Ax = b\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7cfb\u6570\u77e9\u9635</p> </li> <li> <p><code>const Mat &amp;b</code>: \u5e38\u6570\u77e9\u9635</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u89e3\u77e9\u9635 x</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_42","title":"\u5e26\u72b6\u77e9\u9635\u6c42\u89e3","text":"<pre><code>Mat::band_solve(Mat A, Mat b, int k);\n</code></pre> <p>\u63cf\u8ff0: \u89e3\u5e26\u72b6\u77e9\u9635\u65b9\u7a0b Ax = b\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>Mat A</code>: \u5e26\u72b6\u77e9\u9635</p> </li> <li> <p><code>Mat b</code>: \u5e38\u6570\u77e9\u9635</p> </li> <li> <p><code>int k</code>: \u5e26\u5bbd</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u89e3\u77e9\u9635 x</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_43","title":"\u7ebf\u6027\u7cfb\u7edf\u6c42\u6839","text":"<pre><code>Mat::roots(Mat A, Mat y);\n</code></pre> <p>\u63cf\u8ff0: \u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf\u7684\u6839\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>Mat A</code>: \u7cfb\u6570\u77e9\u9635</p> </li> <li> <p><code>Mat y</code>: \u5e38\u6570\u77e9\u9635</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u6839\u77e9\u9635 x</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_44","title":"\u7ebf\u6027\u4ee3\u6570","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_45","title":"\u6d41\u64cd\u4f5c\u7b26","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_46","title":"\u77e9\u9635\u8f93\u51fa\u5230\u6d41","text":"<pre><code>std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n</code></pre> <p>\u63cf\u8ff0: \u5c06\u77e9\u9635\u8f93\u51fa\u5230\u6d41\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>std::ostream &amp;os</code>: \u8f93\u51fa\u6d41\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;m</code>: \u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_47","title":"\u5b50\u77e9\u9635\u8f93\u51fa\u5230\u6d41","text":"<pre><code>std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n</code></pre> <p>\u63cf\u8ff0: \u5c06\u5b50\u77e9\u9635\u8f93\u51fa\u5230\u6d41\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>std::ostream &amp;os</code>: \u8f93\u51fa\u6d41\u5bf9\u8c61</p> </li> <li> <p><code>const Mat::ROI &amp;roi</code>: \u5b50\u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_48","title":"\u77e9\u9635\u8f93\u5165\u6d41","text":"<pre><code>std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n</code></pre> <p>\u63cf\u8ff0: \u4ece\u6d41\u4e2d\u8bfb\u53d6\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>std::istream &amp;is</code>: \u8f93\u5165\u6d41\u5bf9\u8c61</p> </li> <li> <p><code>Mat &amp;m</code>: \u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_49","title":"\u5168\u5c40\u7b97\u6570\u8fd0\u7b97\u7b26","text":"<p>\u63d0\u793a</p> <p>\u672c\u8282\u4e2d\u7684\u8fd0\u7b97\u7b26\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u77e9\u9635\u5bf9\u8c61\uff0c\u4f5c\u4e3a\u8fd0\u7b97\u7ed3\u679c\u3002\u539f\u59cb\u77e9\u9635\u4fdd\u6301\u4e0d\u53d8\u3002\u4e0e\u4e0a\u4e00\u8282\u4e0d\u540c\uff0c\u8fd9\u4e9b\u8fd0\u7b97\u7b26\u65e8\u5728\u5bf9\u5f53\u524d\u77e9\u9635\u672c\u8eab\u6267\u884c\u8fd0\u7b97\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_50","title":"\u52a0\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator+(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0: \u52a0\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u4e24\u4e2a\u77e9\u9635\u76f8\u52a0\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_6","title":"\u52a0\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat operator+(const Mat &amp;A, float C);\n</code></pre> <p>\u63cf\u8ff0: \u52a0\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u77e9\u9635\u4e0e\u5e38\u91cf\u76f8\u52a0\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>float C</code>: \u5e38\u91cf</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_51","title":"\u51cf\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator-(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0: \u51cf\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u7b2c\u4e00\u4e2a\u77e9\u9635\u51cf\u53bb\u7b2c\u4e8c\u4e2a\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_7","title":"\u51cf\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat operator-(const Mat &amp;A, float C);\n</code></pre> <p>\u63cf\u8ff0: \u51cf\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u77e9\u9635\u51cf\u53bb\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>float C</code>: \u5e38\u91cf   </p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_52","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator*(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0: \u4e58\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u4e24\u4e2a\u77e9\u9635\u76f8\u4e58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_8","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat operator*(const Mat &amp;A, float C);\n</code></pre> <p>\u63cf\u8ff0: \u4e58\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u77e9\u9635\u4e0e\u5e38\u91cf\u76f8\u4e58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>float C</code>: \u5e38\u91cf</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_9","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf - \u53cd\u5411","text":"<pre><code>Mat operator*(float C, const Mat &amp;A);\n</code></pre> <p>\u63cf\u8ff0: \u4e58\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u5e38\u91cf\u4e0e\u77e9\u9635\u76f8\u4e58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>float C</code>: \u5e38\u91cf</p> </li> <li> <p><code>const Mat &amp;A</code>: \u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_53","title":"\u9664\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator/(const Mat &amp;A, float C);\n</code></pre> <p>\u63cf\u8ff0: \u9664\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u77e9\u9635\u9664\u4ee5\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>float C</code>: \u5e38\u91cf</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_10","title":"\u9664\u6cd5\u8fd0\u7b97\u7b26 - \u77e9\u9635","text":"<pre><code>Mat operator/(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0: \u9664\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u7b2c\u4e00\u4e2a\u77e9\u9635\u9664\u4ee5\u7b2c\u4e8c\u4e2a\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_54","title":"\u7b49\u4e8e\u8fd0\u7b97\u7b26","text":"<pre><code>bool operator==(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0: \u7b49\u4e8e\u8fd0\u7b97\u7b26\uff0c\u68c0\u67e5\u4e24\u4e2a\u77e9\u9635\u662f\u5426\u76f8\u7b49\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> </ul> <p>\u8fd4\u56de\u503c: \u5e03\u5c14\u503c\uff0c\u8868\u793a\u4e24\u4e2a\u77e9\u9635\u662f\u5426\u76f8\u7b49</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-code/","title":"\u4ee3\u7801","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-test/","title":"\u6d4b\u8bd5","text":"<p>Tip</p> <p>\u4ee5\u4e0b\u7684\u6d4b\u8bd5\u7528\u4ee3\u7801\u548c\u6848\u4f8b\u4e5f\u4f5c\u4e3a\u4f7f\u7528\u6559\u5b66\u6848\u4f8b\u3002</p>"},{"location":"zh/MATH/USAGE/usage/","title":"\u4f7f\u7528\u8bf4\u660e","text":"<p>\u4f7f\u7528\u8bf4\u660e</p> <p>\u8be5\u6587\u6863\u662f\u5bf9 <code>tiny_math</code> \u6a21\u5757\u7684\u4f7f\u7528\u8bf4\u660e\u3002</p>"},{"location":"zh/MATH/USAGE/usage/#tinymath","title":"\u6574\u4f53\u5f15\u5165TinyMath","text":"<p>Info</p> <p>\u9002\u7528\u4e8eC\u9879\u76ee\uff0c\u6216\u8005\u7ed3\u6784\u8f83\u4e3a\u7b80\u5355\u7684C++\u9879\u76ee\u3002</p> <pre><code>#include \"tiny_math.h\"\n</code></pre>"},{"location":"zh/MATH/USAGE/usage/#tinymath_1","title":"\u5206\u6a21\u5757\u5f15\u5165TinyMath","text":"<p>Info</p> <p>\u9002\u7528\u4e8e\u9700\u8981\u7cbe\u786e\u63a7\u5236\u5f15\u5165\u6a21\u5757\u7684\u9879\u76ee\uff0c\u6216\u8005\u590d\u6742\u7684C++\u9879\u76ee\u3002</p> <pre><code>#include \"tiny_vec.h\" // \u5f15\u5165\u5411\u91cf\u6a21\u5757\n#include \"tiny_mat.h\" // \u5f15\u5165\u77e9\u9635\u6a21\u5757\n</code></pre> <pre><code>#include \"tiny_matrix.hpp\" // \u5f15\u5165\u9ad8\u7ea7\u77e9\u9635\u6a21\u5757\n</code></pre> <p>\u6ce8\u610f</p> <ul> <li> <p><code>tiny_vec.h</code> \u548c <code>tiny_mat.h</code> \u662f C \u8bed\u8a00\u7248\u672c\u7684\u5934\u6587\u4ef6\uff0c\u9002\u7528\u4e8e C \u8bed\u8a00\u7f16\u7a0b\u3002</p> </li> <li> <p><code>tiny_matrix.hpp</code> \u662f C++ \u8bed\u8a00\u7248\u672c\u7684\u5934\u6587\u4ef6\uff0c\u9002\u7528\u4e8e C++ \u8bed\u8a00\u7f16\u7a0b\u3002</p> </li> </ul> <p>\u7b80\u5355\u6765\u8bf4\uff0cC\u8bed\u8a00\u9879\u76ee\u53ea\u80fd\u7528 <code>tiny_vec.h</code> \u548c <code>tiny_mat.h</code>\uff0c\u800c C++ \u9879\u76ee\u53ef\u4ee5\u4f7f\u7528 <code>tiny_vec.h</code>\u3001<code>tiny_mat.h</code> \u548c <code>tiny_matrix.hpp</code>\u3002</p> <p>Tip</p> <p>\u5177\u4f53\u7684\u4f7f\u7528\u65b9\u6cd5\u8bf7\u53c2\u8003\u6d4b\u8bd5\u4ee3\u7801\u3002</p>"},{"location":"zh/MATH/VECTOR/api/","title":"\u5411\u91cf\u64cd\u4f5c","text":""},{"location":"zh/MATH/VECTOR/api/#_2","title":"\u76ee\u5f55","text":"<pre><code>// Addition\ntiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Subtraction\ntiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Multiplication\ntiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Division\ntiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\ntiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\n// Square root\ntiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\n// Dot product\ntiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\ntiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n</code></pre>"},{"location":"zh/MATH/VECTOR/api/#_3","title":"\u52a0\u6cd5","text":""},{"location":"zh/MATH/VECTOR/api/#_4","title":"\u4e24\u4e2a\u5411\u91cf\u7684\u52a0\u6cd5","text":"<p><pre><code>tiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> \u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u9010\u5143\u7d20\u52a0\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>input2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_5","title":"\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u52a0\u6cd5","text":"<p><pre><code>tiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> \u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9010\u5143\u7d20\u52a0\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>C</code>\uff1a\u5e38\u6570\u503c\u3002</li> <li><code>step_in</code>\uff1a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_6","title":"\u51cf\u6cd5","text":""},{"location":"zh/MATH/VECTOR/api/#_7","title":"\u4e24\u4e2a\u5411\u91cf\u7684\u51cf\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u9010\u5143\u7d20\u51cf\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>input2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_8","title":"\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u51cf\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9010\u5143\u7d20\u51cf\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>C</code>\uff1a\u5e38\u6570\u503c\u3002</li> <li><code>step_in</code>\uff1a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_9","title":"\u4e58\u6cd5","text":""},{"location":"zh/MATH/VECTOR/api/#_10","title":"\u4e24\u4e2a\u5411\u91cf\u7684\u4e58\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u9010\u5143\u7d20\u4e58\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>input2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_11","title":"\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u4e58\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9010\u5143\u7d20\u4e58\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>C</code>\uff1a\u5e38\u6570\u503c\u3002</li> <li><code>step_in</code>\uff1a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_12","title":"\u9664\u6cd5","text":""},{"location":"zh/MATH/VECTOR/api/#_13","title":"\u4e24\u4e2a\u5411\u91cf\u7684\u9664\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u9010\u5143\u7d20\u9664\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>input2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>allow_divide_by_zero</code>\uff1a\u5e03\u5c14\u503c\uff0c\u6307\u793a\u662f\u5426\u5141\u8bb8\u9664\u4ee5\u96f6\u7684\u64cd\u4f5c\u3002</li> </ul>"},{"location":"zh/MATH/VECTOR/api/#_14","title":"\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9664\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9010\u5143\u7d20\u9664\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>C</code>\uff1a\u5e38\u6570\u503c\u3002</li> <li><code>step_in</code>\uff1a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>allow_divide_by_zero</code>\uff1a\u5e03\u5c14\u503c\uff0c\u6307\u793a\u662f\u5426\u5141\u8bb8\u9664\u4ee5\u96f6\u7684\u64cd\u4f5c\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_15","title":"\u5e73\u65b9\u6839","text":""},{"location":"zh/MATH/VECTOR/api/#_16","title":"\u5411\u91cf\u7684\u5e73\u65b9\u6839","text":"<pre><code>tiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u7684\u9010\u5143\u7d20\u5e73\u65b9\u6839\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_17","title":"\u5411\u91cf\u7684\u5e73\u65b9\u6839\uff08\u5feb\u901f\uff09","text":"<pre><code>tiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u7684\u9010\u5143\u7d20\u5e73\u65b9\u6839\uff08\u5feb\u901f\u7248\u672c\uff09\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_18","title":"\u5411\u91cf\u7684\u5e73\u65b9\u6839\u5012\u6570","text":"<pre><code>tiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u7684\u9010\u5143\u7d20\u5e73\u65b9\u6839\u5012\u6570\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_19","title":"\u5411\u91cf\u7684\u5e73\u65b9\u6839\u5012\u6570\uff08\u5feb\u901f\uff09","text":"<pre><code>tiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u7684\u9010\u5143\u7d20\u5e73\u65b9\u6839\u5012\u6570\uff08\u5feb\u901f\u7248\u672c\uff09\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_20","title":"\u70b9\u79ef","text":""},{"location":"zh/MATH/VECTOR/api/#_21","title":"\u5411\u91cf\u7684\u70b9\u79ef","text":"<pre><code>tiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u70b9\u79ef\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>src1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>src2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>dest</code>\uff1a\u6307\u5411\u8f93\u51fa\u7ed3\u679c\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_22","title":"\u5411\u91cf\u7684\u70b9\u79ef\uff08\u5e26\u6b65\u957f\uff09","text":"<pre><code>tiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u70b9\u79ef\uff08\u5e26\u6b65\u957f\uff09\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>src1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>src2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>dest</code>\uff1a\u6307\u5411\u8f93\u51fa\u7ed3\u679c\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/MATH/VECTOR/test/","title":"\u5411\u91cf\u64cd\u4f5c\u6d4b\u8bd5","text":"<p>\u5411\u91cf\u64cd\u4f5c\u6d4b\u8bd5</p> <p>\u8be5\u6d4b\u8bd5\u7528\u4e8e\u6d4b\u8bd5\u5411\u91cf\u76f8\u5173\u51fd\u6570\u7684\u6027\u80fd\u3002</p>"},{"location":"zh/MATH/VECTOR/test/#_2","title":"\u6d4b\u8bd5\u4ee3\u7801","text":""},{"location":"zh/MATH/VECTOR/test/#_3","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<p>\u57fa\u7840C\u8ba1\u7b97\u60c5\u51b5</p> <p></p> <p>ESP-DSP\u52a0\u901f\u60c5\u51b5</p> <p></p> <p>\u53ef\u4ee5\u53d1\u73b0\u5728\u5f00\u542fESP-DSP\u52a0\u901f\u540e\uff0c\u5411\u91cf\u8fd0\u7b97\u7684\u6027\u80fd\u6709\u663e\u8457\u63d0\u5347\u3002</p>"},{"location":"zh/PREREQUISITE/prerequisite/","title":"\u524d\u7f6e\u6761\u4ef6","text":""},{"location":"zh/PREREQUISITE/prerequisite/#_2","title":"\u786c\u4ef6\u4e0e\u8f6f\u4ef6\u8981\u6c42","text":"<p>ESP32S3 \u5f00\u53d1\u677f, \u63a8\u8350\u53c2\u8003\u4ee5\u4e0b\u9879\u76ee:</p> <ul> <li> <p> NexNode</p> <p>  \u4ee3\u7801 </p> <p>  \u6587\u6863 </p> </li> </ul> <p>\u6211\u4eec\u4ee5\u8be5\u9879\u76ee\u4e2d\u7684\u4ee3\u7801\u4e3a\u57fa\u7840\u8fdb\u884c\u8fdb\u4e00\u6b65\u5f00\u53d1\u3002</p>"},{"location":"zh/PREREQUISITE/prerequisite/#_3","title":"\u4f9d\u8d56\u7ec4\u4ef6","text":"<p>\u4e3a\u4e86\u63d0\u5347\u6211\u4eec\u6846\u67b6\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u6211\u4eec\u9996\u5148\u5f15\u5165ESP-DSP\u5e93\u548cESP-DL\u5e93\uff0c\u5b83\u4eec\u5206\u522b\u63d0\u4f9b\u4e86\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u548c\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684\u9ad8\u6548\u5b9e\u73b0\u3002</p> <p>Tip</p> <p>\u6ce8\u610f\u4ee5\u4e0a\u4e24\u4e2a\u5e93\u4f3c\u4e4e\u662f\u7531\u4e0d\u540c\u56e2\u961f\u5f00\u53d1\uff0c\u56e0\u6b64\u4ed6\u4eec\u7684\u5f88\u591a\u529f\u80fd\u6709\u91cd\u53e0\u3002</p> <pre><code>- espressif__esp-dsp\n- espressif__esp-dl\n   - espressif__dl_fft\n   - espressif__esp_new_jpeg\n</code></pre> <p>\u6211\u4eec\u53ef\u4ee5\u5728ESP-REGISTRY\u4e2d\u627e\u5230\u548c\u4e0b\u8f7d\u8fd9\u4e9b\u7ec4\u4ef6\u5230\u9879\u76ee\u4e2d\u3002\u5728\u672c\u9879\u76ee\u4e2d\u6211\u5c06\u4e0b\u8f7d\u7684\u7ec4\u4ef6\u53ca\u5176\u4f9d\u8d56\u7ec4\u4ef6\u79fb\u52a8\u5230\u4e86<code>middleware</code>\u6587\u4ef6\u5939\u4e0b\uff0c\u5e76\u79fb\u9664\u4e86\u914d\u7f6e\u6587\u4ef6\uff0c\u4ece\u800c\u907f\u514d\u7248\u672c\u9501\u5b9a\u548c\u7f51\u7edc\u4f9d\u8d56\u3002</p>"},{"location":"zh/TOOLBOX/toolbox/","title":"\u5de5\u5177\u7bb1","text":"<p>tiny_toolbox</p> <p>\u5de5\u5177\u7bb1tiny_toolbox\u5b9a\u4f4d\u662f\u7528\u4e8e \u5e73\u53f0\u9002\u914d\u4e0e\u4f18\u5316 \u5e76\u63d0\u4f9b \u5404\u79cd\u5b9e\u7528\u5de5\u5177 \u7684\u5e93\uff0c\u670d\u52a1\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u4e0e\u5e94\u7528\u5f00\u53d1\u3002\u6ce8\u610f\uff0c\u4e4b\u6240\u4ee5\u5c06\u9002\u914d\u548c\u5de5\u5177\u653e\u5728\u4e00\u4e2a\u5e93\u91cc\u9762\uff0c\u662f\u56e0\u4e3a\u5f88\u591a\u5de5\u5177\u5e95\u5c42\u5229\u7528\u7684\u662f\u5e73\u53f0\u63d0\u4f9b\u7684\u529f\u80fd\uff0c\u6240\u4ee5\u5c06\u5e73\u53f0\u9002\u914d\u548c\u5404\u7c7b\u5de5\u5177\u653e\u5728\u540c\u4e00\u4e2a\u5e93\u91cc\u9762\uff0c\u4fbf\u4e8e\u4f7f\u7528\u548c\u7ef4\u62a4\u3002</p> <p>Warning</p> <p>\u76ee\u524d\u5f00\u53d1\u4ee5ESP32\u4e3a\u57fa\u7840\uff0c\u5411STM32\u7b49\u5e73\u53f0\u7684\u8fc1\u79fb\u9700\u8981\u5bf9\u9002\u914d\u5c42\u8fdb\u884c\u4e00\u5b9a\u7684\u4fee\u6539\u3002</p>"},{"location":"zh/TOOLBOX/toolbox/#_2","title":"\u67b6\u6784\u4e0e\u529f\u80fd\u76ee\u5f55","text":"<pre><code>    tiny_toolbox\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 tiny_toolbox.h // serves as a directory, integrating all submodules\n    \u251c\u2500\u2500 time\n    \u2502   \u251c\u2500\u2500 tiny_time.h // submodule for time management - header file\n    \u2502   \u251c\u2500\u2500 tiny_time.c // submodule for time management - source file\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"zh/TOOLBOX/toolbox/#_3","title":"\u65f6\u95f4","text":"<ul> <li>\u83b7\u53d6\u8fd0\u884c\u65f6\u95f4\uff1a <code>tiny_get_running_time()</code></li> <li>SNTP\u5bf9\u65f6\uff1a <code>sync_time_with_timezone(\"CST-8\")</code></li> <li>\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\uff1a <code>tiny_get_current_datetime(1)</code></li> </ul> <p>\u5f85\u5f00\u53d1:</p> <ul> <li>\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u672c\u5730\u5bf9\u65f6-\u5fae\u79d2\u7ea7\u522b</li> </ul>"},{"location":"zh/TOOLBOX/toolbox/#_4","title":"\u4ee3\u7801","text":"<p>Tip</p> <p>tiny_toolbox.h \u53ea\u662f\u4f5c\u4e3a\u4e00\u4e2a\u76ee\u5f55\uff0c\u96c6\u6210\u4e86\u6240\u6709\u7684\u5b50\u6a21\u5757\uff0c\u5177\u4f53\u7684\u529f\u80fd\u5728\u5404\u4e2a\u5b50\u6a21\u5757\u4e2d\u5b9e\u73b0\u3002tiny_toolbox.c \u53ea\u662f\u5f62\u5f0f\u4e0a\u7684\u6e90\u6587\u4ef6\uff0c\u6ca1\u6709\u5177\u4f53\u7684\u529f\u80fd\u3002</p>"},{"location":"zh/TOOLBOX/TIME/code/#_1","title":"\u7ed3\u679c","text":"<pre><code>I (25) boot: ESP-IDF v6.0-dev-1833-g758939caec 2nd stage bootloader\nI (25) boot: compile time Nov  4 2025 23:13:16\nI (25) boot: Multicore bootloader\nI (27) boot: chip revision: v0.2\nI (30) boot: efuse block revision: v1.3\nI (33) qio_mode: Enabling default flash chip QIO\nI (38) boot.esp32s3: Boot SPI Speed : 80MHz\nI (41) boot.esp32s3: SPI Mode       : QIO\nI (45) boot.esp32s3: SPI Flash Size : 16MB\nI (49) boot: Enabling RNG early entropy source...\nI (54) boot: Partition Table:\nI (56) boot: ## Label            Usage          Type ST Offset   Length\nI (62) boot:  0 nvs              WiFi data        01 02 00009000 00006000\nI (69) boot:  1 phy_init         RF data          01 01 0000f000 00001000\nI (75) boot:  2 factory          factory app      00 00 00010000 001f0000\nI (82) boot:  3 vfs              Unknown data     01 81 00200000 00a00000\nI (89) boot:  4 storage          Unknown data     01 82 00c00000 00400000\nI (95) boot: End of partition table\nI (98) esp_image: segment 0: paddr=00010020 vaddr=3c0b0020 size=1df80h (122752) map\nI (124) esp_image: segment 1: paddr=0002dfa8 vaddr=3fc99300 size=02070h (  8304) load\nI (126) esp_image: segment 2: paddr=00030020 vaddr=42000020 size=a26fch (665340) map\nI (227) esp_image: segment 3: paddr=000d2724 vaddr=3fc9b370 size=030e0h ( 12512) load\nI (229) esp_image: segment 4: paddr=000d580c vaddr=40374000 size=152ech ( 86764) load\nI (247) esp_image: segment 5: paddr=000eab00 vaddr=50000000 size=00020h (    32) load\nI (256) boot: Loaded app from partition at offset 0x10000\nI (256) boot: Disabling RNG early entropy source...\nI (266) octal_psram: vendor id    : 0x0d (AP)\nI (267) octal_psram: dev id       : 0x02 (generation 3)\nI (267) octal_psram: density      : 0x03 (64 Mbit)\nI (269) octal_psram: good-die     : 0x01 (Pass)\nI (273) octal_psram: Latency      : 0x01 (Fixed)\nI (277) octal_psram: VCC          : 0x01 (3V)\nI (281) octal_psram: SRF          : 0x01 (Fast Refresh)\nI (286) octal_psram: BurstType    : 0x01 (Hybrid Wrap)\nI (291) octal_psram: BurstLen     : 0x01 (32 Byte)\nI (296) octal_psram: Readlatency  : 0x02 (10 cycles@Fixed)\nI (301) octal_psram: DriveStrength: 0x00 (1/1)\nI (306) MSPI Timing: PSRAM timing tuning index: 5\nI (310) esp_psram: Found 8MB PSRAM device\nI (313) esp_psram: Speed: 80MHz\nI (316) cpu_start: Multicore app\nI (752) esp_psram: SPI SRAM memory test OK\nI (760) cpu_start: GPIO 44 and 43 are used as console UART I/O pins\nI (761) cpu_start: Pro cpu start user code\nI (761) cpu_start: cpu freq: 240000000 Hz\nI (762) app_init: Application information:\nI (766) app_init: Project name:     AIoTNode\nI (770) app_init: App version:      0a79117-dirty\nI (775) app_init: Compile time:     Nov  4 2025 23:13:38\nI (780) app_init: ELF file SHA256:  a5e0090b4...\nI (784) app_init: ESP-IDF:          v6.0-dev-1833-g758939caec\nI (789) efuse_init: Min chip rev:     v0.0\nI (793) efuse_init: Max chip rev:     v0.99 \nI (797) efuse_init: Chip rev:         v0.2\nI (801) heap_init: Initializing. RAM available for dynamic allocation:\nI (807) heap_init: At 3FCA2918 len 00046DF8 (283 KiB): RAM\nI (812) heap_init: At 3FCE9710 len 00005724 (21 KiB): RAM\nI (818) heap_init: At 3FCF0000 len 00008000 (32 KiB): DRAM\nI (823) heap_init: At 600FE000 len 00001FE8 (7 KiB): RTCRAM\nI (828) esp_psram: Adding pool of 8192K of PSRAM memory to heap allocator\nI (835) spi_flash: detected chip: boya\nI (838) spi_flash: flash io: qio\nI (841) sleep_gpio: Configure to isolate all GPIO pins in sleep state\nI (847) sleep_gpio: Enable automatic switching of GPIO sleep configuration\nI (854) main_task: Started on CPU0\nI (878) esp_psram: Reserving pool of 32K of internal memory for DMA/internal allocations\nI (878) main_task: Calling app_main()\nI (883) tiny_time_test: ========================================\nI (884) tiny_time_test:   tiny_time Module Test Program\nI (889) tiny_time_test: ========================================\nI (895) tiny_time_test: Initializing WiFi...\nI (900) pp: pp rom version: e7ae62f\nI (902) net80211: net80211 rom version: e7ae62f\nI (907) wifi:wifi driver task: 3fcaf644, prio:23, stack:6656, core=0\nI (915) wifi:wifi firmware version: 14da9b7\nI (916) wifi:wifi certification version: v7.0\nI (920) wifi:config NVS flash: enabled\nI (924) wifi:config nano formatting: disabled\nI (928) wifi:Init data frame dynamic rx buffer num: 32\nI (933) wifi:Init static rx mgmt buffer num: 5\nI (937) wifi:Init management short buffer num: 32\nI (941) wifi:Init dynamic tx buffer num: 32\nI (945) wifi:Init static tx FG buffer num: 2\nI (949) wifi:Init static rx buffer size: 1600\nI (953) wifi:Init static rx buffer num: 10\nI (957) wifi:Init dynamic rx buffer num: 32\nI (961) wifi_init: rx ba win: 6\nI (964) wifi_init: accept mbox: 6\nI (967) wifi_init: tcpip mbox: 32\nI (970) wifi_init: udp mbox: 6\nI (973) wifi_init: tcp mbox: 6\nI (975) wifi_init: tcp tx win: 5760\nI (979) wifi_init: tcp rx win: 5760\nI (982) wifi_init: tcp mss: 1440\nI (985) wifi_init: WiFi IRAM OP enabled\nI (988) wifi_init: WiFi RX IRAM OP enabled\nI (992) NODE-WIFI: Setting WiFi configuration SSID NTUSECURE...\nI (999) phy_init: phy_version 701,f4f1da3a,Mar  3 2025,15:50:10\nI (1037) wifi:mode : sta (cc:ba:97:09:a7:50)\nI (1038) wifi:enable tsf\nI (1039) tiny_time_test: WiFi initialized successfully\nI (1040) tiny_time_test: Waiting for WiFi connection...\nI (1107) wifi:new:&lt;1,0&gt;, old:&lt;1,0&gt;, ap:&lt;255,255&gt;, sta:&lt;1,0&gt;, prof:1, snd_ch_cfg:0x0\nI (1108) wifi:state: init -&gt; auth (0xb0)\nI (1111) wifi:state: auth -&gt; assoc (0x0)\nI (1115) wifi:state: assoc -&gt; run (0x10)\nI (1430) wifi:connected with NTUSECURE, aid = 2, channel 1, BW20, bssid = a8:9d:21:3c:12:b1\nI (1430) wifi:security: WPA2-ENT, phy: bgn, rssi: -66\nI (1432) wifi:pm start, type: 1\n\nI (1435) wifi:dp: 1, bi: 104448, li: 2, scale listen interval from 307200 us to 208896 us\nI (1443) wifi:set rx beacon pti, rx_bcn_pti: 0, bcn_timeout: 25000, mt_pti: 0, mt_time: 10000\nI (1459) wifi:&lt;ba-add&gt;idx:0 (ifx:0, a8:9d:21:3c:12:b1), tid:0, ssn:1200, winSize:64\nI (1488) wifi:AP's beacon interval = 104448 us, DTIM period = 1\nI (2467) esp_netif_handlers: sta ip: 10.91.180.236, mask: 255.255.0.0, gw: 10.91.255.254\nI (2467) tiny_time_test: WiFi connected!\nI (2467) tiny_time_test: \n--- Test 1: Get Running Time ---\nI (2473) tiny_time_test: Running time: 1644833 microseconds\nI (2478) tiny_time_test: Running time: 1.645 seconds\nI (2483) tiny_time_test: \n--- Test 2: Sync Time with Timezone ---\nI (2489) tiny_time_test: Syncing time with timezone CST-8...\nI (2494) NTP_SYNC: Initializing SNTP\nI (2498) NTP_SYNC: Waiting for system time to be set... (1/15)\nI (4503) NTP_SYNC: Waiting for system time to be set... (2/15)\nI (4715) NTP_SYNC: Time synchronized!\nI (6503) NTP_SYNC: System time is set.\nI (6503) NTP_SYNC: Current time: Tue Nov 04 23:15:34 2025\nI (6503) tiny_time_test: Waiting for time synchronization...\nI (11506) tiny_time_test: \n--- Test 3: Get Current DateTime ---\nI (11506) TIME: Current Time: 2025-11-04 23:15:39.003179\nI (11506) tiny_time_test: \n--- Test 4: Measure Time Elapsed ---\nI (11511) tiny_time_test: Time elapsed: 9038406 microseconds\nI (11517) tiny_time_test: Time elapsed: 9.038 seconds\nI (11521) tiny_time_test: \n========================================\nI (11527) tiny_time_test:   Initial Tests Completed\nI (11532) tiny_time_test: ========================================\n\nI (11538) tiny_time_test: \n========================================\nI (11544) tiny_time_test:   Timer Precision Test\nI (11548) tiny_time_test: ========================================\nI (11554) tiny_time_test: Recording 15 timestamps at 2-second intervals...\nI (11561) tiny_time_test: No printing during recording to avoid timing overhead.\n\nI (11568) tiny_time_test: Timer started. Waiting for 15 timestamps...\nI (41674) tiny_time_test: \n========================================\nI (41674) tiny_time_test:   Timer Precision Test Results\nI (41674) tiny_time_test: ========================================\nI (41680) tiny_time_test: Expected interval: 2000000 microseconds (2.000000 seconds)\n\nI (41687) tiny_time_test: Timestamp # 1: 12740383 microseconds (12.740383 seconds) [baseline]\nI (41696) tiny_time_test: Timestamp # 2: 14740381 microseconds (14.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41708) tiny_time_test: Timestamp # 3: 16740383 microseconds (16.740383 seconds) | Interval: 2000002 us (2.000002 s) | Error: 2 us (0.002 ms)\nI (41721) tiny_time_test: Timestamp # 4: 18740383 microseconds (18.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41733) tiny_time_test: Timestamp # 5: 20740383 microseconds (20.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41746) tiny_time_test: Timestamp # 6: 22740383 microseconds (22.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41759) tiny_time_test: Timestamp # 7: 24740382 microseconds (24.740382 seconds) | Interval: 1999999 us (1.999999 s) | Error: -1 us (-0.001 ms)\nI (41771) tiny_time_test: Timestamp # 8: 26740383 microseconds (26.740383 seconds) | Interval: 2000001 us (2.000001 s) | Error: 1 us (0.001 ms)\nI (41784) tiny_time_test: Timestamp # 9: 28740383 microseconds (28.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41797) tiny_time_test: Timestamp #10: 30740383 microseconds (30.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41809) tiny_time_test: Timestamp #11: 32740383 microseconds (32.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41822) tiny_time_test: Timestamp #12: 34740381 microseconds (34.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41834) tiny_time_test: Timestamp #13: 36740383 microseconds (36.740383 seconds) | Interval: 2000002 us (2.000002 s) | Error: 2 us (0.002 ms)\nI (41847) tiny_time_test: Timestamp #14: 38740383 microseconds (38.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41860) tiny_time_test: Timestamp #15: 40740381 microseconds (40.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41872) tiny_time_test: \n--- Statistics ---\nI (41877) tiny_time_test: Total time: 27999998 microseconds (27.999998 seconds)\nI (41884) tiny_time_test: Expected total: 28000000 microseconds (28.000000 seconds)\nI (41891) tiny_time_test: Total error: -2 microseconds (-0.002 milliseconds)\nI (41898) tiny_time_test: Average interval: 2.000000 seconds (1999999.857 microseconds)\nI (41906) tiny_time_test: \n========================================\nI (41912) tiny_time_test:   Test Complete\nI (41915) tiny_time_test: ========================================\n</code></pre>"},{"location":"zh/TOOLBOX/TIME/log/","title":"LOG","text":"<p>2025-04-10</p> <ul> <li>\u83b7\u53d6\u8fd0\u884c\u65f6\u95f4\uff1a <code>tiny_get_running_time()</code></li> <li>SNTP\u5bf9\u65f6\uff1a <code>sync_time_with_timezone(\"CST-8\")</code></li> <li>\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\uff1a <code>tiny_get_current_datetime(1)</code></li> </ul> <p>\u5f85\u5f00\u53d1:</p> <ul> <li>\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u672c\u5730\u5bf9\u65f6-\u5fae\u79d2\u7ea7\u522b</li> </ul>"},{"location":"zh/TOOLBOX/TIME/notes/","title":"\u65f6\u95f4","text":"<p>\u65f6\u95f4</p> <p>\u65f6\u95f4\u76f8\u5173\u7684\u529f\u80fd\u5bf9\u4e8eMCU\u6765\u8bf4\u975e\u5e38\u91cd\u8981\uff0c\u672c\u8282\u63d0\u4f9b\u4e00\u7cfb\u5217\u65f6\u95f4\u76f8\u5173\u7684\u5b9a\u4e49\u548c\u51fd\u6570\uff0c\u4f9b\u5f00\u53d1\u8005\u4f7f\u7528\u3002</p> <p>MCU\u4e2d\u7684\u65f6\u95f4\u53ef\u4ee5\u5206\u4ee5\u4e0b\u51e0\u79cd\u7c7b\u578b\uff1a</p> <ul> <li> <p>\u8fd0\u884c\u65f6\u95f4\uff1a \u6307\u7684\u662fMCU\u4ece\u4e0a\u7535\u5230\u73b0\u5728\u7684\u65f6\u95f4\u3002</p> </li> <li> <p>\u4e16\u754c\u65f6\u95f4\uff1a \u6307\u7684\u662fMCU\u6240\u5728\u7684\u65f6\u533a\u7684\u65f6\u95f4\u3002\u4e16\u754c\u65f6\u95f4\u53ef\u4ee5\u901a\u8fc7\u6807\u51c6\u7684\u5e74\u6708\u65e5\u65f6\u5206\u79d2\u6765\u8868\u793a\uff0c\u4e5f\u53ef\u4ee5\u8868\u793a\u4e3aUNIX\u65f6\u95f4\u6233\u3002</p> </li> </ul>"},{"location":"zh/TOOLBOX/TIME/notes/#_2","title":"\u8fd0\u884c\u65f6\u95f4","text":"<p>ESP\u6709\u81ea\u5df1\u7684\u83b7\u53d6\u8fd0\u884c\u65f6\u95f4\u7684\u51fd\u6570<code>esp_timer_get_time</code>\uff0c\u4f9d\u8d56\u4e8e<code>esp_timer</code>\u5e93\u3002\u8be5\u51fd\u6570\u8fd4\u56de\u4ece\u4e0a\u7535\u5230\u73b0\u5728\u7684\u65f6\u95f4\uff0c\u5355\u4f4d\u4e3a\u5fae\u79d2\u3002</p> <p>\u4e3a\u4e86\u65b9\u4fbf\u4f7f\u7528\uff0cTinyToolbox\u91cd\u65b0\u5b9a\u4e49\u4e86\u6570\u636e\u7c7b\u578b<code>TinyTimeMark_t</code>\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u51fd\u6570<code>tiny_get_running_time</code>\u6765\u83b7\u53d6\u8fd0\u884c\u65f6\u95f4\u3002\u8be5\u51fd\u6570\u8fd4\u56de\u7684\u65f6\u95f4\u5355\u4f4d\u4e3aint64_t\uff0c\u5176\u957f\u5ea6\u8db3\u591f\u4ee5\u907f\u514d\u6ea2\u51fa\u3002</p> <pre><code>typedef int64_t TinyTimeMark_t;\n</code></pre> <pre><code>/**\n * @brief Get the running time in microseconds\n * @return TinyTimeMark_t\n */\nTinyTimeMark_t tiny_get_running_time(void) { return esp_timer_get_time(); }\n</code></pre> <p>\u4f7f\u7528\u53c2\u8003\uff1a</p> <pre><code>void app_main(void)\n{\n    // Get running time\n    TinyTimeMark_t running_time = tiny_get_running_time();\n    ESP_LOGI(TAG_TIME, \"Running Time: %lld us\", running_time);\n}\n</code></pre>"},{"location":"zh/TOOLBOX/TIME/notes/#_3","title":"\u4e16\u754c\u65f6\u95f4","text":"<p>Warning</p> <p>\u6ce8\u610f\uff0c\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\u9700\u8981\u5efa\u7acb\u5728\u5df2\u7ecf\u8054\u7f51\u7684\u57fa\u7840\u4e0a\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\u7684\u51fd\u6570\u9700\u8981\u5728\u8054\u7f51\u6210\u529f\u540e\u8c03\u7528\u3002</p>"},{"location":"zh/TOOLBOX/TIME/notes/#ntp","title":"NTP\u5bf9\u65f6","text":"<p>NTP\u5bf9\u65f6</p> <p>NTP\uff08Network Time Protocol\uff09\u662f\u7f51\u7edc\u65f6\u95f4\u534f\u8bae\u7684\u7f29\u5199\uff0c\u662f\u4e00\u79cd\u7528\u4e8e\u5728\u8ba1\u7b97\u673a\u7f51\u7edc\u4e2d\u540c\u6b65\u65f6\u95f4\u7684\u534f\u8bae\u3002\u5b83\u53ef\u4ee5\u901a\u8fc7\u4e92\u8054\u7f51\u6216\u5c40\u57df\u7f51\u83b7\u53d6\u51c6\u786e\u7684\u65f6\u95f4\u4fe1\u606f\u3002 NTP\u534f\u8bae\u4f7f\u7528UDP\u534f\u8bae\u8fdb\u884c\u901a\u4fe1\uff0c\u9ed8\u8ba4\u4f7f\u7528123\u7aef\u53e3\u3002NTP\u670d\u52a1\u5668\u4f1a\u5b9a\u671f\u5411\u5ba2\u6237\u7aef\u53d1\u9001\u65f6\u95f4\u4fe1\u606f\uff0c\u5ba2\u6237\u7aef\u6839\u636e\u8fd9\u4e9b\u4fe1\u606f\u6765\u6821\u6b63\u81ea\u5df1\u7684\u7cfb\u7edf\u65f6\u95f4\u3002</p> <pre><code>   Client                      Server\n     |-------------------&gt;      |     T1\uff1a\u8bf7\u6c42\u53d1\u51fa\n     |                          |\n     |         &lt;--------------- |     T2/T3\uff1a\u670d\u52a1\u5668\u6536\u5230 &amp; \u56de\u590d\n     |                          |\n     |-------------------&gt;      |     T4\uff1a\u5ba2\u6237\u7aef\u6536\u5230\u54cd\u5e94\n</code></pre> <p>NTP\u5bf9\u65f6\u539f\u7406</p> <p>NTP\u5bf9\u65f6\u662f\u57fa\u4e8e\u56db\u4e2a\u65f6\u95f4\u6233\uff1a1. \u5ba2\u6237\u7aef\u53d1\u9001\u8bf7\u6c42\u65f6\u7684\u65f6\u95f4\u6233T1 2. \u670d\u52a1\u5668\u63a5\u6536\u5230\u8bf7\u6c42\u65f6\u7684\u65f6\u95f4\u6233T2 3. \u670d\u52a1\u5668\u53d1\u9001\u54cd\u5e94\u65f6\u7684\u65f6\u95f4\u6233T3 4. \u5ba2\u6237\u7aef\u63a5\u6536\u5230\u54cd\u5e94\u65f6\u7684\u65f6\u95f4\u6233T4\u3002\u6839\u636e\u8fd9\u56db\u4e2a\u65f6\u95f4\u6233\uff0c\u53ef\u4ee5\u8ba1\u7b97 \u7f51\u7edc\u5ef6\u8fdf Delay = (T4 - T1) - (T3 - T2)\uff0c\u4ee5\u53ca \u65f6\u95f4\u504f\u79fb Offset = ((T2 - T1) + (T3 - T4)) / 2\u3002</p> <p>ESP32 SNTP\u5bf9\u65f6</p> <p>ESP32\u4e2d\u4f7f\u7528\u7684\u662fSNTP\uff0c\u4e5f\u5c31\u662fSimple Network Time Protocol\u3002SNTP\u662fNTP\u7684\u7b80\u5316\u7248\uff0c\u9002\u7528\u4e8e\u5bf9\u65f6\u95f4\u7cbe\u5ea6\u8981\u6c42\u4e0d\u9ad8\u7684\u573a\u666f\u3002ESP32\u4e2d\u5bf9\u65f6\u4f9d\u8d56\u4e8e<code>esp_sntp</code>\u5e93\u3002SNTP\u7684\u5de5\u4f5c\u539f\u7406\u4e0eNTP\u7c7b\u4f3c\uff0c\u4f46SNTP\u7684\u5b9e\u73b0\u76f8\u5bf9\u7b80\u5355\uff0c\u9002\u5408\u5d4c\u5165\u5f0f\u8bbe\u5907\u4f7f\u7528\u3002\u5176\u7cbe\u5ea6\u901a\u5e38\u5728ms\u7ea7\u522b\uff0c\u9002\u7528\u4e8e\u5927\u591a\u6570\u5e94\u7528\u573a\u666f\u3002</p> <p>\u9996\u5148\u5b9a\u4e49\u4e00\u4e2a\u56de\u8c03\u51fd\u6570\uff0c\u7528\u4e8e\u63a5\u6536\u5bf9\u65f6\u901a\u77e5\uff1a</p> <pre><code>/* WORLD CURRENT TIME - SNTP */\n/**\n * @brief Callback function for time synchronization notification\n * @param tv Pointer to the timeval structure containing the synchronized time\n * @return None\n */\nstatic void time_sync_notification_cb(struct timeval *tv)\n{\n    ESP_LOGI(TAG_SNTP, \"Time synchronized!\");\n}\n</code></pre> <p>\u63a5\u4e0b\u6765\u662fSNTP\u7684\u521d\u59cb\u5316\u51fd\u6570\uff0c\u4e5f\u662f\u5bf9\u65f6\u7684\u6838\u5fc3\u51fd\u6570\uff0c\u901a\u5e38\u5728\u7cfb\u7edf\u521d\u59cb\u5316\u65f6\uff0c\u5b8c\u6210\u8054\u7f51\u540e\u8c03\u7528\u3002\u6ce8\u610f\u5176\u4e2d\u7684\u5bf9\u65f6\u670d\u52a1\u5668\u5730\u5740\u53ef\u4ee5\u6839\u636e\u9700\u8981\u8fdb\u884c\u4fee\u6539\u3002\u5bf9\u65f6\u5b8c\u6210\u540e\uff0cESP32\u4f1a\u5728\u5e95\u5c42\u5bf9\u672c\u673a\u65f6\u95f4\u8fdb\u884c\u8bbe\u7f6e\u3002</p> <pre><code>/**\n * @brief Initialize SNTP\n * @note This function can be called multiple times if needed\n * @return None\n */\nstatic void initialize_sntp(void)\n{\n    ESP_LOGI(TAG_SNTP, \"Initializing SNTP\");\n    esp_sntp_setoperatingmode(SNTP_OPMODE_POLL);\n    esp_sntp_setservername(0, \"pool.ntp.org\"); // NTP server // pool.ntp.org // ntp.aliyun.com\n    esp_sntp_set_time_sync_notification_cb(time_sync_notification_cb);\n    esp_sntp_init();\n}\n</code></pre> <p>\u518d\u63a5\u4e0b\u6765\u662f\u5bf9\u4ee5\u4e0a\u51fd\u6570\u7684\u8fdb\u4e00\u6b65\u5c01\u88c5\uff0c\u5305\u542b\u4e86\u65f6\u533a\u8bbe\u7f6e\u3002\u6ce8\u610f\u4ee5\u4e0b\u51fd\u6570\u4e2d\u5305\u62ec\u4e86\u5bf9RTC\u7684\u8bbe\u7f6e<code>rtc_set_time</code>\uff0c\u4f9d\u8d56\u4e8edriver\u5c42\u7684RTC\u9a71\u52a8\u3002\u6b64\u5904\u4f7f\u7528\u7684\u662f\u6211\u81ea\u5b9a\u4e49\u7684rtc\u9a71\u52a8\uff0c\u82e5\u6ca1\u6709\u76f8\u5173\u529f\u80fd\u53ef\u4ee5\u76f4\u63a5\u6ce8\u91ca\u6389\u3002</p> <pre><code>/**\n * @brief Obtain the current time with timezone\n * @param timezone_str Timezone string (e.g., \"CST-8\" or \"GMT+8\")\n * @note The timezone string format should be compatible with POSIX TZ format\n * (e.g., \"CST-8\", \"GMT+8\")\n * @note To use this function, in application, after internet connection, call\n * sync_time_with_timezone(\"CST-8\")\n * @return None\n */\nvoid sync_time_with_timezone(const char *timezone_str)\n{\n    // Validate input parameter\n    if (timezone_str == NULL)\n    {\n        ESP_LOGE(TAG_SNTP, \"timezone_str is NULL\");\n        return;\n    }\n\n    // Set system timezone\n    if (setenv(\"TZ\", timezone_str, 1) != 0)\n    {\n        ESP_LOGE(TAG_SNTP, \"Failed to set timezone environment variable\");\n        return;\n    }\n    tzset();\n\n    // Initialize SNTP and start time sync\n    initialize_sntp();\n\n    // Wait for system time to be set\n    time_t now = 0;\n    struct tm timeinfo = {0};\n    int retry = 0;\n    const int retry_count = 15;\n\n    while (timeinfo.tm_year &lt; MIN_VALID_YEAR_OFFSET &amp;&amp; ++retry &lt; retry_count)\n    {\n        ESP_LOGI(TAG_SNTP, \"Waiting for system time to be set... (%d/%d)\", retry,\n                 retry_count);\n        vTaskDelay(2000 / portTICK_PERIOD_MS);\n        time(&amp;now);\n        if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n        {\n            ESP_LOGW(TAG_SNTP, \"Failed to convert time to local time\");\n            continue;\n        }\n    }\n\n    if (timeinfo.tm_year &gt;= MIN_VALID_YEAR_OFFSET)\n    {\n        rtc_set_time(timeinfo.tm_year + 1900, timeinfo.tm_mon + 1, timeinfo.tm_mday,\n                     timeinfo.tm_hour, timeinfo.tm_min,\n                     timeinfo.tm_sec); // defined in esp_rtc.c\n        ESP_LOGI(TAG_SNTP, \"System time is set.\");\n    }\n    else\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to sync time.\");\n        return;\n    }\n\n    // Log current local time (using thread-safe formatting)\n    char time_str[64];\n    if (strftime(time_str, sizeof(time_str), \"%a %b %d %H:%M:%S %Y\", &amp;timeinfo) ==\n        0)\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to format time string\");\n    }\n    else\n    {\n        ESP_LOGI(TAG_SNTP, \"Current time: %s\", time_str);\n    }\n\n    // vTaskDelay(10000 / portTICK_PERIOD_MS); // Wait for 10 second\n    // rtc_get_time(); // uncomment to check the RTC time\n    // ESP_LOGI(TAG_SNTP, \"Current RTC time: %04d-%02d-%02d %02d:%02d:%02d\",\n    //          calendar.year, calendar.month, calendar.date,\n    //          calendar.hour, calendar.min, calendar.sec); // uncomment to check\n    //          the RTC time\n}\n</code></pre>"},{"location":"zh/TOOLBOX/TIME/notes/#_4","title":"\u4e16\u754c\u65f6\u95f4\u83b7\u53d6","text":"<p>\u4e3a\u4e86\u65b9\u4fbf\u4e16\u754c\u65f6\u95f4\u7684\u83b7\u53d6\uff0c\u6211\u4eec\u9996\u5148\u5b9a\u4e49\u4e86\u4e00\u4e2a\u6570\u636e\u7ed3\u6784<code>DateTime_t</code>\uff0c\u7528\u4e8e\u5b58\u50a8\u5e74\u6708\u65e5\u65f6\u5206\u79d2\u7b49\u4fe1\u606f\u3002\u7136\u540e\u5b9a\u4e49\u4e86\u4e00\u4e2a\u51fd\u6570<code>tiny_get_current_datetime</code>\uff0c\u7528\u4e8e\u83b7\u53d6\u5f53\u524d\u7684\u4e16\u754c\u65f6\u95f4\u3002\u8be5\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a<code>DateTime_t</code>\u7ed3\u6784\u4f53\uff0c\u5305\u542b\u4e86\u5f53\u524d\u7684\u5e74\u6708\u65e5\u65f6\u5206\u79d2\u7b49\u4fe1\u606f\u3002\u5728\u4f7f\u7528\u65f6\uff0c\u4f20\u5165\u4e00\u4e2a\u5e03\u5c14\u503c<code>print_flag</code>\uff0c\u7528\u4e8e\u63a7\u5236\u662f\u5426\u6253\u5370\u5f53\u524d\u65f6\u95f4\u3002</p> <pre><code>/**\n * @brief Structure to hold date and time\n */\ntypedef struct TinyDateTime_t\n{\n    int year;\n    int month;\n    int day;\n    int hour;\n    int minute;\n    int second;\n    long microsecond;\n} TinyDateTime_t; \n</code></pre> <pre><code>/* WORLD CURRENT TIME - GET TIME */\n/**\n * @name tiny_get_current_datetime\n * @brief Get the current time as a TinyDateTime_t struct\n * @param print_flag Flag to indicate whether to print the time\n * @return TinyDateTime_t structure containing the current date and time\n */\nTinyDateTime_t tiny_get_current_datetime(bool print_flag)\n{\n    TinyDateTime_t result = {0}; // Initialize to zero\n    struct timeval tv;\n\n    // Get current time (seconds + microseconds)\n    if (gettimeofday(&amp;tv, NULL) != 0)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to get time of day\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    time_t now = tv.tv_sec;\n    struct tm timeinfo;\n    if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to convert time to local time\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    result.year = timeinfo.tm_year + 1900;\n    result.month = timeinfo.tm_mon + 1;\n    result.day = timeinfo.tm_mday;\n    result.hour = timeinfo.tm_hour;\n    result.minute = timeinfo.tm_min;\n    result.second = timeinfo.tm_sec;\n    result.microsecond = (int32_t)tv.tv_usec; // Explicit cast for portability\n\n    if (print_flag)\n    {\n        ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06d\",\n                 result.year, result.month, result.day, result.hour, result.minute,\n                 result.second, result.microsecond);\n    }\n\n    return result;\n}\n</code></pre> <p>\u4f7f\u7528\u53c2\u8003\uff1a</p> <pre><code>void app_main(void)\n{\n    // Initialize SNTP and sync time\n    sync_time_with_timezone(\"CST-8\");\n\n    // Get current time\n    TinyDateTime_t current_time = tiny_get_current_datetime(true);\n\n    // Print current time\n    ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06ld\",\n             current_time.year, current_time.month, current_time.day,\n             current_time.hour, current_time.minute, current_time.second, current_time.microsecond);\n}\n</code></pre> <p>\u4f7f\u7528\u6548\u679c\uff1a</p> <p></p> <p>Danger</p> <p>SNTP\u540c\u6b65\u5230RTC\u4e2d\u7684\u7cbe\u5ea6\u4e3a\u79d2\u7ea7\u522b\uff0c\u56e0\u6b64\u5728\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\u65f6\uff0c\u5fae\u79d2\u90e8\u5206\u53ef\u80fd\u5e76\u4e0d\u51c6\u786e\uff0c\u4ec5\u4f9b\u53c2\u8003\u3002</p>"}]}