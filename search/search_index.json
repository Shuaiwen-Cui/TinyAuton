{"config":{"lang":["en","zh"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TINYAUTON: Microcontroller-oriented Distributed Intelligence Framework","text":""},{"location":"#about-this-project","title":"ABOUT THIS PROJECT","text":"<p>This project dedicates to the development of a library for tiny agent related computing running on MCU devices to serve the multi-agent system\uff0ccovering mathematical operations, digital signal processing, and TinyML. </p> <p>About the Name</p> <p>The name \"TinyAuton\" is a combination of \"Tiny\" and \"Auton\". \"Tiny\" means the agent is designed to run on MCU devices, and \"Auton\" is short for \"Autonomous Agent\".</p>"},{"location":"#target-hardware","title":"TARGET HARDWARE","text":"<ul> <li>MCU devices (currently targeting ESP32 as the main platform)</li> </ul>"},{"location":"#scope","title":"SCOPE","text":"<ul> <li>Platform adaptation and various tools (time, communication, etc.)</li> <li>Basic Math Operations</li> <li>Digital Signal Processing</li> <li>TinyML / Edge AI</li> </ul>"},{"location":"#host-devkits","title":"HOST DEVKITS","text":"<p>Tip</p> <p>The following hardwares are for demonstration purposes only. This project is not limited to these and can be ported to other types of hardwares.</p> <ul> <li>DNESP32S3M from Alientek (ESP32-S3)</li> </ul> <p></p> <p></p> <ul> <li> <p> NexNode</p> <p>  Repo </p> <p>  Online Doc </p> </li> </ul>"},{"location":"#project-architecture","title":"PROJECT ARCHITECTURE","text":"<pre><code>+------------------------------+\n| APPLICATION                  |\n+------------------------------+\n|   - TinyAI                   | &lt;-- AI Functions\n|   - TinyDSP                  | &lt;-- DSP Functions\n|   - TinyMath                 | &lt;-- Common Math Functions\n|   - TinyToolbox              | &lt;-- Platform-specific Low-level Optimization + Various Utilities\n| MIDDLEWARE                   |\n+------------------------------+\n| DRIVERS                      |\n+------------------------------+\n| HARDWARE                     |\n+------------------------------+\n</code></pre>"},{"location":"AI/ai/","title":"ARTIFICIAL INTELLIGENCE","text":""},{"location":"ARCHITECTURE/architecture/","title":"ARCHITECTURE","text":""},{"location":"ARCHITECTURE/architecture/#layered-architecture","title":"LAYERED ARCHITECTURE","text":"<pre><code>+------------------------------+\n| AI                           | &lt;-- AI/ML Functions for Edge Devices based on Low Level Functions\n+------------------------------+\n| DSP                          | &lt;-- Digital Signal Processing Functions\n+------------------------------+\n| Math Operations              | &lt;-- Commonly Used Math Functions for Various Applications\n+------------------------------+\n| Adaptation/Toolbox Layer     | &lt;-- To Replace Functions in Standard C with Platform Optimized/Specific Functions\n+------------------------------+\n</code></pre>"},{"location":"DSP/dsp/","title":"DIGITAL SIGNAL PROCESSING","text":"<p>Note</p> <p>This component provides a set of functions designed for signal processing on edge devices, with a focus on lightweight and efficient implementations of commonly used signal processing algorithms.</p> <p>Note</p> <p>This component is a wrapper and extension of the official ESP32 digital signal processing library ESP-DSP, providing higher-level API interfaces. In simple terms, the TinyMath library corresponds to the Math, Matrix, and DotProduct modules in ESP-DSP, while the other modules in ESP-DSP correspond to the TinyDSP library. Additionally, TinyDSP provides some functionalities not available in ESP-DSP, focusing on scenarios such as structural health monitoring.</p>"},{"location":"DSP/dsp/#component-dependencies","title":"COMPONENT DEPENDENCIES","text":"<pre><code>set(src_dirs\n    .\n    signal\n    filter\n    transform\n    support\n)\n\nset(include_dirs\n    .\n    include\n    signal\n    filter\n    transform\n    support\n)\n\nset(requires\n    tiny_math\n)\n\nidf_component_register(SRC_DIRS ${src_dirs} INCLUDE_DIRS ${include_dirs} REQUIRES ${requires})\n</code></pre>"},{"location":"DSP/dsp/#architecture-and-directory","title":"ARCHITECTURE AND DIRECTORY","text":""},{"location":"DSP/dsp/#dependency-diagram","title":"Dependency Diagram","text":""},{"location":"DSP/dsp/#code-tree","title":"Code Tree","text":"<pre><code>tiny_dsp/\n\u251c\u2500\u2500 include/                     \n\u2502   \u251c\u2500\u2500 tiny_dsp.h               # entrance header file\n\u2502   \u2514\u2500\u2500 tiny_dsp_config.h        # dsp module configuration file\n\u2502\n\u251c\u2500\u2500 signal/\n\u2502   \u251c\u2500\u2500 tiny_conv.h              # convolution - header file\n\u2502   \u251c\u2500\u2500 tiny_conv.c              # convolution - source file\n\u2502   \u251c\u2500\u2500 tiny_conv_test.h         # convolution - test header file\n\u2502   \u251c\u2500\u2500 tiny_conv_test.c         # convolution - test source file\n\u2502   \u251c\u2500\u2500 tiny_corr.h              # correlation - header file\n\u2502   \u251c\u2500\u2500 tiny_corr.c              # correlation - source file\n\u2502   \u251c\u2500\u2500 tiny_corr_test.h         # correlation - test header file\n\u2502   \u251c\u2500\u2500 tiny_corr_test.c         # correlation - test source file\n\u2502   \u251c\u2500\u2500 tiny_resample.h          # resampling - header file\n\u2502   \u251c\u2500\u2500 tiny_resample.c          # resampling - source file\n\u2502   \u251c\u2500\u2500 tiny_resample_test.h     # resampling - test header file\n\u2502   \u2514\u2500\u2500 tiny_resample_test.c     # resampling - test source file\n\u2502\n\u251c\u2500\u2500 filter/\n\u2502   \u251c\u2500\u2500 tiny_fir.h               # FIR filter - header file\n\u2502   \u251c\u2500\u2500 tiny_fir.c               # FIR filter - source file\n\u2502   \u251c\u2500\u2500 tiny_fir_test.h          # FIR filter - test header file\n\u2502   \u251c\u2500\u2500 tiny_fir_test.c          # FIR filter - test source file\n\u2502   \u251c\u2500\u2500 tiny_iir.h               # IIR filter - header file\n\u2502   \u251c\u2500\u2500 tiny_iir.c               # IIR filter - source file\n\u2502   \u251c\u2500\u2500 tiny_iir_test.h          # IIR filter - test header file\n\u2502   \u2514\u2500\u2500 tiny_iir_test.c          # IIR filter - test source file\n\u2502\n\u251c\u2500\u2500 transform/\n\u2502   \u251c\u2500\u2500 tiny_fft.h               # fast fourier transform - header file\n\u2502   \u251c\u2500\u2500 tiny_fft.c               # fast fourier transform - source file\n\u2502   \u251c\u2500\u2500 tiny_fft_test.h          # fast fourier transform - test header file\n\u2502   \u251c\u2500\u2500 tiny_fft_test.c          # fast fourier transform - test source file\n\u2502   \u251c\u2500\u2500 tiny_dwt.h               # discrete wavelet transform - header file\n\u2502   \u251c\u2500\u2500 tiny_dwt.c               # discrete wavelet transform - source file\n\u2502   \u251c\u2500\u2500 tiny_dwt_test.h          # discrete wavelet transform - test header file\n\u2502   \u251c\u2500\u2500 tiny_dwt_test.c          # discrete wavelet transform - test source file\n\u2502   \u251c\u2500\u2500 tiny_ica.h               # independent component analysis - header file\n\u2502   \u251c\u2500\u2500 tiny_ica.c               # independent component analysis - source file\n\u2502   \u251c\u2500\u2500 tiny_ica_test.h          # independent component analysis - test header file\n\u2502   \u2514\u2500\u2500 tiny_ica_test.c          # independent component analysis - test source file\n\u2502\n\u2514\u2500\u2500 support/\n    \u251c\u2500\u2500 tiny_view.h              # signal view/support - header file\n    \u251c\u2500\u2500 tiny_view.c              # signal view/support - source file\n    \u251c\u2500\u2500 tiny_view_test.h         # signal view/support - test header file\n    \u2514\u2500\u2500 tiny_view_test.c         # signal view/support - test source file\n</code></pre>"},{"location":"DSP/FILTER/FIR/code/","title":"CODE","text":""},{"location":"DSP/FILTER/FIR/code/#tiny_firh","title":"tiny_fir.h","text":"<pre><code>/**\n * @file tiny_fir.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_fir | FIR (Finite Impulse Response) Filter | header\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n * @details\n * FIR Filter Implementation\n * - Always stable (no poles, only zeros)\n * - Linear phase response possible\n * - Implemented via convolution\n * - Support for low-pass, high-pass, band-pass, band-stop filters\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n\n// tiny_dsp submodules\n#include \"tiny_conv.h\" // FIR filtering uses convolution\n\n// ESP32 DSP Library for Acceleration\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n#include \"dsps_fir.h\"\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @brief FIR filter types\n     */\n    typedef enum\n    {\n        TINY_FIR_LOWPASS = 0,   // Low-pass filter\n        TINY_FIR_HIGHPASS,      // High-pass filter\n        TINY_FIR_BANDPASS,      // Band-pass filter\n        TINY_FIR_BANDSTOP,      // Band-stop (notch) filter\n        TINY_FIR_COUNT\n    } tiny_fir_type_t;\n\n    /**\n     * @brief FIR filter design methods\n     */\n    typedef enum\n    {\n        TINY_FIR_DESIGN_WINDOW = 0,        // Window method (Hamming, Hanning, etc.)\n        TINY_FIR_DESIGN_EQUIRIPPLE,        // Equiripple (Parks-McClellan) - future\n        TINY_FIR_DESIGN_FREQ_SAMPLING,     // Frequency sampling - future\n        TINY_FIR_DESIGN_COUNT\n    } tiny_fir_design_method_t;\n\n    /**\n     * @brief Window functions for FIR design\n     */\n    typedef enum\n    {\n        TINY_FIR_WINDOW_RECTANGULAR = 0, // Rectangular (no window)\n        TINY_FIR_WINDOW_HAMMING,         // Hamming window\n        TINY_FIR_WINDOW_HANNING,         // Hanning window\n        TINY_FIR_WINDOW_BLACKMAN,        // Blackman window\n        TINY_FIR_WINDOW_KAISER,          // Kaiser window - future\n        TINY_FIR_WINDOW_COUNT\n    } tiny_fir_window_t;\n\n    /**\n     * @brief FIR filter structure\n     * @note For real-time filtering, use this structure to maintain state\n     */\n    typedef struct\n    {\n        float *coefficients;  // Filter coefficients (taps)\n        int num_taps;         // Number of filter taps (coefficients)\n        float *delay_line;    // Delay line for real-time filtering\n        int delay_index;      // Current position in delay line\n        int initialized;      // Initialization flag\n    } tiny_fir_filter_t;\n\n    /* ============================================================================\n     * FIR FILTER DESIGN FUNCTIONS\n     * ============================================================================ */\n\n    /**\n     * @name tiny_fir_design_lowpass\n     * @brief Design a low-pass FIR filter using window method\n     *\n     * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5, where 0.5 = Nyquist)\n     * @param num_taps Number of filter taps (should be odd for linear phase)\n     * @param window Window function to use\n     * @param coefficients Output array for filter coefficients (size: num_taps)\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fir_design_lowpass(float cutoff_freq, int num_taps,\n                                         tiny_fir_window_t window,\n                                         float *coefficients);\n\n    /**\n     * @name tiny_fir_design_highpass\n     * @brief Design a high-pass FIR filter using window method\n     *\n     * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n     * @param num_taps Number of filter taps (should be odd)\n     * @param window Window function to use\n     * @param coefficients Output array for filter coefficients (size: num_taps)\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fir_design_highpass(float cutoff_freq, int num_taps,\n                                           tiny_fir_window_t window,\n                                           float *coefficients);\n\n    /**\n     * @name tiny_fir_design_bandpass\n     * @brief Design a band-pass FIR filter using window method\n     *\n     * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n     * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n     * @param num_taps Number of filter taps (should be odd)\n     * @param window Window function to use\n     * @param coefficients Output array for filter coefficients (size: num_taps)\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fir_design_bandpass(float low_freq, float high_freq,\n                                           int num_taps,\n                                           tiny_fir_window_t window,\n                                           float *coefficients);\n\n    /**\n     * @name tiny_fir_design_bandstop\n     * @brief Design a band-stop (notch) FIR filter using window method\n     *\n     * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n     * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n     * @param num_taps Number of filter taps (should be odd)\n     * @param window Window function to use\n     * @param coefficients Output array for filter coefficients (size: num_taps)\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fir_design_bandstop(float low_freq, float high_freq,\n                                           int num_taps,\n                                           tiny_fir_window_t window,\n                                           float *coefficients);\n\n    /* ============================================================================\n     * FIR FILTER APPLICATION FUNCTIONS\n     * ============================================================================ */\n\n    /**\n     * @name tiny_fir_filter_f32\n     * @brief Apply FIR filter to a signal (batch processing)\n     * @note This function uses convolution internally\n     *\n     * @param input Input signal array\n     * @param input_len Length of input signal\n     * @param coefficients FIR filter coefficients (taps)\n     * @param num_taps Number of filter taps\n     * @param output Output filtered signal array (size: input_len)\n     * @param padding_mode Padding mode for boundary handling\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fir_filter_f32(const float *input, int input_len,\n                                      const float *coefficients, int num_taps,\n                                      float *output,\n                                      tiny_padding_mode_t padding_mode);\n\n    /**\n     * @name tiny_fir_init\n     * @brief Initialize FIR filter structure for real-time filtering\n     *\n     * @param filter Pointer to FIR filter structure\n     * @param coefficients Filter coefficients (will be copied internally)\n     * @param num_taps Number of filter taps\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fir_init(tiny_fir_filter_t *filter,\n                                const float *coefficients, int num_taps);\n\n    /**\n     * @name tiny_fir_deinit\n     * @brief Deinitialize FIR filter and free allocated memory\n     *\n     * @param filter Pointer to FIR filter structure\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fir_deinit(tiny_fir_filter_t *filter);\n\n    /**\n     * @name tiny_fir_process_sample\n     * @brief Process a single sample through FIR filter (real-time)\n     *\n     * @param filter Pointer to initialized FIR filter structure\n     * @param input Input sample value\n     *\n     * @return Filtered output sample\n     */\n    float tiny_fir_process_sample(tiny_fir_filter_t *filter, float input);\n\n    /**\n     * @name tiny_fir_reset\n     * @brief Reset FIR filter state (clear delay line)\n     *\n     * @param filter Pointer to FIR filter structure\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fir_reset(tiny_fir_filter_t *filter);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/FILTER/FIR/code/#tiny_firc","title":"tiny_fir.c","text":"<pre><code>/**\n * @file tiny_fir.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_fir | FIR (Finite Impulse Response) Filter | source\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_fir.h\"\n#include &lt;math.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846f\n#endif\n\n/* ============================================================================\n * HELPER FUNCTIONS\n * ============================================================================ */\n\n/**\n * @brief Apply window function to filter coefficients\n */\nstatic void apply_window(float *coeffs, int num_taps, tiny_fir_window_t window)\n{\n    if (window == TINY_FIR_WINDOW_RECTANGULAR)\n    {\n        // No window applied (already rectangular)\n        return;\n    }\n\n    for (int i = 0; i &lt; num_taps; i++)\n    {\n        float w = 1.0f;\n        float n = (float)i;\n        float N = (float)(num_taps - 1);\n\n        switch (window)\n        {\n        case TINY_FIR_WINDOW_HAMMING:\n            w = 0.54f - 0.46f * cosf(2.0f * M_PI * n / N);\n            break;\n        case TINY_FIR_WINDOW_HANNING:\n            w = 0.5f * (1.0f - cosf(2.0f * M_PI * n / N));\n            break;\n        case TINY_FIR_WINDOW_BLACKMAN:\n            w = 0.42f - 0.5f * cosf(2.0f * M_PI * n / N) + 0.08f * cosf(4.0f * M_PI * n / N);\n            break;\n        default:\n            w = 1.0f;\n            break;\n        }\n\n        coeffs[i] *= w;\n    }\n}\n\n/**\n * @brief Generate ideal low-pass filter impulse response\n */\nstatic void generate_ideal_lowpass(float *coeffs, int num_taps, float cutoff_freq)\n{\n    int center = (num_taps - 1) / 2;\n\n    for (int i = 0; i &lt; num_taps; i++)\n    {\n        int n = i - center;\n        if (n == 0)\n        {\n            coeffs[i] = 2.0f * cutoff_freq;\n        }\n        else\n        {\n            coeffs[i] = sinf(2.0f * M_PI * cutoff_freq * n) / (M_PI * n);\n        }\n    }\n}\n\n/**\n * @brief Generate ideal high-pass filter impulse response\n */\nstatic void generate_ideal_highpass(float *coeffs, int num_taps, float cutoff_freq)\n{\n    int center = (num_taps - 1) / 2;\n\n    for (int i = 0; i &lt; num_taps; i++)\n    {\n        int n = i - center;\n        if (n == 0)\n        {\n            coeffs[i] = 1.0f - 2.0f * cutoff_freq;\n        }\n        else\n        {\n            coeffs[i] = -sinf(2.0f * M_PI * cutoff_freq * n) / (M_PI * n);\n        }\n    }\n}\n\n/* ============================================================================\n * FIR FILTER DESIGN FUNCTIONS\n * ============================================================================ */\n\ntiny_error_t tiny_fir_design_lowpass(float cutoff_freq, int num_taps,\n                                      tiny_fir_window_t window,\n                                      float *coefficients)\n{\n    if (coefficients == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (num_taps &lt;= 0 || cutoff_freq &lt;= 0.0f || cutoff_freq &gt;= 0.5f)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    if (num_taps % 2 == 0)\n        return TINY_ERR_DSP_INVALID_PARAM; // Should be odd for linear phase\n\n    // Generate ideal low-pass filter\n    generate_ideal_lowpass(coefficients, num_taps, cutoff_freq);\n\n    // Apply window\n    apply_window(coefficients, num_taps, window);\n\n    return TINY_OK;\n}\n\ntiny_error_t tiny_fir_design_highpass(float cutoff_freq, int num_taps,\n                                       tiny_fir_window_t window,\n                                       float *coefficients)\n{\n    if (coefficients == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (num_taps &lt;= 0 || cutoff_freq &lt;= 0.0f || cutoff_freq &gt;= 0.5f)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    if (num_taps % 2 == 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // Generate ideal high-pass filter\n    generate_ideal_highpass(coefficients, num_taps, cutoff_freq);\n\n    // Apply window\n    apply_window(coefficients, num_taps, window);\n\n    return TINY_OK;\n}\n\ntiny_error_t tiny_fir_design_bandpass(float low_freq, float high_freq,\n                                       int num_taps,\n                                       tiny_fir_window_t window,\n                                       float *coefficients)\n{\n    if (coefficients == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (num_taps &lt;= 0 || low_freq &lt;= 0.0f || high_freq &lt;= 0.0f ||\n        low_freq &gt;= 0.5f || high_freq &gt;= 0.5f || low_freq &gt;= high_freq)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    if (num_taps % 2 == 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    int center = (num_taps - 1) / 2;\n    float center_freq = (low_freq + high_freq) / 2.0f;\n    float bandwidth = high_freq - low_freq;\n\n    // Generate band-pass filter (low-pass shifted to center frequency)\n    for (int i = 0; i &lt; num_taps; i++)\n    {\n        int n = i - center;\n        if (n == 0)\n        {\n            coefficients[i] = 2.0f * bandwidth;\n        }\n        else\n        {\n            coefficients[i] = 2.0f * bandwidth * cosf(2.0f * M_PI * center_freq * n) *\n                              sinf(M_PI * bandwidth * n) / (M_PI * n);\n        }\n    }\n\n    // Apply window\n    apply_window(coefficients, num_taps, window);\n\n    return TINY_OK;\n}\n\ntiny_error_t tiny_fir_design_bandstop(float low_freq, float high_freq,\n                                       int num_taps,\n                                       tiny_fir_window_t window,\n                                       float *coefficients)\n{\n    if (coefficients == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (num_taps &lt;= 0 || low_freq &lt;= 0.0f || high_freq &lt;= 0.0f ||\n        low_freq &gt;= 0.5f || high_freq &gt;= 0.5f || low_freq &gt;= high_freq)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    if (num_taps % 2 == 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // Band-stop = All-pass - Band-pass\n    // First generate low-pass and high-pass, then combine\n    float *lp_coeffs = (float *)malloc(num_taps * sizeof(float));\n    float *hp_coeffs = (float *)malloc(num_taps * sizeof(float));\n\n    if (!lp_coeffs || !hp_coeffs)\n    {\n        free(lp_coeffs);\n        free(hp_coeffs);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Generate low-pass at low_freq\n    generate_ideal_lowpass(lp_coeffs, num_taps, low_freq);\n    apply_window(lp_coeffs, num_taps, window);\n\n    // Generate high-pass at high_freq\n    generate_ideal_highpass(hp_coeffs, num_taps, high_freq);\n    apply_window(hp_coeffs, num_taps, window);\n\n    // Combine: band-stop = low-pass + high-pass\n    for (int i = 0; i &lt; num_taps; i++)\n    {\n        coefficients[i] = lp_coeffs[i] + hp_coeffs[i];\n    }\n\n    free(lp_coeffs);\n    free(hp_coeffs);\n\n    return TINY_OK;\n}\n\n/* ============================================================================\n * FIR FILTER APPLICATION FUNCTIONS\n * ============================================================================ */\n\ntiny_error_t tiny_fir_filter_f32(const float *input, int input_len,\n                                   const float *coefficients, int num_taps,\n                                   float *output,\n                                   tiny_padding_mode_t padding_mode)\n{\n    if (input == NULL || coefficients == NULL || output == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || num_taps &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // tiny_conv_ex_f32 with TINY_CONV_CENTER mode internally performs full convolution\n    // and writes to output buffer, which may cause buffer overflow if output buffer\n    // is smaller than input_len + num_taps - 1. To avoid this, we use TINY_CONV_FULL\n    // mode with a temporary buffer, then extract the center portion.\n    int conv_full_len = input_len + num_taps - 1;\n    float *temp_buffer = (float *)malloc(conv_full_len * sizeof(float));\n    if (temp_buffer == NULL)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    // Perform full convolution\n    tiny_error_t err = tiny_conv_ex_f32(input, input_len, coefficients, num_taps,\n                                         temp_buffer, padding_mode, TINY_CONV_FULL);\n    if (err != TINY_OK)\n    {\n        free(temp_buffer);\n        return err;\n    }\n\n    // Extract center portion (equivalent to TINY_CONV_CENTER mode)\n    int center_start = (num_taps - 1) / 2;\n    for (int i = 0; i &lt; input_len; i++)\n    {\n        output[i] = temp_buffer[center_start + i];\n    }\n\n    free(temp_buffer);\n    return TINY_OK;\n}\n\ntiny_error_t tiny_fir_init(tiny_fir_filter_t *filter,\n                             const float *coefficients, int num_taps)\n{\n    if (filter == NULL || coefficients == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (num_taps &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // Allocate memory for coefficients\n    filter-&gt;coefficients = (float *)malloc(num_taps * sizeof(float));\n    if (filter-&gt;coefficients == NULL)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    // Allocate memory for delay line\n    filter-&gt;delay_line = (float *)calloc(num_taps, sizeof(float));\n    if (filter-&gt;delay_line == NULL)\n    {\n        free(filter-&gt;coefficients);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Copy coefficients\n    memcpy(filter-&gt;coefficients, coefficients, num_taps * sizeof(float));\n\n    filter-&gt;num_taps = num_taps;\n    filter-&gt;delay_index = 0;\n    filter-&gt;initialized = 1;\n\n    return TINY_OK;\n}\n\ntiny_error_t tiny_fir_deinit(tiny_fir_filter_t *filter)\n{\n    if (filter == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (filter-&gt;initialized)\n    {\n        free(filter-&gt;coefficients);\n        free(filter-&gt;delay_line);\n        filter-&gt;coefficients = NULL;\n        filter-&gt;delay_line = NULL;\n        filter-&gt;num_taps = 0;\n        filter-&gt;delay_index = 0;\n        filter-&gt;initialized = 0;\n    }\n\n    return TINY_OK;\n}\n\nfloat tiny_fir_process_sample(tiny_fir_filter_t *filter, float input)\n{\n    if (filter == NULL || !filter-&gt;initialized)\n        return 0.0f;\n\n    // Add input to delay line\n    filter-&gt;delay_line[filter-&gt;delay_index] = input;\n\n    // Compute output (convolution)\n    float output = 0.0f;\n    int idx = filter-&gt;delay_index;\n    for (int i = 0; i &lt; filter-&gt;num_taps; i++)\n    {\n        output += filter-&gt;coefficients[i] * filter-&gt;delay_line[idx];\n        idx = (idx + 1) % filter-&gt;num_taps; // Circular buffer\n    }\n\n    // Update delay index\n    filter-&gt;delay_index = (filter-&gt;delay_index + filter-&gt;num_taps - 1) % filter-&gt;num_taps;\n\n    return output;\n}\n\ntiny_error_t tiny_fir_reset(tiny_fir_filter_t *filter)\n{\n    if (filter == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (!filter-&gt;initialized)\n        return TINY_ERR_DSP_UNINITIALIZED;\n\n    // Clear delay line\n    memset(filter-&gt;delay_line, 0, filter-&gt;num_taps * sizeof(float));\n    filter-&gt;delay_index = 0;\n\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/FILTER/FIR/notes/","title":"NOTES","text":"<p>Note</p> <p>Finite Impulse Response (FIR) filters are digital filters with no feedback, making them always stable. FIR filters can achieve linear phase response, which is important for applications requiring phase preservation. They are implemented via convolution and are widely used in audio processing, communications, and signal conditioning.</p>"},{"location":"DSP/FILTER/FIR/notes/#fir-filter-overview","title":"FIR FILTER OVERVIEW","text":""},{"location":"DSP/FILTER/FIR/notes/#mathematical-principle","title":"Mathematical Principle","text":"<p>An FIR filter is defined by its impulse response \\( h[n] \\), which has finite length. The output \\( y[n] \\) is computed as:</p> \\[ y[n] = \\sum_{k=0}^{M-1} h[k] \\cdot x[n-k] \\] <p>Where:</p> <ul> <li> <p>\\( x[n] \\) is the input signal</p> </li> <li> <p>\\( h[k] \\) are the filter coefficients (taps)</p> </li> <li> <p>\\( M \\) is the number of filter taps</p> </li> <li> <p>\\( y[n] \\) is the output signal</p> </li> </ul> <p>Transfer Function:</p> \\[ H(z) = \\sum_{k=0}^{M-1} h[k] \\cdot z^{-k} \\] <p>Key Properties:</p> <ul> <li> <p>Always Stable: No poles, only zeros</p> </li> <li> <p>Linear Phase: Possible with symmetric coefficients</p> </li> <li> <p>Finite Memory: Only requires \\( M \\) past samples</p> </li> <li> <p>No Feedback: Output depends only on input</p> </li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#filter-types","title":"FILTER TYPES","text":"<p>The library supports four basic filter types:</p> <ul> <li>Low-Pass: Passes frequencies below cutoff, attenuates above</li> <li>High-Pass: Passes frequencies above cutoff, attenuates below</li> <li>Band-Pass: Passes frequencies within a band, attenuates outside</li> <li>Band-Stop (Notch): Attenuates frequencies within a band, passes outside</li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#filter-design","title":"FILTER DESIGN","text":""},{"location":"DSP/FILTER/FIR/notes/#window-method","title":"Window Method","text":"<p>The library uses the window method for FIR filter design:</p> <ol> <li>Generate Ideal Filter: Create ideal frequency response</li> <li>Apply Window: Multiply by window function to reduce Gibbs phenomenon</li> <li>Truncate: Limit to finite number of taps</li> </ol> <p>Supported Windows:</p> <ul> <li> <p>Rectangular: No window (fastest, but may have ringing)</p> </li> <li> <p>Hamming: Good balance of main lobe width and side lobe suppression</p> </li> <li> <p>Hanning: Similar to Hamming, slightly better side lobe suppression</p> </li> <li> <p>Blackman: Best side lobe suppression, wider main lobe</p> </li> </ul> <p>Window Selection Guidelines:</p> <ul> <li> <p>Hamming: General purpose, good balance</p> </li> <li> <p>Hanning: Better side lobe suppression than Hamming</p> </li> <li> <p>Blackman: Best for applications requiring low side lobes</p> </li> <li> <p>Rectangular: Only for very simple applications</p> </li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#design-parameters","title":"Design Parameters","text":"<ul> <li>Cutoff Frequency: Normalized frequency (0.0 to 0.5, where 0.5 = Nyquist)</li> <li>Number of Taps: Should be odd for linear phase (Type I filter)</li> <li>Window Type: Affects transition bandwidth and side lobe levels</li> </ul> <p>Normalized Frequency:</p> \\[ f_{norm} = \\frac{f_{cutoff}}{f_s / 2} \\] <p>Where \\( f_s \\) is the sampling rate.</p>"},{"location":"DSP/FILTER/FIR/notes/#filter-design-functions","title":"FILTER DESIGN FUNCTIONS","text":""},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_design_lowpass","title":"tiny_fir_design_lowpass","text":"<pre><code>/**\n * @name tiny_fir_design_lowpass\n * @brief Design a low-pass FIR filter using window method\n * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n * @param num_taps Number of filter taps (should be odd)\n * @param window Window function to use\n * @param coefficients Output array for filter coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_design_lowpass(float cutoff_freq, int num_taps,\n                                     tiny_fir_window_t window,\n                                     float *coefficients);\n</code></pre> <p>Description: </p> <p>Designs a low-pass FIR filter using the window method. The ideal low-pass filter impulse response is generated and then windowed to reduce Gibbs phenomenon.</p> <p>Parameters:</p> <ul> <li> <p><code>cutoff_freq</code>: Normalized cutoff frequency (0.0 to 0.5, where 0.5 = Nyquist frequency).</p> </li> <li> <p><code>num_taps</code>: Number of filter taps. Must be odd for linear phase response.</p> </li> <li> <p><code>window</code>: Window function type from <code>tiny_fir_window_t</code> enum.</p> </li> <li> <p><code>coefficients</code>: Output array for filter coefficients. Size must be at least <code>num_taps</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Note: </p> <p>The cutoff frequency is normalized: <code>cutoff_freq = actual_freq / (sample_rate / 2)</code>. For example, a 100 Hz cutoff at 1 kHz sample rate would be <code>0.2</code> (100 / 500).</p>"},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_design_highpass","title":"tiny_fir_design_highpass","text":"<pre><code>/**\n * @name tiny_fir_design_highpass\n * @brief Design a high-pass FIR filter using window method\n * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n * @param num_taps Number of filter taps (should be odd)\n * @param window Window function to use\n * @param coefficients Output array for filter coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_design_highpass(float cutoff_freq, int num_taps,\n                                      tiny_fir_window_t window,\n                                      float *coefficients);\n</code></pre> <p>Description: </p> <p>Designs a high-pass FIR filter using the window method. The ideal high-pass filter impulse response is generated and then windowed.</p> <p>Parameters:</p> <ul> <li> <p><code>cutoff_freq</code>: Normalized cutoff frequency (0.0 to 0.5).</p> </li> <li> <p><code>num_taps</code>: Number of filter taps. Must be odd.</p> </li> <li> <p><code>window</code>: Window function type.</p> </li> <li> <p><code>coefficients</code>: Output array for filter coefficients. Size must be at least <code>num_taps</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_design_bandpass","title":"tiny_fir_design_bandpass","text":"<pre><code>/**\n * @name tiny_fir_design_bandpass\n * @brief Design a band-pass FIR filter using window method\n * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n * @param num_taps Number of filter taps (should be odd)\n * @param window Window function to use\n * @param coefficients Output array for filter coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_design_bandpass(float low_freq, float high_freq,\n                                      int num_taps,\n                                      tiny_fir_window_t window,\n                                      float *coefficients);\n</code></pre> <p>Description: </p> <p>Designs a band-pass FIR filter using the window method. The filter passes frequencies between <code>low_freq</code> and <code>high_freq</code>.</p> <p>Parameters:</p> <ul> <li> <p><code>low_freq</code>: Lower cutoff frequency (normalized, 0.0 to 0.5). Must be less than <code>high_freq</code>.</p> </li> <li> <p><code>high_freq</code>: Upper cutoff frequency (normalized, 0.0 to 0.5). Must be greater than <code>low_freq</code>.</p> </li> <li> <p><code>num_taps</code>: Number of filter taps. Must be odd.</p> </li> <li> <p><code>window</code>: Window function type.</p> </li> <li> <p><code>coefficients</code>: Output array for filter coefficients. Size must be at least <code>num_taps</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_design_bandstop","title":"tiny_fir_design_bandstop","text":"<pre><code>/**\n * @name tiny_fir_design_bandstop\n * @brief Design a band-stop (notch) FIR filter using window method\n * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n * @param num_taps Number of filter taps (should be odd)\n * @param window Window function to use\n * @param coefficients Output array for filter coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_design_bandstop(float low_freq, float high_freq,\n                                      int num_taps,\n                                      tiny_fir_window_t window,\n                                      float *coefficients);\n</code></pre> <p>Description: </p> <p>Designs a band-stop (notch) FIR filter using the window method. The filter attenuates frequencies between <code>low_freq</code> and <code>high_freq</code>.</p> <p>Parameters:</p> <ul> <li> <p><code>low_freq</code>: Lower cutoff frequency (normalized, 0.0 to 0.5). Must be less than <code>high_freq</code>.</p> </li> <li> <p><code>high_freq</code>: Upper cutoff frequency (normalized, 0.0 to 0.5). Must be greater than <code>low_freq</code>.</p> </li> <li> <p><code>num_taps</code>: Number of filter taps. Must be odd.</p> </li> <li> <p><code>window</code>: Window function type.</p> </li> <li> <p><code>coefficients</code>: Output array for filter coefficients. Size must be at least <code>num_taps</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/FIR/notes/#filter-application","title":"FILTER APPLICATION","text":""},{"location":"DSP/FILTER/FIR/notes/#batch-processing","title":"Batch Processing","text":""},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_filter_f32","title":"tiny_fir_filter_f32","text":"<pre><code>/**\n * @name tiny_fir_filter_f32\n * @brief Apply FIR filter to a signal (batch processing)\n * @param input Input signal array\n * @param input_len Length of input signal\n * @param coefficients FIR filter coefficients (taps)\n * @param num_taps Number of filter taps\n * @param output Output filtered signal array\n * @param padding_mode Padding mode for boundary handling\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_filter_f32(const float *input, int input_len,\n                                  const float *coefficients, int num_taps,\n                                  float *output,\n                                  tiny_padding_mode_t padding_mode);\n</code></pre> <p>Description: </p> <p>Applies an FIR filter to an entire signal using convolution. This is suitable for batch processing when the entire signal is available.</p> <p>Features:</p> <ul> <li> <p>Uses convolution internally</p> </li> <li> <p>Supports different padding modes for boundary handling</p> </li> <li> <p>Output length equals input length</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to input signal array.</p> </li> <li> <p><code>input_len</code>: Length of input signal.</p> </li> <li> <p><code>coefficients</code>: Pointer to FIR filter coefficients (taps).</p> </li> <li> <p><code>num_taps</code>: Number of filter taps.</p> </li> <li> <p><code>output</code>: Pointer to output array for filtered signal. Size must be at least <code>input_len</code>.</p> </li> <li> <p><code>padding_mode</code>: Padding mode for boundary handling (e.g., <code>TINY_PADDING_SYMMETRIC</code>).</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/FIR/notes/#real-time-processing","title":"Real-Time Processing","text":""},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_init","title":"tiny_fir_init","text":"<pre><code>/**\n * @name tiny_fir_init\n * @brief Initialize FIR filter structure for real-time filtering\n * @param filter Pointer to FIR filter structure\n * @param coefficients Filter coefficients (will be copied internally)\n * @param num_taps Number of filter taps\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_init(tiny_fir_filter_t *filter,\n                            const float *coefficients, int num_taps);\n</code></pre> <p>Description: </p> <p>Initializes an FIR filter structure for real-time sample-by-sample processing. Allocates memory for coefficients and delay line.</p> <p>Parameters:</p> <ul> <li> <p><code>filter</code>: Pointer to <code>tiny_fir_filter_t</code> structure.</p> </li> <li> <p><code>coefficients</code>: Pointer to filter coefficients. Will be copied internally.</p> </li> <li> <p><code>num_taps</code>: Number of filter taps.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Memory Management: </p> <p>The function allocates memory internally. Use <code>tiny_fir_deinit()</code> to free it.</p>"},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_deinit","title":"tiny_fir_deinit","text":"<pre><code>/**\n * @name tiny_fir_deinit\n * @brief Deinitialize FIR filter and free allocated memory\n * @param filter Pointer to FIR filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_deinit(tiny_fir_filter_t *filter);\n</code></pre> <p>Description: </p> <p>Deinitializes an FIR filter and frees all allocated memory.</p> <p>Parameters:</p> <ul> <li><code>filter</code>: Pointer to <code>tiny_fir_filter_t</code> structure.</li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_process_sample","title":"tiny_fir_process_sample","text":"<pre><code>/**\n * @name tiny_fir_process_sample\n * @brief Process a single sample through FIR filter (real-time)\n * @param filter Pointer to initialized FIR filter structure\n * @param input Input sample value\n * @return Filtered output sample\n */\nfloat tiny_fir_process_sample(tiny_fir_filter_t *filter, float input);\n</code></pre> <p>Description: </p> <p>Processes a single input sample through the FIR filter and returns the filtered output. Uses a circular buffer for efficient delay line implementation.</p> <p>Parameters:</p> <ul> <li> <p><code>filter</code>: Pointer to initialized <code>tiny_fir_filter_t</code> structure.</p> </li> <li> <p><code>input</code>: Input sample value.</p> </li> </ul> <p>Return Value: </p> <p>Returns filtered output sample.</p> <p>Note: </p> <p>The filter maintains internal state (delay line) between calls. Use <code>tiny_fir_reset()</code> to clear the state.</p>"},{"location":"DSP/FILTER/FIR/notes/#tiny_fir_reset","title":"tiny_fir_reset","text":"<pre><code>/**\n * @name tiny_fir_reset\n * @brief Reset FIR filter state (clear delay line)\n * @param filter Pointer to FIR filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_reset(tiny_fir_filter_t *filter);\n</code></pre> <p>Description: </p> <p>Resets the FIR filter state by clearing the delay line. Useful when starting a new signal or after a discontinuity.</p> <p>Parameters:</p> <ul> <li><code>filter</code>: Pointer to initialized <code>tiny_fir_filter_t</code> structure.</li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/FIR/notes/#usage-workflow","title":"USAGE WORKFLOW","text":""},{"location":"DSP/FILTER/FIR/notes/#batch-filtering-workflow","title":"Batch Filtering Workflow","text":"<ol> <li> <p>Design Filter:    <pre><code>float coeffs[51];\ntiny_fir_design_lowpass(0.1f, 51, TINY_FIR_WINDOW_HAMMING, coeffs);\n</code></pre></p> </li> <li> <p>Apply Filter:    <pre><code>float input[256], output[256];\ntiny_fir_filter_f32(input, 256, coeffs, 51, output, TINY_PADDING_SYMMETRIC);\n</code></pre></p> </li> </ol>"},{"location":"DSP/FILTER/FIR/notes/#real-time-filtering-workflow","title":"Real-Time Filtering Workflow","text":"<ol> <li> <p>Design Filter:    <pre><code>float coeffs[21];\ntiny_fir_design_lowpass(0.1f, 21, TINY_FIR_WINDOW_HAMMING, coeffs);\n</code></pre></p> </li> <li> <p>Initialize Filter:    <pre><code>tiny_fir_filter_t filter;\ntiny_fir_init(&amp;filter, coeffs, 21);\n</code></pre></p> </li> <li> <p>Process Samples:    <pre><code>for (int i = 0; i &lt; num_samples; i++) {\n    float output = tiny_fir_process_sample(&amp;filter, input[i]);\n    // Use output...\n}\n</code></pre></p> </li> <li> <p>Cleanup:    <pre><code>tiny_fir_deinit(&amp;filter);\n</code></pre></p> </li> </ol>"},{"location":"DSP/FILTER/FIR/notes/#applications","title":"APPLICATIONS","text":"<p>FIR filters are widely used in:</p> <ul> <li>Audio Processing: Equalization, noise reduction, anti-aliasing</li> <li>Communications: Pulse shaping, matched filtering, channel equalization</li> <li>Biomedical: ECG/EEG signal conditioning, artifact removal</li> <li>Control Systems: Signal conditioning, noise filtering</li> <li>Image Processing: Edge detection, smoothing, sharpening</li> <li>Sensor Signal Processing: Noise reduction, signal conditioning</li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#advantages-and-disadvantages","title":"ADVANTAGES AND DISADVANTAGES","text":""},{"location":"DSP/FILTER/FIR/notes/#advantages","title":"Advantages","text":"<ul> <li>Always Stable: No feedback, guaranteed stability</li> <li>Linear Phase: Can achieve exact linear phase response</li> <li>Simple Design: Window method is straightforward</li> <li>No Limit Cycles: No quantization-induced oscillations</li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#disadvantages","title":"Disadvantages","text":"<ul> <li>Higher Computational Cost: Requires more taps than IIR for same specifications</li> <li>Longer Delay: Group delay proportional to filter length</li> <li>Memory Requirements: Needs storage for all filter taps</li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#design-considerations","title":"DESIGN CONSIDERATIONS","text":""},{"location":"DSP/FILTER/FIR/notes/#number-of-taps","title":"Number of Taps","text":"<ul> <li>More Taps: Sharper transition, better stopband attenuation, but higher computation</li> <li>Fewer Taps: Faster computation, but wider transition band</li> <li>Rule of Thumb: Transition bandwidth \u2248 4 / num_taps (for Hamming window)</li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#window-selection","title":"Window Selection","text":"<ul> <li>Hamming: Good general-purpose choice</li> <li>Hanning: Better side lobe suppression</li> <li>Blackman: Best side lobe suppression, wider transition</li> <li>Rectangular: Only for very simple cases (not recommended)</li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#normalized-frequency","title":"Normalized Frequency","text":"<p>Remember to normalize frequencies:</p> <ul> <li>Cutoff at 100 Hz with 1 kHz sample rate: <code>0.2</code> (100 / 500)</li> <li>Cutoff at 1 kHz with 10 kHz sample rate: <code>0.2</code> (1000 / 5000)</li> </ul>"},{"location":"DSP/FILTER/FIR/notes/#notes_1","title":"NOTES","text":"<ul> <li>FIR filters are always stable (no poles)</li> <li>Linear phase requires odd number of taps and symmetric coefficients</li> <li>Window method is simple but may not be optimal for all applications</li> <li>For real-time applications, use <code>tiny_fir_init()</code> and <code>tiny_fir_process_sample()</code></li> <li>For batch processing, use <code>tiny_fir_filter_f32()</code></li> </ul>"},{"location":"DSP/FILTER/FIR/test/","title":"TESTS","text":""},{"location":"DSP/FILTER/FIR/test/#tiny_fir_testh","title":"tiny_fir_test.h","text":"<pre><code>/**\n * @file tiny_fir_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_fir | test | header\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_fir.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_fir_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/FILTER/FIR/test/#tiny_fir_testc","title":"tiny_fir_test.c","text":"<pre><code>/**\n * @file tiny_fir_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_fir | test | source\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_fir_test.h\"\n#include \"tiny_view.h\" // For signal visualization\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846f\n#endif\n\n#define EPSILON 1e-4f // Tolerance for floating-point comparison\n\n/**\n * @brief Generate a test signal with multiple frequency components\n */\nstatic void generate_test_signal(float *signal, int len, float sample_rate)\n{\n    // Generate signal: DC + 10Hz + 50Hz + 100Hz\n    for (int i = 0; i &lt; len; i++)\n    {\n        float t = (float)i / sample_rate;\n        signal[i] = 1.0f +                                    // DC component\n                    sinf(2.0f * M_PI * 10.0f * t) +          // 10 Hz\n                    0.5f * sinf(2.0f * M_PI * 50.0f * t) +   // 50 Hz\n                    0.3f * sinf(2.0f * M_PI * 100.0f * t);   // 100 Hz\n    }\n}\n\n/**\n * @brief Test FIR filter design\n */\nstatic void test_fir_design(void)\n{\n    printf(\"========== FIR Filter Design Test ==========\\n\\n\");\n\n    const int num_taps = 51;\n    float *coeffs = (float *)malloc(num_taps * sizeof(float));\n    if (!coeffs)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        return;\n    }\n\n    // Test 1: Low-pass filter design\n    printf(\"Test 1: Low-Pass Filter Design\\n\");\n    printf(\"  Parameters: cutoff=0.1 (normalized), taps=%d, window=Hamming\\n\", num_taps);\n    tiny_error_t err = tiny_fir_design_lowpass(0.1f, num_taps, TINY_FIR_WINDOW_HAMMING, coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Low-pass design failed: %d\\n\", err);\n        free(coeffs);\n        return;\n    }\n    printf(\"  \u2713 Low-pass filter designed successfully\\n\");\n    printf(\"  Coefficient range: [%.6f, %.6f]\\n\",\n           coeffs[0], coeffs[num_taps / 2]);\n    printf(\"\\n\");\n\n    // Test 2: High-pass filter design\n    printf(\"Test 2: High-Pass Filter Design\\n\");\n    printf(\"  Parameters: cutoff=0.2 (normalized), taps=%d, window=Hanning\\n\", num_taps);\n    err = tiny_fir_design_highpass(0.2f, num_taps, TINY_FIR_WINDOW_HANNING, coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 High-pass design failed: %d\\n\", err);\n        free(coeffs);\n        return;\n    }\n    printf(\"  \u2713 High-pass filter designed successfully\\n\");\n    printf(\"\\n\");\n\n    // Test 3: Band-pass filter design\n    printf(\"Test 3: Band-Pass Filter Design\\n\");\n    printf(\"  Parameters: low=0.1, high=0.3 (normalized), taps=%d, window=Blackman\\n\", num_taps);\n    err = tiny_fir_design_bandpass(0.1f, 0.3f, num_taps, TINY_FIR_WINDOW_BLACKMAN, coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Band-pass design failed: %d\\n\", err);\n        free(coeffs);\n        return;\n    }\n    printf(\"  \u2713 Band-pass filter designed successfully\\n\");\n    printf(\"\\n\");\n\n    // Test 4: Band-stop filter design\n    printf(\"Test 4: Band-Stop Filter Design\\n\");\n    printf(\"  Parameters: low=0.1, high=0.3 (normalized), taps=%d, window=Hamming\\n\", num_taps);\n    err = tiny_fir_design_bandstop(0.1f, 0.3f, num_taps, TINY_FIR_WINDOW_HAMMING, coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Band-stop design failed: %d\\n\", err);\n        free(coeffs);\n        return;\n    }\n    printf(\"  \u2713 Band-stop filter designed successfully\\n\");\n    printf(\"\\n\");\n\n    free(coeffs);\n    printf(\"========================================\\n\\n\");\n}\n\n/**\n * @brief Test FIR filter application (batch processing)\n */\nstatic void test_fir_batch_filtering(void)\n{\n    printf(\"========== FIR Batch Filtering Test ==========\\n\\n\");\n\n    const int signal_len = 256;\n    const float sample_rate = 1000.0f; // 1 kHz\n    const int num_taps = 51;\n    const float cutoff_freq = 0.1f; // Normalized (100 Hz at 1 kHz sample rate)\n\n    // Allocate memory\n    float *input = (float *)malloc(signal_len * sizeof(float));\n    float *output = (float *)malloc(signal_len * sizeof(float));\n    float *coeffs = (float *)malloc(num_taps * sizeof(float));\n\n    if (!input || !output || !coeffs)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        free(input);\n        free(output);\n        free(coeffs);\n        return;\n    }\n\n    // Generate test signal\n    generate_test_signal(input, signal_len, sample_rate);\n\n    // Design low-pass filter\n    printf(\"Test: Low-Pass FIR Filtering\\n\");\n    printf(\"  Input signal: DC + 10Hz + 50Hz + 100Hz components\\n\");\n    printf(\"  Filter: Low-pass, cutoff=%.1f Hz (normalized=%.3f)\\n\",\n           cutoff_freq * sample_rate, cutoff_freq);\n    printf(\"  Taps: %d, Window: Hamming\\n\\n\", num_taps);\n\n    tiny_error_t err = tiny_fir_design_lowpass(cutoff_freq, num_taps,\n                                                TINY_FIR_WINDOW_HAMMING, coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter design failed: %d\\n\", err);\n        goto cleanup;\n    }\n\n    // Apply filter\n    err = tiny_fir_filter_f32(input, signal_len, coeffs, num_taps,\n                               output, TINY_PADDING_SYMMETRIC);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filtering failed: %d\\n\", err);\n        goto cleanup;\n    }\n\n    printf(\"  \u2713 Filtering completed successfully\\n\\n\");\n\n    // Visualize signals\n    printf(\"Signal Visualization:\\n\");\n    tiny_view_signal_f32(input, signal_len, 64, 12, 0, 0, \"Original Signal\");\n    tiny_view_signal_f32(output, signal_len, 64, 12, 0, 0, \"Filtered Signal (Low-Pass)\");\n\n    // Calculate statistics\n    float input_mean = 0.0f, output_mean = 0.0f;\n    float input_power = 0.0f, output_power = 0.0f;\n    for (int i = 0; i &lt; signal_len; i++)\n    {\n        input_mean += input[i];\n        output_mean += output[i];\n        input_power += input[i] * input[i];\n        output_power += output[i] * output[i];\n    }\n    input_mean /= signal_len;\n    output_mean /= signal_len;\n    input_power /= signal_len;\n    output_power /= signal_len;\n\n    printf(\"\\nStatistics:\\n\");\n    printf(\"  Input:  mean=%.4f, power=%.4f\\n\", input_mean, input_power);\n    printf(\"  Output: mean=%.4f, power=%.4f\\n\", output_mean, output_power);\n    printf(\"  Power reduction: %.2f%%\\n\", (1.0f - output_power / input_power) * 100.0f);\n\ncleanup:\n    free(input);\n    free(output);\n    free(coeffs);\n    printf(\"\\n========================================\\n\\n\");\n}\n\n/**\n * @brief Test FIR real-time filtering\n */\nstatic void test_fir_realtime_filtering(void)\n{\n    printf(\"========== FIR Real-Time Filtering Test ==========\\n\\n\");\n\n    const int num_taps = 21;\n    const float cutoff_freq = 0.1f;\n\n    // Design filter\n    float *coeffs = (float *)malloc(num_taps * sizeof(float));\n    if (!coeffs)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        return;\n    }\n\n    tiny_error_t err = tiny_fir_design_lowpass(cutoff_freq, num_taps,\n                                                TINY_FIR_WINDOW_HAMMING, coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter design failed: %d\\n\", err);\n        free(coeffs);\n        return;\n    }\n\n    // Initialize filter\n    tiny_fir_filter_t filter;\n    err = tiny_fir_init(&amp;filter, coeffs, num_taps);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter initialization failed: %d\\n\", err);\n        free(coeffs);\n        return;\n    }\n\n    printf(\"Test: Real-Time FIR Filtering\\n\");\n    printf(\"  Filter: Low-pass, taps=%d\\n\", num_taps);\n    printf(\"  Processing samples one by one...\\n\\n\");\n\n    // Process test samples\n    const int num_samples = 20;\n    float test_input[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f,\n                          0.0f, 1.0f, 2.0f, 3.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f, 0.0f};\n    float *output = (float *)malloc(num_samples * sizeof(float));\n\n    if (!output)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        tiny_fir_deinit(&amp;filter);\n        free(coeffs);\n        return;\n    }\n\n    printf(\"  Input samples: \");\n    for (int i = 0; i &lt; num_samples; i++)\n    {\n        printf(\"%.1f \", test_input[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"  Output samples: \");\n    for (int i = 0; i &lt; num_samples; i++)\n    {\n        output[i] = tiny_fir_process_sample(&amp;filter, test_input[i]);\n        printf(\"%.3f \", output[i]);\n    }\n    printf(\"\\n\\n\");\n\n    // Test reset\n    printf(\"  Testing filter reset...\\n\");\n    err = tiny_fir_reset(&amp;filter);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter reset failed: %d\\n\", err);\n    }\n    else\n    {\n        printf(\"  \u2713 Filter reset successful\\n\");\n    }\n\n    // Cleanup\n    tiny_fir_deinit(&amp;filter);\n    free(coeffs);\n    free(output);\n\n    printf(\"\\n========================================\\n\\n\");\n}\n\n/**\n * @brief Main FIR test function\n */\nvoid tiny_fir_test(void)\n{\n    printf(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\\n\");\n    printf(\"\u2551          TinyFIR Filter Test Suite                      \u2551\\n\");\n    printf(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\n\\n\");\n\n    // Run all tests\n    test_fir_design();\n    test_fir_batch_filtering();\n    test_fir_realtime_filtering();\n\n    printf(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\\n\");\n    printf(\"\u2551          All FIR Tests Completed                          \u2551\\n\");\n    printf(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\n\");\n}\n</code></pre>"},{"location":"DSP/FILTER/FIR/test/#outputs","title":"OUTPUTS","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551          TinyFIR Filter Test Suite                      \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\n========== FIR Filter Design Test ==========\n\nTest 1: Low-Pass Filter Design\n  Parameters: cutoff=0.1 (normalized), taps=51, window=Hamming\n  \u2713 Low-pass filter designed successfully\n  Coefficient range: [-0.000000, 0.200000]\n\nTest 2: High-Pass Filter Design\n  Parameters: cutoff=0.2 (normalized), taps=51, window=Hanning\n  \u2713 High-pass filter designed successfully\n\nTest 3: Band-Pass Filter Design\n  Parameters: low=0.1, high=0.3 (normalized), taps=51, window=Blackman\n  \u2713 Band-pass filter designed successfully\n\nTest 4: Band-Stop Filter Design\n  Parameters: low=0.1, high=0.3 (normalized), taps=51, window=Hamming\n  \u2713 Band-stop filter designed successfully\n\n========================================\n\n========== FIR Batch Filtering Test ==========\n\nTest: Low-Pass FIR Filtering\n  Input signal: DC + 10Hz + 50Hz + 100Hz components\n  Filter: Low-pass, cutoff=100.0 Hz (normalized=0.100)\n  Taps: 51, Window: Hamming\n\n  \u2713 Filtering completed successfully\n\nSignal Visualization:\n\nOriginal Signal\nValue\n  3.02 |                                                                \n  2.65 |      *                                                *        \n  2.28 |     **                       **                      * *   *   \n  1.92 | *   * **  *              *  *  *  *              *   *  * **   \n  1.55 |* ***   * **             * ***   ** *            * ****  * **   \n  1.18 |*   *    *  *           *    *    *  *           *        ** *  \n  0.82 |*            *  *    *  *            *  *    *   *            * \n  0.45 |             * **   * ***             ** *  * ****            * \n  0.08 |              *  ***    *              *  * *                  *\n -0.28 |                  **                       **                   \n -0.65 |                   *                        *                   \n -1.02 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.018, 3.018], Length: 256\n\n\nFiltered Signal (Low-Pass)\nValue\n  2.88 |                                                                \n  2.54 |      *                        *                       *        \n  2.20 |     * *                      **                      * *       \n  1.85 |  *  *  *  *              *  *  *  **              *  *  *  *   \n  1.51 |** **   * **             * ***   ** *             * ***   ** *  \n  1.17 |    *    *  *           *         *  *           *           *  \n  0.83 |            *   *    *  *            *  *        *            * \n  0.49 |             * **   * * *             ** *   *** *             *\n  0.15 |              *  *  *  **              *  * *   *               \n -0.19 |                  **                      * *                   \n -0.53 |                   *                       **                   \n -0.87 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-0.872, 2.877], Length: 256\n\n\nStatistics:\n  Input:  mean=1.1294, power=1.9174\n  Output: mean=1.1321, power=1.8899\n  Power reduction: 1.43%\n\n========================================\n\n========== FIR Real-Time Filtering Test ==========\n\nTest: Real-Time FIR Filtering\n  Filter: Low-pass, taps=21\n  Processing samples one by one...\n\n  Input samples: 1.0 2.0 3.0 4.0 5.0 4.0 3.0 2.0 1.0 0.0 0.0 1.0 2.0 3.0 4.0 3.0 2.0 1.0 0.0 0.0 \n  Output samples: 0.000 -0.002 -0.011 -0.031 -0.063 -0.096 -0.092 0.006 0.265 0.733 1.400 2.184 2.934 3.472 3.652 3.419 2.845 2.109 1.446 1.063 \n\n  Testing filter reset...\n  \u2713 Filter reset successful\n\n========================================\n\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551          All FIR Tests Completed                          \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"DSP/FILTER/IIR/code/","title":"CODE","text":""},{"location":"DSP/FILTER/IIR/code/#tiny_iirh","title":"tiny_iir.h","text":"<pre><code>/**\n * @file tiny_iir.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_iir | IIR (Infinite Impulse Response) Filter | header\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n * @details\n * IIR Filter Implementation\n * - Recursive filter (uses feedback)\n * - More efficient than FIR for same specifications\n * - Can be unstable if not designed carefully\n * - Support for Butterworth, Chebyshev, Elliptic designs\n * - Direct Form II transposed structure (efficient)\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n\n// ESP32 DSP Library for Acceleration\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n#include \"dsps_biquad.h\"\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @brief IIR filter types\n     */\n    typedef enum\n    {\n        TINY_IIR_LOWPASS = 0,   // Low-pass filter\n        TINY_IIR_HIGHPASS,      // High-pass filter\n        TINY_IIR_BANDPASS,      // Band-pass filter\n        TINY_IIR_BANDSTOP,      // Band-stop (notch) filter\n        TINY_IIR_COUNT\n    } tiny_iir_type_t;\n\n    /**\n     * @brief IIR filter design methods\n     */\n    typedef enum\n    {\n        TINY_IIR_DESIGN_BUTTERWORTH = 0, // Butterworth (maximally flat)\n        TINY_IIR_DESIGN_CHEBYSHEV1,      // Chebyshev Type I (equiripple passband)\n        TINY_IIR_DESIGN_CHEBYSHEV2,      // Chebyshev Type II (equiripple stopband)\n        TINY_IIR_DESIGN_ELLIPTIC,        // Elliptic (equiripple both bands) - future\n        TINY_IIR_DESIGN_BESSEL,          // Bessel (linear phase) - future\n        TINY_IIR_DESIGN_COUNT\n    } tiny_iir_design_method_t;\n\n    /**\n     * @brief IIR filter structure (Direct Form II Transposed)\n     * @note This structure maintains filter state for real-time processing\n     */\n    typedef struct\n    {\n        // Numerator coefficients (feedforward, b coefficients)\n        float *b_coeffs;\n        int num_b; // Number of b coefficients (order + 1)\n\n        // Denominator coefficients (feedback, a coefficients)\n        float *a_coeffs;\n        int num_a; // Number of a coefficients (order + 1)\n\n        // State variables (delay line)\n        float *state;\n        int state_size; // Size of state array (max(num_b, num_a) - 1)\n\n        // Filter order\n        int order;\n\n        // Initialization flag\n        int initialized;\n    } tiny_iir_filter_t;\n\n    /**\n     * @brief Biquad (second-order) IIR filter structure\n     * @note More efficient for cascaded biquad implementations\n     */\n    typedef struct\n    {\n        // Biquad coefficients (5 coefficients: b0, b1, b2, a1, a2)\n        // Note: a0 is always 1.0 in normalized form\n        float b0, b1, b2; // Numerator coefficients\n        float a1, a2;     // Denominator coefficients (a0 = 1.0)\n\n        // State variables (2 delay elements)\n        float w1, w2; // Internal state\n\n        // Initialization flag\n        int initialized;\n    } tiny_iir_biquad_t;\n\n    /* ============================================================================\n     * IIR FILTER DESIGN FUNCTIONS\n     * ============================================================================ */\n\n    /**\n     * @name tiny_iir_design_lowpass\n     * @brief Design a low-pass IIR filter\n     *\n     * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5, where 0.5 = Nyquist)\n     * @param order Filter order\n     * @param design_method Design method (Butterworth, Chebyshev, etc.)\n     * @param ripple_db Passband ripple in dB (for Chebyshev, typically 0.5-2.0 dB)\n     * @param b_coeffs Output numerator coefficients (size: order + 1)\n     * @param a_coeffs Output denominator coefficients (size: order + 1)\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_design_lowpass(float cutoff_freq, int order,\n                                          tiny_iir_design_method_t design_method,\n                                          float ripple_db,\n                                          float *b_coeffs, float *a_coeffs);\n\n    /**\n     * @name tiny_iir_design_highpass\n     * @brief Design a high-pass IIR filter\n     *\n     * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n     * @param order Filter order\n     * @param design_method Design method\n     * @param ripple_db Passband ripple in dB\n     * @param b_coeffs Output numerator coefficients (size: order + 1)\n     * @param a_coeffs Output denominator coefficients (size: order + 1)\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_design_highpass(float cutoff_freq, int order,\n                                           tiny_iir_design_method_t design_method,\n                                           float ripple_db,\n                                           float *b_coeffs, float *a_coeffs);\n\n    /**\n     * @name tiny_iir_design_bandpass\n     * @brief Design a band-pass IIR filter\n     *\n     * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n     * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n     * @param order Filter order (will be doubled for bandpass)\n     * @param design_method Design method\n     * @param ripple_db Passband ripple in dB\n     * @param b_coeffs Output numerator coefficients\n     * @param a_coeffs Output denominator coefficients\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_design_bandpass(float low_freq, float high_freq,\n                                           int order,\n                                           tiny_iir_design_method_t design_method,\n                                           float ripple_db,\n                                           float *b_coeffs, float *a_coeffs);\n\n    /**\n     * @name tiny_iir_design_bandstop\n     * @brief Design a band-stop (notch) IIR filter\n     *\n     * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n     * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n     * @param order Filter order\n     * @param design_method Design method\n     * @param ripple_db Passband ripple in dB\n     * @param b_coeffs Output numerator coefficients\n     * @param a_coeffs Output denominator coefficients\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_design_bandstop(float low_freq, float high_freq,\n                                           int order,\n                                           tiny_iir_design_method_t design_method,\n                                           float ripple_db,\n                                           float *b_coeffs, float *a_coeffs);\n\n    /* ============================================================================\n     * IIR FILTER APPLICATION FUNCTIONS\n     * ============================================================================ */\n\n    /**\n     * @name tiny_iir_filter_f32\n     * @brief Apply IIR filter to a signal (batch processing)\n     *\n     * @param input Input signal array\n     * @param input_len Length of input signal\n     * @param b_coeffs Numerator coefficients\n     * @param num_b Number of b coefficients\n     * @param a_coeffs Denominator coefficients\n     * @param num_a Number of a coefficients\n     * @param output Output filtered signal array (size: input_len)\n     * @param initial_state Initial state vector (can be NULL for zero initial conditions)\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_filter_f32(const float *input, int input_len,\n                                      const float *b_coeffs, int num_b,\n                                      const float *a_coeffs, int num_a,\n                                      float *output,\n                                      const float *initial_state);\n\n    /**\n     * @name tiny_iir_init\n     * @brief Initialize IIR filter structure for real-time filtering\n     *\n     * @param filter Pointer to IIR filter structure\n     * @param b_coeffs Numerator coefficients (will be copied)\n     * @param num_b Number of b coefficients\n     * @param a_coeffs Denominator coefficients (will be copied)\n     * @param num_a Number of a coefficients\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_init(tiny_iir_filter_t *filter,\n                                const float *b_coeffs, int num_b,\n                                const float *a_coeffs, int num_a);\n\n    /**\n     * @name tiny_iir_deinit\n     * @brief Deinitialize IIR filter and free allocated memory\n     *\n     * @param filter Pointer to IIR filter structure\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_deinit(tiny_iir_filter_t *filter);\n\n    /**\n     * @name tiny_iir_process_sample\n     * @brief Process a single sample through IIR filter (real-time)\n     *\n     * @param filter Pointer to initialized IIR filter structure\n     * @param input Input sample value\n     *\n     * @return Filtered output sample\n     */\n    float tiny_iir_process_sample(tiny_iir_filter_t *filter, float input);\n\n    /**\n     * @name tiny_iir_reset\n     * @brief Reset IIR filter state (clear delay line)\n     *\n     * @param filter Pointer to IIR filter structure\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_reset(tiny_iir_filter_t *filter);\n\n    /* ============================================================================\n     * BIQUAD (SECOND-ORDER) IIR FILTER FUNCTIONS\n     * ============================================================================ */\n\n    /**\n     * @name tiny_iir_biquad_init\n     * @brief Initialize a biquad (second-order) IIR filter\n     *\n     * @param biquad Pointer to biquad filter structure\n     * @param b0 Numerator coefficient b0\n     * @param b1 Numerator coefficient b1\n     * @param b2 Numerator coefficient b2\n     * @param a1 Denominator coefficient a1 (a0 = 1.0)\n     * @param a2 Denominator coefficient a2\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_biquad_init(tiny_iir_biquad_t *biquad,\n                                       float b0, float b1, float b2,\n                                       float a1, float a2);\n\n    /**\n     * @name tiny_iir_biquad_process_sample\n     * @brief Process a single sample through biquad filter (real-time)\n     *\n     * @param biquad Pointer to initialized biquad filter structure\n     * @param input Input sample value\n     *\n     * @return Filtered output sample\n     */\n    float tiny_iir_biquad_process_sample(tiny_iir_biquad_t *biquad, float input);\n\n    /**\n     * @name tiny_iir_biquad_reset\n     * @brief Reset biquad filter state\n     *\n     * @param biquad Pointer to biquad filter structure\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_iir_biquad_reset(tiny_iir_biquad_t *biquad);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/FILTER/IIR/code/#tiny_iirc","title":"tiny_iir.c","text":"<pre><code>/**\n * @file tiny_iir.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_iir | IIR (Infinite Impulse Response) Filter | source\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_iir.h\"\n#include &lt;math.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846f\n#endif\n\n/* ============================================================================\n * HELPER FUNCTIONS\n * ============================================================================ */\n\n/**\n * @brief Bilinear transform: convert analog frequency to digital\n */\nstatic float bilinear_transform(float analog_freq, float sample_rate)\n{\n    float w = 2.0f * M_PI * analog_freq / sample_rate;\n    return tanf(w / 2.0f);\n}\n\n/**\n * @brief Calculate Butterworth filter coefficients for low-pass\n */\nstatic void butterworth_lowpass_coeffs(float cutoff_freq, int order,\n                                        float *b_coeffs, float *a_coeffs)\n{\n    // Simplified Butterworth design (for order 1 and 2)\n    // For higher orders, would need to cascade biquads\n\n    if (order == 1)\n    {\n        // First-order Butterworth: H(s) = 1 / (s + 1)\n        // Bilinear transform to z-domain\n        float wc = 2.0f * M_PI * cutoff_freq;\n        float k = tanf(wc / 2.0f);\n        float a0 = 1.0f + k;\n\n        b_coeffs[0] = k / a0;\n        b_coeffs[1] = k / a0;\n        b_coeffs[2] = 0.0f;\n\n        a_coeffs[0] = 1.0f;\n        a_coeffs[1] = (1.0f - k) / a0;\n        a_coeffs[2] = 0.0f;\n    }\n    else if (order == 2)\n    {\n        // Second-order Butterworth: H(s) = 1 / (s^2 + sqrt(2)*s + 1)\n        float wc = 2.0f * M_PI * cutoff_freq;\n        float k = tanf(wc / 2.0f);\n        float k2 = k * k;\n        float sqrt2 = 1.4142135623730951f;\n        float a0 = 1.0f + sqrt2 * k + k2;\n\n        b_coeffs[0] = k2 / a0;\n        b_coeffs[1] = 2.0f * k2 / a0;\n        b_coeffs[2] = k2 / a0;\n\n        a_coeffs[0] = 1.0f;\n        a_coeffs[1] = 2.0f * (k2 - 1.0f) / a0;\n        a_coeffs[2] = (1.0f - sqrt2 * k + k2) / a0;\n    }\n    else\n    {\n        // For higher orders, would cascade biquads\n        // This is a placeholder - full implementation would decompose into biquads\n        // For now, use second-order approximation\n        butterworth_lowpass_coeffs(cutoff_freq, 2, b_coeffs, a_coeffs);\n    }\n}\n\n/**\n * @brief Calculate Butterworth filter coefficients for high-pass\n */\nstatic void butterworth_highpass_coeffs(float cutoff_freq, int order,\n                                        float *b_coeffs, float *a_coeffs)\n{\n    // High-pass is frequency transformation of low-pass\n    // H_HP(z) = H_LP(-z) with frequency transformation\n    if (order == 1)\n    {\n        float wc = 2.0f * M_PI * cutoff_freq;\n        float k = tanf(wc / 2.0f);\n        float a0 = 1.0f + k;\n\n        b_coeffs[0] = 1.0f / a0;\n        b_coeffs[1] = -1.0f / a0;\n        b_coeffs[2] = 0.0f;\n\n        a_coeffs[0] = 1.0f;\n        a_coeffs[1] = (1.0f - k) / a0;\n        a_coeffs[2] = 0.0f;\n    }\n    else if (order == 2)\n    {\n        float wc = 2.0f * M_PI * cutoff_freq;\n        float k = tanf(wc / 2.0f);\n        float k2 = k * k;\n        float sqrt2 = 1.4142135623730951f;\n        float a0 = 1.0f + sqrt2 * k + k2;\n\n        b_coeffs[0] = 1.0f / a0;\n        b_coeffs[1] = -2.0f / a0;\n        b_coeffs[2] = 1.0f / a0;\n\n        a_coeffs[0] = 1.0f;\n        a_coeffs[1] = 2.0f * (k2 - 1.0f) / a0;\n        a_coeffs[2] = (1.0f - sqrt2 * k + k2) / a0;\n    }\n    else\n    {\n        butterworth_highpass_coeffs(cutoff_freq, 2, b_coeffs, a_coeffs);\n    }\n}\n\n/* ============================================================================\n * IIR FILTER DESIGN FUNCTIONS\n * ============================================================================ */\n\ntiny_error_t tiny_iir_design_lowpass(float cutoff_freq, int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs)\n{\n    if (b_coeffs == NULL || a_coeffs == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (cutoff_freq &lt;= 0.0f || cutoff_freq &gt;= 0.5f || order &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // Initialize coefficients\n    for (int i = 0; i &lt;= order; i++)\n    {\n        b_coeffs[i] = 0.0f;\n        a_coeffs[i] = 0.0f;\n    }\n\n    switch (design_method)\n    {\n    case TINY_IIR_DESIGN_BUTTERWORTH:\n        butterworth_lowpass_coeffs(cutoff_freq, order, b_coeffs, a_coeffs);\n        break;\n    case TINY_IIR_DESIGN_CHEBYSHEV1:\n    case TINY_IIR_DESIGN_CHEBYSHEV2:\n    case TINY_IIR_DESIGN_ELLIPTIC:\n    case TINY_IIR_DESIGN_BESSEL:\n        // Future implementation\n        return TINY_ERR_NOT_SUPPORTED;\n    default:\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    return TINY_OK;\n}\n\ntiny_error_t tiny_iir_design_highpass(float cutoff_freq, int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs)\n{\n    if (b_coeffs == NULL || a_coeffs == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (cutoff_freq &lt;= 0.0f || cutoff_freq &gt;= 0.5f || order &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // Initialize coefficients\n    for (int i = 0; i &lt;= order; i++)\n    {\n        b_coeffs[i] = 0.0f;\n        a_coeffs[i] = 0.0f;\n    }\n\n    switch (design_method)\n    {\n    case TINY_IIR_DESIGN_BUTTERWORTH:\n        butterworth_highpass_coeffs(cutoff_freq, order, b_coeffs, a_coeffs);\n        break;\n    default:\n        return TINY_ERR_NOT_SUPPORTED;\n    }\n\n    return TINY_OK;\n}\n\ntiny_error_t tiny_iir_design_bandpass(float low_freq, float high_freq,\n                                       int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs)\n{\n    // Band-pass design: cascade low-pass and high-pass\n    // This is a simplified implementation\n    // Full implementation would design band-pass directly\n\n    if (b_coeffs == NULL || a_coeffs == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (low_freq &lt;= 0.0f || high_freq &lt;= 0.0f || low_freq &gt;= high_freq ||\n        low_freq &gt;= 0.5f || high_freq &gt;= 0.5f || order &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // For now, return not supported - would need proper band-pass design\n    return TINY_ERR_NOT_SUPPORTED;\n}\n\ntiny_error_t tiny_iir_design_bandstop(float low_freq, float high_freq,\n                                       int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs)\n{\n    // Band-stop design: parallel low-pass and high-pass\n    // This is a simplified implementation\n\n    if (b_coeffs == NULL || a_coeffs == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (low_freq &lt;= 0.0f || high_freq &lt;= 0.0f || low_freq &gt;= high_freq ||\n        low_freq &gt;= 0.5f || high_freq &gt;= 0.5f || order &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // For now, return not supported - would need proper band-stop design\n    return TINY_ERR_NOT_SUPPORTED;\n}\n\n/* ============================================================================\n * IIR FILTER APPLICATION FUNCTIONS\n * ============================================================================ */\n\ntiny_error_t tiny_iir_filter_f32(const float *input, int input_len,\n                                  const float *b_coeffs, int num_b,\n                                  const float *a_coeffs, int num_a,\n                                  float *output,\n                                  const float *initial_state)\n{\n    if (input == NULL || b_coeffs == NULL || a_coeffs == NULL || output == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || num_b &lt;= 0 || num_a &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // ESP32 optimized implementation\n    // Note: ESP-DSP uses biquad structure, would need to convert\n    // For now, use generic implementation\n#endif\n\n    // Direct Form II Transposed implementation\n    int state_size = (num_b &gt; num_a ? num_b : num_a) - 1;\n    float *state = (float *)calloc(state_size, sizeof(float));\n\n    if (state == NULL)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    // Initialize state if provided\n    if (initial_state != NULL)\n    {\n        memcpy(state, initial_state, state_size * sizeof(float));\n    }\n\n    // Filter each sample\n    for (int n = 0; n &lt; input_len; n++)\n    {\n        // Feedforward part (b coefficients)\n        float y = b_coeffs[0] * input[n];\n        for (int i = 1; i &lt; num_b &amp;&amp; i &lt;= state_size; i++)\n        {\n            y += b_coeffs[i] * state[i - 1];\n        }\n\n        // Feedback part (a coefficients) and update state\n        for (int i = state_size; i &gt; 0; i--)\n        {\n            if (i &lt; num_a)\n            {\n                y -= a_coeffs[i] * state[i - 1];\n            }\n            if (i &gt; 1)\n            {\n                state[i - 1] = state[i - 2];\n            }\n        }\n        state[0] = input[n];\n\n        output[n] = y;\n    }\n\n    free(state);\n    return TINY_OK;\n}\n\ntiny_error_t tiny_iir_init(tiny_iir_filter_t *filter,\n                            const float *b_coeffs, int num_b,\n                            const float *a_coeffs, int num_a)\n{\n    if (filter == NULL || b_coeffs == NULL || a_coeffs == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (num_b &lt;= 0 || num_a &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // Allocate memory for coefficients\n    filter-&gt;b_coeffs = (float *)malloc(num_b * sizeof(float));\n    filter-&gt;a_coeffs = (float *)malloc(num_a * sizeof(float));\n\n    if (filter-&gt;b_coeffs == NULL || filter-&gt;a_coeffs == NULL)\n    {\n        free(filter-&gt;b_coeffs);\n        free(filter-&gt;a_coeffs);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Allocate memory for state\n    filter-&gt;state_size = (num_b &gt; num_a ? num_b : num_a) - 1;\n    filter-&gt;state = (float *)calloc(filter-&gt;state_size, sizeof(float));\n\n    if (filter-&gt;state == NULL)\n    {\n        free(filter-&gt;b_coeffs);\n        free(filter-&gt;a_coeffs);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Copy coefficients\n    memcpy(filter-&gt;b_coeffs, b_coeffs, num_b * sizeof(float));\n    memcpy(filter-&gt;a_coeffs, a_coeffs, num_a * sizeof(float));\n\n    filter-&gt;num_b = num_b;\n    filter-&gt;num_a = num_a;\n    filter-&gt;order = (num_b &gt; num_a ? num_b : num_a) - 1;\n    filter-&gt;initialized = 1;\n\n    return TINY_OK;\n}\n\ntiny_error_t tiny_iir_deinit(tiny_iir_filter_t *filter)\n{\n    if (filter == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (filter-&gt;initialized)\n    {\n        free(filter-&gt;b_coeffs);\n        free(filter-&gt;a_coeffs);\n        free(filter-&gt;state);\n        filter-&gt;b_coeffs = NULL;\n        filter-&gt;a_coeffs = NULL;\n        filter-&gt;state = NULL;\n        filter-&gt;num_b = 0;\n        filter-&gt;num_a = 0;\n        filter-&gt;state_size = 0;\n        filter-&gt;order = 0;\n        filter-&gt;initialized = 0;\n    }\n\n    return TINY_OK;\n}\n\nfloat tiny_iir_process_sample(tiny_iir_filter_t *filter, float input)\n{\n    if (filter == NULL || !filter-&gt;initialized)\n        return 0.0f;\n\n    // Direct Form II Transposed\n    // Feedforward part\n    float output = filter-&gt;b_coeffs[0] * input;\n    for (int i = 1; i &lt; filter-&gt;num_b &amp;&amp; i &lt;= filter-&gt;state_size; i++)\n    {\n        output += filter-&gt;b_coeffs[i] * filter-&gt;state[i - 1];\n    }\n\n    // Feedback part and update state\n    float temp = input;\n    for (int i = 1; i &lt; filter-&gt;num_a &amp;&amp; i &lt;= filter-&gt;state_size; i++)\n    {\n        output -= filter-&gt;a_coeffs[i] * filter-&gt;state[i - 1];\n    }\n\n    // Shift state\n    for (int i = filter-&gt;state_size - 1; i &gt; 0; i--)\n    {\n        filter-&gt;state[i] = filter-&gt;state[i - 1];\n    }\n    filter-&gt;state[0] = temp;\n\n    return output;\n}\n\ntiny_error_t tiny_iir_reset(tiny_iir_filter_t *filter)\n{\n    if (filter == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (!filter-&gt;initialized)\n        return TINY_ERR_DSP_UNINITIALIZED;\n\n    // Clear state\n    memset(filter-&gt;state, 0, filter-&gt;state_size * sizeof(float));\n\n    return TINY_OK;\n}\n\n/* ============================================================================\n * BIQUAD FILTER FUNCTIONS\n * ============================================================================ */\n\ntiny_error_t tiny_iir_biquad_init(tiny_iir_biquad_t *biquad,\n                                    float b0, float b1, float b2,\n                                    float a1, float a2)\n{\n    if (biquad == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    biquad-&gt;b0 = b0;\n    biquad-&gt;b1 = b1;\n    biquad-&gt;b2 = b2;\n    biquad-&gt;a1 = a1;\n    biquad-&gt;a2 = a2;\n    biquad-&gt;w1 = 0.0f;\n    biquad-&gt;w2 = 0.0f;\n    biquad-&gt;initialized = 1;\n\n    return TINY_OK;\n}\n\nfloat tiny_iir_biquad_process_sample(tiny_iir_biquad_t *biquad, float input)\n{\n    if (biquad == NULL || !biquad-&gt;initialized)\n        return 0.0f;\n\n    // Direct Form II Transposed for biquad\n    float w0 = input - biquad-&gt;a1 * biquad-&gt;w1 - biquad-&gt;a2 * biquad-&gt;w2;\n    float output = biquad-&gt;b0 * w0 + biquad-&gt;b1 * biquad-&gt;w1 + biquad-&gt;b2 * biquad-&gt;w2;\n\n    // Update state\n    biquad-&gt;w2 = biquad-&gt;w1;\n    biquad-&gt;w1 = w0;\n\n    return output;\n}\n\ntiny_error_t tiny_iir_biquad_reset(tiny_iir_biquad_t *biquad)\n{\n    if (biquad == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    biquad-&gt;w1 = 0.0f;\n    biquad-&gt;w2 = 0.0f;\n\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/FILTER/IIR/notes/","title":"NOTES","text":"<p>Note</p> <p>Infinite Impulse Response (IIR) filters are recursive digital filters that use feedback, making them more efficient than FIR filters for the same specifications. However, IIR filters can be unstable if not designed carefully. They are widely used in audio processing, control systems, and signal conditioning where computational efficiency is important.</p>"},{"location":"DSP/FILTER/IIR/notes/#iir-filter-overview","title":"IIR FILTER OVERVIEW","text":""},{"location":"DSP/FILTER/IIR/notes/#mathematical-principle","title":"Mathematical Principle","text":"<p>An IIR filter is defined by its difference equation, which includes both feedforward and feedback terms:</p> \\[ y[n] = \\sum_{k=0}^{M} b[k] \\cdot x[n-k] - \\sum_{k=1}^{N} a[k] \\cdot y[n-k] \\] <p>Where:</p> <ul> <li> <p>\\( x[n] \\) is the input signal</p> </li> <li> <p>\\( y[n] \\) is the output signal</p> </li> <li> <p>\\( b[k] \\) are feedforward (numerator) coefficients</p> </li> <li> <p>\\( a[k] \\) are feedback (denominator) coefficients</p> </li> <li> <p>\\( M \\) is the order of the numerator</p> </li> <li> <p>\\( N \\) is the order of the denominator</p> </li> </ul> <p>Transfer Function:</p> \\[ H(z) = \\frac{\\sum_{k=0}^{M} b[k] \\cdot z^{-k}}{1 + \\sum_{k=1}^{N} a[k] \\cdot z^{-k}} \\] <p>Key Properties:</p> <ul> <li> <p>Recursive: Uses feedback (previous outputs)</p> </li> <li> <p>Efficient: Fewer coefficients than FIR for same specifications</p> </li> <li> <p>Can be Unstable: Poles must be inside unit circle</p> </li> <li> <p>Non-Linear Phase: Generally has non-linear phase response</p> </li> </ul>"},{"location":"DSP/FILTER/IIR/notes/#filter-types","title":"FILTER TYPES","text":"<p>The library supports four basic filter types:</p> <ul> <li>Low-Pass: Passes frequencies below cutoff, attenuates above</li> <li>High-Pass: Passes frequencies above cutoff, attenuates below</li> <li>Band-Pass: Passes frequencies within a band, attenuates outside</li> <li>Band-Stop (Notch): Attenuates frequencies within a band, passes outside</li> </ul>"},{"location":"DSP/FILTER/IIR/notes/#filter-design","title":"FILTER DESIGN","text":""},{"location":"DSP/FILTER/IIR/notes/#design-methods","title":"Design Methods","text":"<p>The library supports Butterworth filter design (with plans for Chebyshev, Elliptic, and Bessel):</p> <ul> <li>Butterworth: Maximally flat passband, monotonic stopband</li> <li>Chebyshev Type I: Equiripple passband, monotonic stopband (future)</li> <li>Chebyshev Type II: Monotonic passband, equiripple stopband (future)</li> <li>Elliptic: Equiripple in both passband and stopband (future)</li> <li>Bessel: Linear phase response (future)</li> </ul>"},{"location":"DSP/FILTER/IIR/notes/#bilinear-transform","title":"Bilinear Transform","text":"<p>IIR filters are designed using the bilinear transform, which maps the analog s-plane to the digital z-plane:</p> \\[ s = \\frac{2}{T} \\cdot \\frac{1 - z^{-1}}{1 + z^{-1}} \\] <p>Where \\( T \\) is the sampling period.</p>"},{"location":"DSP/FILTER/IIR/notes/#design-parameters","title":"Design Parameters","text":"<ul> <li>Cutoff Frequency: Normalized frequency (0.0 to 0.5, where 0.5 = Nyquist)</li> <li>Filter Order: Determines sharpness of transition and stopband attenuation</li> <li>Design Method: Affects passband/stopband characteristics</li> </ul> <p>Normalized Frequency:</p> \\[ f_{norm} = \\frac{f_{cutoff}}{f_s / 2} \\] <p>Where \\( f_s \\) is the sampling rate.</p>"},{"location":"DSP/FILTER/IIR/notes/#filter-design-functions","title":"FILTER DESIGN FUNCTIONS","text":""},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_design_lowpass","title":"tiny_iir_design_lowpass","text":"<pre><code>/**\n * @name tiny_iir_design_lowpass\n * @brief Design a low-pass IIR filter\n * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n * @param order Filter order\n * @param design_method Design method (Butterworth, Chebyshev, etc.)\n * @param ripple_db Passband ripple in dB (for Chebyshev)\n * @param b_coeffs Output numerator coefficients (size: order + 1)\n * @param a_coeffs Output denominator coefficients (size: order + 1)\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_design_lowpass(float cutoff_freq, int order,\n                                      tiny_iir_design_method_t design_method,\n                                      float ripple_db,\n                                      float *b_coeffs, float *a_coeffs);\n</code></pre> <p>Description: </p> <p>Designs a low-pass IIR filter using the specified design method. Currently supports Butterworth design for orders 1 and 2.</p> <p>Parameters:</p> <ul> <li> <p><code>cutoff_freq</code>: Normalized cutoff frequency (0.0 to 0.5, where 0.5 = Nyquist frequency).</p> </li> <li> <p><code>order</code>: Filter order. Currently supports 1 and 2 for Butterworth.</p> </li> <li> <p><code>design_method</code>: Design method from <code>tiny_iir_design_method_t</code> enum. Currently only <code>TINY_IIR_DESIGN_BUTTERWORTH</code> is supported.</p> </li> <li> <p><code>ripple_db</code>: Passband ripple in dB (for Chebyshev designs, currently unused).</p> </li> <li> <p><code>b_coeffs</code>: Output array for numerator coefficients. Size must be at least <code>order + 1</code>.</p> </li> <li> <p><code>a_coeffs</code>: Output array for denominator coefficients. Size must be at least <code>order + 1</code>. Note: <code>a[0]</code> is always 1.0 (normalized form).</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Note: </p> <p>The coefficients are in normalized form where <code>a[0] = 1.0</code>. Higher order filters would need to be decomposed into cascaded biquads (second-order sections).</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_design_highpass","title":"tiny_iir_design_highpass","text":"<pre><code>/**\n * @name tiny_iir_design_highpass\n * @brief Design a high-pass IIR filter\n * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n * @param order Filter order\n * @param design_method Design method\n * @param ripple_db Passband ripple in dB\n * @param b_coeffs Output numerator coefficients (size: order + 1)\n * @param a_coeffs Output denominator coefficients (size: order + 1)\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_design_highpass(float cutoff_freq, int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs);\n</code></pre> <p>Description: </p> <p>Designs a high-pass IIR filter using the specified design method. Currently supports Butterworth design for orders 1 and 2.</p> <p>Parameters:</p> <ul> <li> <p><code>cutoff_freq</code>: Normalized cutoff frequency (0.0 to 0.5).</p> </li> <li> <p><code>order</code>: Filter order. Currently supports 1 and 2.</p> </li> <li> <p><code>design_method</code>: Design method. Currently only <code>TINY_IIR_DESIGN_BUTTERWORTH</code> is supported.</p> </li> <li> <p><code>ripple_db</code>: Passband ripple in dB (currently unused).</p> </li> <li> <p><code>b_coeffs</code>: Output array for numerator coefficients. Size must be at least <code>order + 1</code>.</p> </li> <li> <p><code>a_coeffs</code>: Output array for denominator coefficients. Size must be at least <code>order + 1</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_design_bandpass","title":"tiny_iir_design_bandpass","text":"<pre><code>/**\n * @name tiny_iir_design_bandpass\n * @brief Design a band-pass IIR filter\n * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n * @param order Filter order\n * @param design_method Design method\n * @param ripple_db Passband ripple in dB\n * @param b_coeffs Output numerator coefficients\n * @param a_coeffs Output denominator coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_design_bandpass(float low_freq, float high_freq,\n                                       int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs);\n</code></pre> <p>Description: </p> <p>Designs a band-pass IIR filter. Currently returns <code>TINY_ERR_NOT_SUPPORTED</code> as full band-pass design is not yet implemented.</p> <p>Parameters:</p> <ul> <li> <p><code>low_freq</code>: Lower cutoff frequency (normalized, 0.0 to 0.5). Must be less than <code>high_freq</code>.</p> </li> <li> <p><code>high_freq</code>: Upper cutoff frequency (normalized, 0.0 to 0.5). Must be greater than <code>low_freq</code>.</p> </li> <li> <p><code>order</code>: Filter order.</p> </li> <li> <p><code>design_method</code>: Design method.</p> </li> <li> <p><code>ripple_db</code>: Passband ripple in dB.</p> </li> <li> <p><code>b_coeffs</code>: Output array for numerator coefficients.</p> </li> <li> <p><code>a_coeffs</code>: Output array for denominator coefficients.</p> </li> </ul> <p>Return Value: </p> <p>Currently returns <code>TINY_ERR_NOT_SUPPORTED</code>.</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_design_bandstop","title":"tiny_iir_design_bandstop","text":"<pre><code>/**\n * @name tiny_iir_design_bandstop\n * @brief Design a band-stop (notch) IIR filter\n * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n * @param order Filter order\n * @param design_method Design method\n * @param ripple_db Passband ripple in dB\n * @param b_coeffs Output numerator coefficients\n * @param a_coeffs Output denominator coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_design_bandstop(float low_freq, float high_freq,\n                                       int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs);\n</code></pre> <p>Description: </p> <p>Designs a band-stop (notch) IIR filter. Currently returns <code>TINY_ERR_NOT_SUPPORTED</code> as full band-stop design is not yet implemented.</p> <p>Parameters:</p> <ul> <li> <p><code>low_freq</code>: Lower cutoff frequency (normalized, 0.0 to 0.5). Must be less than <code>high_freq</code>.</p> </li> <li> <p><code>high_freq</code>: Upper cutoff frequency (normalized, 0.0 to 0.5). Must be greater than <code>low_freq</code>.</p> </li> <li> <p><code>order</code>: Filter order.</p> </li> <li> <p><code>design_method</code>: Design method.</p> </li> <li> <p><code>ripple_db</code>: Passband ripple in dB.</p> </li> <li> <p><code>b_coeffs</code>: Output array for numerator coefficients.</p> </li> <li> <p><code>a_coeffs</code>: Output array for denominator coefficients.</p> </li> </ul> <p>Return Value: </p> <p>Currently returns <code>TINY_ERR_NOT_SUPPORTED</code>.</p>"},{"location":"DSP/FILTER/IIR/notes/#filter-application","title":"FILTER APPLICATION","text":""},{"location":"DSP/FILTER/IIR/notes/#batch-processing","title":"Batch Processing","text":""},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_filter_f32","title":"tiny_iir_filter_f32","text":"<pre><code>/**\n * @name tiny_iir_filter_f32\n * @brief Apply IIR filter to a signal (batch processing)\n * @param input Input signal array\n * @param input_len Length of input signal\n * @param b_coeffs Numerator coefficients\n * @param num_b Number of b coefficients\n * @param a_coeffs Denominator coefficients\n * @param num_a Number of a coefficients\n * @param output Output filtered signal array (size: input_len)\n * @param initial_state Initial state vector (can be NULL for zero initial conditions)\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_filter_f32(const float *input, int input_len,\n                                  const float *b_coeffs, int num_b,\n                                  const float *a_coeffs, int num_a,\n                                  float *output,\n                                  const float *initial_state);\n</code></pre> <p>Description: </p> <p>Applies an IIR filter to an entire signal using Direct Form II Transposed structure. This is suitable for batch processing when the entire signal is available.</p> <p>Features:</p> <ul> <li> <p>Uses Direct Form II Transposed implementation (efficient)</p> </li> <li> <p>Supports initial state conditions</p> </li> <li> <p>Output length equals input length</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to input signal array.</p> </li> <li> <p><code>input_len</code>: Length of input signal.</p> </li> <li> <p><code>b_coeffs</code>: Pointer to numerator coefficients.</p> </li> <li> <p><code>num_b</code>: Number of numerator coefficients.</p> </li> <li> <p><code>a_coeffs</code>: Pointer to denominator coefficients. Note: <code>a[0]</code> should be 1.0 (normalized form).</p> </li> <li> <p><code>num_a</code>: Number of denominator coefficients.</p> </li> <li> <p><code>output</code>: Pointer to output array for filtered signal. Size must be at least <code>input_len</code>.</p> </li> <li> <p><code>initial_state</code>: Initial state vector. Can be <code>NULL</code> for zero initial conditions. Size should be <code>max(num_b, num_a) - 1</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Note: </p> <p>The filter uses Direct Form II Transposed structure, which is computationally efficient and requires minimal state storage.</p>"},{"location":"DSP/FILTER/IIR/notes/#real-time-processing","title":"Real-Time Processing","text":""},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_init","title":"tiny_iir_init","text":"<pre><code>/**\n * @name tiny_iir_init\n * @brief Initialize IIR filter structure for real-time filtering\n * @param filter Pointer to IIR filter structure\n * @param b_coeffs Numerator coefficients (will be copied)\n * @param num_b Number of b coefficients\n * @param a_coeffs Denominator coefficients (will be copied)\n * @param num_a Number of a coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_init(tiny_iir_filter_t *filter,\n                            const float *b_coeffs, int num_b,\n                            const float *a_coeffs, int num_a);\n</code></pre> <p>Description: </p> <p>Initializes an IIR filter structure for real-time sample-by-sample processing. Allocates memory for coefficients and state variables.</p> <p>Parameters:</p> <ul> <li> <p><code>filter</code>: Pointer to <code>tiny_iir_filter_t</code> structure.</p> </li> <li> <p><code>b_coeffs</code>: Pointer to numerator coefficients. Will be copied internally.</p> </li> <li> <p><code>num_b</code>: Number of numerator coefficients.</p> </li> <li> <p><code>a_coeffs</code>: Pointer to denominator coefficients. Will be copied internally.</p> </li> <li> <p><code>num_a</code>: Number of denominator coefficients.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Memory Management: </p> <p>The function allocates memory internally. Use <code>tiny_iir_deinit()</code> to free it.</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_deinit","title":"tiny_iir_deinit","text":"<pre><code>/**\n * @name tiny_iir_deinit\n * @brief Deinitialize IIR filter and free allocated memory\n * @param filter Pointer to IIR filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_deinit(tiny_iir_filter_t *filter);\n</code></pre> <p>Description: </p> <p>Deinitializes an IIR filter and frees all allocated memory.</p> <p>Parameters:</p> <ul> <li><code>filter</code>: Pointer to <code>tiny_iir_filter_t</code> structure.</li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_process_sample","title":"tiny_iir_process_sample","text":"<pre><code>/**\n * @name tiny_iir_process_sample\n * @brief Process a single sample through IIR filter (real-time)\n * @param filter Pointer to initialized IIR filter structure\n * @param input Input sample value\n * @return Filtered output sample\n */\nfloat tiny_iir_process_sample(tiny_iir_filter_t *filter, float input);\n</code></pre> <p>Description: </p> <p>Processes a single input sample through the IIR filter and returns the filtered output. Uses Direct Form II Transposed structure.</p> <p>Parameters:</p> <ul> <li> <p><code>filter</code>: Pointer to initialized <code>tiny_iir_filter_t</code> structure.</p> </li> <li> <p><code>input</code>: Input sample value.</p> </li> </ul> <p>Return Value: </p> <p>Returns filtered output sample.</p> <p>Note: </p> <p>The filter maintains internal state between calls. Use <code>tiny_iir_reset()</code> to clear the state.</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_reset","title":"tiny_iir_reset","text":"<pre><code>/**\n * @name tiny_iir_reset\n * @brief Reset IIR filter state (clear delay line)\n * @param filter Pointer to IIR filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_reset(tiny_iir_filter_t *filter);\n</code></pre> <p>Description: </p> <p>Resets the IIR filter state by clearing the state variables. Useful when starting a new signal or after a discontinuity.</p> <p>Parameters:</p> <ul> <li><code>filter</code>: Pointer to initialized <code>tiny_iir_filter_t</code> structure.</li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/IIR/notes/#biquad-filters","title":"BIQUAD FILTERS","text":"<p>Biquad (second-order) filters are a special case of IIR filters that are particularly efficient and commonly used. Higher-order filters are often decomposed into cascaded biquads for numerical stability.</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_biquad_init","title":"tiny_iir_biquad_init","text":"<pre><code>/**\n * @name tiny_iir_biquad_init\n * @brief Initialize a biquad (second-order) IIR filter\n * @param biquad Pointer to biquad filter structure\n * @param b0 Numerator coefficient b0\n * @param b1 Numerator coefficient b1\n * @param b2 Numerator coefficient b2\n * @param a1 Denominator coefficient a1 (a0 = 1.0)\n * @param a2 Denominator coefficient a2\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_biquad_init(tiny_iir_biquad_t *biquad,\n                                    float b0, float b1, float b2,\n                                    float a1, float a2);\n</code></pre> <p>Description: </p> <p>Initializes a biquad (second-order) IIR filter. Biquads are efficient and commonly used building blocks for higher-order filters.</p> <p>Parameters:</p> <ul> <li> <p><code>biquad</code>: Pointer to <code>tiny_iir_biquad_t</code> structure.</p> </li> <li> <p><code>b0</code>, <code>b1</code>, <code>b2</code>: Numerator coefficients.</p> </li> <li> <p><code>a1</code>, <code>a2</code>: Denominator coefficients (a0 = 1.0 in normalized form).</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_biquad_process_sample","title":"tiny_iir_biquad_process_sample","text":"<pre><code>/**\n * @name tiny_iir_biquad_process_sample\n * @brief Process a single sample through biquad filter (real-time)\n * @param biquad Pointer to initialized biquad filter structure\n * @param input Input sample value\n * @return Filtered output sample\n */\nfloat tiny_iir_biquad_process_sample(tiny_iir_biquad_t *biquad, float input);\n</code></pre> <p>Description: </p> <p>Processes a single input sample through the biquad filter and returns the filtered output.</p> <p>Parameters:</p> <ul> <li> <p><code>biquad</code>: Pointer to initialized <code>tiny_iir_biquad_t</code> structure.</p> </li> <li> <p><code>input</code>: Input sample value.</p> </li> </ul> <p>Return Value: </p> <p>Returns filtered output sample.</p>"},{"location":"DSP/FILTER/IIR/notes/#tiny_iir_biquad_reset","title":"tiny_iir_biquad_reset","text":"<pre><code>/**\n * @name tiny_iir_biquad_reset\n * @brief Reset biquad filter state\n * @param biquad Pointer to biquad filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_biquad_reset(tiny_iir_biquad_t *biquad);\n</code></pre> <p>Description: </p> <p>Resets the biquad filter state by clearing internal state variables.</p> <p>Parameters:</p> <ul> <li><code>biquad</code>: Pointer to <code>tiny_iir_biquad_t</code> structure.</li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/FILTER/IIR/notes/#usage-workflow","title":"USAGE WORKFLOW","text":""},{"location":"DSP/FILTER/IIR/notes/#batch-filtering-workflow","title":"Batch Filtering Workflow","text":"<ol> <li> <p>Design Filter:    <pre><code>float b_coeffs[3], a_coeffs[3];\ntiny_iir_design_lowpass(0.1f, 2, TINY_IIR_DESIGN_BUTTERWORTH, 0.0f, b_coeffs, a_coeffs);\n</code></pre></p> </li> <li> <p>Apply Filter:    <pre><code>float input[256], output[256];\ntiny_iir_filter_f32(input, 256, b_coeffs, 3, a_coeffs, 3, output, NULL);\n</code></pre></p> </li> </ol>"},{"location":"DSP/FILTER/IIR/notes/#real-time-filtering-workflow","title":"Real-Time Filtering Workflow","text":"<ol> <li> <p>Design Filter:    <pre><code>float b_coeffs[3], a_coeffs[3];\ntiny_iir_design_lowpass(0.1f, 2, TINY_IIR_DESIGN_BUTTERWORTH, 0.0f, b_coeffs, a_coeffs);\n</code></pre></p> </li> <li> <p>Initialize Filter:    <pre><code>tiny_iir_filter_t filter;\ntiny_iir_init(&amp;filter, b_coeffs, 3, a_coeffs, 3);\n</code></pre></p> </li> <li> <p>Process Samples:    <pre><code>for (int i = 0; i &lt; num_samples; i++) {\n    float output = tiny_iir_process_sample(&amp;filter, input[i]);\n    // Use output...\n}\n</code></pre></p> </li> <li> <p>Cleanup:    <pre><code>tiny_iir_deinit(&amp;filter);\n</code></pre></p> </li> </ol>"},{"location":"DSP/FILTER/IIR/notes/#biquad-workflow","title":"Biquad Workflow","text":"<ol> <li> <p>Design Filter (or use pre-designed coefficients):    <pre><code>float b_coeffs[3], a_coeffs[3];\ntiny_iir_design_lowpass(0.1f, 2, TINY_IIR_DESIGN_BUTTERWORTH, 0.0f, b_coeffs, a_coeffs);\n</code></pre></p> </li> <li> <p>Initialize Biquad:    <pre><code>tiny_iir_biquad_t biquad;\ntiny_iir_biquad_init(&amp;biquad, b_coeffs[0], b_coeffs[1], b_coeffs[2],\n                     a_coeffs[1], a_coeffs[2]);\n</code></pre></p> </li> <li> <p>Process Samples:    <pre><code>for (int i = 0; i &lt; num_samples; i++) {\n    float output = tiny_iir_biquad_process_sample(&amp;biquad, input[i]);\n    // Use output...\n}\n</code></pre></p> </li> </ol>"},{"location":"DSP/FILTER/IIR/notes/#applications","title":"APPLICATIONS","text":"<p>IIR filters are widely used in:</p> <ul> <li>Audio Processing: Equalization, tone control, audio effects</li> <li>Control Systems: Signal conditioning, noise filtering, feedback control</li> <li>Biomedical: ECG/EEG signal conditioning, artifact removal</li> <li>Communications: Channel equalization, noise reduction</li> <li>Sensor Signal Processing: Noise reduction, signal conditioning</li> <li>Real-Time Systems: Where computational efficiency is critical</li> </ul>"},{"location":"DSP/FILTER/IIR/notes/#advantages-and-disadvantages","title":"ADVANTAGES AND DISADVANTAGES","text":""},{"location":"DSP/FILTER/IIR/notes/#advantages","title":"Advantages","text":"<ul> <li>Efficient: Fewer coefficients than FIR for same specifications</li> <li>Sharp Transition: Can achieve sharp frequency response with low order</li> <li>Low Latency: Minimal group delay compared to FIR</li> <li>Memory Efficient: Requires less memory than FIR</li> </ul>"},{"location":"DSP/FILTER/IIR/notes/#disadvantages","title":"Disadvantages","text":"<ul> <li>Potential Instability: Can be unstable if poles are outside unit circle</li> <li>Non-Linear Phase: Generally has non-linear phase response</li> <li>Design Complexity: More complex design than FIR window method</li> <li>Limit Cycles: Can exhibit quantization-induced limit cycles</li> </ul>"},{"location":"DSP/FILTER/IIR/notes/#stability-considerations","title":"STABILITY CONSIDERATIONS","text":"<p>For an IIR filter to be stable, all poles must lie inside the unit circle in the z-plane:</p> \\[ |p_k| &lt; 1 \\quad \\forall k \\] <p>Where \\( p_k \\) are the poles of the transfer function.</p> <p>Stability Check:</p> <p>The denominator polynomial \\( A(z) = 1 + \\sum_{k=1}^{N} a[k] \\cdot z^{-k} \\) must have all roots inside the unit circle.</p>"},{"location":"DSP/FILTER/IIR/notes/#design-considerations","title":"DESIGN CONSIDERATIONS","text":""},{"location":"DSP/FILTER/IIR/notes/#filter-order","title":"Filter Order","text":"<ul> <li>Higher Order: Sharper transition, better stopband attenuation, but more complex</li> <li>Lower Order: Simpler, faster, but wider transition band</li> <li>Butterworth: Order determines -3 dB point and stopband attenuation</li> </ul>"},{"location":"DSP/FILTER/IIR/notes/#normalized-frequency","title":"Normalized Frequency","text":"<p>Remember to normalize frequencies:</p> <ul> <li>Cutoff at 100 Hz with 1 kHz sample rate: <code>0.2</code> (100 / 500)</li> <li>Cutoff at 1 kHz with 10 kHz sample rate: <code>0.2</code> (1000 / 5000)</li> </ul>"},{"location":"DSP/FILTER/IIR/notes/#coefficient-normalization","title":"Coefficient Normalization","text":"<p>IIR filters use normalized coefficients where <code>a[0] = 1.0</code>. This is standard practice and simplifies implementation.</p>"},{"location":"DSP/FILTER/IIR/notes/#notes_1","title":"NOTES","text":"<ul> <li>IIR filters can be unstable if not designed properly</li> <li>Always check stability when designing custom filters</li> <li>For higher orders, decompose into cascaded biquads for numerical stability</li> <li>Direct Form II Transposed is used for efficient implementation</li> <li>For real-time applications, use <code>tiny_iir_init()</code> and <code>tiny_iir_process_sample()</code></li> <li>For batch processing, use <code>tiny_iir_filter_f32()</code></li> <li>Biquad filters are recommended for higher-order designs</li> </ul>"},{"location":"DSP/FILTER/IIR/test/","title":"TESTS","text":""},{"location":"DSP/FILTER/IIR/test/#tiny_iir_testh","title":"tiny_iir_test.h","text":"<pre><code>/**\n * @file tiny_iir_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_iir | test | header\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_iir.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_iir_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/FILTER/IIR/test/#tiny_iir_testc","title":"tiny_iir_test.c","text":"<pre><code>/**\n * @file tiny_iir_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_iir | test | source\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_iir_test.h\"\n#include \"tiny_view.h\" // For signal visualization\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846f\n#endif\n\n#define EPSILON 1e-4f // Tolerance for floating-point comparison\n\n/**\n * @brief Generate a test signal with multiple frequency components\n */\nstatic void generate_test_signal(float *signal, int len, float sample_rate)\n{\n    // Generate signal: DC + 10Hz + 50Hz + 100Hz\n    for (int i = 0; i &lt; len; i++)\n    {\n        float t = (float)i / sample_rate;\n        signal[i] = 1.0f +                                    // DC component\n                    sinf(2.0f * M_PI * 10.0f * t) +          // 10 Hz\n                    0.5f * sinf(2.0f * M_PI * 50.0f * t) +   // 50 Hz\n                    0.3f * sinf(2.0f * M_PI * 100.0f * t);   // 100 Hz\n    }\n}\n\n/**\n * @brief Test IIR filter design\n */\nstatic void test_iir_design(void)\n{\n    printf(\"========== IIR Filter Design Test ==========\\n\\n\");\n\n    const int order = 2;\n    const int num_coeffs = order + 1;\n    float *b_coeffs = (float *)malloc(num_coeffs * sizeof(float));\n    float *a_coeffs = (float *)malloc(num_coeffs * sizeof(float));\n\n    if (!b_coeffs || !a_coeffs)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        free(b_coeffs);\n        free(a_coeffs);\n        return;\n    }\n\n    // Test 1: Low-pass Butterworth filter design\n    printf(\"Test 1: Low-Pass Butterworth Filter Design\\n\");\n    printf(\"  Parameters: cutoff=0.1 (normalized), order=%d\\n\", order);\n    tiny_error_t err = tiny_iir_design_lowpass(0.1f, order,\n                                                TINY_IIR_DESIGN_BUTTERWORTH, 0.0f,\n                                                b_coeffs, a_coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Low-pass design failed: %d\\n\", err);\n        goto cleanup;\n    }\n    printf(\"  \u2713 Low-pass filter designed successfully\\n\");\n    printf(\"  B coefficients: \");\n    for (int i = 0; i &lt; num_coeffs; i++)\n    {\n        printf(\"%.6f \", b_coeffs[i]);\n    }\n    printf(\"\\n  A coefficients: \");\n    for (int i = 0; i &lt; num_coeffs; i++)\n    {\n        printf(\"%.6f \", a_coeffs[i]);\n    }\n    printf(\"\\n\");\n    printf(\"  Note: a[0] should be 1.0 (normalized)\\n\");\n    printf(\"\\n\");\n\n    // Test 2: High-pass Butterworth filter design\n    printf(\"Test 2: High-Pass Butterworth Filter Design\\n\");\n    printf(\"  Parameters: cutoff=0.2 (normalized), order=%d\\n\", order);\n    err = tiny_iir_design_highpass(0.2f, order,\n                                    TINY_IIR_DESIGN_BUTTERWORTH, 0.0f,\n                                    b_coeffs, a_coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 High-pass design failed: %d\\n\", err);\n        goto cleanup;\n    }\n    printf(\"  \u2713 High-pass filter designed successfully\\n\");\n    printf(\"  B coefficients: \");\n    for (int i = 0; i &lt; num_coeffs; i++)\n    {\n        printf(\"%.6f \", b_coeffs[i]);\n    }\n    printf(\"\\n  A coefficients: \");\n    for (int i = 0; i &lt; num_coeffs; i++)\n    {\n        printf(\"%.6f \", a_coeffs[i]);\n    }\n    printf(\"\\n\\n\");\n\n    // Test 3: Band-pass (should return not supported for now)\n    printf(\"Test 3: Band-Pass Filter Design\\n\");\n    printf(\"  Parameters: low=0.1, high=0.3 (normalized), order=%d\\n\", order);\n    err = tiny_iir_design_bandpass(0.1f, 0.3f, order,\n                                    TINY_IIR_DESIGN_BUTTERWORTH, 0.0f,\n                                    b_coeffs, a_coeffs);\n    if (err == TINY_ERR_NOT_SUPPORTED)\n    {\n        printf(\"  \u26a0 Band-pass design not yet implemented (expected)\\n\");\n    }\n    else if (err == TINY_OK)\n    {\n        printf(\"  \u2713 Band-pass filter designed successfully\\n\");\n    }\n    else\n    {\n        printf(\"  \u2717 Band-pass design failed: %d\\n\", err);\n    }\n    printf(\"\\n\");\n\ncleanup:\n    free(b_coeffs);\n    free(a_coeffs);\n    printf(\"========================================\\n\\n\");\n}\n\n/**\n * @brief Test IIR filter application (batch processing)\n */\nstatic void test_iir_batch_filtering(void)\n{\n    printf(\"========== IIR Batch Filtering Test ==========\\n\\n\");\n\n    const int signal_len = 256;\n    const float sample_rate = 1000.0f; // 1 kHz\n    const int order = 2;\n    const int num_coeffs = order + 1;\n    const float cutoff_freq = 0.1f; // Normalized (100 Hz at 1 kHz sample rate)\n\n    // Allocate memory\n    float *input = (float *)malloc(signal_len * sizeof(float));\n    float *output = (float *)malloc(signal_len * sizeof(float));\n    float *b_coeffs = (float *)malloc(num_coeffs * sizeof(float));\n    float *a_coeffs = (float *)malloc(num_coeffs * sizeof(float));\n\n    if (!input || !output || !b_coeffs || !a_coeffs)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        free(input);\n        free(output);\n        free(b_coeffs);\n        free(a_coeffs);\n        return;\n    }\n\n    // Generate test signal\n    generate_test_signal(input, signal_len, sample_rate);\n\n    // Design low-pass filter\n    printf(\"Test: Low-Pass IIR Filtering (Butterworth)\\n\");\n    printf(\"  Input signal: DC + 10Hz + 50Hz + 100Hz components\\n\");\n    printf(\"  Filter: Low-pass Butterworth, cutoff=%.1f Hz (normalized=%.3f)\\n\",\n           cutoff_freq * sample_rate, cutoff_freq);\n    printf(\"  Order: %d\\n\\n\", order);\n\n    tiny_error_t err = tiny_iir_design_lowpass(cutoff_freq, order,\n                                                TINY_IIR_DESIGN_BUTTERWORTH, 0.0f,\n                                                b_coeffs, a_coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter design failed: %d\\n\", err);\n        goto cleanup;\n    }\n\n    // Apply filter\n    err = tiny_iir_filter_f32(input, signal_len, b_coeffs, num_coeffs,\n                              a_coeffs, num_coeffs, output, NULL);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filtering failed: %d\\n\", err);\n        goto cleanup;\n    }\n\n    printf(\"  \u2713 Filtering completed successfully\\n\\n\");\n\n    // Visualize signals\n    printf(\"Signal Visualization:\\n\");\n    tiny_view_signal_f32(input, signal_len, 64, 12, 0, 0, \"Original Signal\");\n    tiny_view_signal_f32(output, signal_len, 64, 12, 0, 0, \"Filtered Signal (Low-Pass IIR)\");\n\n    // Calculate statistics\n    float input_mean = 0.0f, output_mean = 0.0f;\n    float input_power = 0.0f, output_power = 0.0f;\n    for (int i = 0; i &lt; signal_len; i++)\n    {\n        input_mean += input[i];\n        output_mean += output[i];\n        input_power += input[i] * input[i];\n        output_power += output[i] * output[i];\n    }\n    input_mean /= signal_len;\n    output_mean /= signal_len;\n    input_power /= signal_len;\n    output_power /= signal_len;\n\n    printf(\"\\nStatistics:\\n\");\n    printf(\"  Input:  mean=%.4f, power=%.4f\\n\", input_mean, input_power);\n    printf(\"  Output: mean=%.4f, power=%.4f\\n\", output_mean, output_power);\n    printf(\"  Power reduction: %.2f%%\\n\", (1.0f - output_power / input_power) * 100.0f);\n\ncleanup:\n    free(input);\n    free(output);\n    free(b_coeffs);\n    free(a_coeffs);\n    printf(\"\\n========================================\\n\\n\");\n}\n\n/**\n * @brief Test IIR real-time filtering\n */\nstatic void test_iir_realtime_filtering(void)\n{\n    printf(\"========== IIR Real-Time Filtering Test ==========\\n\\n\");\n\n    const int order = 2;\n    const int num_coeffs = order + 1;\n    const float cutoff_freq = 0.1f;\n\n    // Design filter\n    float *b_coeffs = (float *)malloc(num_coeffs * sizeof(float));\n    float *a_coeffs = (float *)malloc(num_coeffs * sizeof(float));\n\n    if (!b_coeffs || !a_coeffs)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        return;\n    }\n\n    tiny_error_t err = tiny_iir_design_lowpass(cutoff_freq, order,\n                                                TINY_IIR_DESIGN_BUTTERWORTH, 0.0f,\n                                                b_coeffs, a_coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter design failed: %d\\n\", err);\n        free(b_coeffs);\n        free(a_coeffs);\n        return;\n    }\n\n    // Initialize filter\n    tiny_iir_filter_t filter;\n    err = tiny_iir_init(&amp;filter, b_coeffs, num_coeffs, a_coeffs, num_coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter initialization failed: %d\\n\", err);\n        free(b_coeffs);\n        free(a_coeffs);\n        return;\n    }\n\n    printf(\"Test: Real-Time IIR Filtering\\n\");\n    printf(\"  Filter: Low-pass Butterworth, order=%d\\n\", order);\n    printf(\"  Processing samples one by one...\\n\\n\");\n\n    // Process test samples\n    const int num_samples = 20;\n    float test_input[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f,\n                          0.0f, 1.0f, 2.0f, 3.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f, 0.0f};\n    float *output = (float *)malloc(num_samples * sizeof(float));\n\n    if (!output)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        tiny_iir_deinit(&amp;filter);\n        free(b_coeffs);\n        free(a_coeffs);\n        return;\n    }\n\n    printf(\"  Input samples: \");\n    for (int i = 0; i &lt; num_samples; i++)\n    {\n        printf(\"%.1f \", test_input[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"  Output samples: \");\n    for (int i = 0; i &lt; num_samples; i++)\n    {\n        output[i] = tiny_iir_process_sample(&amp;filter, test_input[i]);\n        printf(\"%.3f \", output[i]);\n    }\n    printf(\"\\n\\n\");\n\n    // Test reset\n    printf(\"  Testing filter reset...\\n\");\n    err = tiny_iir_reset(&amp;filter);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter reset failed: %d\\n\", err);\n    }\n    else\n    {\n        printf(\"  \u2713 Filter reset successful\\n\");\n    }\n\n    // Cleanup\n    tiny_iir_deinit(&amp;filter);\n    free(b_coeffs);\n    free(a_coeffs);\n    free(output);\n\n    printf(\"\\n========================================\\n\\n\");\n}\n\n/**\n * @brief Test IIR biquad filter\n */\nstatic void test_iir_biquad(void)\n{\n    printf(\"========== IIR Biquad Filter Test ==========\\n\\n\");\n\n    // Design a simple low-pass biquad (second-order Butterworth)\n    const float cutoff_freq = 0.1f;\n    float b_coeffs[3], a_coeffs[3];\n\n    tiny_error_t err = tiny_iir_design_lowpass(cutoff_freq, 2,\n                                                TINY_IIR_DESIGN_BUTTERWORTH, 0.0f,\n                                                b_coeffs, a_coeffs);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Filter design failed: %d\\n\", err);\n        return;\n    }\n\n    // Initialize biquad\n    tiny_iir_biquad_t biquad;\n    err = tiny_iir_biquad_init(&amp;biquad, b_coeffs[0], b_coeffs[1], b_coeffs[2],\n                                a_coeffs[1], a_coeffs[2]);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Biquad initialization failed: %d\\n\", err);\n        return;\n    }\n\n    printf(\"Test: Biquad (Second-Order) IIR Filter\\n\");\n    printf(\"  Coefficients: b0=%.6f, b1=%.6f, b2=%.6f, a1=%.6f, a2=%.6f\\n\",\n           biquad.b0, biquad.b1, biquad.b2, biquad.a1, biquad.a2);\n    printf(\"\\n\");\n\n    // Process test samples\n    const int num_samples = 10;\n    float test_input[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f};\n\n    printf(\"  Input samples: \");\n    for (int i = 0; i &lt; num_samples; i++)\n    {\n        printf(\"%.1f \", test_input[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"  Output samples: \");\n    for (int i = 0; i &lt; num_samples; i++)\n    {\n        float output = tiny_iir_biquad_process_sample(&amp;biquad, test_input[i]);\n        printf(\"%.3f \", output);\n    }\n    printf(\"\\n\\n\");\n\n    // Test reset\n    err = tiny_iir_biquad_reset(&amp;biquad);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Biquad reset failed: %d\\n\", err);\n    }\n    else\n    {\n        printf(\"  \u2713 Biquad reset successful\\n\");\n    }\n\n    printf(\"\\n========================================\\n\\n\");\n}\n\n/**\n * @brief Main IIR test function\n */\nvoid tiny_iir_test(void)\n{\n    printf(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\\n\");\n    printf(\"\u2551          TinyIIR Filter Test Suite                       \u2551\\n\");\n    printf(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\n\\n\");\n\n    // Run all tests\n    test_iir_design();\n    test_iir_batch_filtering();\n    test_iir_realtime_filtering();\n    test_iir_biquad();\n\n    printf(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\\n\");\n    printf(\"\u2551          All IIR Tests Completed                          \u2551\\n\");\n    printf(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\n\");\n}\n</code></pre>"},{"location":"DSP/FILTER/IIR/test/#outputs","title":"OUTPUTS","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551          TinyIIR Filter Test Suite                       \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\n========== IIR Filter Design Test ==========\n\nTest 1: Low-Pass Butterworth Filter Design\n  Parameters: cutoff=0.1 (normalized), order=2\n  \u2713 Low-pass filter designed successfully\n  B coefficients: 0.067455 0.134911 0.067455 \n  A coefficients: 1.000000 -1.142980 0.412802 \n  Note: a[0] should be 1.0 (normalized)\n\nTest 2: High-Pass Butterworth Filter Design\n  Parameters: cutoff=0.2 (normalized), order=2\n  \u2713 High-pass filter designed successfully\n  B coefficients: 0.391336 -0.782672 0.391336 \n  A coefficients: 1.000000 -0.369527 0.195816 \n\nTest 3: Band-Pass Filter Design\n  Parameters: low=0.1, high=0.3 (normalized), order=2\n  \u26a0 Band-pass design not yet implemented (expected)\n\n========================================\n\n========== IIR Batch Filtering Test ==========\n\nTest: Low-Pass IIR Filtering (Butterworth)\n  Input signal: DC + 10Hz + 50Hz + 100Hz components\n  Filter: Low-pass Butterworth, cutoff=100.0 Hz (normalized=0.100)\n  Order: 2\n\n  \u2713 Filtering completed successfully\n\nSignal Visualization:\n\nOriginal Signal\nValue\n  3.02 |                                                                \n  2.65 |      *                                                *        \n  2.28 |     **                       **                      * *   *   \n  1.92 | *   * **  *              *  *  *  *              *   *  * **   \n  1.55 |* ***   * **             * ***   ** *            * ****  * **   \n  1.18 |*   *    *  *           *    *    *  *           *        ** *  \n  0.82 |*            *  *    *  *            *  *    *   *            * \n  0.45 |             * **   * ***             ** *  * ****            * \n  0.08 |              *  ***    *              *  * *                  *\n -0.28 |                  **                       **                   \n -0.65 |                   *                        *                   \n -1.02 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.018, 3.018], Length: 256\n\n\nFiltered Signal (Low-Pass IIR)\nValue\n  3.06 |                                                                \n  2.69 |      *                        *                       *        \n  2.32 |     **                       **                      * *       \n  1.94 | *   * **  *              *  *  ** **                 *  *  *   \n  1.57 |* ***   * **             * ***   ** *             *****   ** *  \n  1.20 |*   *    *  *            *   *    *  *           *    *    * *  \n  0.82 |*            *  *    *  *             * *        *            * \n  0.45 |*            * **   * ***             ** *   *****             *\n  0.07 |*             *  ** *   *             **  * *    *              \n -0.30 |                  **                   *   **                   \n -0.67 |                   *                        *                   \n -1.05 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.046, 3.064], Length: 256\n\n\nStatistics:\n  Input:  mean=1.1294, power=1.9174\n  Output: mean=1.1294, power=1.9329\n  Power reduction: -0.81%\n\n========================================\n\n========== IIR Real-Time Filtering Test ==========\n\nTest: Real-Time IIR Filtering\n  Filter: Low-pass Butterworth, order=2\n  Processing samples one by one...\n\n  Input samples: 1.0 2.0 3.0 4.0 5.0 4.0 3.0 2.0 1.0 0.0 0.0 1.0 2.0 3.0 4.0 3.0 2.0 1.0 0.0 0.0 \n  Output samples: 0.067 1.413 2.413 3.413 4.413 5.278 3.587 2.587 1.587 0.587 -0.345 0.067 1.413 2.413 3.413 4.278 2.587 1.587 0.587 -0.345 \n\n  Testing filter reset...\n  \u2713 Filter reset successful\n\n========================================\n\n========== IIR Biquad Filter Test ==========\n\nTest: Biquad (Second-Order) IIR Filter\n  Coefficients: b0=0.067455, b1=0.134911, b2=0.067455, a1=-1.142980, a2=0.412802\n\n  Input samples: 1.0 2.0 3.0 4.0 5.0 4.0 3.0 2.0 1.0 0.0 \n  Output samples: 0.067 0.347 0.908 1.704 2.652 3.542 4.033 3.957 3.398 2.520 \n\n  \u2713 Biquad reset successful\n\n========================================\n\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551          All IIR Tests Completed                          \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"DSP/HEADER-FILE/tiny_dsp/","title":"TinyDSP HEADER FILE","text":"<p>Info</p> <p>This is the main header file of the TinyDSP library. It includes all necessary header files and provides a unified interface to use the functions of the library. After completing the porting of this library in the project, you can insert this header file where you want to use the relevant functions to use all functions in the library. The documentation update speed is slow and may not be consistent with the actual code, please refer to the actual code.</p> <pre><code>/**\n * @file tiny_dsp.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_dsp | Main header file - Unified entry point for all DSP functionality\n * @version 1.0\n * @date 2025-04-28\n * @copyright Copyright (c) 2025\n *\n * @details\n * This header file provides a unified interface to all DSP (Digital Signal Processing)\n * functionality in the tiny_dsp middleware. It includes:\n *\n * - Signal Processing: Convolution, Correlation, Resampling\n * - Filters: FIR (Finite Impulse Response), IIR (Infinite Impulse Response)\n * - Transforms: FFT (Fast Fourier Transform), DWT (Discrete Wavelet Transform), ICA (Independent Component Analysis)\n * - Support: Signal visualization and analysis tools\n *\n * Usage:\n *   Simply include this header to access all DSP functions:\n *   @code\n *   #include \"tiny_dsp.h\"\n *   @endcode\n */\n\n#pragma once\n\n/* ============================================================================\n * DEPENDENCIES\n * ============================================================================ */\n\n// Core configuration\n#include \"tiny_dsp_config.h\"\n\n/* ============================================================================\n * SIGNAL PROCESSING MODULES\n * ============================================================================ */\n\n/**\n * @name Signal Processing - Convolution\n * @brief Convolution operations with various padding and output modes\n * @details\n * - Full, center, head, and tail convolution modes\n * - Zero, symmetric, and periodic padding options\n * - Platform-optimized for ESP32\n */\n#include \"tiny_conv.h\"\n#include \"tiny_conv_test.h\"\n\n/**\n * @name Signal Processing - Correlation\n * @brief Correlation and cross-correlation functions\n * @details\n * - Auto-correlation: Pattern matching, template matching\n * - Cross-correlation: Signal alignment, delay estimation\n * - Platform-optimized for ESP32\n */\n#include \"tiny_corr.h\"\n#include \"tiny_corr_test.h\"\n\n/**\n * @name Signal Processing - Resampling\n * @brief Signal resampling, upsampling, and downsampling\n * @details\n * - Linear interpolation resampling\n * - Zero-insertion upsampling\n * - Skip-based downsampling\n */\n#include \"tiny_resample.h\"\n#include \"tiny_resample_test.h\"\n\n/* ============================================================================\n * FILTER MODULES\n * ============================================================================ */\n\n/**\n * @name Filter - FIR (Finite Impulse Response)\n * @brief FIR filter design and application\n * @details\n * - Always stable (no poles, only zeros)\n * - Linear phase response possible\n * - Window-based design methods (Hamming, Hanning, Blackman)\n * - Support for low-pass, high-pass, band-pass, band-stop\n * - Real-time and batch processing modes\n * - Platform-optimized for ESP32\n */\n#include \"tiny_fir.h\"\n#include \"tiny_fir_test.h\"\n\n/**\n * @name Filter - IIR (Infinite Impulse Response)\n * @brief IIR filter design and application\n * @details\n * - Recursive filter with feedback\n * - More efficient than FIR for same specifications\n * - Butterworth, Chebyshev design methods\n * - Support for low-pass, high-pass, band-pass, band-stop\n * - Direct Form II transposed structure\n * - Biquad (second-order) cascade support\n * - Real-time and batch processing modes\n * - Platform-optimized for ESP32\n */\n#include \"tiny_iir.h\"\n#include \"tiny_iir_test.h\"\n\n/* ============================================================================\n * TRANSFORM MODULES\n * ============================================================================ */\n\n/**\n * @name Transform - Discrete Wavelet Transform (DWT)\n * @brief Multi-level wavelet decomposition and reconstruction\n * @details\n * - Support for Daubechies wavelets (DB1-DB10)\n * - Single-level and multi-level decomposition\n * - Perfect reconstruction capability\n * - Energy preservation analysis\n */\n#include \"tiny_dwt.h\"\n#include \"tiny_dwt_test.h\"\n\n/**\n * @name Transform - Fast Fourier Transform (FFT)\n * @brief FFT/IFFT and frequency domain analysis\n * @details\n * - Forward and inverse FFT\n * - Power spectrum density calculation\n * - Peak frequency detection with parabolic interpolation\n * - Top N frequencies detection with peak merging\n * - Window functions: Hanning, Hamming, Blackman\n * - Platform-optimized for ESP32\n */\n#include \"tiny_fft.h\"\n#include \"tiny_fft_test.h\"\n\n/**\n * @name Transform - Independent Component Analysis (ICA)\n * @brief Blind source separation using ICA\n * @details\n * Independent Component Analysis for blind source separation from mixed observations.\n * \n * Algorithm:\n * - FastICA algorithm implementation (default)\n * - Blind source separation model: X = A * S\n *   where X is mixed signals, A is mixing matrix, S is independent sources\n * \n * Preprocessing:\n * - Centering: Subtract mean from each observation\n * - Whitening: Decorrelate and normalize variance using eigenvalue decomposition\n * \n * Features:\n * - Multiple nonlinearity functions:\n *   - tanh: Good for super-Gaussian sources (default)\n *   - exp(-u\u00b2/2): Good for sub-Gaussian sources\n *   - u\u00b3: Alternative for super-Gaussian sources\n * - Orthogonalization: Ensures extracted components are independent\n * - Iterative convergence with configurable tolerance\n * \n * API Modes:\n * - Batch processing: Direct separation via tiny_ica_separate_f32()\n * - Structure-based: Initialize once, fit model, transform multiple times\n *   (efficient for repeated separations with same mixing model)\n * \n * Requirements:\n * - num_sources &lt;= num_obs (cannot extract more sources than observations)\n * - Sufficient samples for stable statistics (recommended: &gt; 100 samples)\n * - Sources must be statistically independent and non-Gaussian\n * \n * Dependencies:\n * - Reuses tiny_math matrix operations (tiny_mat_mult_f32)\n * - Implements eigenvalue decomposition for whitening (Jacobi method)\n * \n * Applications:\n * - Audio source separation (cocktail party problem)\n * - Signal denoising and artifact removal\n * - Feature extraction from sensor arrays\n * - Biomedical signal processing (EEG, ECG artifact removal)\n */\n#include \"tiny_ica.h\"\n#include \"tiny_ica_test.h\"\n\n/* ============================================================================\n * SUPPORT MODULES\n * ============================================================================ */\n\n/**\n * @name Support - Signal Visualization\n * @brief ASCII-based signal and spectrum visualization tools\n * @details\n * - Signal plotting with configurable resolution\n * - Spectrum visualization\n * - Array formatting and statistics\n * - Console-based output (similar to ESP-DSP built-in features)\n */\n#include \"tiny_view.h\"\n#include \"tiny_view_test.h\"\n\n/* ============================================================================\n * C++ COMPATIBILITY\n * ============================================================================ */\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    // All DSP functions are C-compatible and can be called from C++\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/HEADER-FILE/tiny_dsp_config/","title":"TinyDSP CONFIGURATION","text":"<p>Info</p> <p>This header file configures the entire TinyDSP module, and each submodule includes this header file. It defines the configuration options and macros for TinyDSP, allowing users to customize settings as needed. By modifying the configuration options in this header file, users can easily adjust the behavior and functionality of TinyDSP to meet specific requirements. The documentation update speed is slow and may not be consistent with the actual code, please refer to the actual code.</p> <p>Tip</p> <p>For platform acceleration options, please set them in the TinyMath configuration file.</p> <pre><code>/**\n * @file tiny_dsp_config.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_dsp middleware.\n * @version 1.0\n * @date 2025-04-27\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_math.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SIGNAL/CONVOLUTION/code/","title":"CODE","text":""},{"location":"DSP/SIGNAL/CONVOLUTION/code/#tiny_convh","title":"tiny_conv.h","text":"<pre><code>/**\n * @file tiny_conv.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_conv | code | header \n * @version 1.0\n * @date 2025-04-27\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n\n// ESP32 DSP Library for Acceleration\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n\n#include \"dsps_conv.h\"\n#include \"dspi_conv.h\"\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/**\n * @name: tiny_conv_f32\n * @brief Convolution function\n * \n * @param Signal The input signal array\n * @param siglen The length of the input signal array\n * @param Kernel The input kernel array\n * @param kernlen The length of the input kernel array\n * @param convout The output array for the convolution result\n * \n * @return tiny_error_t \n */\ntiny_error_t tiny_conv_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *convout);\n\ntypedef enum\n{\n    TINY_PADDING_ZERO = 0,      // Zero padding\n    TINY_PADDING_SYMMETRIC = 1, // Symmetric reflection\n    TINY_PADDING_PERIODIC = 2   // Periodic extension\n} tiny_padding_mode_t;\n\ntypedef enum\n{\n    TINY_CONV_FULL = 0,   // Full convolution (len = siglen + kernlen - 1)\n    TINY_CONV_HEAD = 1,   // Head mode (first lkern points)\n    TINY_CONV_CENTER = 2, // Centered mode (output siglen points)\n    TINY_CONV_TAIL = 3    // Tail mode (last lkern points)\n} tiny_conv_mode_t;\n\n/**\n * @name: tiny_conv_ex_f32\n * @brief Extended convolution function with padding and mode options\n *\n * @param Signal The input signal array\n * @param siglen The length of the input signal array\n * @param Kernel The input kernel array\n * @param kernlen The length of the input kernel array\n * @param convout The output array for the convolution result\n * @param padding_mode Padding mode (zero, symmetric, periodic)\n * @param conv_mode Convolution mode (full, head, center, tail)\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_conv_ex_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *convout, tiny_padding_mode_t padding_mode, tiny_conv_mode_t conv_mode);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SIGNAL/CONVOLUTION/code/#tiny_convc","title":"tiny_conv.c","text":"<pre><code>/**\n * @file tiny_conv.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_conv | code | source\n * @version 1.0\n * @date 2025-04-27\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_conv.h\"\n\n/**\n * @name: tiny_conv_f32\n * @brief Convolution function\n *\n * @param Signal The input signal array\n * @param siglen The length of the input signal array\n * @param Kernel The input kernel array\n * @param kernlen The length of the input kernel array\n * @param convout The output array for the convolution result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_conv_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *convout)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == convout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n    if (siglen &lt;= 0 || kernlen &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n    if (siglen &lt; kernlen)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // ESP32 DSP library\n    dsps_conv_f32(Signal, siglen, Kernel, kernlen, convout);\n#else\n    float *sig = (float *)Signal;\n    float *kern = (float *)Kernel;\n    int lsig = siglen;\n    int lkern = kernlen;\n\n    // stage I\n    for (int n = 0; n &lt; lkern; n++)\n    {\n        size_t k;\n\n        convout[n] = 0;\n\n        for (k = 0; k &lt;= n; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n\n    // stage II\n    for (int n = lkern; n &lt; lsig; n++)\n    {\n        size_t kmin, kmax, k;\n\n        convout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = n;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n\n    // stage III\n    for (int n = lsig; n &lt; lsig + lkern - 1; n++)\n    {\n        size_t kmin, kmax, k;\n\n        convout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = lsig - 1;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n#endif\n\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_conv_ex_f32\n * @brief Extended convolution function with padding and mode options\n *\n * @param Signal The input signal array\n * @param siglen The length of the input signal array\n * @param Kernel The input kernel array\n * @param kernlen The length of the input kernel array\n * @param convout The output array for the convolution result\n * @param padding_mode Padding mode (zero, symmetric, periodic)\n * @param conv_mode Convolution mode (full, head, center, tail)\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_conv_ex_f32(const float *Signal, const int siglen,\n                              const float *Kernel, const int kernlen,\n                              float *convout,\n                              tiny_padding_mode_t padding_mode,\n                              tiny_conv_mode_t conv_mode)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == convout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n    if (siglen &lt;= 0 || kernlen &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n    if (siglen &lt; kernlen)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padding_mode == TINY_PADDING_ZERO &amp;&amp; conv_mode == TINY_CONV_FULL)\n    {\n        dsps_conv_f32(Signal, siglen, Kernel, kernlen, convout);\n        return TINY_OK;\n    }\n#endif\n\n    int pad_len = kernlen - 1;\n    int padded_len = siglen + 2 * pad_len;\n    float *padded_signal = (float *)calloc(padded_len, sizeof(float));\n    if (padded_signal == NULL)\n    {\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Fill padded signal\n    switch (padding_mode)\n    {\n    case TINY_PADDING_ZERO:\n        // Middle copy only, left and right are zeros (calloc already zeroed)\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen);\n        break;\n\n    case TINY_PADDING_SYMMETRIC:\n        for (int i = 0; i &lt; pad_len; i++)\n        {\n            padded_signal[pad_len - 1 - i] = Signal[i];                   // Mirror left\n            padded_signal[pad_len + siglen + i] = Signal[siglen - 1 - i]; // Mirror right\n        }\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen); // Copy center\n        break;\n\n    case TINY_PADDING_PERIODIC:\n        for (int i = 0; i &lt; pad_len; i++)\n        {\n            padded_signal[pad_len - 1 - i] = Signal[(siglen - pad_len + i) % siglen]; // Wrap left\n            padded_signal[pad_len + siglen + i] = Signal[i % siglen];                 // Wrap right\n        }\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen); // Copy center\n        break;\n\n    default:\n        free(padded_signal);\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Full convolution\n    int convlen_full = siglen + kernlen - 1;\n    for (int n = 0; n &lt; convlen_full; n++)\n    {\n        float sum = 0.0f;\n        for (int k = 0; k &lt; kernlen; k++)\n        {\n            sum += padded_signal[n + k] * Kernel[kernlen - 1 - k]; // Convolution is flip+slide\n        }\n        convout[n] = sum;\n    }\n\n    free(padded_signal);\n\n    // Handle output mode\n    if (conv_mode == TINY_CONV_FULL)\n    {\n        return TINY_OK;\n    }\n    else\n    {\n        int start_idx = 0;\n        int out_len = 0;\n\n        switch (conv_mode)\n        {\n        case TINY_CONV_HEAD:\n            start_idx = 0;\n            out_len = kernlen;\n            break;\n        case TINY_CONV_CENTER:\n            start_idx = (kernlen - 1) / 2;\n            out_len = siglen;\n            break;\n        case TINY_CONV_TAIL:\n            start_idx = siglen - 1;\n            out_len = kernlen;\n            break;\n        default:\n            return TINY_ERR_DSP_INVALID_MODE;\n        }\n\n        // Copy the selected part to the beginning\n        for (int i = 0; i &lt; out_len; i++)\n        {\n            convout[i] = convout[start_idx + i];\n        }\n    }\n\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/SIGNAL/CONVOLUTION/notes/","title":"NOTES","text":""},{"location":"DSP/SIGNAL/CONVOLUTION/notes/#mathematical-principle-of-convolution","title":"Mathematical Principle of Convolution","text":"<p>Convolution is an important operation in signal processing, which is used to describe the relationship between two signals. It can be regarded as the weighted average of one signal and another signal. The mathematical definition of convolution is as follows:</p> \\[y(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) d\\tau\\] <p>Where \\(x(t)\\) is the input signal, \\(h(t)\\) is the impulse response of the system, and \\(y(t)\\) is the output signal. The result of convolution is a new signal that contains all the information between the input signal and the impulse response of the system.</p> <p></p> <ul> <li> <p> Physical Meaning of Convolution \uff08Chinese\uff09</p> <p>  Portal </p> </li> </ul>"},{"location":"DSP/SIGNAL/CONVOLUTION/notes/#programming-philosophy","title":"Programming Philosophy","text":"<p>The convolution operation in this library actually reverses the direction of the convolution kernel and then multiplies it point by point with the input signal and sums it.</p>"},{"location":"DSP/SIGNAL/CONVOLUTION/notes/#tiny_conv_f32","title":"tiny_conv_f32","text":"<pre><code>/**\n * @name: tiny_conv_f32\n * @brief Convolution function\n *\n * @param Signal The input signal array\n * @param siglen The length of the input signal array\n * @param Kernel The input kernel array\n * @param kernlen The length of the input kernel array\n * @param convout The output array for the convolution result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_conv_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *convout)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == convout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n    if (siglen &lt;= 0 || kernlen &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n    if (siglen &lt; kernlen)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // ESP32 DSP library\n    dsps_conv_f32(Signal, siglen, Kernel, kernlen, convout);\n#else\n    float *sig = (float *)Signal;\n    float *kern = (float *)Kernel;\n    int lsig = siglen;\n    int lkern = kernlen;\n\n    // stage I\n    for (int n = 0; n &lt; lkern; n++)\n    {\n        size_t k;\n\n        convout[n] = 0;\n\n        for (k = 0; k &lt;= n; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n\n    // stage II\n    for (int n = lkern; n &lt; lsig; n++)\n    {\n        size_t kmin, kmax, k;\n\n        convout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = n;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n\n    // stage III\n    for (int n = lsig; n &lt; lsig + lkern - 1; n++)\n    {\n        size_t kmin, kmax, k;\n\n        convout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = lsig - 1;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n#endif\n\n    return TINY_OK;\n}\n</code></pre> <p>Description:  </p> <p>This function performs the convolution operation between the input signal and the kernel. It first checks whether the input parameters are <code>NULL</code>, and then selects either the ESP32 DSP library or a standard C implementation for the convolution calculation based on the platform. The function returns the convolution result.</p> <p>Features:</p> <ul> <li>Supports acceleration with the ESP32 DSP library.</li> <li>Supports swapping the signal and kernel to ensure the signal length is greater than the kernel length.</li> </ul> <p>Parameters:</p> <ul> <li><code>Signal</code>: Input signal array.</li> <li><code>siglen</code>: Length of the input signal array.</li> <li><code>Kernel</code>: Input kernel array.</li> <li><code>kernlen</code>: Length of the input kernel array.</li> <li><code>convout</code>: Output array to store the convolution result.</li> </ul> <p>Return Value:</p> <ul> <li><code>TINY_OK</code>: Convolution completed successfully.</li> <li><code>TINY_ERR_DSP_NULL_POINTER</code>: One or more input parameters are <code>NULL</code>.</li> </ul>"},{"location":"DSP/SIGNAL/CONVOLUTION/notes/#tiny_conv_ex_f32","title":"tiny_conv_ex_f32","text":"<pre><code>/**\n * @name: tiny_conv_ex_f32\n * @brief Extended convolution function with padding and mode options\n *\n * @param Signal The input signal array\n * @param siglen The length of the input signal array\n * @param Kernel The input kernel array\n * @param kernlen The length of the input kernel array\n * @param convout The output array for the convolution result\n * @param padding_mode Padding mode (zero, symmetric, periodic)\n * @param conv_mode Convolution mode (full, head, center, tail)\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_conv_ex_f32(const float *Signal, const int siglen,\n                              const float *Kernel, const int kernlen,\n                              float *convout,\n                              tiny_padding_mode_t padding_mode,\n                              tiny_conv_mode_t conv_mode)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == convout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n    if (siglen &lt;= 0 || kernlen &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n    if (siglen &lt; kernlen)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padding_mode == TINY_PADDING_ZERO &amp;&amp; conv_mode == TINY_CONV_FULL)\n    {\n        dsps_conv_f32(Signal, siglen, Kernel, kernlen, convout);\n        return TINY_OK;\n    }\n#endif\n\n    int pad_len = kernlen - 1;\n    int padded_len = siglen + 2 * pad_len;\n    float *padded_signal = (float *)calloc(padded_len, sizeof(float));\n    if (padded_signal == NULL)\n    {\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Fill padded signal\n    switch (padding_mode)\n    {\n    case TINY_PADDING_ZERO:\n        // Middle copy only, left and right are zeros (calloc already zeroed)\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen);\n        break;\n\n    case TINY_PADDING_SYMMETRIC:\n        for (int i = 0; i &lt; pad_len; i++)\n        {\n            padded_signal[pad_len - 1 - i] = Signal[i];                   // Mirror left\n            padded_signal[pad_len + siglen + i] = Signal[siglen - 1 - i]; // Mirror right\n        }\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen); // Copy center\n        break;\n\n    case TINY_PADDING_PERIODIC:\n        for (int i = 0; i &lt; pad_len; i++)\n        {\n            padded_signal[pad_len - 1 - i] = Signal[(siglen - pad_len + i) % siglen]; // Wrap left\n            padded_signal[pad_len + siglen + i] = Signal[i % siglen];                 // Wrap right\n        }\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen); // Copy center\n        break;\n\n    default:\n        free(padded_signal);\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Full convolution\n    int convlen_full = siglen + kernlen - 1;\n    for (int n = 0; n &lt; convlen_full; n++)\n    {\n        float sum = 0.0f;\n        for (int k = 0; k &lt; kernlen; k++)\n        {\n            sum += padded_signal[n + k] * Kernel[kernlen - 1 - k]; // Convolution is flip+slide\n        }\n        convout[n] = sum;\n    }\n\n    free(padded_signal);\n\n    // Handle output mode\n    if (conv_mode == TINY_CONV_FULL)\n    {\n        return TINY_OK;\n    }\n    else\n    {\n        int start_idx = 0;\n        int out_len = 0;\n\n        switch (conv_mode)\n        {\n        case TINY_CONV_HEAD:\n            start_idx = 0;\n            out_len = kernlen;\n            break;\n        case TINY_CONV_CENTER:\n            start_idx = (kernlen - 1) / 2;\n            out_len = siglen;\n            break;\n        case TINY_CONV_TAIL:\n            start_idx = siglen - 1;\n            out_len = kernlen;\n            break;\n        default:\n            return TINY_ERR_DSP_INVALID_MODE;\n        }\n\n        // Copy the selected part to the beginning\n        for (int i = 0; i &lt; out_len; i++)\n        {\n            convout[i] = convout[start_idx + i];\n        }\n    }\n\n    return TINY_OK;\n}\n</code></pre> <p>Description:</p> <p>This function performs an extended convolution operation with options for padding and output mode. It first checks the input parameters and allocates memory for the padded signal. Depending on the selected padding mode, it fills the padded signal accordingly. The convolution is then performed, and the result is returned based on the specified output mode.</p> <p>Features:</p> <ul> <li> <p>Supports different padding modes: zero, symmetric, periodic.</p> </li> <li> <p>Supports different convolution modes: full, head, center, tail.</p> </li> <li> <p>Handles memory allocation and deallocation for the padded signal.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>Signal</code>: Input signal array.</p> </li> <li> <p><code>siglen</code>: Length of the input signal array.</p> </li> <li> <p><code>Kernel</code>: Input kernel array.</p> </li> <li> <p><code>kernlen</code>: Length of the input kernel array.</p> </li> <li> <p><code>convout</code>: Output array for the convolution result.</p> </li> <li> <p><code>padding_mode</code>: Padding mode (zero, symmetric, periodic).</p> </li> <li> <p><code>conv_mode</code>: Convolution mode (full, head, center, tail).</p> </li> </ul> <p>Return Value:</p> <ul> <li> <p><code>TINY_OK</code>: Convolution completed successfully.</p> </li> <li> <p><code>TINY_ERR_DSP_NULL_POINTER</code>: One or more input parameters are <code>NULL</code>.</p> </li> <li> <p><code>TINY_ERR_DSP_INVALID_PARAM</code>: Invalid parameters provided.</p> </li> <li> <p><code>TINY_ERR_DSP_MEMORY_ALLOC</code>: Memory allocation failed.</p> </li> </ul>"},{"location":"DSP/SIGNAL/CONVOLUTION/notes/#function-comparison","title":"Function Comparison","text":"<p>To help readers choose the appropriate function for their needs, here is a comparison between <code>tiny_conv_f32</code> and <code>tiny_conv_ex_f32</code>:</p> Feature <code>tiny_conv_f32</code> <code>tiny_conv_ex_f32</code> Padding Mode Zero padding only (implicit) Zero, symmetric, or periodic padding (explicit) Output Mode Full convolution only Full, head, center, or tail modes Output Length <code>siglen + kernlen - 1</code> Configurable based on <code>conv_mode</code> Memory Usage No dynamic allocation Requires dynamic memory allocation for padded signal Performance Optimized (ESP32 hardware acceleration available) Optimized only when using zero padding + full mode on ESP32 Use Cases Simple full convolution with zero padding Advanced convolution with custom padding and output modes"},{"location":"DSP/SIGNAL/CONVOLUTION/notes/#when-to-use-tiny_conv_f32","title":"When to Use <code>tiny_conv_f32</code>","text":"<p>Use <code>tiny_conv_f32</code> when:</p> <ul> <li> <p>You need a simple full convolution result</p> </li> <li> <p>Zero padding is acceptable for boundary handling</p> </li> <li> <p>You want maximum performance (especially on ESP32 with hardware acceleration)</p> </li> <li> <p>You want to avoid dynamic memory allocation</p> </li> <li> <p>The output length <code>siglen + kernlen - 1</code> is acceptable</p> </li> </ul> <p>Example scenarios:</p> <ul> <li> <p>Basic signal filtering</p> </li> <li> <p>Simple correlation operations</p> </li> <li> <p>Real-time processing where memory allocation should be avoided</p> </li> </ul>"},{"location":"DSP/SIGNAL/CONVOLUTION/notes/#when-to-use-tiny_conv_ex_f32","title":"When to Use <code>tiny_conv_ex_f32</code>","text":"<p>Use <code>tiny_conv_ex_f32</code> when: - You need different padding strategies (symmetric or periodic) to handle signal boundaries</p> <ul> <li> <p>You want to extract specific parts of the convolution result (head, center, or tail)</p> </li> <li> <p>You need output length equal to input signal length (center mode)</p> </li> <li> <p>You are processing signals where boundary effects matter (e.g., image processing, periodic signals)</p> </li> <li> <p>You can tolerate dynamic memory allocation</p> </li> </ul> <p>Example scenarios:</p> <ul> <li> <p>Image filtering with symmetric padding to reduce boundary artifacts</p> </li> <li> <p>Processing periodic signals with periodic padding</p> </li> <li> <p>Extracting only the valid convolution region (center mode) when output length should match input</p> </li> <li> <p>Advanced signal processing where boundary handling is critical</p> </li> </ul>"},{"location":"DSP/SIGNAL/CONVOLUTION/test/","title":"TESTS","text":""},{"location":"DSP/SIGNAL/CONVOLUTION/test/#tiny_conv_testh","title":"tiny_conv_test.h","text":"<pre><code>/**\n * @file tiny_conv_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_conv | test | header\n * @version 1.0\n * @date 2025-04-28\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_conv\n#include \"tiny_conv.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_signal_conv_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SIGNAL/CONVOLUTION/test/#tiny_conv_testc","title":"tiny_conv_test.c","text":"<pre><code>/**\n * @file tiny_conv_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_conv | test | header\n * @version 1.0\n * @date 2025-04-28\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n// tiny_conv\n#include \"tiny_conv_test.h\"\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;math.h&gt;\n\n#define EPSILON 1e-5  // Tolerance for floating-point comparison\n\n// Helper function to compare two float arrays\nint compare_float_arrays(const float *a, const float *b, int len, float tol)\n{\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (fabs(a[i] - b[i]) &gt; tol)\n        {\n            return 0; // Not equal\n        }\n    }\n    return 1; // Equal\n}\n\n// Test function\nvoid tiny_signal_conv_test(void)\n{\n    printf(\"===== tiny_conv_f32 and tiny_conv_ex_f32 Test Start =====\\n\");\n\n    // Define sample signal and kernel\n    float signal[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f, 10.0f, 11.0f};\n    float kernel[] = {0.2f, 0.5f, 0.3f};\n    int siglen = sizeof(signal) / sizeof(signal[0]);\n    int kernlen = sizeof(kernel) / sizeof(kernel[0]);\n\n    int convlen_full = siglen + kernlen - 1;\n    float convout_ref[convlen_full];\n    float convout_test[convlen_full];\n\n    // show signal and kernel \n    printf(\"Signal: \");\n    for (int i = 0; i &lt; siglen; i++)\n    {\n        printf(\"%.2f \", signal[i]);\n    }\n    printf(\"\\nKernel: \");\n    for (int i = 0; i &lt; kernlen; i++)\n    {\n        printf(\"%.2f \", kernel[i]);\n    }\n    printf(\"\\n\");\n\n    // 1. Test basic tiny_conv_f32\n    printf(\"\\n[Test] tiny_conv_f32 basic full convolution...\\n\");\n    memset(convout_ref, 0, sizeof(convout_ref));\n    if (tiny_conv_f32(signal, siglen, kernel, kernlen, convout_ref) != TINY_OK)\n    {\n        printf(\"[FAIL] tiny_conv_f32 error.\\n\");\n        return;\n    }\n    printf(\"[PASS] tiny_conv_f32 full convolution completed.\\n\");\n\n    // 2. Test tiny_conv_ex_f32 with padding = zero, conv_mode = full\n    printf(\"\\n[Test] tiny_conv_ex_f32 padding=zero, mode=full...\\n\");\n    memset(convout_test, 0, sizeof(convout_test));\n    if (tiny_conv_ex_f32(signal, siglen, kernel, kernlen, convout_test, TINY_PADDING_ZERO, TINY_CONV_FULL) != TINY_OK)\n    {\n        printf(\"[FAIL] tiny_conv_ex_f32 error.\\n\");\n        return;\n    }\n\n    if (compare_float_arrays(convout_ref, convout_test, convlen_full, EPSILON))\n    {\n        printf(\"[PASS] tiny_conv_ex_f32 matches tiny_conv_f32 (zero padding, full mode).\\n\");\n    }\n    else\n    {\n        printf(\"[FAIL] tiny_conv_ex_f32 result mismatch!\\n\");\n        return;\n    }\n\n    // 3. Test tiny_conv_ex_f32 with different padding modes\n    tiny_padding_mode_t paddings[] = {TINY_PADDING_ZERO, TINY_PADDING_SYMMETRIC, TINY_PADDING_PERIODIC};\n    const char *padding_names[] = {\"ZERO\", \"SYMMETRIC\", \"PERIODIC\"};\n\n    // 4. Test different convolution modes\n    tiny_conv_mode_t modes[] = {TINY_CONV_FULL, TINY_CONV_HEAD, TINY_CONV_CENTER, TINY_CONV_TAIL};\n    const char *mode_names[] = {\"FULL\", \"HEAD\", \"CENTER\", \"TAIL\"};\n\n    for (int p = 0; p &lt; 3; p++)\n    {\n        for (int m = 0; m &lt; 4; m++)\n        {\n            printf(\"\\n[Test] tiny_conv_ex_f32 padding=%s, mode=%s...\\n\", padding_names[p], mode_names[m]);\n            memset(convout_test, 0, sizeof(convout_test));\n\n            if (tiny_conv_ex_f32(signal, siglen, kernel, kernlen, convout_test, paddings[p], modes[m]) != TINY_OK)\n            {\n                printf(\"[FAIL] tiny_conv_ex_f32 error at padding=%s, mode=%s.\\n\", padding_names[p], mode_names[m]);\n                continue;\n            }\n\n            printf(\"[PASS] tiny_conv_ex_f32 completed (padding=%s, mode=%s).\\n\", padding_names[p], mode_names[m]);\n            printf(\"Output:\\n\");\n\n            int out_len = 0;\n            switch (modes[m])\n            {\n            case TINY_CONV_FULL:\n                out_len = siglen + kernlen - 1;\n                break;\n            case TINY_CONV_HEAD:\n                out_len = kernlen;\n                break;\n            case TINY_CONV_CENTER:\n                out_len = siglen;\n                break;\n            case TINY_CONV_TAIL:\n                out_len = kernlen;\n                break;\n            default:\n                break;\n            }\n\n            for (int i = 0; i &lt; out_len; i++)\n            {\n                printf(\"%.5f \", convout_test[i]);\n            }\n            printf(\"\\n\");\n        }\n    }\n\n    printf(\"\\n===== tiny_conv_f32 and tiny_conv_ex_f32 Test End =====\\n\");\n}\n</code></pre>"},{"location":"DSP/SIGNAL/CONVOLUTION/test/#test-results","title":"test results","text":"<pre><code>===== tiny_conv_f32 and tiny_conv_ex_f32 Test Start =====\nSignal: 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 11.00 \nKernel: 0.20 0.50 0.30 \n\n[Test] tiny_conv_f32 basic full convolution...\n[PASS] tiny_conv_f32 full convolution completed.\n\n[Test] tiny_conv_ex_f32 padding=zero, mode=full...\n[PASS] tiny_conv_ex_f32 matches tiny_conv_f32 (zero padding, full mode).\n\n[Test] tiny_conv_ex_f32 padding=ZERO, mode=FULL...\n[PASS] tiny_conv_ex_f32 completed (padding=ZERO, mode=FULL).\nOutput:\n0.20000 0.90000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 8.50000 3.30000 \n\n[Test] tiny_conv_ex_f32 padding=ZERO, mode=HEAD...\n[PASS] tiny_conv_ex_f32 completed (padding=ZERO, mode=HEAD).\nOutput:\n0.20000 0.90000 1.90000 \n\n[Test] tiny_conv_ex_f32 padding=ZERO, mode=CENTER...\n[PASS] tiny_conv_ex_f32 completed (padding=ZERO, mode=CENTER).\nOutput:\n0.90000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 8.50000 \n\n[Test] tiny_conv_ex_f32 padding=ZERO, mode=TAIL...\n[PASS] tiny_conv_ex_f32 completed (padding=ZERO, mode=TAIL).\nOutput:\n9.90000 8.50000 3.30000 \n\n[Test] tiny_conv_ex_f32 padding=SYMMETRIC, mode=FULL...\n[PASS] tiny_conv_ex_f32 completed (padding=SYMMETRIC, mode=FULL).\nOutput:\n1.30000 1.20000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 10.70000 10.80000 \n\n[Test] tiny_conv_ex_f32 padding=SYMMETRIC, mode=HEAD...\n[PASS] tiny_conv_ex_f32 completed (padding=SYMMETRIC, mode=HEAD).\nOutput:\n1.30000 1.20000 1.90000 \n\n[Test] tiny_conv_ex_f32 padding=SYMMETRIC, mode=CENTER...\n[PASS] tiny_conv_ex_f32 completed (padding=SYMMETRIC, mode=CENTER).\nOutput:\n1.20000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 10.70000 \n\n[Test] tiny_conv_ex_f32 padding=SYMMETRIC, mode=TAIL...\n[PASS] tiny_conv_ex_f32 completed (padding=SYMMETRIC, mode=TAIL).\nOutput:\n9.90000 10.70000 10.80000 \n\n[Test] tiny_conv_ex_f32 padding=PERIODIC, mode=FULL...\n[PASS] tiny_conv_ex_f32 completed (padding=PERIODIC, mode=FULL).\nOutput:\n8.50000 3.90000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 8.70000 4.20000 \n\n[Test] tiny_conv_ex_f32 padding=PERIODIC, mode=HEAD...\n[PASS] tiny_conv_ex_f32 completed (padding=PERIODIC, mode=HEAD).\nOutput:\n8.50000 3.90000 1.90000 \n\n[Test] tiny_conv_ex_f32 padding=PERIODIC, mode=CENTER...\n[PASS] tiny_conv_ex_f32 completed (padding=PERIODIC, mode=CENTER).\nOutput:\n3.90000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 8.70000 \n\n[Test] tiny_conv_ex_f32 padding=PERIODIC, mode=TAIL...\n[PASS] tiny_conv_ex_f32 completed (padding=PERIODIC, mode=TAIL).\nOutput:\n9.90000 8.70000 4.20000 \n\n===== tiny_conv_f32 and tiny_conv_ex_f32 Test End =====\n</code></pre>"},{"location":"DSP/SIGNAL/CORRELATION/code/","title":"CODE","text":""},{"location":"DSP/SIGNAL/CORRELATION/code/#tiny_corrh","title":"tiny_corr.h","text":"<pre><code>/**\n * @file tiny_corr.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_corr | code | header\n * @version 1.0\n * @date 2025-04-27\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n\n// ESP32 DSP Library for Acceleration\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n\n#include \"dsps_corr.h\"\n#include \"dsps_ccorr.h\"\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @name: tiny_corr_f32\n     * @brief Correlation function\n     *\n     * @param Signal: input signal array\n     * @param siglen: length of the signal array\n     * @param Pattern: input pattern array\n     * @param patlen: length of the pattern array\n     * @param dest: output array for the correlation result\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_corr_f32(const float *Signal, const int siglen, const float *Pattern, const int patlen, float *dest);\n\n    /**\n     * @name: tiny_ccorr_f32\n     * @brief Cross-correlation function\n     *\n     * @param Signal: input signal array\n     * @param siglen: length of the signal array\n     * @param Kernel: input kernel array\n     * @param kernlen: length of the kernel array\n     * @param corrvout: output array for the cross-correlation result\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_ccorr_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *corrvout);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SIGNAL/CORRELATION/code/#tiny_corrc","title":"tiny_corr.c","text":"<pre><code>/**\n * @file tiny_corr.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_corr | code | source\n * @version 1.0\n * @date 2025-04-27\n * @copyright Copyright (c) 2025\n *\n */\n/* DEPENDENCIES */\n#include \"tiny_corr.h\"\n\n/**\n * @name: tiny_corr_f32\n * @brief Correlation function\n *\n * @param Signal: input signal array\n * @param siglen: length of the signal array\n * @param Pattern: input pattern array\n * @param patlen: length of the pattern array\n * @param dest: output array for the correlation result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_corr_f32(const float *Signal, const int siglen, const float *Pattern, const int patlen, float *dest)\n{\n    if (NULL == Signal || NULL == Pattern || NULL == dest)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    if (siglen &lt; patlen) // signal length shoudl be greater than pattern length\n    {\n        return TINY_ERR_DSP_MISMATCH;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_corr_f32(Signal, siglen, Pattern, patlen, dest);\n#else\n\n    for (size_t n = 0; n &lt;= (siglen - patlen); n++)\n    {\n        float k_corr = 0;\n        for (size_t m = 0; m &lt; patlen; m++)\n        {\n            k_corr += Signal[n + m] * Pattern[m];\n        }\n        dest[n] = k_corr;\n    }\n\n#endif\n\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_ccorr_f32\n * @brief Cross-correlation function\n *\n * @param Signal: input signal array\n * @param siglen: length of the signal array\n * @param Kernel: input kernel array\n * @param kernlen: length of the kernel array\n * @param corrvout: output array for the cross-correlation result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_ccorr_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *corrvout)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == corrvout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_ccorr_f32(Signal, siglen, Kernel, kernlen, corrvout);\n#else\n    float *sig = (float *)Signal;\n    float *kern = (float *)Kernel;\n    int lsig = siglen;\n    int lkern = kernlen;\n\n    // swap signal and kernel if needed\n    if (siglen &lt; kernlen)\n    {\n        sig = (float *)Kernel;\n        kern = (float *)Signal;\n        lsig = kernlen;\n        lkern = siglen;\n    }\n    // stage I\n    for (int n = 0; n &lt; lkern; n++)\n    {\n        size_t k;\n        size_t kmin = lkern - 1 - n;\n        corrvout[n] = 0;\n\n        for (k = 0; k &lt;= n; k++)\n        {\n            corrvout[n] += sig[k] * kern[kmin + k];\n        }\n    }\n\n    // stage II\n    for (int n = lkern; n &lt; lsig; n++)\n    {\n        size_t kmin, kmax, k;\n\n        corrvout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = n;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            corrvout[n] += sig[k] * kern[k - kmin];\n        }\n    }\n\n    // stage III\n    for (int n = lsig; n &lt; lsig + lkern - 1; n++)\n    {\n        size_t kmin, kmax, k;\n\n        corrvout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = lsig - 1;\n\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            corrvout[n] += sig[k] * kern[k - kmin];\n        }\n    }\n#endif\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/SIGNAL/CORRELATION/notes/","title":"NOTES","text":"<p>Note</p> <p>Correlation is an important concept in signal processing, often used to analyze similarities or dependencies between signals. It is useful in many applications, such as pattern recognition, time series analysis, and signal detection.</p>"},{"location":"DSP/SIGNAL/CORRELATION/notes/#correlation-function","title":"CORRELATION FUNCTION","text":""},{"location":"DSP/SIGNAL/CORRELATION/notes/#mathematical-principle","title":"Mathematical Principle","text":"<p>The correlation is computed as:</p> \\[ \\text{Correlation}[n] = \\sum_{m=0}^{L_p - 1} S[n + m] \\cdot P[m] \\] <p>Where:</p> <ul> <li> <p>\\( S \\) is the input signal of length \\( L_s \\)</p> </li> <li> <p>\\( P \\) is the pattern of length \\( L_p \\)</p> </li> <li> <p>\\( n \\in [0, L_s - L_p] \\)</p> </li> </ul> <p>Output Length:</p> \\[ L_{\\text{out}} = L_s - L_p + 1 \\]"},{"location":"DSP/SIGNAL/CORRELATION/notes/#tiny_corr_f32","title":"tiny_corr_f32","text":"<pre><code>/**\n * @name: tiny_corr_f32\n * @brief Correlation function\n *\n * @param Signal: input signal array\n * @param siglen: length of the signal array\n * @param Pattern: input pattern array\n * @param patlen: length of the pattern array\n * @param dest: output array for the correlation result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_corr_f32(const float *Signal, const int siglen, const float *Pattern, const int patlen, float *dest)\n{\n    if (NULL == Signal || NULL == Pattern || NULL == dest)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    if (siglen &lt; patlen) // signal length shoudl be greater than pattern length\n    {\n        return TINY_ERR_DSP_MISMATCH;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_corr_f32(Signal, siglen, Pattern, patlen, dest);\n#else\n\n    for (size_t n = 0; n &lt;= (siglen - patlen); n++)\n    {\n        float k_corr = 0;\n        for (size_t m = 0; m &lt; patlen; m++)\n        {\n            k_corr += Signal[n + m] * Pattern[m];\n        }\n        dest[n] = k_corr;\n    }\n\n#endif\n\n    return TINY_OK;\n}\n</code></pre> <p>Description: </p> <p>Computes the correlation between a signal and a pattern.</p> <p>Features:</p> <ul> <li>Platform-specific optimization enabled.</li> </ul> <p>Parameters:</p> <ul> <li> <p><code>Signal</code>: Pointer to the input signal array.</p> </li> <li> <p><code>siglen</code>: Length of the signal array.</p> </li> <li> <p><code>Pattern</code>: Pointer to the input pattern array.</p> </li> <li> <p><code>patlen</code>: Length of the pattern array.</p> </li> <li> <p><code>dest</code>: Pointer to the output array for the correlation result.</p> </li> </ul> <p>Return Value: Returns success or error code.</p>"},{"location":"DSP/SIGNAL/CORRELATION/notes/#cross-correlation-function","title":"CROSS-CORRELATION FUNCTION","text":""},{"location":"DSP/SIGNAL/CORRELATION/notes/#mathematical-principle_1","title":"Mathematical Principle","text":"<p>The cross-correlation is computed as:</p> \\[ R_{xy}[n] = \\sum_{k} x[k] \\cdot y[k + n] \\] <p>Where:</p> <ul> <li> <p>\\( x \\) is the signal of length \\( L_x \\)</p> </li> <li> <p>\\( y \\) is the kernel of length \\( L_y \\)</p> </li> <li> <p>\\( n \\in [0, L_x + L_y - 2] \\)</p> </li> </ul> <p>Output Length:</p> \\[ L_{\\text{out}} = L_x + L_y - 1 \\]"},{"location":"DSP/SIGNAL/CORRELATION/notes/#tiny_ccorr_f32","title":"tiny_ccorr_f32","text":"<pre><code>/**\n * @name: tiny_ccorr_f32\n * @brief Cross-correlation function\n *\n * @param Signal: input signal array\n * @param siglen: length of the signal array\n * @param Kernel: input kernel array\n * @param kernlen: length of the kernel array\n * @param corrvout: output array for the cross-correlation result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_ccorr_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *corrvout)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == corrvout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    float *sig = (float *)Signal;\n    float *kern = (float *)Kernel;\n    int lsig = siglen;\n    int lkern = kernlen;\n\n    // swap signal and kernel if needed\n    if (siglen &lt; kernlen)\n    {\n        sig = (float *)Kernel;\n        kern = (float *)Signal;\n        lsig = kernlen;\n        lkern = siglen;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_ccorr_f32(Signal, siglen, Kernel, kernlen, corrvout);\n#else\n    // stage I\n    for (int n = 0; n &lt; lkern; n++)\n    {\n        size_t k;\n        size_t kmin = lkern - 1 - n;\n        corrvout[n] = 0;\n\n        for (k = 0; k &lt;= n; k++)\n        {\n            corrvout[n] += sig[k] * kern[kmin + k];\n        }\n    }\n\n    // stage II\n    for (int n = lkern; n &lt; lsig; n++)\n    {\n        size_t kmin, kmax, k;\n\n        corrvout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = n;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            corrvout[n] += sig[k] * kern[k - kmin];\n        }\n    }\n\n    // stage III\n    for (int n = lsig; n &lt; lsig + lkern - 1; n++)\n    {\n        size_t kmin, kmax, k;\n\n        corrvout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = lsig - 1;\n\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            corrvout[n] += sig[k] * kern[k - kmin];\n        }\n    }\n#endif\n    return TINY_OK;\n}\n</code></pre> <p>Description: </p> <p>Computes the cross-correlation between a signal and a kernel.</p> <p>Features:</p> <ul> <li> <p>Platform-specific optimization enabled.</p> </li> <li> <p>Automatically handles length swapping when signal is shorter than kernel.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>Signal</code>: Pointer to the input signal array.</p> </li> <li> <p><code>siglen</code>: Length of the signal array.</p> </li> <li> <p><code>Kernel</code>: Pointer to the input kernel array.</p> </li> <li> <p><code>kernlen</code>: Length of the kernel array.</p> </li> <li> <p><code>corrvout</code>: Pointer to the output array for the cross-correlation result.</p> </li> </ul> <p>Return Value: Returns success or error code.</p>"},{"location":"DSP/SIGNAL/CORRELATION/notes/#comparison-and-summary","title":"COMPARISON AND SUMMARY","text":""},{"location":"DSP/SIGNAL/CORRELATION/notes/#key-differences","title":"Key Differences","text":"Feature <code>tiny_corr_f32</code> <code>tiny_ccorr_f32</code> Output Length \\( L_{\\text{out}} = L_s - L_p + 1 \\) \\( L_{\\text{out}} = L_x + L_y - 1 \\) Length Requirement Signal length must be \u2265 pattern length Works with any length (auto-swaps if needed) Computation Type Sliding correlation (valid region only) Full cross-correlation (includes partial overlaps) Implementation Single-stage nested loop Three-stage computation Use Case Pattern matching, template detection Full correlation analysis, signal alignment"},{"location":"DSP/SIGNAL/CORRELATION/notes/#when-to-use-which-function","title":"When to Use Which Function","text":"<p>Use <code>tiny_corr_f32</code> when:</p> <ul> <li> <p>You need to find a pattern within a longer signal (pattern matching)</p> </li> <li> <p>You only care about positions where the pattern fully overlaps with the signal</p> </li> <li> <p>The signal is guaranteed to be longer than the pattern</p> </li> <li> <p>You want a more efficient computation for template matching applications</p> </li> <li> <p>You need to detect occurrences of a known pattern in a signal</p> </li> </ul> <p>Example applications:</p> <ul> <li> <p>Template matching in image processing</p> </li> <li> <p>Pattern detection in time series</p> </li> <li> <p>Signal detection and recognition</p> </li> <li> <p>Feature matching</p> </li> </ul> <p>Use <code>tiny_ccorr_f32</code> when:</p> <ul> <li> <p>You need the complete cross-correlation including partial overlaps</p> </li> <li> <p>The lengths of the two sequences can be arbitrary (either can be longer)</p> </li> <li> <p>You need to analyze all possible alignments between two signals</p> </li> <li> <p>You want to find the best alignment or time delay between signals</p> </li> <li> <p>You need the full correlation function for further analysis</p> </li> </ul> <p>Example applications:</p> <ul> <li> <p>Time delay estimation between two signals</p> </li> <li> <p>Signal alignment and synchronization</p> </li> <li> <p>Full correlation analysis</p> </li> <li> <p>When signal lengths are unknown or variable</p> </li> </ul>"},{"location":"DSP/SIGNAL/CORRELATION/notes/#summary","title":"Summary","text":"<ul> <li> <p><code>tiny_corr_f32</code> is optimized for pattern matching scenarios where you search for a shorter pattern in a longer signal. It only computes correlations where the pattern fully overlaps, resulting in a shorter output and faster computation.</p> </li> <li> <p><code>tiny_ccorr_f32</code> computes the full cross-correlation between two sequences of any length, including all partial overlaps. This provides complete correlation information but requires more computation and produces a longer output.</p> </li> </ul> <p>Choose <code>tiny_corr_f32</code> for efficient pattern matching, and <code>tiny_ccorr_f32</code> when you need comprehensive correlation analysis or when signal lengths are variable.</p>"},{"location":"DSP/SIGNAL/CORRELATION/test/","title":"TESTS","text":""},{"location":"DSP/SIGNAL/CORRELATION/test/#tiny_corr_testh","title":"tiny_corr_test.h","text":"<pre><code>/**\n * @file tiny_corr_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_corr | test | header\n * @version 1.0\n * @date 2025-04-27\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_corr.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_signal_corr_ccorr_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SIGNAL/CORRELATION/test/#tiny_corr_testc","title":"tiny_corr_test.c","text":"<pre><code>/**\n * @file tiny_corr_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_corr | test | source\n * @version 1.0\n * @date 2025-04-27\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_corr_test.h\"\n\n#define EPSILON 1e-3f // Tolerance for floating-point comparison\n\n// Helper function to print float arrays\nstatic void print_float_array(const char *label, const float *array, int length) {\n    printf(\"%s: [\", label);\n    for (int i = 0; i &lt; length; i++) {\n        printf(\"%.2f\", array[i]);\n        if (i != length -1) {\n            printf(\", \");\n        }\n    }\n    printf(\"]\\n\");\n}\n\nvoid tiny_signal_corr_ccorr_test(void)\n{\n    printf(\"\\n========== Correlation &amp; Cross-Correlation Test ==========\\n\");\n\n    /*** Test 1: Correlation Function - tiny_corr_f32 ***/\n    const float signal[]  = {1.0f, 2.0f, 3.0f, 4.0f, 2.0f, 1.0f};\n    const float pattern[] = {2.0f, 1.0f, 0.0f};\n    const int siglen  = sizeof(signal) / sizeof(signal[0]);\n    const int patlen  = sizeof(pattern) / sizeof(pattern[0]);\n    const int corr_len = siglen - patlen + 1;\n\n    float corr_output[corr_len];\n    const float expected_corr[] = {4.0f, 7.0f, 10.0f, 10.0f};\n\n    printf(\"\\n--- Test 1: tiny_corr_f32 ---\\n\");\n    print_float_array(\"Input Signal \", signal, siglen);\n    print_float_array(\"Pattern      \", pattern, patlen);\n\n    tiny_error_t status_corr = tiny_corr_f32(signal, siglen, pattern, patlen, corr_output);\n\n    if (status_corr != TINY_OK) {\n        printf(\"[tiny_corr_f32 Test] Failed with error code: %d\\n\", status_corr);\n    } else {\n        printf(\"Output vs Expected:\\n\");\n        int pass = 1;\n        for (int i = 0; i &lt; corr_len; i++) {\n            printf(\"  [%d] Output = %.3f | Expected = %.3f\\n\", i, corr_output[i], expected_corr[i]);\n            if (fabs(corr_output[i] - expected_corr[i]) &gt; EPSILON) {\n                pass = 0;\n            }\n        }\n        printf(\"[tiny_corr_f32 Test] [%s]\\n\", pass ? \"PASS\" : \"FAIL\");\n    }\n\n    /*** Test 2: Cross-Correlation Function - tiny_ccorr_f32 ***/\n    const float x[] = {1.0f, 3.0f, 2.0f, 0.0f, 1.0f, 2.0f};\n    const float y[] = {2.0f, 1.0f, 0.0f, -1.0f};\n    const int len_x = sizeof(x) / sizeof(x[0]);\n    const int len_y = sizeof(y) / sizeof(y[0]);\n    const int ccorr_len = len_x + len_y - 1;\n\n    float ccorr_output[ccorr_len];\n    const float expected_ccorr[] = {-1.0f, -3.0f, -1.0f, 5.0f, 7.0f, 2.0f, 1.0f, 4.0f, 4.0f};\n\n    printf(\"\\n--- Test 2: tiny_ccorr_f32 ---\\n\");\n    print_float_array(\"Input Signal X\", x, len_x);\n    print_float_array(\"Input Signal Y\", y, len_y);\n\n    tiny_error_t status_ccorr = tiny_ccorr_f32(x, len_x, y, len_y, ccorr_output);\n\n    if (status_ccorr != TINY_OK) {\n        printf(\"[tiny_ccorr_f32 Test] Failed with error code: %d\\n\", status_ccorr);\n    } else {\n        printf(\"Output vs Expected:\\n\");\n        int pass = 1;\n        for (int i = 0; i &lt; ccorr_len; i++) {\n            printf(\"  [%d] Output = %.3f | Expected = %.3f\\n\", i, ccorr_output[i], expected_ccorr[i]);\n            if (fabs(ccorr_output[i] - expected_ccorr[i]) &gt; EPSILON) {\n                pass = 0;\n            }\n        }\n        printf(\"[tiny_ccorr_f32 Test] [%s]\\n\", pass ? \"PASS\" : \"FAIL\");\n    }\n\n    printf(\"==========================================================\\n\");\n}\n</code></pre>"},{"location":"DSP/SIGNAL/CORRELATION/test/#test-results","title":"TEST RESULTS","text":"<pre><code>========== Correlation &amp; Cross-Correlation Test ==========\n\n--- Test 1: tiny_corr_f32 ---\nInput Signal : [1.00, 2.00, 3.00, 4.00, 2.00, 1.00]\nPattern      : [2.00, 1.00, 0.00]\nOutput vs Expected:\n  [0] Output = 4.000 | Expected = 4.000\n  [1] Output = 7.000 | Expected = 7.000\n  [2] Output = 10.000 | Expected = 10.000\n  [3] Output = 10.000 | Expected = 10.000\n[tiny_corr_f32 Test] [PASS]\n\n--- Test 2: tiny_ccorr_f32 ---\nInput Signal X: [1.00, 3.00, 2.00, 0.00, 1.00, 2.00]\nInput Signal Y: [2.00, 1.00, 0.00, -1.00]\nOutput vs Expected:\n  [0] Output = -1.000 | Expected = -1.000\n  [1] Output = -3.000 | Expected = -3.000\n  [2] Output = -1.000 | Expected = -1.000\n  [3] Output = 5.000 | Expected = 5.000\n  [4] Output = 7.000 | Expected = 7.000\n  [5] Output = 2.000 | Expected = 2.000\n  [6] Output = 1.000 | Expected = 1.000\n  [7] Output = 4.000 | Expected = 4.000\n  [8] Output = 4.000 | Expected = 4.000\n[tiny_ccorr_f32 Test] [PASS]\n==========================================================\n</code></pre>"},{"location":"DSP/SIGNAL/RESAMPLE/code/","title":"CODE","text":""},{"location":"DSP/SIGNAL/RESAMPLE/code/#tiny_resampleh","title":"tiny_resample.h","text":"<pre><code>/**\n * @file tiny_resample.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_resample | code | header\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n\n// ESP32 DSP Library for Acceleration\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @name tiny_downsample_skip_f32\n     * @brief Downsample a signal by a given factor using skipping\n     *\n     * @param input pointer to the input signal array\n     * @param input_len length of the input signal array\n     * @param output pointer to the output signal array\n     * @param output_len pointer to the length of the output signal array\n     * @param keep number of samples to keep\n     * @param skip number of samples to skip\n     *\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_downsample_skip_f32(const float *input, int input_len, float *output, int *output_len, int keep, int skip);\n\n    /**\n     * @name tiny_upsample_zero_f32\n     * @brief Upsample a signal using zero-insertion between samples\n     *\n     * @param input pointer to the input signal array\n     * @param input_len length of the input signal array\n     * @param output pointer to the output signal array\n     * @param target_len target length for the output signal array\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_upsample_zero_f32(const float *input, int input_len, float *output, int target_len);\n\n    /**\n     * @name: tiny_resample_f32\n     * @brief Resample a signal to a target length\n     *\n     * @param input pointer to the input signal array\n     * @param input_len length of the input signal array\n     * @param output pointer to the output signal array\n     * @param target_len target length for the output signal array\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_resample_f32(const float *input,\n                                   int input_len,\n                                   float *output,\n                                   int target_len);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SIGNAL/RESAMPLE/code/#tiny_resamplec","title":"tiny_resample.c","text":"<pre><code>/**\n * @file tiny_resample.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_resample | code | source\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_resample.h\" // tiny_resample header\n\n/**\n * @name tiny_downsample_skip_f32\n * @brief Downsample a signal by a given factor using skipping\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param output_len pointer to the length of the output signal array\n * @param keep number of samples to keep\n * @param skip number of samples to skip\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_downsample_skip_f32(const float *input, int input_len, float *output, int *output_len, int keep, int skip)\n{\n    if (!input || !output || !output_len)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || keep &lt;= 0 || skip &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    int out_len = input_len / skip;\n    *output_len = out_len;\n\n    for (int i = 0; i &lt; out_len; i++)\n    {\n        output[i] = input[i * skip];\n    }\n\n    return TINY_OK;\n}\n\n/**\n * @name tiny_upsample_zero_f32\n * @brief Upsample a signal using zero-insertion between samples\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param target_len target length for the output signal array\n * @return tiny_error_t\n */\ntiny_error_t tiny_upsample_zero_f32(const float *input, int input_len, float *output, int target_len)\n{\n    if (!input || !output)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || target_len &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    int factor = target_len / input_len;\n    if (factor &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    for (int i = 0; i &lt; target_len; i++)\n    {\n        output[i] = (i % factor == 0) ? input[i / factor] : 0.0f;\n    }\n\n    return TINY_OK;\n}\n\n\n/**\n * @name: tiny_resample_f32\n * @brief Resample a signal to a target length\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param target_len target length for the output signal array\n * @return tiny_error_t\n */\ntiny_error_t tiny_resample_f32(const float *input,\n                               int input_len,\n                               float *output,\n                               int target_len)\n{\n    if (!input || !output)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || target_len &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    float ratio = (float)(target_len) / (float)(input_len);\n\n    for (int i = 0; i &lt; target_len; i++)\n    {\n        float pos = i / ratio;\n        int index = (int)floorf(pos);\n        float frac = pos - index;\n\n        if (index &gt;= input_len - 1)\n            output[i] = input[input_len - 1]; // Clamp at end\n        else\n            output[i] = input[index] * (1.0f - frac) + input[index + 1] * frac;\n    }\n\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/SIGNAL/RESAMPLE/notes/","title":"NOTES","text":"<p>Note</p> <p>Resampling is an important step in signal processing, typically used to change the sampling rate of a signal. It can be used in audio, video, and other types of signal processing.</p>"},{"location":"DSP/SIGNAL/RESAMPLE/notes/#signal-downsampling-skip","title":"SIGNAL DOWNSAMPLING - SKIP","text":"<pre><code>Signal downsampling by skipping samples is a method of selecting samples from the original signal at regular intervals. It is typically used to reduce the sampling rate of a signal. Note that this is different from decimation, which involves filtering before downsampling.\n</code></pre> <pre><code>/**\n * @name tiny_downsample_skip_f32\n * @brief Downsample a signal by a given factor using skipping\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param output_len pointer to the length of the output signal array\n * @param keep number of samples to keep\n * @param skip number of samples to skip\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_downsample_skip_f32(const float *input, int input_len, float *output, int *output_len, int keep, int skip)\n{\n    if (!input || !output || !output_len)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || keep &lt;= 0 || skip &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    int out_len = input_len / skip;\n    *output_len = out_len;\n\n    for (int i = 0; i &lt; out_len; i++)\n    {\n        output[i] = input[i * skip];\n    }\n\n    return TINY_OK;\n}\n</code></pre> <p>Description:</p> <p>Signal downsampling function that uses two integer parameters <code>keep</code> and <code>skip</code> to control the downsampling process. <code>keep</code> indicates the number of samples to keep, while <code>skip</code> indicates the number of samples to skip.</p> <p>Features:</p> <ul> <li> <p>Integer Factor Downsampling</p> </li> <li> <p>Skip Downsampling</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input signal array</p> </li> <li> <p><code>input_len</code>: Length of the input signal array</p> </li> <li> <p><code>output</code>: Pointer to the output signal array</p> </li> <li> <p><code>output_len</code>: Pointer to the length of the output signal array</p> </li> <li> <p><code>keep</code>: Number of samples to keep</p> </li> <li> <p><code>skip</code>: Number of samples to skip</p> </li> </ul>"},{"location":"DSP/SIGNAL/RESAMPLE/notes/#signal-upsampling-0-insertion","title":"SIGNAL UPSAMPLING - 0 INSERTION","text":"<pre><code>Signal upsampling by inserting zeros is a method of increasing the sampling rate of a signal by inserting zeros between the original samples. This is typically used to prepare a signal for further processing, such as filtering.\n</code></pre> <pre><code>/**\n * @name tiny_upsample_zero_f32\n * @brief Upsample a signal using zero-insertion between samples\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param target_len target length for the output signal array\n * @return tiny_error_t\n */\ntiny_error_t tiny_upsample_zero_f32(const float *input, int input_len, float *output, int target_len)\n{\n    if (!input || !output)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || target_len &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    int factor = target_len / input_len;\n    if (factor &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    for (int i = 0; i &lt; target_len; i++)\n    {\n        output[i] = (i % factor == 0) ? input[i / factor] : 0.0f;\n    }\n\n    return TINY_OK;\n}\n</code></pre> <p>Description:</p> <p>Signal upsampling is the process of increasing the sampling rate of a signal by inserting zeros between the original samples. It is typically used to increase the sampling rate of a signal. Note that this is different from interpolation, which involves filling in gaps between samples.</p> <p>Features:</p> <ul> <li> <p>Integer Factor Upsampling</p> </li> <li> <p>Zero Insertion</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input signal array</p> </li> <li> <p><code>input_len</code>: Length of the input signal array</p> </li> <li> <p><code>output</code>: Pointer to the output signal array</p> </li> <li> <p><code>target_len</code>: Target length for the output signal array</p> </li> </ul>"},{"location":"DSP/SIGNAL/RESAMPLE/notes/#signal-resampling-any-factor-linear-interpolation","title":"SIGNAL RESAMPLING - ANY FACTOR - LINEAR INTERPOLATION","text":"<pre><code>Signal resampling is the process of changing the sampling rate of a signal. We need to first calculate the proportional factor and then use interpolation to fill in the gaps.\n</code></pre> <pre><code>/**\n * @name: tiny_resample_f32\n * @brief Resample a signal to a target length\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param target_len target length for the output signal array\n * @return tiny_error_t\n */\ntiny_error_t tiny_resample_f32(const float *input,\n                               int input_len,\n                               float *output,\n                               int target_len)\n{\n    if (!input || !output)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || target_len &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    float ratio = (float)(target_len) / (float)(input_len);\n\n    for (int i = 0; i &lt; target_len; i++)\n    {\n        float pos = i / ratio;\n        int index = (int)floorf(pos);\n        float frac = pos - index;\n\n        if (index &gt;= input_len - 1)\n            output[i] = input[input_len - 1]; // Clamp at end\n        else\n            output[i] = input[index] * (1.0f - frac) + input[index + 1] * frac;\n    }\n\n    return TINY_OK;\n}\n</code></pre> <p>***Description**:</p> <p>Signal resampling is the process of changing the sampling rate of a signal. Here, we use the most straightforward linear interpolation method. First, we calculate the approximate position of the new signal in the old signal, and then balance the left and right values to generate the new signal.</p> <p>Features:</p> <ul> <li> <p>Non-integer Factor</p> </li> <li> <p>Linear Interpolation</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input signal array</p> </li> <li> <p><code>input_len</code>: Length of the input signal array</p> </li> <li> <p><code>output</code>: Pointer to the output signal array</p> </li> <li> <p><code>target_len</code>: Target length for the output signal array</p> </li> </ul>"},{"location":"DSP/SIGNAL/RESAMPLE/test/","title":"TESTS","text":""},{"location":"DSP/SIGNAL/RESAMPLE/test/#tiny_resampleh","title":"tiny_resample.h","text":"<pre><code>/**\n * @file tiny_resample_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_resample | test | header\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_resample.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_resample_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SIGNAL/RESAMPLE/test/#tiny_resamplec","title":"tiny_resample.c","text":"<pre><code>/**\n * @file tiny_resample_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_resample | test | source\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_resample_test.h\" // tiny_resample test header\n#include &lt;math.h&gt;               // for fabs()\n\n\nvoid tiny_resample_test(void)\n{\n    printf(\"========== TinyResample Test ==========\\n\\n\");\n\n    // Original signal\n    const float input[] = {1, 2, 3, 4, 5, 6, 7, 8};\n    const int input_len = sizeof(input) / sizeof(input[0]);\n\n    printf(\"Original Signal (length=%d):\\n\", input_len);\n    printf(\"  Input: \");\n    for (int i = 0; i &lt; input_len; i++) printf(\" %.2f\", input[i]);\n    printf(\"\\n\\n\");\n\n    // ============================================================\n    // Test 1: Downsampling\n    // ============================================================\n    printf(\"Test 1: Downsampling (keep=1, skip=2)\\n\");\n    printf(\"  Description: Keep every 2nd sample, discard others\\n\");\n    printf(\"  Input:  \");\n    for (int i = 0; i &lt; input_len; i++) printf(\" %.2f\", input[i]);\n    printf(\"  (length=%d)\\n\", input_len);\n\n    float downsampled[8];\n    int down_len = 0;\n    tiny_downsample_skip_f32(input, input_len, downsampled, &amp;down_len, 1, 2);\n\n    printf(\"  Output: \");\n    for (int i = 0; i &lt; down_len; i++) printf(\" %.2f\", downsampled[i]);\n    printf(\"  (length=%d)\\n\", down_len);\n    printf(\"  Mapping: input[0,2,4,6] -&gt; output[0,1,2,3] = [1.00, 3.00, 5.00, 7.00]\\n\\n\");\n\n    // ============================================================\n    // Test 2: Upsampling\n    // ============================================================\n    printf(\"Test 2: Upsampling (Zero-insertion)\\n\");\n    printf(\"  Description: Insert zeros between samples to increase length\\n\");\n    printf(\"  Input:  \");\n    for (int i = 0; i &lt; down_len; i++) printf(\" %.2f\", downsampled[i]);\n    printf(\"  (length=%d)\\n\", down_len);\n\n    float upsampled[16];\n    tiny_upsample_zero_f32(downsampled, down_len, upsampled, 16);\n\n    printf(\"  Output: \");\n    for (int i = 0; i &lt; 16; i++) printf(\" %.2f\", upsampled[i]);\n    printf(\"  (length=16)\\n\");\n    printf(\"  Mapping: input[0,1,2,3] -&gt; output[0,4,8,12] = [1.00, 3.00, 5.00, 7.00]\\n\");\n    printf(\"           (zeros inserted at positions 1,2,3,5,6,7,9,10,11,13,14,15)\\n\\n\");\n\n    // ============================================================\n    // Test 3: Resampling\n    // ============================================================\n    printf(\"Test 3: Resampling (Linear Interpolation)\\n\");\n    printf(\"  Description: Resample from %d to 12 samples using linear interpolation\\n\", input_len);\n    printf(\"  Input:  \");\n    for (int i = 0; i &lt; input_len; i++) printf(\" %.2f\", input[i]);\n    printf(\"  (length=%d)\\n\", input_len);\n\n    float resampled[12];\n    tiny_resample_f32(input, input_len, resampled, 12);\n\n    printf(\"  Output: \");\n    for (int i = 0; i &lt; 12; i++) printf(\" %.2f\", resampled[i]);\n    printf(\"  (length=12)\\n\");\n    printf(\"  Mapping: Linear interpolation between input samples\\n\");\n    printf(\"           output[0,2,4,6,8,10] = input[0,1,2,3,4,5] = [1.00, 2.00, 3.00, 4.00, 5.00, 6.00]\\n\");\n    printf(\"           output[1,3,5,7,9,11] = interpolated midpoints\\n\\n\");\n\n    // ============================================================\n    // Test 4: Validation - Verify interpolation correctness\n    // ============================================================\n    printf(\"Test 4: Validation - Verify Linear Interpolation Correctness\\n\");\n    printf(\"  Purpose: Verify that interpolated values are correctly calculated\\n\");\n    printf(\"           using the formula: output[i] = input[index]*(1-frac) + input[index+1]*frac\\n\");\n    printf(\"           where pos = i/ratio, index = floor(pos), frac = pos - index\\n\\n\");\n\n    float ratio = 12.0f / 8.0f;\n    int validation_errors = 0;\n\n    printf(\"  Sample verification (checking a few key points):\\n\");\n    for (int i = 0; i &lt; 12; i++) {\n        float pos = i / ratio;\n        int index = (int)floorf(pos);\n        float frac = pos - index;\n        float expected;\n\n        if (index &gt;= input_len - 1) {\n            expected = input[input_len - 1];\n        } else {\n            expected = input[index] * (1.0f - frac) + input[index + 1] * frac;\n        }\n\n        float diff = fabs(resampled[i] - expected);\n        if (diff &gt; 0.01f) {\n            validation_errors++;\n        }\n\n        // Only print a few key points to avoid clutter\n        if (i == 0 || i == 1 || i == 2 || i == 6 || i == 11) {\n            printf(\"    output[%2d]: pos=%.3f, index=%d, frac=%.3f -&gt; %.2f (expected: %.2f) %s\\n\",\n                   i, pos, index, frac, resampled[i], expected,\n                   (diff &lt; 0.01f) ? \"\u2713\" : \"\u2717\");\n        }\n    }\n\n    if (validation_errors == 0) {\n        printf(\"  \u2713 All interpolated values are correct!\\n\");\n    } else {\n        printf(\"  \u2717 Found %d interpolation errors\\n\", validation_errors);\n    }\n\n    printf(\"\\n========================================\\n\");\n}\n</code></pre>"},{"location":"DSP/SIGNAL/RESAMPLE/test/#test-output","title":"Test Output","text":"<pre><code>========== TinyResample Test ==========\n\nOriginal Signal (length=8):\n  Input:  1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00\n\nTest 1: Downsampling (keep=1, skip=2)\n  Description: Keep every 2nd sample, discard others\n  Input:   1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00  (length=8)\n  Output:  1.00 3.00 5.00 7.00  (length=4)\n  Mapping: input[0,2,4,6] -&gt; output[0,1,2,3] = [1.00, 3.00, 5.00, 7.00]\n\nTest 2: Upsampling (Zero-insertion)\n  Description: Insert zeros between samples to increase length\n  Input:   1.00 3.00 5.00 7.00  (length=4)\n  Output:  1.00 0.00 0.00 0.00 3.00 0.00 0.00 0.00 5.00 0.00 0.00 0.00 7.00 0.00 0.00 0.00  (length=16)\n  Mapping: input[0,1,2,3] -&gt; output[0,4,8,12] = [1.00, 3.00, 5.00, 7.00]\n           (zeros inserted at positions 1,2,3,5,6,7,9,10,11,13,14,15)\n\nTest 3: Resampling (Linear Interpolation)\n  Description: Resample from 8 to 12 samples using linear interpolation\n  Input:   1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00  (length=8)\n  Output:  1.00 1.67 2.33 3.00 3.67 4.33 5.00 5.67 6.33 7.00 7.67 8.00  (length=12)\n  Mapping: Linear interpolation between input samples\n           output[0,2,4,6,8,10] = input[0,1,2,3,4,5] = [1.00, 2.00, 3.00, 4.00, 5.00, 6.00]\n           output[1,3,5,7,9,11] = interpolated midpoints\n\nTest 4: Validation - Verify Linear Interpolation Correctness\n  Purpose: Verify that interpolated values are correctly calculated\n           using the formula: output[i] = input[index]*(1-frac) + input[index+1]*frac\n           where pos = i/ratio, index = floor(pos), frac = pos - index\n\n  Sample verification (checking a few key points):\n    output[ 0]: pos=0.000, index=0, frac=0.000 -&gt; 1.00 (expected: 1.00) \u2713\n    output[ 1]: pos=0.667, index=0, frac=0.667 -&gt; 1.67 (expected: 1.67) \u2713\n    output[ 2]: pos=1.333, index=1, frac=0.333 -&gt; 2.33 (expected: 2.33) \u2713\n    output[ 6]: pos=4.000, index=4, frac=0.000 -&gt; 5.00 (expected: 5.00) \u2713\n    output[11]: pos=7.333, index=7, frac=0.333 -&gt; 8.00 (expected: 8.00) \u2713\n  \u2713 All interpolated values are correct!\n\n========================================\n</code></pre>"},{"location":"DSP/SUPPORT/code/","title":"CODE","text":""},{"location":"DSP/SUPPORT/code/#tiny_viewh","title":"tiny_view.h","text":"<pre><code>/**\n * @file tiny_view.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_view | code | header\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n#include &lt;stdio.h&gt;\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @name: tiny_view_signal_f32\n     * @brief Visualize a signal in ASCII format (like oscilloscope)\n     * @param data Input signal array\n     * @param len Length of the signal\n     * @param width Width of the plot in characters (default: 64)\n     * @param height Height of the plot in lines (default: 16)\n     * @param min Minimum Y-axis value (auto-detect if min == max)\n     * @param max Maximum Y-axis value (auto-detect if min == max)\n     * @param title Optional title for the plot (NULL for no title)\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_view_signal_f32(const float *data, int len, int width, int height, float min, float max, const char *title);\n\n    /**\n     * @name: tiny_view_spectrum_f32\n     * @brief Visualize power spectrum in ASCII format (optimized for frequency domain)\n     * @param power_spectrum Power spectrum array\n     * @param len Length of the spectrum\n     * @param sample_rate Sampling rate (Hz) for frequency axis labels\n     * @param title Optional title for the plot (NULL for no title)\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_view_spectrum_f32(const float *power_spectrum, int len, float sample_rate, const char *title);\n\n    /**\n     * @name: tiny_view_array_f32\n     * @brief Print array values in a formatted table\n     * @param data Input array\n     * @param len Length of the array\n     * @param name Name/label for the array\n     * @param precision Number of decimal places (default: 3)\n     * @param items_per_line Number of items per line (default: 8)\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_view_array_f32(const float *data, int len, const char *name, int precision, int items_per_line);\n\n    /**\n     * @name: tiny_view_statistics_f32\n     * @brief Print statistical information about a signal\n     * @param data Input signal array\n     * @param len Length of the signal\n     * @param name Name/label for the signal\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_view_statistics_f32(const float *data, int len, const char *name);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SUPPORT/code/#tiny_viewc","title":"tiny_view.c","text":"<pre><code>/**\n * @file tiny_view.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_view | code | source\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_view.h\"\n#include &lt;math.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n\n/**\n * @brief Find min and max values in array\n */\nstatic void find_min_max(const float *data, int len, float *min_val, float *max_val)\n{\n    *min_val = data[0];\n    *max_val = data[0];\n    for (int i = 1; i &lt; len; i++)\n    {\n        if (data[i] &lt; *min_val)\n            *min_val = data[i];\n        if (data[i] &gt; *max_val)\n            *max_val = data[i];\n    }\n}\n\n/**\n * @name: tiny_view_signal_f32\n * @brief Visualize a signal in ASCII format\n */\ntiny_error_t tiny_view_signal_f32(const float *data, int len, int width, int height, float min, float max, const char *title)\n{\n    if (NULL == data || len &lt;= 0 || width &lt;= 0 || height &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Auto-detect min/max if they are equal\n    float min_val = min;\n    float max_val = max;\n    if (min == max)\n    {\n        find_min_max(data, len, &amp;min_val, &amp;max_val);\n        // Add small margin\n        float margin = (max_val - min_val) * 0.1f;\n        if (margin == 0.0f)\n            margin = 0.1f;\n        min_val -= margin;\n        max_val += margin;\n    }\n\n    // Allocate buffer for plot\n    char *plot = (char *)malloc(width * height * sizeof(char));\n    if (plot == NULL)\n    {\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Initialize plot with spaces\n    memset(plot, ' ', width * height);\n\n    // Calculate scaling factors\n    float x_scale = (len &gt; 1) ? (float)(len - 1) / (width - 1) : 0.0f;  // Inverse: data index per pixel\n    float y_scale = (max_val &gt; min_val) ? (float)(height - 1) / (max_val - min_val) : 1.0f;\n\n    // High-resolution drawing: for each pixel column, interpolate the signal value\n    for (int x = 0; x &lt; width; x++)\n    {\n        // Calculate corresponding data index (with interpolation)\n        float data_idx = x * x_scale;\n        int idx0 = (int)data_idx;\n        int idx1 = idx0 + 1;\n        float frac = data_idx - idx0;\n\n        // Clamp indices\n        if (idx0 &lt; 0) idx0 = 0;\n        if (idx0 &gt;= len) idx0 = len - 1;\n        if (idx1 &lt; 0) idx1 = 0;\n        if (idx1 &gt;= len) idx1 = len - 1;\n\n        // Linear interpolation between data points\n        float val;\n        if (len == 1)\n        {\n            val = data[0];\n        }\n        else if (idx0 == len - 1)\n        {\n            val = data[idx0];\n        }\n        else\n        {\n            val = data[idx0] * (1.0f - frac) + data[idx1] * frac;\n        }\n\n        // Clamp value to range\n        if (val &lt; min_val)\n            val = min_val;\n        if (val &gt; max_val)\n            val = max_val;\n\n        // Calculate Y position\n        int y = (int)((max_val - val) * y_scale + 0.5f);\n        if (y &lt; 0)\n            y = 0;\n        if (y &gt;= height)\n            y = height - 1;\n\n        // Draw point\n        plot[y * width + x] = '*';\n\n        // For better visualization, also draw adjacent points if there's a significant change\n        // This helps show the signal shape more clearly\n        if (x &gt; 0)\n        {\n            float prev_data_idx = (x - 1) * x_scale;\n            int prev_idx0 = (int)prev_data_idx;\n            int prev_idx1 = prev_idx0 + 1;\n            float prev_frac = prev_data_idx - prev_idx0;\n\n            if (prev_idx0 &lt; 0) prev_idx0 = 0;\n            if (prev_idx0 &gt;= len) prev_idx0 = len - 1;\n            if (prev_idx1 &lt; 0) prev_idx1 = 0;\n            if (prev_idx1 &gt;= len) prev_idx1 = len - 1;\n\n            float prev_val;\n            if (len == 1)\n            {\n                prev_val = data[0];\n            }\n            else if (prev_idx0 == len - 1)\n            {\n                prev_val = data[prev_idx0];\n            }\n            else\n            {\n                prev_val = data[prev_idx0] * (1.0f - prev_frac) + data[prev_idx1] * prev_frac;\n            }\n\n            if (prev_val &lt; min_val) prev_val = min_val;\n            if (prev_val &gt; max_val) prev_val = max_val;\n\n            int prev_y = (int)((max_val - prev_val) * y_scale + 0.5f);\n            if (prev_y &lt; 0) prev_y = 0;\n            if (prev_y &gt;= height) prev_y = height - 1;\n\n            // Draw line between previous and current point\n            int dy = y - prev_y;\n            int steps = abs(dy);\n            if (steps &gt; 1)\n            {\n                for (int s = 1; s &lt; steps; s++)\n                {\n                    int py = prev_y + (dy * s) / steps;\n                    if (py &gt;= 0 &amp;&amp; py &lt; height)\n                    {\n                        plot[py * width + (x - 1)] = '*';\n                    }\n                }\n            }\n        }\n    }\n\n    // Print title\n    if (title != NULL)\n    {\n        printf(\"\\n%s\\n\", title);\n    }\n\n    // Print Y-axis labels and plot\n    printf(\"Value\\n\");\n    for (int y = 0; y &lt; height; y++)\n    {\n        // Calculate Y value correctly: from max_val at top (y=0) to min_val at bottom (y=height-1)\n        float y_val = (height &gt; 1) ? (max_val - (float)y * (max_val - min_val) / (height - 1)) : max_val;\n        printf(\"%6.2f |\", y_val);\n        for (int x = 0; x &lt; width; x++)\n        {\n            printf(\"%c\", plot[y * width + x]);\n        }\n        printf(\"\\n\");\n    }\n\n    // Print X-axis\n    printf(\"       \");\n    for (int x = 0; x &lt; width; x++)\n    {\n        printf(\"-\");\n    }\n    printf(\"\\n\");\n    printf(\"       \");\n    for (int x = 0; x &lt; width; x += width / 8)\n    {\n        printf(\"%-*d\", width / 8, x);\n    }\n    printf(\" (Sample Index)\\n\");\n\n    printf(\"Range: [%.3f, %.3f], Length: %d\\n\\n\", min_val, max_val, len);\n\n    free(plot);\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_view_spectrum_f32\n * @brief Visualize power spectrum\n */\ntiny_error_t tiny_view_spectrum_f32(const float *power_spectrum, int len, float sample_rate, const char *title)\n{\n    if (NULL == power_spectrum || len &lt;= 0 || sample_rate &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    const int width = 64;\n    const int height = 16;\n\n    // Find min/max\n    float min_val, max_val;\n    find_min_max(power_spectrum, len, &amp;min_val, &amp;max_val);\n    if (max_val == min_val)\n    {\n        max_val = min_val + 1.0f;\n    }\n\n    // Allocate buffer\n    char *plot = (char *)malloc(width * height * sizeof(char));\n    if (plot == NULL)\n    {\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n    memset(plot, ' ', width * height);\n\n    // Calculate scaling (only use first half for real signals)\n    // Power spectrum length is typically half of FFT length\n    // So FFT length = 2 * len, frequency resolution = sample_rate / (2 * len)\n    int plot_len = len / 2;\n    int fft_len = 2 * len;  // FFT length is typically 2x power spectrum length\n    float x_scale = (plot_len &gt; 1) ? (float)(plot_len - 1) / (width - 1) : 0.0f;  // Inverse: data index per pixel\n    float y_scale = (max_val &gt; min_val) ? (float)(height - 1) / (max_val - min_val) : 1.0f;\n\n    // High-resolution drawing: for each pixel column, interpolate the spectrum value\n    for (int x = 0; x &lt; width; x++)\n    {\n        // Calculate corresponding spectrum index (with interpolation)\n        float spec_idx = x * x_scale;\n        int idx0 = (int)spec_idx;\n        int idx1 = idx0 + 1;\n        float frac = spec_idx - idx0;\n\n        // Clamp indices\n        if (idx0 &lt; 0) idx0 = 0;\n        if (idx0 &gt;= plot_len) idx0 = plot_len - 1;\n        if (idx1 &lt; 0) idx1 = 0;\n        if (idx1 &gt;= plot_len) idx1 = plot_len - 1;\n\n        // Linear interpolation between spectrum points\n        float val;\n        if (plot_len == 1)\n        {\n            val = power_spectrum[0];\n        }\n        else if (idx0 == plot_len - 1)\n        {\n            val = power_spectrum[idx0];\n        }\n        else\n        {\n            val = power_spectrum[idx0] * (1.0f - frac) + power_spectrum[idx1] * frac;\n        }\n\n        // Clamp value to range\n        if (val &lt; min_val)\n            val = min_val;\n        if (val &gt; max_val)\n            val = max_val;\n\n        // Calculate Y position\n        int y = (int)((max_val - val) * y_scale + 0.5f);\n        if (y &lt; 0)\n            y = 0;\n        if (y &gt;= height)\n            y = height - 1;\n\n        // Draw bar from bottom to value\n        for (int bar_y = height - 1; bar_y &gt;= y; bar_y--)\n        {\n            plot[bar_y * width + x] = '|';\n        }\n    }\n\n    // Print title\n    if (title != NULL)\n    {\n        printf(\"\\n%s\\n\", title);\n    }\n\n    // Print plot\n    printf(\"Power\\n\");\n    for (int y = 0; y &lt; height; y++)\n    {\n        // Calculate Y value correctly: from max_val at top (y=0) to min_val at bottom (y=height-1)\n        float y_val = (height &gt; 1) ? (max_val - (float)y * (max_val - min_val) / (height - 1)) : max_val;\n        printf(\"%6.2f |\", y_val);\n        for (int x = 0; x &lt; width; x++)\n        {\n            printf(\"%c\", plot[y * width + x]);\n        }\n        printf(\"\\n\");\n    }\n\n    // Print X-axis with frequency labels\n    printf(\"       \");\n    for (int x = 0; x &lt; width; x++)\n    {\n        printf(\"-\");\n    }\n    printf(\"\\n\");\n\n    // Print frequency labels aligned with X-axis positions\n    if (x_scale &gt; 0.0f &amp;&amp; plot_len &gt; 0)\n    {\n        // Create a buffer for frequency labels\n        char *freq_line = (char *)calloc(width + 20, sizeof(char));\n        if (freq_line != NULL)\n        {\n            memset(freq_line, ' ', width + 20);\n            freq_line[width + 19] = '\\0';\n\n            // Place frequency labels at 8 evenly spaced positions\n            int fft_len = 2 * len;  // FFT length is 2x power spectrum length\n            for (int label_idx = 0; label_idx &lt; 8; label_idx++)\n            {\n                int x_pos = (label_idx * width) / 8;\n                // Convert x position back to array index (x_scale is now inverse: data_idx per pixel)\n                float array_idx = (float)x_pos * x_scale;\n                int idx = (int)(array_idx + 0.5f);\n                if (idx &gt;= plot_len)\n                    idx = plot_len - 1;\n                if (idx &lt; 0)\n                    idx = 0;\n                // Frequency = idx * sample_rate / fft_len\n                float freq = (float)idx * sample_rate / fft_len;\n\n                // Format frequency string with appropriate precision\n                char freq_str[12];\n                if (freq &lt; 10.0f)\n                {\n                    snprintf(freq_str, sizeof(freq_str), \"%.1f\", freq);\n                }\n                else if (freq &lt; 100.0f)\n                {\n                    snprintf(freq_str, sizeof(freq_str), \"%.0f\", freq);\n                }\n                else\n                {\n                    snprintf(freq_str, sizeof(freq_str), \"%.0f\", freq);\n                }\n\n                // Place string at x_pos (centered if possible)\n                int str_len = strlen(freq_str);\n                int start_pos = x_pos - str_len / 2;\n                if (start_pos &lt; 0)\n                    start_pos = 0;\n                if (start_pos + str_len &gt; width)\n                    start_pos = width - str_len;\n\n                memcpy(freq_line + start_pos, freq_str, str_len);\n            }\n\n            printf(\"       %s (Hz)\\n\", freq_line);\n            free(freq_line);\n        }\n        else\n        {\n            // Fallback: simple printing\n            int fft_len = 2 * len;  // FFT length is 2x power spectrum length\n            printf(\"       \");\n            for (int label_idx = 0; label_idx &lt; 8; label_idx++)\n            {\n                int x_pos = (label_idx * width) / 8;\n                // Convert x position back to array index (x_scale is now inverse: data_idx per pixel)\n                float array_idx = (float)x_pos * x_scale;\n                int idx = (int)(array_idx + 0.5f);\n                if (idx &gt;= plot_len)\n                    idx = plot_len - 1;\n                if (idx &lt; 0)\n                    idx = 0;\n                // Frequency = idx * sample_rate / fft_len\n                float freq = (float)idx * sample_rate / fft_len;\n                if (freq &lt; 10.0f)\n                {\n                    printf(\"%6.1f\", freq);\n                }\n                else\n                {\n                    printf(\"%7.0f\", freq);\n                }\n            }\n            printf(\" (Hz)\\n\");\n        }\n    }\n    else\n    {\n        // Fallback: just print frequency range\n        printf(\"       0    %5.0f (Hz)\\n\", sample_rate / 2.0f);\n    }\n\n    printf(\"Range: [%.3f, %.3f], Nyquist: %.1f Hz\\n\\n\", min_val, max_val, sample_rate / 2.0f);\n\n    free(plot);\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_view_array_f32\n * @brief Print array in formatted table\n */\ntiny_error_t tiny_view_array_f32(const float *data, int len, const char *name, int precision, int items_per_line)\n{\n    if (NULL == data || len &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    if (precision &lt; 0)\n        precision = 3;\n    if (items_per_line &lt;= 0)\n        items_per_line = 8;\n\n    if (name != NULL)\n    {\n        printf(\"\\n%s [%d elements]:\\n\", name, len);\n    }\n    else\n    {\n        printf(\"\\nArray [%d elements]:\\n\", len);\n    }\n\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (i % items_per_line == 0)\n        {\n            printf(\"  [%3d] \", i);\n        }\n        printf(\"%*.*f \", precision + 4, precision, data[i]);\n        if ((i + 1) % items_per_line == 0 || i == len - 1)\n        {\n            printf(\"\\n\");\n        }\n    }\n    printf(\"\\n\");\n\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_view_statistics_f32\n * @brief Print statistical information\n */\ntiny_error_t tiny_view_statistics_f32(const float *data, int len, const char *name)\n{\n    if (NULL == data || len &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Calculate statistics and find positions in one pass\n    float min_val = data[0];\n    float max_val = data[0];\n    int min_idx = 0;\n    int max_idx = 0;\n    int peak_idx = 0;\n    float peak_val = fabsf(data[0]);\n\n    float sum = data[0];\n    float sum_sq = data[0] * data[0];\n\n    for (int i = 1; i &lt; len; i++)\n    {\n        // Update min/max and their positions\n        if (data[i] &lt; min_val)\n        {\n            min_val = data[i];\n            min_idx = i;\n        }\n        if (data[i] &gt; max_val)\n        {\n            max_val = data[i];\n            max_idx = i;\n        }\n\n        // Update peak (absolute value)\n        float abs_val = fabsf(data[i]);\n        if (abs_val &gt; peak_val)\n        {\n            peak_val = abs_val;\n            peak_idx = i;\n        }\n\n        // Accumulate for mean/variance\n        sum += data[i];\n        sum_sq += data[i] * data[i];\n    }\n\n    float mean = sum / len;\n    float variance = (sum_sq / len) - (mean * mean);\n    float std_dev = sqrtf(variance &gt; 0 ? variance : 0);\n\n    // Print statistics\n    if (name != NULL)\n    {\n        printf(\"\\n=== Statistics: %s ===\\n\", name);\n    }\n    else\n    {\n        printf(\"\\n=== Statistics ===\\n\");\n    }\n    printf(\"  Length:     %d samples\\n\", len);\n    printf(\"  Min:        %.6f (at index %d)\\n\", min_val, min_idx);\n    printf(\"  Max:        %.6f (at index %d)\\n\", max_val, max_idx);\n    printf(\"  Peak:       %.6f (at index %d)\\n\", data[peak_idx], peak_idx);\n    printf(\"  Mean:       %.6f\\n\", mean);\n    printf(\"  Std Dev:    %.6f\\n\", std_dev);\n    printf(\"  Variance:   %.6f\\n\", variance);\n    printf(\"  Range:      %.6f\\n\", max_val - min_val);\n    printf(\"========================\\n\\n\");\n\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/SUPPORT/notes/","title":"NOTES","text":"<p>Note</p> <p>The support module provides visualization and analysis utilities for signal processing. These functions help developers visualize signals, analyze data, and debug DSP algorithms by providing ASCII-based plots and formatted output. This is particularly useful in embedded systems where graphical displays may not be available.</p>"},{"location":"DSP/SUPPORT/notes/#overview","title":"OVERVIEW","text":"<p>The support module includes four main functions:</p> <ol> <li>Signal Visualization: Plot signals in ASCII format (like an oscilloscope)</li> <li>Spectrum Visualization: Visualize power spectra with frequency axis labels</li> <li>Array Printing: Print arrays in formatted tables</li> <li>Statistics: Calculate and display statistical information about signals</li> </ol>"},{"location":"DSP/SUPPORT/notes/#signal-visualization","title":"SIGNAL VISUALIZATION","text":""},{"location":"DSP/SUPPORT/notes/#tiny_view_signal_f32","title":"tiny_view_signal_f32","text":"<pre><code>/**\n * @name: tiny_view_signal_f32\n * @brief Visualize a signal in ASCII format (like oscilloscope)\n * @param data Input signal array\n * @param len Length of the signal\n * @param width Width of the plot in characters (default: 64)\n * @param height Height of the plot in lines (default: 16)\n * @param min Minimum Y-axis value (auto-detect if min == max)\n * @param max Maximum Y-axis value (auto-detect if min == max)\n * @param title Optional title for the plot (NULL for no title)\n * @return tiny_error_t\n */\ntiny_error_t tiny_view_signal_f32(const float *data, int len, int width, int height, float min, float max, const char *title);\n</code></pre> <p>Description: </p> <p>Visualizes a signal in ASCII format, similar to an oscilloscope display. The function creates a character-based plot showing the signal waveform.</p> <p>Features:</p> <ul> <li> <p>High-resolution drawing with linear interpolation between data points</p> </li> <li> <p>Automatic Y-axis range detection when min == max</p> </li> <li> <p>Customizable plot dimensions (width and height)</p> </li> <li> <p>Optional title display</p> </li> <li> <p>Y-axis labels showing value range</p> </li> <li> <p>X-axis labels showing sample indices</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>data</code>: Pointer to the input signal array.</p> </li> <li> <p><code>len</code>: Length of the signal array.</p> </li> <li> <p><code>width</code>: Width of the plot in characters (typically 64).</p> </li> <li> <p><code>height</code>: Height of the plot in lines (typically 16).</p> </li> <li> <p><code>min</code>: Minimum Y-axis value. If <code>min == max</code>, the function will auto-detect the range.</p> </li> </ul>"},{"location":"DSP/SUPPORT/notes/#-max-maximum-y-axis-value-if-min-max-the-function-will-auto-detect-the-range","title":"- <code>max</code>: Maximum Y-axis value. If <code>min == max</code>, the function will auto-detect the range.","text":"<ul> <li><code>title</code>: Optional title string for the plot. Pass <code>NULL</code> for no title.</li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Output Format:</p> <p>The function prints:</p> <ul> <li> <p>Title (if provided)</p> </li> <li> <p>Y-axis labels with value range</p> </li> <li> <p>ASCII plot with '*' characters representing the signal</p> </li> <li> <p>X-axis with sample index labels</p> </li> <li> <p>Summary line with value range and signal length</p> </li> </ul> <p>Example Output:</p> <pre><code>Test Signal: 10 Hz Sine Wave\nValue\n  1.20 |                                        \n  1.00 |                                        \n  0.80 |                                        \n  0.60 |                                        \n  0.40 |                                        \n  0.20 |                                        \n  0.00 |                                        \n -0.20 |                                        \n -0.40 |                                        \n -0.60 |                                        \n -0.80 |                                        \n -1.00 |                                        \n -1.20 |                                        \n       ------------------------------------------------------------------------\n       0        8       16      24      32      40      48      56 (Sample Index)\nRange: [-1.200, 1.200], Length: 64\n</code></pre>"},{"location":"DSP/SUPPORT/notes/#spectrum-visualization","title":"SPECTRUM VISUALIZATION","text":""},{"location":"DSP/SUPPORT/notes/#tiny_view_spectrum_f32","title":"tiny_view_spectrum_f32","text":"<pre><code>/**\n * @name: tiny_view_spectrum_f32\n * @brief Visualize power spectrum in ASCII format (optimized for frequency domain)\n * @param power_spectrum Power spectrum array\n * @param len Length of the spectrum\n * @param sample_rate Sampling rate (Hz) for frequency axis labels\n * @param title Optional title for the plot (NULL for no title)\n * @return tiny_error_t\n */\ntiny_error_t tiny_view_spectrum_f32(const float *power_spectrum, int len, float sample_rate, const char *title);\n</code></pre> <p>Description: </p> <p>Visualizes a power spectrum in ASCII format with frequency axis labels. The function creates a bar chart showing the power at different frequencies.</p> <p>Features:</p> <ul> <li> <p>Bar chart visualization (vertical bars)</p> </li> <li> <p>Automatic frequency axis labeling based on sample rate</p> </li> <li> <p>Optimized for frequency domain data (uses first half of spectrum)</p> </li> <li> <p>Frequency labels in Hz</p> </li> <li> <p>Nyquist frequency indication</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>power_spectrum</code>: Pointer to the power spectrum array.</p> </li> <li> <p><code>len</code>: Length of the power spectrum array.</p> </li> <li> <p><code>sample_rate</code>: Sampling rate of the original signal in Hz (used for frequency axis labels).</p> </li> <li> <p><code>title</code>: Optional title string for the plot. Pass <code>NULL</code> for no title.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Output Format:</p> <p>The function prints:</p> <ul> <li> <p>Title (if provided)</p> </li> <li> <p>Y-axis labels with power values</p> </li> <li> <p>ASCII bar chart with '|' characters</p> </li> <li> <p>X-axis with frequency labels in Hz</p> </li> <li> <p>Summary line with value range and Nyquist frequency</p> </li> </ul> <p>Note: </p> <p>The function assumes the power spectrum length is half of the FFT length (typical for real signals). Frequency labels are calculated as: <code>freq = index * sample_rate / (2 * len)</code>.</p>"},{"location":"DSP/SUPPORT/notes/#array-printing","title":"ARRAY PRINTING","text":""},{"location":"DSP/SUPPORT/notes/#tiny_view_array_f32","title":"tiny_view_array_f32","text":"<pre><code>/**\n * @name: tiny_view_array_f32\n * @brief Print array values in a formatted table\n * @param data Input array\n * @param len Length of the array\n * @param name Name/label for the array\n * @param precision Number of decimal places (default: 3)\n * @param items_per_line Number of items per line (default: 8)\n * @return tiny_error_t\n */\ntiny_error_t tiny_view_array_f32(const float *data, int len, const char *name, int precision, int items_per_line);\n</code></pre> <p>Description: </p> <p>Prints array values in a formatted table with customizable precision and items per line.</p> <p>Features:</p> <ul> <li> <p>Formatted table output with index labels</p> </li> <li> <p>Customizable precision (decimal places)</p> </li> <li> <p>Customizable items per line</p> </li> <li> <p>Optional array name/label</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>data</code>: Pointer to the input array.</p> </li> <li> <p><code>len</code>: Length of the array.</p> </li> <li> <p><code>name</code>: Optional name/label for the array. Pass <code>NULL</code> for default label.</p> </li> <li> <p><code>precision</code>: Number of decimal places to display. If negative, defaults to 3.</p> </li> <li> <p><code>items_per_line</code>: Number of items to print per line. If \u2264 0, defaults to 8.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Output Format:</p> <p>The function prints:</p> <ul> <li> <p>Array name and length</p> </li> <li> <p>Formatted table with index labels and values</p> </li> </ul> <p>Example Output:</p> <pre><code>Test Signal [64 elements]:\n  [  0] 0.000  0.063  0.125  0.188  0.250  0.313  0.375  0.438 \n  [  8] 0.500  0.563  0.625  0.688  0.750  0.813  0.875  0.938 \n  ...\n</code></pre>"},{"location":"DSP/SUPPORT/notes/#statistics","title":"STATISTICS","text":""},{"location":"DSP/SUPPORT/notes/#tiny_view_statistics_f32","title":"tiny_view_statistics_f32","text":"<pre><code>/**\n * @name: tiny_view_statistics_f32\n * @brief Print statistical information about a signal\n * @param data Input signal array\n * @param len Length of the signal\n * @param name Name/label for the signal\n * @return tiny_error_t\n */\ntiny_error_t tiny_view_statistics_f32(const float *data, int len, const char *name);\n</code></pre> <p>Description: </p> <p>Calculates and prints statistical information about a signal, including min, max, mean, standard deviation, variance, and peak values.</p> <p>Features:</p> <ul> <li> <p>Single-pass calculation (efficient)</p> </li> <li> <p>Comprehensive statistics:</p> </li> <li>Minimum and maximum values with indices</li> <li>Peak value (absolute maximum) with index</li> <li>Mean (average)</li> <li>Standard deviation</li> <li>Variance</li> <li> <p>Range (max - min)</p> </li> <li> <p>Optional signal name/label</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>data</code>: Pointer to the input signal array.</p> </li> <li> <p><code>len</code>: Length of the signal array.</p> </li> <li> <p><code>name</code>: Optional name/label for the signal. Pass <code>NULL</code> for default label.</p> </li> </ul> <p>Return Value: Returns success or error code.</p> <p>Output Format:</p> <p>The function prints:</p> <ul> <li> <p>Statistics header with signal name</p> </li> <li> <p>All calculated statistics in a formatted table</p> </li> </ul> <p>Example Output:</p> <pre><code>=== Statistics: Test Signal ===\n  Length:     64 samples\n  Min:        -1.200000 (at index 48)\n  Max:         1.200000 (at index 16)\n  Peak:        1.200000 (at index 16)\n  Mean:        0.000000\n  Std Dev:     0.707107\n  Variance:    0.500000\n  Range:       2.400000\n========================\n</code></pre> <p>Mathematical Formulas:</p> <ul> <li> <p>Mean: \\( \\mu = \\frac{1}{N} \\sum_{i=0}^{N-1} x[i] \\)</p> </li> <li> <p>Variance: \\( \\sigma^2 = \\frac{1}{N} \\sum_{i=0}^{N-1} x[i]^2 - \\mu^2 \\)</p> </li> <li> <p>Standard Deviation: \\( \\sigma = \\sqrt{\\sigma^2} \\)</p> </li> <li> <p>Range: \\( \\text{range} = \\max(x) - \\min(x) \\)</p> </li> </ul>"},{"location":"DSP/SUPPORT/notes/#usage-workflow","title":"USAGE WORKFLOW","text":""},{"location":"DSP/SUPPORT/notes/#typical-visualization-workflow","title":"Typical Visualization Workflow","text":"<ol> <li> <p>Visualize Signal:    <pre><code>float signal[64];\n// ... fill signal with data ...\ntiny_view_signal_f32(signal, 64, 64, 16, 0, 0, \"My Signal\");\n</code></pre></p> </li> <li> <p>Print Array:    <pre><code>tiny_view_array_f32(signal, 64, \"Signal Data\", 3, 8);\n</code></pre></p> </li> <li> <p>Show Statistics:    <pre><code>tiny_view_statistics_f32(signal, 64, \"Signal\");\n</code></pre></p> </li> <li> <p>Visualize Spectrum:    <pre><code>float power[128];\n// ... calculate power spectrum ...\ntiny_view_spectrum_f32(power, 128, 1000.0f, \"Power Spectrum\");\n</code></pre></p> </li> </ol>"},{"location":"DSP/SUPPORT/notes/#applications","title":"APPLICATIONS","text":"<p>The support module is useful for:</p> <ul> <li> <p>Debugging: Visualize signals during algorithm development</p> </li> <li> <p>Analysis: Quick statistical analysis of signals</p> </li> <li> <p>Education: Demonstrate signal processing concepts</p> </li> <li> <p>Embedded Systems: Debug DSP algorithms without graphical displays</p> </li> <li> <p>Testing: Verify signal processing results</p> </li> <li> <p>Documentation: Generate ASCII plots for documentation</p> </li> </ul>"},{"location":"DSP/SUPPORT/notes/#notes_1","title":"NOTES","text":"<ul> <li> <p>All visualization functions output to <code>stdout</code> using <code>printf</code></p> </li> <li> <p>The ASCII plots are designed for monospace fonts</p> </li> <li> <p>For best results, use a terminal with at least 80 characters width</p> </li> <li> <p>Signal visualization uses linear interpolation for smooth plots</p> </li> <li> <p>Spectrum visualization uses bar charts optimized for frequency domain data</p> </li> </ul>"},{"location":"DSP/SUPPORT/test/","title":"TESTS","text":""},{"location":"DSP/SUPPORT/test/#tiny_view_testh","title":"tiny_view_test.h","text":"<pre><code>/**\n * @file tiny_view_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_view | test | header\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_view.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_view_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/SUPPORT/test/#tiny_view_testc","title":"tiny_view_test.c","text":"<pre><code>/**\n * @file tiny_view_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_view | test | source\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_view_test.h\"\n#include &lt;math.h&gt;\n\n/**\n * @brief Generate a test signal (sine wave with noise)\n */\nstatic void generate_test_signal(float *signal, int len, float freq, float sample_rate)\n{\n    for (int i = 0; i &lt; len; i++)\n    {\n        float t = (float)i / sample_rate;\n        signal[i] = sinf(2.0f * M_PI * freq * t) + 0.1f * sinf(2.0f * M_PI * freq * 3.0f * t);\n    }\n}\n\nvoid tiny_view_test(void)\n{\n    printf(\"========== TinyView Test ==========\\n\\n\");\n\n    const int signal_len = 64;\n    const float sample_rate = 1000.0f;\n    float signal[signal_len];\n\n    // Generate test signal\n    generate_test_signal(signal, signal_len, 10.0f, sample_rate);\n\n    // Test 1: Signal visualization\n    printf(\"Test 1: Signal Visualization\\n\");\n    printf(\"  Input: Sine wave signal (length=%d)\\n\", signal_len);\n    tiny_view_signal_f32(signal, signal_len, 64, 16, 0, 0, \"Test Signal: 10 Hz Sine Wave\");\n\n    // Test 2: Array printing\n    printf(\"Test 2: Array Printing\\n\");\n    printf(\"  Input: Signal array (length=%d)\\n\", signal_len);\n    tiny_view_array_f32(signal, signal_len, \"Test Signal\", 3, 8);\n\n    // Test 3: Statistics\n    printf(\"Test 3: Signal Statistics\\n\");\n    printf(\"  Input: Signal array (length=%d)\\n\", signal_len);\n    tiny_view_statistics_f32(signal, signal_len, \"Test Signal\");\n\n    // Test 4: Power spectrum visualization\n    printf(\"Test 4: Power Spectrum Visualization\\n\");\n    printf(\"  Input: Simulated power spectrum (length=128)\\n\");\n    float power_spectrum[128];\n    for (int i = 0; i &lt; 128; i++)\n    {\n        // Simulate power spectrum with peaks at 10 Hz and 30 Hz\n        float freq = (float)i * sample_rate / 256.0f;\n        if (fabsf(freq - 10.0f) &lt; 2.0f)\n        {\n            power_spectrum[i] = 100.0f - fabsf(freq - 10.0f) * 10.0f;\n        }\n        else if (fabsf(freq - 30.0f) &lt; 2.0f)\n        {\n            power_spectrum[i] = 50.0f - fabsf(freq - 30.0f) * 5.0f;\n        }\n        else\n        {\n            power_spectrum[i] = 1.0f + (float)(i % 5);\n        }\n    }\n    tiny_view_spectrum_f32(power_spectrum, 128, sample_rate, \"Power Spectrum: Peaks at 10 Hz and 30 Hz\");\n\n    printf(\"========================================\\n\");\n}\n</code></pre>"},{"location":"DSP/SUPPORT/test/#test-results","title":"TEST RESULTS","text":"<pre><code>========== TinyView Test ==========\n\nTest 1: Signal Visualization\n  Input: Sine wave signal (length=64)\n\nTest Signal: 10 Hz Sine Wave\nValue\n  1.07 |                                                                \n  0.93 |                 *****************                              \n  0.80 |            *****                 *****                         \n  0.66 |         ***                           ***                      \n  0.53 |       **                                 **                    \n  0.39 |     **                                     **                  \n  0.26 |   **                                         **                \n  0.12 | **                                             **              \n -0.01 |*                                                 **            \n -0.15 |                                                    *           \n -0.28 |                                                     **         \n -0.42 |                                                       **       \n -0.56 |                                                         **     \n -0.69 |                                                           ***  \n -0.83 |                                                              **\n -0.96 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-0.962, 1.069], Length: 64\n\nTest 2: Array Printing\n  Input: Signal array (length=64)\n\nTest Signal [64 elements]:\n  [  0]   0.000   0.082   0.162   0.241   0.317   0.390   0.459   0.523 \n  [  8]   0.582   0.635   0.683   0.725   0.762   0.793   0.819   0.840 \n  [ 16]   0.857   0.870   0.880   0.887   0.892   0.896   0.898   0.899 \n  [ 24]   0.900   0.900   0.900   0.899   0.898   0.896   0.892   0.887 \n  [ 32]   0.880   0.870   0.857   0.840   0.819   0.793   0.762   0.725 \n  [ 40]   0.683   0.635   0.582   0.523   0.459   0.390   0.317   0.241 \n  [ 48]   0.162   0.082  -0.000  -0.082  -0.162  -0.241  -0.317  -0.390 \n  [ 56]  -0.459  -0.523  -0.582  -0.635  -0.683  -0.725  -0.762  -0.793 \n\nTest 3: Signal Statistics\n  Input: Signal array (length=64)\n\n=== Statistics: Test Signal ===\n  Length:     64 samples\n  Min:        -0.792711 (at index 63)\n  Max:        0.900000 (at index 25)\n  Peak:       0.900000 (at index 25)\n  Mean:       0.414478\n  Std Dev:    0.530688\n  Variance:   0.281630\n  Range:      1.692711\n========================\n\nTest 4: Power Spectrum Visualization\n  Input: Simulated power spectrum (length=128)\n\nPower Spectrum: Peaks at 10 Hz and 30 Hz\nPower\n 82.81 |   |                                                            \n 77.36 |   |                                                            \n 71.90 |   |                                                            \n 66.45 |   |                                                            \n 61.00 |   |                                                            \n 55.54 |   |                                                            \n 50.09 |   |                                                            \n 44.63 |   |    |                                                       \n 39.18 |   |    |                                                       \n 33.72 |   |    |                                                       \n 28.27 |   |    |                                                       \n 22.82 |   |    |                                                       \n 17.36 |   |    |                                                       \n 11.91 |   |    |                                                       \n  6.45 |   ||   ||   ||   ||   ||   ||   ||   ||   ||   ||   ||   ||   |\n  1.00 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n       ----------------------------------------------------------------\n       0.0    31      62      94      125     156     188     219                          (Hz)\nRange: [1.000, 82.812], Nyquist: 500.0 Hz\n\n========================================\n</code></pre> <p>Warning</p> <p>As can be seen, the output through serial terminal is not quite accurate due to the limitation of character-based visualization. For more precise and detailed visualization, consider using graphical tools or libraries that support plotting and rendering of signals and spectra.</p>"},{"location":"DSP/TRANSFORM/DWT/code/","title":"CODE","text":""},{"location":"DSP/TRANSFORM/DWT/code/#tiny_dwth","title":"tiny_dwt.h","text":"<pre><code>/**\n * @file tiny_dwt.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_dwt | code | header\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n\n// tiny_dsp submodules\n#include \"tiny_conv.h\"     // Convolution\n#include \"tiny_resample.h\" // Resampling\n\n// ESP32 DSP Library for Acceleration\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n\n// Currently No ESP32 DSP Library for DWT\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /* DWT FILTERS */\n\n    typedef enum\n    {\n        TINY_WAVELET_DB1 = 0,\n        TINY_WAVELET_DB2,\n        TINY_WAVELET_DB3,\n        TINY_WAVELET_DB4,\n        TINY_WAVELET_DB5,\n        TINY_WAVELET_DB6,\n        TINY_WAVELET_DB7,\n        TINY_WAVELET_DB8,\n        TINY_WAVELET_DB9,\n        TINY_WAVELET_DB10,\n        TINY_WAVELET_COUNT\n    } tiny_wavelet_type_t;\n\n    extern const float *tiny_lo_d_table[TINY_WAVELET_COUNT];\n    extern const float *tiny_hi_d_table[TINY_WAVELET_COUNT];\n    extern const float *tiny_lo_r_table[TINY_WAVELET_COUNT];\n    extern const float *tiny_hi_r_table[TINY_WAVELET_COUNT];\n    extern const int tiny_filter_length_table[TINY_WAVELET_COUNT];\n\n#define TINY_WAVELET_GET_LO_D(w) tiny_lo_d_table[(w)]\n#define TINY_WAVELET_GET_HI_D(w) tiny_hi_d_table[(w)]\n#define TINY_WAVELET_GET_LO_R(w) tiny_lo_r_table[(w)]\n#define TINY_WAVELET_GET_HI_R(w) tiny_hi_r_table[(w)]\n#define TINY_WAVELET_GET_LEN(w) tiny_filter_length_table[(w)]\n\n    /* FUNCTION STATEMENTS */\n    /**\n     * @name tiny_dwt_decompose_f32\n     * @brief Perform single-level discrete wavelet decomposition\n     */\n    tiny_error_t tiny_dwt_decompose_f32(const float *input, int input_len,\n                                        tiny_wavelet_type_t wavelet,\n                                        float *cA, float *cD,\n                                        int *cA_len, int *cD_len);\n\n    /**\n     * @name tiny_dwt_reconstruct_f32\n     * @brief Perform single-level discrete wavelet reconstruction\n     */\n    tiny_error_t tiny_dwt_reconstruct_f32(const float *cA, const float *cD, int coeff_len,\n                                          tiny_wavelet_type_t wavelet,\n                                          float *output, int *output_len);\n\n    /**\n     * @name tiny_dwt_multilevel_decompose_f32\n     * @brief Perform multi-level DWT decomposition\n     */\n    tiny_error_t tiny_dwt_multilevel_decompose_f32(const float *input, int input_len,\n                                                   tiny_wavelet_type_t wavelet, int levels,\n                                                   float **cA_out, float **cD_out, int *len_out);\n\n    /**\n     * @name tiny_dwt_coeffs_process\n     * @brief Placeholder for user-defined coefficient processing\n     */\n    void tiny_dwt_coeffs_process(float *cA, float *cD, int cA_len, int cD_len, int levels);\n\n    /**\n     * @name tiny_dwt_multilevel_reconstruct_f32\n     * @brief Perform multi-level DWT reconstruction\n     */\n    tiny_error_t tiny_dwt_multilevel_reconstruct_f32(const float *cA_init, const float *cD_all,\n                                                     int final_len, tiny_wavelet_type_t wavelet, int levels,\n                                                     float *output);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/TRANSFORM/DWT/code/#tiny_dwtc","title":"tiny_dwt.c","text":"<pre><code>/**\n * @file tiny_dwt.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_dwt | code | source\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_dwt.h\" // TinyDWT Header\n\n/* DWT FILTERS */\nconst float db1_lo_d[2] = {\n    0.70710678f, 0.70710678f};\n\nconst float db1_hi_d[2] = {\n    -0.70710678f, 0.70710678f};\n\nconst float db1_lo_r[2] = {\n    0.70710678f, 0.70710678f};\n\nconst float db1_hi_r[2] = {\n    0.70710678f, -0.70710678f};\n\nconst float db2_lo_d[4] = {\n    -0.12940952f, 0.22414387f, 0.83651630f, 0.48296291f};\n\nconst float db2_hi_d[4] = {\n    -0.48296291f, 0.83651630f, -0.22414387f, -0.12940952f};\n\nconst float db2_lo_r[4] = {\n    0.48296291f, 0.83651630f, 0.22414387f, -0.12940952f};\n\nconst float db2_hi_r[4] = {\n    -0.12940952f, -0.22414387f, 0.83651630f, -0.48296291f};\n\nconst float db3_lo_d[6] = {\n    0.03522629f, -0.08544127f, -0.13501102f, 0.45987750f,\n    0.80689151f, 0.33267055f};\n\nconst float db3_hi_d[6] = {\n    -0.33267055f, 0.80689151f, -0.45987750f, -0.13501102f,\n    0.08544127f, 0.03522629f};\n\nconst float db3_lo_r[6] = {\n    0.33267055f, 0.80689151f, 0.45987750f, -0.13501102f,\n    -0.08544127f, 0.03522629f};\n\nconst float db3_hi_r[6] = {\n    0.03522629f, 0.08544127f, -0.13501102f, -0.45987750f,\n    0.80689151f, -0.33267055f};\n\nconst float db4_lo_d[8] = {\n    -0.01059740f, 0.03288301f, 0.03084138f, -0.18703481f,\n    -0.02798377f, 0.63088077f, 0.71484657f, 0.23037781f};\n\nconst float db4_hi_d[8] = {\n    -0.23037781f, 0.71484657f, -0.63088077f, -0.02798377f,\n    0.18703481f, 0.03084138f, -0.03288301f, -0.01059740f};\n\nconst float db4_lo_r[8] = {\n    0.23037781f, 0.71484657f, 0.63088077f, -0.02798377f,\n    -0.18703481f, 0.03084138f, 0.03288301f, -0.01059740f};\n\nconst float db4_hi_r[8] = {\n    -0.01059740f, -0.03288301f, 0.03084138f, 0.18703481f,\n    -0.02798377f, -0.63088077f, 0.71484657f, -0.23037781f};\n\nconst float db5_lo_d[10] = {\n    0.00333573f, -0.01258075f, -0.00624149f, 0.07757149f,\n    -0.03224487f, -0.24229489f, 0.13842815f, 0.72430853f,\n    0.60382927f, 0.16010240f};\n\nconst float db5_hi_d[10] = {\n    -0.16010240f, 0.60382927f, -0.72430853f, 0.13842815f,\n    0.24229489f, -0.03224487f, -0.07757149f, -0.00624149f,\n    0.01258075f, 0.00333573f};\n\nconst float db5_lo_r[10] = {\n    0.16010240f, 0.60382927f, 0.72430853f, 0.13842815f,\n    -0.24229489f, -0.03224487f, 0.07757149f, -0.00624149f,\n    -0.01258075f, 0.00333573f};\n\nconst float db5_hi_r[10] = {\n    0.00333573f, 0.01258075f, -0.00624149f, -0.07757149f,\n    -0.03224487f, 0.24229489f, 0.13842815f, -0.72430853f,\n    0.60382927f, -0.16010240f};\n\nconst float db6_lo_d[12] = {\n    -0.00107730f, 0.00477726f, 0.00055384f, -0.03158204f,\n    0.02752287f, 0.09750161f, -0.12976687f, -0.22626469f,\n    0.31525035f, 0.75113391f, 0.49462389f, 0.11154074f};\n\nconst float db6_hi_d[12] = {\n    -0.11154074f, 0.49462389f, -0.75113391f, 0.31525035f,\n    0.22626469f, -0.12976687f, -0.09750161f, 0.02752287f,\n    0.03158204f, 0.00055384f, -0.00477726f, -0.00107730f};\n\nconst float db6_lo_r[12] = {\n    0.11154074f, 0.49462389f, 0.75113391f, 0.31525035f,\n    -0.22626469f, -0.12976687f, 0.09750161f, 0.02752287f,\n    -0.03158204f, 0.00055384f, 0.00477726f, -0.00107730f};\n\nconst float db6_hi_r[12] = {\n    -0.00107730f, -0.00477726f, 0.00055384f, 0.03158204f,\n    0.02752287f, -0.09750161f, -0.12976687f, 0.22626469f,\n    0.31525035f, -0.75113391f, 0.49462389f, -0.11154074f};\n\nconst float db7_lo_d[14] = {\n    0.00035371f, -0.00180164f, 0.00042958f, 0.01255100f,\n    -0.01657454f, -0.03802994f, 0.08061261f, 0.07130922f,\n    -0.22403618f, -0.14390600f, 0.46978229f, 0.72913209f,\n    0.39653932f, 0.07785205f};\n\nconst float db7_hi_d[14] = {\n    -0.07785205f, 0.39653932f, -0.72913209f, 0.46978229f,\n    0.14390600f, -0.22403618f, -0.07130922f, 0.08061261f,\n    0.03802994f, -0.01657454f, -0.01255100f, 0.00042958f,\n    0.00180164f, 0.00035371f};\n\nconst float db7_lo_r[14] = {\n    0.07785205f, 0.39653932f, 0.72913209f, 0.46978229f,\n    -0.14390600f, -0.22403618f, 0.07130922f, 0.08061261f,\n    -0.03802994f, -0.01657454f, 0.01255100f, 0.00042958f,\n    -0.00180164f, 0.00035371f};\n\nconst float db7_hi_r[14] = {\n    0.00035371f, 0.00180164f, 0.00042958f, -0.01255100f,\n    -0.01657454f, 0.03802994f, 0.08061261f, -0.07130922f,\n    -0.22403618f, 0.14390600f, 0.46978229f, -0.72913209f,\n    0.39653932f, -0.07785205f};\n\nconst float db8_lo_d[16] = {\n    -0.00011748f, 0.00067545f, -0.00039174f, -0.00487035f,\n    0.00874609f, 0.01398103f, -0.04408825f, -0.01736930f,\n    0.12874743f, 0.00047248f, -0.28401554f, -0.01582911f,\n    0.58535468f, 0.67563074f, 0.31287159f, 0.05441584f};\n\nconst float db8_hi_d[16] = {\n    -0.05441584f, 0.31287159f, -0.67563074f, 0.58535468f,\n    0.01582911f, -0.28401554f, -0.00047248f, 0.12874743f,\n    0.01736930f, -0.04408825f, -0.01398103f, 0.00874609f,\n    0.00487035f, -0.00039174f, -0.00067545f, -0.00011748f};\n\nconst float db8_lo_r[16] = {\n    0.05441584f, 0.31287159f, 0.67563074f, 0.58535468f,\n    -0.01582911f, -0.28401554f, 0.00047248f, 0.12874743f,\n    -0.01736930f, -0.04408825f, 0.01398103f, 0.00874609f,\n    -0.00487035f, -0.00039174f, 0.00067545f, -0.00011748f};\n\nconst float db8_hi_r[16] = {\n    -0.00011748f, -0.00067545f, -0.00039174f, 0.00487035f,\n    0.00874609f, -0.01398103f, -0.04408825f, 0.01736930f,\n    0.12874743f, -0.00047248f, -0.28401554f, 0.01582911f,\n    0.58535468f, -0.67563074f, 0.31287159f, -0.05441584f};\n\nconst float db9_lo_d[18] = {\n    0.00003935f, -0.00025196f, 0.00023039f, 0.00184765f,\n    -0.00428150f, -0.00472320f, 0.02236166f, 0.00025095f,\n    -0.06763283f, 0.03072568f, 0.14854075f, -0.09684078f,\n    -0.29327378f, 0.13319739f, 0.65728808f, 0.60482312f,\n    0.24383467f, 0.03807795f};\n\nconst float db9_hi_d[18] = {\n    -0.03807795f, 0.24383467f, -0.60482312f, 0.65728808f,\n    -0.13319739f, -0.29327378f, 0.09684078f, 0.14854075f,\n    -0.03072568f, -0.06763283f, -0.00025095f, 0.02236166f,\n    0.00472320f, -0.00428150f, -0.00184765f, 0.00023039f,\n    0.00025196f, 0.00003935f};\n\nconst float db9_lo_r[18] = {\n    0.03807795f, 0.24383467f, 0.60482312f, 0.65728808f,\n    0.13319739f, -0.29327378f, -0.09684078f, 0.14854075f,\n    0.03072568f, -0.06763283f, 0.00025095f, 0.02236166f,\n    -0.00472320f, -0.00428150f, 0.00184765f, 0.00023039f,\n    -0.00025196f, 0.00003935f};\n\nconst float db9_hi_r[18] = {\n    0.00003935f, 0.00025196f, 0.00023039f, -0.00184765f,\n    -0.00428150f, 0.00472320f, 0.02236166f, -0.00025095f,\n    -0.06763283f, -0.03072568f, 0.14854075f, 0.09684078f,\n    -0.29327378f, -0.13319739f, 0.65728808f, -0.60482312f,\n    0.24383467f, -0.03807795f};\n\nconst float db10_lo_d[20] = {\n    -0.00001326f, 0.00009359f, -0.00011647f, -0.00068586f,\n    0.00199241f, 0.00139535f, -0.01073318f, 0.00360655f,\n    0.03321267f, -0.02945754f, -0.07139415f, 0.09305736f,\n    0.12736934f, -0.19594627f, -0.24984642f, 0.28117234f,\n    0.68845904f, 0.52720119f, 0.18817680f, 0.02667006f};\n\nconst float db10_hi_d[20] = {\n    -0.02667006f, 0.18817680f, -0.52720119f, 0.68845904f,\n    -0.28117234f, -0.24984642f, 0.19594627f, 0.12736934f,\n    -0.09305736f, -0.07139415f, 0.02945754f, 0.03321267f,\n    -0.00360655f, -0.01073318f, -0.00139535f, 0.00199241f,\n    0.00068586f, -0.00011647f, -0.00009359f, -0.00001326f};\n\nconst float db10_lo_r[20] = {\n    0.02667006f, 0.18817680f, 0.52720119f, 0.68845904f,\n    0.28117234f, -0.24984642f, -0.19594627f, 0.12736934f,\n    0.09305736f, -0.07139415f, -0.02945754f, 0.03321267f,\n    0.00360655f, -0.01073318f, 0.00139535f, 0.00199241f,\n    -0.00068586f, -0.00011647f, 0.00009359f, -0.00001326f};\n\nconst float db10_hi_r[20] = {\n    -0.00001326f, -0.00009359f, -0.00011647f, 0.00068586f,\n    0.00199241f, -0.00139535f, -0.01073318f, -0.00360655f,\n    0.03321267f, 0.02945754f, -0.07139415f, -0.09305736f,\n    0.12736934f, 0.19594627f, -0.24984642f, -0.28117234f,\n    0.68845904f, -0.52720119f, 0.18817680f, -0.02667006f};\n\n// Lookup tables for decomposition and reconstruction filters\nconst float *tiny_lo_d_table[TINY_WAVELET_COUNT] = {\n    db1_lo_d, db2_lo_d, db3_lo_d, db4_lo_d, db5_lo_d,\n    db6_lo_d, db7_lo_d, db8_lo_d, db9_lo_d, db10_lo_d};\n\nconst float *tiny_hi_d_table[TINY_WAVELET_COUNT] = {\n    db1_hi_d, db2_hi_d, db3_hi_d, db4_hi_d, db5_hi_d,\n    db6_hi_d, db7_hi_d, db8_hi_d, db9_hi_d, db10_hi_d};\n\nconst float *tiny_lo_r_table[TINY_WAVELET_COUNT] = {\n    db1_lo_r, db2_lo_r, db3_lo_r, db4_lo_r, db5_lo_r,\n    db6_lo_r, db7_lo_r, db8_lo_r, db9_lo_r, db10_lo_r};\n\nconst float *tiny_hi_r_table[TINY_WAVELET_COUNT] = {\n    db1_hi_r, db2_hi_r, db3_hi_r, db4_hi_r, db5_hi_r,\n    db6_hi_r, db7_hi_r, db8_hi_r, db9_hi_r, db10_hi_r};\n\nconst int tiny_filter_length_table[TINY_WAVELET_COUNT] = {\n    2, 4, 6, 8, 10,\n    12, 14, 16, 18, 20};\n\n/* FUNCTION DEFINITIONS */\n\n/**\n * @name tiny_dwt_decompose_f32\n * @brief Perform single-level discrete wavelet decomposition\n */\ntiny_error_t tiny_dwt_decompose_f32(const float *input, int input_len,\n                                    tiny_wavelet_type_t wavelet,\n                                    float *cA, float *cD,\n                                    int *cA_len, int *cD_len)\n{\n    if (!input || !cA || !cD || !cA_len || !cD_len)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    int filter_len = TINY_WAVELET_GET_LEN(wavelet);\n    const float *lo_d = TINY_WAVELET_GET_LO_D(wavelet);\n    const float *hi_d = TINY_WAVELET_GET_HI_D(wavelet);\n\n    // TINY_CONV_CENTER mode internally performs FULL convolution first\n    // Need buffer size: input_len + filter_len - 1 for FULL convolution\n    int conv_full_len = input_len + filter_len - 1;\n    float *temp_conv_full = (float *)calloc(conv_full_len, sizeof(float));\n    if (!temp_conv_full)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    // Temporary buffer for CENTER mode output (input_len samples)\n    float *temp_conv = (float *)calloc(input_len, sizeof(float));\n    if (!temp_conv)\n    {\n        free(temp_conv_full);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Low-pass filter convolution\n    tiny_error_t err = tiny_conv_ex_f32(input, input_len, lo_d, filter_len, temp_conv_full,\n                                        TINY_PADDING_SYMMETRIC, TINY_CONV_FULL);\n    if (err != TINY_OK)\n    {\n        free(temp_conv_full);\n        free(temp_conv);\n        return err;\n    }\n\n    // Extract center portion (equivalent to TINY_CONV_CENTER mode)\n    int center_start = (filter_len - 1) / 2;\n    for (int i = 0; i &lt; input_len; i++)\n    {\n        temp_conv[i] = temp_conv_full[center_start + i];\n    }\n\n    err = tiny_downsample_skip_f32(temp_conv, input_len, cA, cA_len, 1, 2);\n    if (err != TINY_OK)\n    {\n        free(temp_conv_full);\n        free(temp_conv);\n        return err;\n    }\n\n    // High-pass filter convolution\n    err = tiny_conv_ex_f32(input, input_len, hi_d, filter_len, temp_conv_full,\n                           TINY_PADDING_SYMMETRIC, TINY_CONV_FULL);\n    if (err != TINY_OK)\n    {\n        free(temp_conv_full);\n        free(temp_conv);\n        return err;\n    }\n\n    // Extract center portion\n    for (int i = 0; i &lt; input_len; i++)\n    {\n        temp_conv[i] = temp_conv_full[center_start + i];\n    }\n\n    err = tiny_downsample_skip_f32(temp_conv, input_len, cD, cD_len, 1, 2);\n    if (err != TINY_OK)\n    {\n        free(temp_conv_full);\n        free(temp_conv);\n        return err;\n    }\n\n    free(temp_conv_full);\n    free(temp_conv);\n    return TINY_OK;\n}\n\n/**\n * @name tiny_dwt_reconstruct_f32\n * @brief Perform single-level discrete wavelet reconstruction\n */\ntiny_error_t tiny_dwt_reconstruct_f32(const float *cA, const float *cD, int coeff_len,\n                                      tiny_wavelet_type_t wavelet,\n                                      float *output, int *output_len)\n{\n    if (!cA || !cD || !output || !output_len)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    int filter_len = TINY_WAVELET_GET_LEN(wavelet);\n    const float *lo_r = TINY_WAVELET_GET_LO_R(wavelet);\n    const float *hi_r = TINY_WAVELET_GET_HI_R(wavelet);\n\n    int up_len = coeff_len * 2;\n    int conv_len = up_len + filter_len - 1;\n    // Correct offset: for FULL convolution, center extraction starts at (filter_len - 1) / 2\n    // This aligns with TINY_CONV_CENTER mode logic\n    int offset = (filter_len - 1) / 2;\n\n    // Allocate memory for upsampled signals (only need up_len, not conv_len)\n    float *upA = (float *)calloc(up_len, sizeof(float));\n    float *upD = (float *)calloc(up_len, sizeof(float));\n    if (!upA || !upD)\n    {\n        free(upA);\n        free(upD);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    tiny_error_t err = tiny_upsample_zero_f32(cA, coeff_len, upA, up_len);\n    if (err != TINY_OK)\n    {\n        free(upA);\n        free(upD);\n        return err;\n    }\n    err = tiny_upsample_zero_f32(cD, coeff_len, upD, up_len);\n    if (err != TINY_OK)\n    {\n        free(upA);\n        free(upD);\n        return err;\n    }\n\n    // Allocate memory for convolution results (FULL mode output length)\n    float *recA = (float *)calloc(conv_len, sizeof(float));\n    float *recD = (float *)calloc(conv_len, sizeof(float));\n    if (!recA || !recD)\n    {\n        free(upA);\n        free(upD);\n        free(recA);\n        free(recD);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    err = tiny_conv_ex_f32(upA, up_len, lo_r, filter_len, recA,\n                           TINY_PADDING_SYMMETRIC, TINY_CONV_FULL);\n    if (err != TINY_OK)\n        goto cleanup;\n\n    err = tiny_conv_ex_f32(upD, up_len, hi_r, filter_len, recD,\n                           TINY_PADDING_SYMMETRIC, TINY_CONV_FULL);\n    if (err != TINY_OK)\n        goto cleanup;\n\n    // Extract center portion from FULL convolution result\n    // With offset = (filter_len - 1) / 2, we can safely extract up_len samples\n    // because: offset + up_len - 1 = (filter_len - 1) / 2 + up_len - 1\n    //         = (filter_len - 1) / 2 + up_len - 1\n    //         &lt; (filter_len - 1) + up_len - 1\n    //         = filter_len + up_len - 2\n    //         &lt; up_len + filter_len - 1 = conv_len\n    for (int i = 0; i &lt; up_len; i++)\n    {\n        int idx = i + offset;\n        if (idx &lt; conv_len)\n        {\n            output[i] = recA[idx] + recD[idx];\n        }\n        else\n        {\n            // This shouldn't happen with correct offset, but handle gracefully\n            output[i] = 0.0f;\n        }\n    }\n\n    *output_len = up_len;\n\ncleanup:\n    free(upA);\n    free(upD);\n    free(recA);\n    free(recD);\n    return err;\n}\n\n/**\n * @name tiny_dwt_multilevel_decompose_f32\n * @brief Perform multi-level DWT decomposition\n */\ntiny_error_t tiny_dwt_multilevel_decompose_f32(const float *input, int input_len,\n                                               tiny_wavelet_type_t wavelet, int levels,\n                                               float **cA_out, float **cD_out, int *len_out)\n{\n    if (!input || !cA_out || !cD_out || !len_out || levels &lt;= 0)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    float *current = (float *)malloc(sizeof(float) * input_len);\n    if (!current)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    memcpy(current, input, sizeof(float) * input_len);\n\n    float *cD_all = (float *)malloc(sizeof(float) * input_len);\n    int *cD_lens = (int *)malloc(sizeof(int) * levels);\n    int cD_pos = 0;\n\n    int current_len = input_len;\n    for (int l = 0; l &lt; levels; l++)\n    {\n        int cA_len = 0, cD_len = 0;\n        float *cA_temp = (float *)malloc(sizeof(float) * current_len);\n        float *cD_temp = (float *)malloc(sizeof(float) * current_len);\n        if (!cA_temp || !cD_temp)\n        {\n            free(cA_temp);\n            free(cD_temp);\n            free(current);\n            free(cD_all);\n            free(cD_lens);\n            return TINY_ERR_DSP_MEMORY_ALLOC;\n        }\n\n        tiny_error_t err = tiny_dwt_decompose_f32(current, current_len, wavelet, cA_temp, cD_temp, &amp;cA_len, &amp;cD_len);\n        if (err != TINY_OK)\n        {\n            free(current);\n            free(cD_all);\n            free(cD_lens);\n            free(cA_temp);\n            free(cD_temp);\n            return err;\n        }\n\n        memcpy(cD_all + cD_pos, cD_temp, sizeof(float) * cD_len);\n        cD_lens[l] = cD_len;\n        cD_pos += cD_len;\n\n        free(current);\n        current = cA_temp;\n        current_len = cA_len;\n        free(cD_temp);\n    }\n\n    *cA_out = current;\n    *cD_out = cD_all;\n    *len_out = current_len;\n\n    free(cD_lens); // optional if not passed out\n    return TINY_OK;\n}\n\n/**\n * @name tiny_dwt_coeffs_process\n * @brief Placeholder for user-defined coefficient processing\n */\nvoid tiny_dwt_coeffs_process(float *cA, float *cD, int cA_len, int cD_len, int levels)\n{\n    // Currently does nothing, can be extended by user\n    (void)cA;\n    (void)cD;\n    (void)cA_len;\n    (void)cD_len;\n    (void)levels;\n}\n\n/**\n * @name tiny_dwt_multilevel_reconstruct_f32\n * @brief Perform multi-level DWT reconstruction\n */\ntiny_error_t tiny_dwt_multilevel_reconstruct_f32(const float *cA_init, const float *cD_all,\n                                                 int final_len, tiny_wavelet_type_t wavelet, int levels,\n                                                 float *output)\n{\n    if (!cA_init || !cD_all || !output)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    float *current = (float *)malloc(sizeof(float) * final_len);\n    if (!current)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    memcpy(current, cA_init, sizeof(float) * final_len);\n\n    int cA_len = final_len;\n    int cD_pos = 0;\n\n    for (int l = 0; l &lt; levels; l++)\n    {\n        int cD_len = cA_len;\n        float *cD = (float *)malloc(sizeof(float) * cD_len);\n        if (!cD)\n        {\n            free(current);\n            return TINY_ERR_DSP_MEMORY_ALLOC;\n        }\n\n        memcpy(cD, cD_all + cD_pos, sizeof(float) * cD_len);\n        cD_pos += cD_len;\n\n        int out_len = 0;\n        float *recon = (float *)malloc(sizeof(float) * cD_len * 2);\n        if (!recon)\n        {\n            free(current);\n            free(cD);\n            return TINY_ERR_DSP_MEMORY_ALLOC;\n        }\n\n        tiny_error_t err = tiny_dwt_reconstruct_f32(current, cD, cD_len, wavelet, recon, &amp;out_len);\n        free(current);\n        free(cD);\n        if (err != TINY_OK)\n        {\n            free(recon);\n            return err;\n        }\n\n        current = recon;\n        cA_len = out_len;\n    }\n\n    memcpy(output, current, sizeof(float) * cA_len);\n    free(current);\n\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/TRANSFORM/DWT/notes/","title":"NOTES","text":"<p>Note</p> <p>Discrete Wavelet Transform (DWT) is a powerful signal processing technique that decomposes signals into different frequency components at multiple resolution levels. Unlike FFT which provides global frequency information, DWT provides both time and frequency localization, making it ideal for analyzing non-stationary signals, denoising, compression, and feature extraction.</p>"},{"location":"DSP/TRANSFORM/DWT/notes/#dwt-overview","title":"DWT OVERVIEW","text":""},{"location":"DSP/TRANSFORM/DWT/notes/#mathematical-principle","title":"Mathematical Principle","text":"<p>The Discrete Wavelet Transform decomposes a signal into approximation (low-frequency) and detail (high-frequency) coefficients using a pair of filters: a low-pass filter (scaling function) and a high-pass filter (wavelet function).</p> <p>Single-Level Decomposition:</p> \\[ cA[n] = \\sum_{k} x[k] \\cdot h_0[2n - k] \\] \\[ cD[n] = \\sum_{k} x[k] \\cdot h_1[2n - k] \\] <p>Where:</p> <ul> <li> <p>\\( x[k] \\) is the input signal</p> </li> <li> <p>\\( h_0 \\) is the low-pass decomposition filter</p> </li> <li> <p>\\( h_1 \\) is the high-pass decomposition filter</p> </li> <li> <p>\\( cA[n] \\) are approximation coefficients (low-frequency)</p> </li> <li> <p>\\( cD[n] \\) are detail coefficients (high-frequency)</p> </li> </ul> <p>Output Length:</p> \\[ L_{cA} = L_{cD} = \\left\\lceil \\frac{L_{input}}{2} \\right\\rceil \\] <p>Reconstruction:</p> \\[ x[n] = \\sum_{k} (cA[k] \\cdot g_0[n - 2k] + cD[k] \\cdot g_1[n - 2k]) \\] <p>Where:</p> <ul> <li> <p>\\( g_0 \\) is the low-pass reconstruction filter</p> </li> <li> <p>\\( g_1 \\) is the high-pass reconstruction filter</p> </li> </ul>"},{"location":"DSP/TRANSFORM/DWT/notes/#wavelet-types","title":"WAVELET TYPES","text":"<p>The library supports Daubechies wavelets (DB1 through DB10):</p> <ul> <li>DB1 (Haar): Simplest wavelet, 2-tap filter, good for edge detection</li> <li>DB2: 4-tap filter, better frequency resolution than DB1</li> <li>DB3: 6-tap filter, smoother than DB2</li> <li>DB4: 8-tap filter, commonly used, good balance</li> <li>DB5-DB10: Higher order wavelets with better frequency resolution but longer filters</li> </ul> <p>Filter Length:</p> \\[ L_{filter} = 2 \\times N \\] <p>Where \\( N \\) is the wavelet order (DB1: N=1, DB2: N=2, ..., DB10: N=10).</p>"},{"location":"DSP/TRANSFORM/DWT/notes/#single-level-dwt","title":"SINGLE-LEVEL DWT","text":""},{"location":"DSP/TRANSFORM/DWT/notes/#tiny_dwt_decompose_f32","title":"tiny_dwt_decompose_f32","text":"<pre><code>/**\n * @name tiny_dwt_decompose_f32\n * @brief Perform single-level discrete wavelet decomposition\n * @param input Input signal array\n * @param input_len Length of the input signal\n * @param wavelet Wavelet type (DB1-DB10)\n * @param cA Output array for approximation coefficients\n * @param cD Output array for detail coefficients\n * @param cA_len Output length of approximation coefficients\n * @param cD_len Output length of detail coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_dwt_decompose_f32(const float *input, int input_len,\n                                    tiny_wavelet_type_t wavelet,\n                                    float *cA, float *cD,\n                                    int *cA_len, int *cD_len);\n</code></pre> <p>Description: </p> <p>Performs single-level discrete wavelet decomposition, splitting the input signal into approximation (low-frequency) and detail (high-frequency) coefficients.</p> <p>Features:</p> <ul> <li> <p>Uses symmetric padding to handle boundaries</p> </li> <li> <p>Performs convolution with low-pass and high-pass filters</p> </li> <li> <p>Downsamples by factor of 2 to maintain critical sampling</p> </li> <li> <p>Supports all Daubechies wavelets (DB1-DB10)</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input signal array.</p> </li> <li> <p><code>input_len</code>: Length of the input signal.</p> </li> <li> <p><code>wavelet</code>: Wavelet type from <code>tiny_wavelet_type_t</code> enum:</p> </li> <li> <p><code>TINY_WAVELET_DB1</code> through <code>TINY_WAVELET_DB10</code></p> </li> <li> <p><code>cA</code>: Pointer to output array for approximation coefficients. Size should be at least <code>(input_len + 1) / 2</code>.</p> </li> <li> <p><code>cD</code>: Pointer to output array for detail coefficients. Size should be at least <code>(input_len + 1) / 2</code>.</p> </li> <li> <p><code>cA_len</code>: Pointer to output variable for approximation coefficients length.</p> </li> <li> <p><code>cD_len</code>: Pointer to output variable for detail coefficients length.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Note: </p> <p>The output coefficient arrays are approximately half the length of the input signal. Boundary effects may occur near the signal edges due to convolution operations.</p>"},{"location":"DSP/TRANSFORM/DWT/notes/#tiny_dwt_reconstruct_f32","title":"tiny_dwt_reconstruct_f32","text":"<pre><code>/**\n * @name tiny_dwt_reconstruct_f32\n * @brief Perform single-level discrete wavelet reconstruction\n * @param cA Approximation coefficients array\n * @param cD Detail coefficients array\n * @param coeff_len Length of coefficient arrays (cA and cD must have same length)\n * @param wavelet Wavelet type (DB1-DB10)\n * @param output Output array for reconstructed signal\n * @param output_len Output length of reconstructed signal\n * @return tiny_error_t\n */\ntiny_error_t tiny_dwt_reconstruct_f32(const float *cA, const float *cD, int coeff_len,\n                                      tiny_wavelet_type_t wavelet,\n                                      float *output, int *output_len);\n</code></pre> <p>Description: </p> <p>Performs single-level discrete wavelet reconstruction, combining approximation and detail coefficients to reconstruct the original signal.</p> <p>Features:</p> <ul> <li> <p>Upsamples coefficients by factor of 2</p> </li> <li> <p>Performs convolution with reconstruction filters</p> </li> <li> <p>Combines low-pass and high-pass reconstruction results</p> </li> <li> <p>Perfect reconstruction (within numerical precision) for center region</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>cA</code>: Pointer to approximation coefficients array.</p> </li> <li> <p><code>cD</code>: Pointer to detail coefficients array.</p> </li> <li> <p><code>coeff_len</code>: Length of both coefficient arrays (must be equal).</p> </li> <li> <p><code>wavelet</code>: Wavelet type used for decomposition.</p> </li> <li> <p><code>output</code>: Pointer to output array for reconstructed signal. Size should be at least <code>coeff_len * 2</code>.</p> </li> <li> <p><code>output_len</code>: Pointer to output variable for reconstructed signal length.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Note: </p> <p>The reconstructed signal length is <code>coeff_len * 2</code>. Boundary effects may occur, especially near signal edges. The center region typically has very high reconstruction accuracy.</p>"},{"location":"DSP/TRANSFORM/DWT/notes/#multi-level-dwt","title":"MULTI-LEVEL DWT","text":""},{"location":"DSP/TRANSFORM/DWT/notes/#tiny_dwt_multilevel_decompose_f32","title":"tiny_dwt_multilevel_decompose_f32","text":"<pre><code>/**\n * @name tiny_dwt_multilevel_decompose_f32\n * @brief Perform multi-level DWT decomposition\n * @param input Input signal array\n * @param input_len Length of the input signal\n * @param wavelet Wavelet type (DB1-DB10)\n * @param levels Number of decomposition levels\n * @param cA_out Output pointer for final approximation coefficients\n * @param cD_out Output pointer for all detail coefficients (concatenated)\n * @param len_out Output length of final approximation coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_dwt_multilevel_decompose_f32(const float *input, int input_len,\n                                               tiny_wavelet_type_t wavelet, int levels,\n                                               float **cA_out, float **cD_out, int *len_out);\n</code></pre> <p>Description: </p> <p>Performs multi-level discrete wavelet decomposition, recursively decomposing the approximation coefficients to create a hierarchical representation of the signal.</p> <p>Features:</p> <ul> <li> <p>Recursive decomposition of approximation coefficients</p> </li> <li> <p>Stores all detail coefficients from all levels</p> </li> <li> <p>Returns final approximation and concatenated detail coefficients</p> </li> <li> <p>Memory is allocated internally and must be freed by caller</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input signal array.</p> </li> <li> <p><code>input_len</code>: Length of the input signal.</p> </li> <li> <p><code>wavelet</code>: Wavelet type from <code>tiny_wavelet_type_t</code> enum.</p> </li> <li> <p><code>levels</code>: Number of decomposition levels. Must be positive.</p> </li> <li> <p><code>cA_out</code>: Pointer to output pointer for final approximation coefficients. Memory is allocated internally.</p> </li> <li> <p><code>cD_out</code>: Pointer to output pointer for all detail coefficients (concatenated from all levels). Memory is allocated internally.</p> </li> <li> <p><code>len_out</code>: Pointer to output variable for final approximation coefficients length.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Memory Management: </p> <p>The function allocates memory for <code>cA_out</code> and <code>cD_out</code>. The caller is responsible for freeing this memory using <code>free()</code>.</p> <p>Coefficient Structure:</p> <p>For N-level decomposition:</p> <ul> <li> <p>Level 1: cA1 (length \u2248 input_len/2), cD1 (length \u2248 input_len/2)</p> </li> <li> <p>Level 2: cA2 (length \u2248 input_len/4), cD2 (length \u2248 input_len/4)</p> </li> <li> <p>...</p> </li> <li> <p>Level N: cAN (length \u2248 input_len/2^N), cDN (length \u2248 input_len/2^N)</p> </li> </ul> <p>The <code>cD_out</code> array contains: [cD1, cD2, ..., cDN] concatenated.</p>"},{"location":"DSP/TRANSFORM/DWT/notes/#tiny_dwt_multilevel_reconstruct_f32","title":"tiny_dwt_multilevel_reconstruct_f32","text":"<pre><code>/**\n * @name tiny_dwt_multilevel_reconstruct_f32\n * @brief Perform multi-level DWT reconstruction\n * @param cA_init Final approximation coefficients from multi-level decomposition\n * @param cD_all All detail coefficients (concatenated from all levels)\n * @param final_len Length of final approximation coefficients\n * @param wavelet Wavelet type (DB1-DB10)\n * @param levels Number of decomposition levels\n * @param output Output array for reconstructed signal\n * @return tiny_error_t\n */\ntiny_error_t tiny_dwt_multilevel_reconstruct_f32(const float *cA_init, const float *cD_all,\n                                                 int final_len, tiny_wavelet_type_t wavelet, int levels,\n                                                 float *output);\n</code></pre> <p>Description: </p> <p>Performs multi-level discrete wavelet reconstruction, recursively reconstructing from the final approximation and all detail coefficients.</p> <p>Features:</p> <ul> <li> <p>Recursive reconstruction starting from final approximation</p> </li> <li> <p>Reconstructs each level using corresponding detail coefficients</p> </li> <li> <p>Output length matches original input length</p> </li> <li> <p>Boundary effects accumulate with decomposition levels</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>cA_init</code>: Pointer to final approximation coefficients from multi-level decomposition.</p> </li> <li> <p><code>cD_all</code>: Pointer to all detail coefficients concatenated from all levels.</p> </li> <li> <p><code>final_len</code>: Length of final approximation coefficients.</p> </li> <li> <p><code>wavelet</code>: Wavelet type used for decomposition.</p> </li> <li> <p><code>levels</code>: Number of decomposition levels.</p> </li> <li> <p><code>output</code>: Pointer to output array for reconstructed signal. Size should be at least original input length.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Note: </p> <p>The <code>cD_all</code> array should contain detail coefficients in order: [cD_level1, cD_level2, ..., cD_levelN]. Boundary effects become more pronounced with increasing decomposition levels.</p>"},{"location":"DSP/TRANSFORM/DWT/notes/#coefficient-processing","title":"COEFFICIENT PROCESSING","text":""},{"location":"DSP/TRANSFORM/DWT/notes/#tiny_dwt_coeffs_process","title":"tiny_dwt_coeffs_process","text":"<pre><code>/**\n * @name tiny_dwt_coeffs_process\n * @brief Placeholder for user-defined coefficient processing\n * @param cA Approximation coefficients\n * @param cD Detail coefficients\n * @param cA_len Length of approximation coefficients\n * @param cD_len Length of detail coefficients\n * @param levels Number of decomposition levels\n */\nvoid tiny_dwt_coeffs_process(float *cA, float *cD, int cA_len, int cD_len, int levels);\n</code></pre> <p>Description: </p> <p>Placeholder function for user-defined coefficient processing. This function can be extended by users to implement denoising, thresholding, or other coefficient manipulation operations.</p> <p>Parameters:</p> <ul> <li> <p><code>cA</code>: Pointer to approximation coefficients (can be modified).</p> </li> <li> <p><code>cD</code>: Pointer to detail coefficients (can be modified).</p> </li> <li> <p><code>cA_len</code>: Length of approximation coefficients.</p> </li> <li> <p><code>cD_len</code>: Length of detail coefficients.</p> </li> <li> <p><code>levels</code>: Number of decomposition levels.</p> </li> </ul> <p>Note: </p> <p>Currently this function does nothing. Users can modify it to implement custom processing such as:</p> <ul> <li> <p>Hard/soft thresholding for denoising</p> </li> <li> <p>Coefficient selection for compression</p> </li> <li> <p>Feature extraction</p> </li> <li> <p>Anomaly detection</p> </li> </ul>"},{"location":"DSP/TRANSFORM/DWT/notes/#usage-workflow","title":"USAGE WORKFLOW","text":""},{"location":"DSP/TRANSFORM/DWT/notes/#single-level-dwt-workflow","title":"Single-Level DWT Workflow","text":"<ol> <li> <p>Decompose Signal:    <pre><code>float input[64];\nfloat cA[32], cD[32];\nint cA_len, cD_len;\ntiny_dwt_decompose_f32(input, 64, TINY_WAVELET_DB4, cA, cD, &amp;cA_len, &amp;cD_len);\n</code></pre></p> </li> <li> <p>Process Coefficients (optional):    <pre><code>// Apply thresholding, denoising, etc.\n</code></pre></p> </li> <li> <p>Reconstruct Signal:    <pre><code>float output[64];\nint output_len;\ntiny_dwt_reconstruct_f32(cA, cD, cA_len, TINY_WAVELET_DB4, output, &amp;output_len);\n</code></pre></p> </li> </ol>"},{"location":"DSP/TRANSFORM/DWT/notes/#multi-level-dwt-workflow","title":"Multi-Level DWT Workflow","text":"<ol> <li> <p>Multi-Level Decomposition:    <pre><code>float *cA, *cD;\nint cA_len;\ntiny_dwt_multilevel_decompose_f32(input, 128, TINY_WAVELET_DB4, 3, &amp;cA, &amp;cD, &amp;cA_len);\n</code></pre></p> </li> <li> <p>Process Coefficients (optional):    <pre><code>tiny_dwt_coeffs_process(cA, cD, cA_len, 128 - cA_len, 3);\n</code></pre></p> </li> <li> <p>Multi-Level Reconstruction:    <pre><code>float output[128];\ntiny_dwt_multilevel_reconstruct_f32(cA, cD, cA_len, TINY_WAVELET_DB4, 3, output);\n</code></pre></p> </li> <li> <p>Free Memory:    <pre><code>free(cA);\nfree(cD);\n</code></pre></p> </li> </ol>"},{"location":"DSP/TRANSFORM/DWT/notes/#applications","title":"APPLICATIONS","text":"<p>DWT is widely used in various applications:</p> <ul> <li>Signal Denoising: Threshold detail coefficients to remove noise</li> <li>Data Compression: Store only significant coefficients</li> <li>Feature Extraction: Analyze coefficients at different scales</li> <li>Image Processing: 2D DWT for image compression and analysis</li> <li>Biomedical Signal Processing: ECG/EEG analysis, artifact removal</li> <li>Structural Health Monitoring: Vibration analysis, damage detection</li> <li>Time-Frequency Analysis: Localize events in both time and frequency</li> </ul>"},{"location":"DSP/TRANSFORM/DWT/notes/#boundary-effects","title":"BOUNDARY EFFECTS","text":"<p>DWT operations use symmetric padding to handle signal boundaries. However, boundary effects may still occur:</p> <ul> <li>Single-Level: Boundary effects typically extend ~filter_length samples from each edge</li> <li>Multi-Level: Boundary effects accumulate and extend ~filter_length \u00d7 levels samples</li> <li>Center Region: Typically has very high reconstruction accuracy</li> <li>Recommendation: Use signals longer than 2 \u00d7 filter_length \u00d7 levels for best results</li> </ul>"},{"location":"DSP/TRANSFORM/DWT/notes/#energy-preservation","title":"ENERGY PRESERVATION","text":"<p>For perfect reconstruction wavelets (like Daubechies), energy should be approximately preserved:</p> \\[ E_{input} \\approx E_{cA} + E_{cD} \\] \\[ E_{output} \\approx E_{input} \\] <p>Where energy is calculated as:</p> \\[ E = \\sum_{n} |x[n]|^2 \\] <p>Boundary effects may cause slight energy differences, but the center region should maintain excellent energy preservation.</p>"},{"location":"DSP/TRANSFORM/DWT/test/","title":"TESTS","text":""},{"location":"DSP/TRANSFORM/DWT/test/#tiny_dwt_testh","title":"tiny_dwt_test.h","text":"<pre><code>/**\n * @file tiny_dwt_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_dwt | test | header\n * @version 1.0\n * @date 2025-04-30\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_dwt.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/**\n * @name tiny_dwt_test\n * @brief Unit test for single-level DWT and inverse DWT\n */\nvoid tiny_dwt_test(void);\n\n/**\n * @name tiny_dwt_test_multilevel\n * @brief Unit test for multi-level DWT and inverse DWT\n */\nvoid tiny_dwt_test_multilevel(void);\n\n/**\n * @name tiny_dwt_test_wavelets\n * @brief Test different wavelet types (DB1-DB10)\n */\nvoid tiny_dwt_test_wavelets(void);\n\n/**\n * @name tiny_dwt_test_all\n * @brief Run all DWT tests\n */\nvoid tiny_dwt_test_all(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/TRANSFORM/DWT/test/#tiny_dwt_testc","title":"tiny_dwt_test.c","text":"<pre><code>/**\n * @file tiny_dwt_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_dwt | test | source\n * @version 1.0\n * @date 2025-04-30\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_dwt_test.h\" // TinyDWT Test Header\n#include \"tiny_view.h\"     // Signal visualization\n#include &lt;math.h&gt;\n#include &lt;stdlib.h&gt;        // For malloc/free\n\n/**\n * @brief Calculate signal energy (sum of squares)\n */\nstatic float calculate_energy(const float *signal, int len)\n{\n    float energy = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        energy += signal[i] * signal[i];\n    }\n    return energy;\n}\n\n/**\n * @brief Calculate maximum absolute error between two signals\n */\nstatic float calculate_max_error(const float *signal1, const float *signal2, int len, int *max_err_idx)\n{\n    float max_err = 0.0f;\n    int max_idx = 0;\n    for (int i = 0; i &lt; len; i++)\n    {\n        float err = fabsf(signal1[i] - signal2[i]);\n        if (err &gt; max_err)\n        {\n            max_err = err;\n            max_idx = i;\n        }\n    }\n    if (max_err_idx)\n        *max_err_idx = max_idx;\n    return max_err;\n}\n\n/**\n * @brief Calculate mean squared error (MSE)\n */\nstatic float calculate_mse(const float *signal1, const float *signal2, int len)\n{\n    float mse = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        float diff = signal1[i] - signal2[i];\n        mse += diff * diff;\n    }\n    return mse / len;\n}\n\n/**\n * @name tiny_dwt_test\n * @brief Unit test for single-level DWT and inverse DWT\n */\nvoid tiny_dwt_test(void)\n{\n    printf(\"========== TinyDWT Single-Level Test ==========\\n\\n\");\n\n    // Test signal: longer sinusoidal pattern to reduce boundary effects\n    // Generate 64 samples: 2 cycles of sine wave\n    // Use dynamic allocation to avoid stack overflow\n    #define TEST_SIGNAL_LEN 64\n    float *input = (float *)malloc(TEST_SIGNAL_LEN * sizeof(float));\n    if (!input)\n    {\n        printf(\"  \u2717 Memory allocation failed for input signal\\n\");\n        return;\n    }\n\n    for (int i = 0; i &lt; TEST_SIGNAL_LEN; i++)\n    {\n        input[i] = 2.0f * sinf(2.0f * M_PI * i / (TEST_SIGNAL_LEN / 2.0f));\n    }\n    int input_len = TEST_SIGNAL_LEN;\n\n    printf(\"Test 1: Single-Level DWT Decomposition and Reconstruction\\n\");\n    printf(\"  Input: Sinusoidal signal (length=%d, 2 cycles)\\n\", input_len);\n    printf(\"  Wavelet: DB4\\n\");\n    printf(\"  Note: Using longer signal to better assess boundary effects\\n\\n\");\n\n    float *cA = (float *)calloc(128, sizeof(float));\n    float *cD = (float *)calloc(128, sizeof(float));\n    float *output = (float *)calloc(256, sizeof(float));\n\n    if (!cA || !cD || !output)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        free(input);\n        free(cA);\n        free(cD);\n        free(output);\n        return;\n    }\n\n    int cA_len = 0, cD_len = 0;\n    int output_len = 0;\n\n    tiny_error_t err;\n\n    // Decomposition\n    printf(\"1. DWT Decomposition:\\n\");\n    printf(\"  Input: Original signal (length=%d)\\n\", input_len);\n    err = tiny_dwt_decompose_f32(input, input_len, TINY_WAVELET_DB4, cA, cD, &amp;cA_len, &amp;cD_len);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 DWT decomposition failed: %d\\n\", err);\n        return;\n    }\n    printf(\"  \u2713 Decomposition completed\\n\");\n    printf(\"  Output: Approximation coefficients (cA, length=%d)\\n\", cA_len);\n    printf(\"  Output: Detail coefficients (cD, length=%d)\\n\", cD_len);\n\n    // Calculate energy preservation\n    float input_energy = calculate_energy(input, input_len);\n    float cA_energy = calculate_energy(cA, cA_len);\n    float cD_energy = calculate_energy(cD, cD_len);\n    float coeff_energy = cA_energy + cD_energy;\n    float energy_ratio = (input_energy &gt; 0) ? (coeff_energy / input_energy) : 0.0f;\n    printf(\"  Energy: Input=%.3f, cA=%.3f, cD=%.3f, Total=%.3f (ratio=%.4f)\\n\\n\",\n           input_energy, cA_energy, cD_energy, coeff_energy, energy_ratio);\n\n    // Reconstruction\n    printf(\"2. DWT Reconstruction:\\n\");\n    printf(\"  Input: cA (length=%d) + cD (length=%d)\\n\", cA_len, cD_len);\n    err = tiny_dwt_reconstruct_f32(cA, cD, cA_len, TINY_WAVELET_DB4, output, &amp;output_len);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 DWT reconstruction failed: %d\\n\", err);\n        return;\n    }\n    printf(\"  \u2713 Reconstruction completed\\n\");\n    printf(\"  Output: Reconstructed signal (length=%d)\\n\\n\", output_len);\n\n    // Visualization\n    printf(\"3. Signal Visualization:\\n\");\n    tiny_view_signal_f32(input, input_len, 64, 12, 0, 0, \"Original Signal\");\n    tiny_view_signal_f32(cA, cA_len, 32, 12, 0, 0, \"Approximation (cA)\");\n    tiny_view_signal_f32(cD, cD_len, 32, 12, 0, 0, \"Detail (cD)\");\n    tiny_view_signal_f32(output, output_len, 64, 12, 0, 0, \"Reconstructed Signal\");\n\n    // Error analysis with boundary effect assessment\n    printf(\"4. Reconstruction Error Analysis:\\n\");\n    int filter_len = TINY_WAVELET_GET_LEN(TINY_WAVELET_DB4);\n    int boundary_width = filter_len;  // Boundary effect typically extends ~filter_len samples\n    int end = (input_len &lt; output_len) ? input_len : output_len;\n\n    int max_err_idx = 0;\n    float max_err = calculate_max_error(input, output, end, &amp;max_err_idx);\n    float mse = calculate_mse(input, output, end);\n    float rmse = sqrtf(mse);\n\n    printf(\"  Comparison length: %d samples\\n\", end);\n    printf(\"  Max absolute error: %.6f (at index %d)\\n\", max_err, max_err_idx);\n    printf(\"  Mean squared error (MSE): %.6f\\n\", mse);\n    printf(\"  Root mean squared error (RMSE): %.6f\\n\", rmse);\n\n    // Analyze boundary regions vs center region\n    if (end &gt; 2 * boundary_width)\n    {\n        // Left boundary region\n        float left_max_err = 0.0f;\n        float left_mse = 0.0f;\n        for (int i = 0; i &lt; boundary_width; i++)\n        {\n            float err = fabsf(output[i] - input[i]);\n            if (err &gt; left_max_err)\n                left_max_err = err;\n            left_mse += (output[i] - input[i]) * (output[i] - input[i]);\n        }\n        left_mse /= boundary_width;\n\n        // Right boundary region\n        float right_max_err = 0.0f;\n        float right_mse = 0.0f;\n        for (int i = end - boundary_width; i &lt; end; i++)\n        {\n            float err = fabsf(output[i] - input[i]);\n            if (err &gt; right_max_err)\n                right_max_err = err;\n            right_mse += (output[i] - input[i]) * (output[i] - input[i]);\n        }\n        right_mse /= boundary_width;\n\n        // Center region (excluding boundaries)\n        float center_max_err = 0.0f;\n        float center_mse = 0.0f;\n        int center_count = end - 2 * boundary_width;\n        for (int i = boundary_width; i &lt; end - boundary_width; i++)\n        {\n            float err = fabsf(output[i] - input[i]);\n            if (err &gt; center_max_err)\n                center_max_err = err;\n            center_mse += (output[i] - input[i]) * (output[i] - input[i]);\n        }\n        center_mse /= center_count;\n        float center_rmse = sqrtf(center_mse);\n\n        printf(\"\\n  Boundary Effect Analysis:\\n\");\n        printf(\"  Left boundary (indices 0-%d):\\n\", boundary_width - 1);\n        printf(\"    Max error: %.6f, RMSE: %.6f\\n\", left_max_err, sqrtf(left_mse));\n        printf(\"  Center region (indices %d-%d, %d samples):\\n\", \n               boundary_width, end - boundary_width - 1, center_count);\n        printf(\"    Max error: %.6f, RMSE: %.6f\\n\", center_max_err, center_rmse);\n        printf(\"  Right boundary (indices %d-%d):\\n\", end - boundary_width, end - 1);\n        printf(\"    Max error: %.6f, RMSE: %.6f\\n\", right_max_err, sqrtf(right_mse));\n\n        // Compare center vs boundaries\n        if (center_rmse &lt; 1e-3f &amp;&amp; (sqrtf(left_mse) &gt; 1e-2f || sqrtf(right_mse) &gt; 1e-2f))\n        {\n            printf(\"  \u2713 Center region is highly accurate, boundary effects confirmed\\n\");\n        }\n        else if (center_rmse &lt; 1e-2f)\n        {\n            printf(\"  \u26a0 Center region has minor errors\\n\");\n        }\n        else\n        {\n            printf(\"  \u2717 Center region has significant errors (may indicate implementation issue)\\n\");\n        }\n    }\n    else\n    {\n        printf(\"  \u26a0 Signal too short for boundary analysis (need &gt; %d samples)\\n\", 2 * boundary_width);\n    }\n    printf(\"\\n\");\n\n    // Energy preservation check\n    float output_energy = calculate_energy(output, output_len);\n    float energy_preservation = (input_energy &gt; 0) ? (output_energy / input_energy) : 0.0f;\n    printf(\"5. Energy Preservation:\\n\");\n    printf(\"  Input energy: %.6f\\n\", input_energy);\n    printf(\"  Output energy: %.6f\\n\", output_energy);\n    printf(\"  Preservation ratio: %.6f\\n\", energy_preservation);\n    if (fabsf(energy_preservation - 1.0f) &lt; 0.1f)\n        printf(\"  \u2713 Energy is well preserved\\n\");\n    else\n        printf(\"  \u26a0 Energy preservation ratio: %.2f%%\\n\", energy_preservation * 100.0f);\n    printf(\"\\n\");\n\n    // Cleanup\n    free(input);\n    free(cA);\n    free(cD);\n    free(output);\n\n    printf(\"========================================\\n\");\n}\n\n/**\n * @name tiny_dwt_test_multilevel\n * @brief Test multi-level DWT decomposition and reconstruction\n */\nvoid tiny_dwt_test_multilevel(void)\n{\n    printf(\"========== TinyDWT Multi-Level Test ==========\\n\\n\");\n\n    // Extended test signal: longer sinusoidal pattern\n    // Generate 128 samples: 4 cycles of sine wave\n    // Use dynamic allocation to avoid stack overflow\n    #define MULTI_TEST_SIGNAL_LEN 128\n    float *input = (float *)malloc(MULTI_TEST_SIGNAL_LEN * sizeof(float));\n    if (!input)\n    {\n        printf(\"  \u2717 Memory allocation failed for input signal\\n\");\n        return;\n    }\n\n    for (int i = 0; i &lt; MULTI_TEST_SIGNAL_LEN; i++)\n    {\n        input[i] = 2.0f * sinf(2.0f * M_PI * i / (MULTI_TEST_SIGNAL_LEN / 4.0f));\n    }\n    int input_len = MULTI_TEST_SIGNAL_LEN;\n    int levels = 3;\n\n    printf(\"Test 2: Multi-Level DWT Decomposition and Reconstruction\\n\");\n    printf(\"  Input: Sinusoidal signal (length=%d, 4 cycles)\\n\", input_len);\n    printf(\"  Wavelet: DB4\\n\");\n    printf(\"  Decomposition levels: %d\\n\", levels);\n    printf(\"  Note: Using longer signal to better assess boundary effects in multi-level decomposition\\n\\n\");\n\n    float *cA = NULL;\n    float *cD = NULL;\n    int cA_len = 0;\n\n    // Multi-level decomposition\n    printf(\"1. Multi-Level DWT Decomposition:\\n\");\n    printf(\"  Input: Original signal (length=%d)\\n\", input_len);\n    tiny_error_t err = tiny_dwt_multilevel_decompose_f32(input, input_len, TINY_WAVELET_DB4, levels, &amp;cA, &amp;cD, &amp;cA_len);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Multi-level DWT decomposition failed: %d\\n\", err);\n        return;\n    }\n    printf(\"  \u2713 Decomposition completed\\n\");\n    printf(\"  Output: Final approximation (cA, length=%d)\\n\", cA_len);\n    printf(\"  Output: All detail coefficients (cD, total length=%d)\\n\", input_len - cA_len);\n\n    // Calculate energy\n    float input_energy = calculate_energy(input, input_len);\n    float cA_energy = calculate_energy(cA, cA_len);\n    float cD_energy = calculate_energy(cD, input_len - cA_len);\n    float total_coeff_energy = cA_energy + cD_energy;\n    printf(\"  Energy: Input=%.3f, cA=%.3f, cD=%.3f, Total=%.3f\\n\\n\",\n           input_energy, cA_energy, cD_energy, total_coeff_energy);\n\n    // Coefficient processing (placeholder)\n    printf(\"2. Coefficient Processing:\\n\");\n    tiny_dwt_coeffs_process(cA, cD, cA_len, input_len - cA_len, levels);\n    printf(\"  \u2713 Coefficient processing completed (placeholder function)\\n\\n\");\n\n    // Multi-level reconstruction\n    printf(\"3. Multi-Level DWT Reconstruction:\\n\");\n    printf(\"  Input: cA (length=%d) + cD (total length=%d)\\n\", cA_len, input_len - cA_len);\n    float *output = (float *)malloc(sizeof(float) * input_len);\n    if (!output)\n    {\n        printf(\"  \u2717 Memory allocation failed for output\\n\");\n        free(cA);\n        free(cD);\n        return;\n    }\n\n    err = tiny_dwt_multilevel_reconstruct_f32(cA, cD, cA_len, TINY_WAVELET_DB4, levels, output);\n    if (err != TINY_OK)\n    {\n        printf(\"  \u2717 Multi-level DWT reconstruction failed: %d\\n\", err);\n        free(cA);\n        free(cD);\n        free(output);\n        return;\n    }\n    printf(\"  \u2713 Reconstruction completed\\n\");\n    printf(\"  Output: Reconstructed signal (length=%d)\\n\\n\", input_len);\n\n    // Visualization\n    printf(\"4. Signal Visualization:\\n\");\n    tiny_view_signal_f32(input, input_len, 64, 12, 0, 0, \"Original Signal\");\n    tiny_view_signal_f32(cA, cA_len, 32, 12, 0, 0, \"Final Approximation (cA)\");\n    tiny_view_signal_f32(output, input_len, 64, 12, 0, 0, \"Reconstructed Signal\");\n\n    // Error analysis with boundary effect assessment\n    printf(\"5. Reconstruction Error Analysis:\\n\");\n    int filter_len = TINY_WAVELET_GET_LEN(TINY_WAVELET_DB4);\n    int boundary_width = filter_len * levels;  // Boundary effect accumulates with levels\n    int max_err_idx = 0;\n    float max_err = calculate_max_error(input, output, input_len, &amp;max_err_idx);\n    float mse = calculate_mse(input, output, input_len);\n    float rmse = sqrtf(mse);\n\n    printf(\"  Max absolute error: %.6f (at index %d)\\n\", max_err, max_err_idx);\n    printf(\"  Mean squared error (MSE): %.6f\\n\", mse);\n    printf(\"  Root mean squared error (RMSE): %.6f\\n\", rmse);\n\n    // Analyze boundary regions vs center region\n    if (input_len &gt; 2 * boundary_width)\n    {\n        // Left boundary region\n        float left_max_err = 0.0f;\n        float left_mse = 0.0f;\n        for (int i = 0; i &lt; boundary_width; i++)\n        {\n            float err = fabsf(output[i] - input[i]);\n            if (err &gt; left_max_err)\n                left_max_err = err;\n            left_mse += (output[i] - input[i]) * (output[i] - input[i]);\n        }\n        left_mse /= boundary_width;\n\n        // Right boundary region\n        float right_max_err = 0.0f;\n        float right_mse = 0.0f;\n        for (int i = input_len - boundary_width; i &lt; input_len; i++)\n        {\n            float err = fabsf(output[i] - input[i]);\n            if (err &gt; right_max_err)\n                right_max_err = err;\n            right_mse += (output[i] - input[i]) * (output[i] - input[i]);\n        }\n        right_mse /= boundary_width;\n\n        // Center region (excluding boundaries)\n        float center_max_err = 0.0f;\n        float center_mse = 0.0f;\n        int center_count = input_len - 2 * boundary_width;\n        for (int i = boundary_width; i &lt; input_len - boundary_width; i++)\n        {\n            float err = fabsf(output[i] - input[i]);\n            if (err &gt; center_max_err)\n                center_max_err = err;\n            center_mse += (output[i] - input[i]) * (output[i] - input[i]);\n        }\n        center_mse /= center_count;\n        float center_rmse = sqrtf(center_mse);\n\n        printf(\"\\n  Boundary Effect Analysis (Multi-Level):\\n\");\n        printf(\"  Left boundary (indices 0-%d):\\n\", boundary_width - 1);\n        printf(\"    Max error: %.6f, RMSE: %.6f\\n\", left_max_err, sqrtf(left_mse));\n        printf(\"  Center region (indices %d-%d, %d samples):\\n\", \n               boundary_width, input_len - boundary_width - 1, center_count);\n        printf(\"    Max error: %.6f, RMSE: %.6f\\n\", center_max_err, center_rmse);\n        printf(\"  Right boundary (indices %d-%d):\\n\", input_len - boundary_width, input_len - 1);\n        printf(\"    Max error: %.6f, RMSE: %.6f\\n\", right_max_err, sqrtf(right_mse));\n\n        // Compare center vs boundaries\n        if (center_rmse &lt; 0.01f &amp;&amp; (sqrtf(left_mse) &gt; 0.1f || sqrtf(right_mse) &gt; 0.1f))\n        {\n            printf(\"  \u2713 Center region is accurate, boundary effects confirmed (expected in multi-level)\\n\");\n        }\n        else if (center_rmse &lt; 0.1f)\n        {\n            printf(\"  \u26a0 Center region has minor errors\\n\");\n        }\n        else\n        {\n            printf(\"  \u2717 Center region has significant errors (may indicate implementation issue)\\n\");\n        }\n    }\n    else\n    {\n        printf(\"  \u26a0 Signal too short for boundary analysis (need &gt; %d samples)\\n\", 2 * boundary_width);\n    }\n    printf(\"\\n\");\n\n    // Energy preservation\n    float output_energy = calculate_energy(output, input_len);\n    float energy_preservation = (input_energy &gt; 0) ? (output_energy / input_energy) : 0.0f;\n    printf(\"6. Energy Preservation:\\n\");\n    printf(\"  Input energy: %.6f\\n\", input_energy);\n    printf(\"  Output energy: %.6f\\n\", output_energy);\n    printf(\"  Preservation ratio: %.6f\\n\", energy_preservation);\n    if (fabsf(energy_preservation - 1.0f) &lt; 0.1f)\n        printf(\"  \u2713 Energy is well preserved\\n\");\n    else\n        printf(\"  \u26a0 Energy preservation ratio: %.2f%%\\n\", energy_preservation * 100.0f);\n    printf(\"\\n\");\n\n    free(input);\n    free(cA);\n    free(cD);\n    free(output);\n    printf(\"========================================\\n\");\n}\n\n/**\n * @name tiny_dwt_test_wavelets\n * @brief Test different wavelet types\n */\nvoid tiny_dwt_test_wavelets(void)\n{\n    printf(\"========== TinyDWT Wavelet Types Test ==========\\n\\n\");\n\n    // Simple test signal\n    float input[] = {1.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0, -1.0, -2.0, -3.0, -2.0, -1.0, 0.0};\n    int input_len = sizeof(input) / sizeof(input[0]);\n\n    const char *wavelet_names[] = {\n        \"DB1\", \"DB2\", \"DB3\", \"DB4\", \"DB5\",\n        \"DB6\", \"DB7\", \"DB8\", \"DB9\", \"DB10\"\n    };\n\n    tiny_wavelet_type_t wavelets[] = {\n        TINY_WAVELET_DB1, TINY_WAVELET_DB2, TINY_WAVELET_DB3, TINY_WAVELET_DB4, TINY_WAVELET_DB5,\n        TINY_WAVELET_DB6, TINY_WAVELET_DB7, TINY_WAVELET_DB8, TINY_WAVELET_DB9, TINY_WAVELET_DB10\n    };\n\n    printf(\"Test 3: Different Wavelet Types\\n\");\n    printf(\"  Input: Test signal (length=%d)\\n\", input_len);\n    printf(\"  Testing: DB1 through DB10\\n\\n\");\n\n    int passed = 0;\n    int failed = 0;\n\n    for (int w = 0; w &lt; TINY_WAVELET_COUNT; w++)\n    {\n        tiny_wavelet_type_t wavelet = wavelets[w];\n        int filter_len = TINY_WAVELET_GET_LEN(wavelet);\n\n        // Skip if signal is too short for this wavelet\n        if (input_len &lt; filter_len * 2)\n        {\n            printf(\"  [%s] Skipped (signal too short: need &gt;= %d, have %d)\\n\",\n                   wavelet_names[w], filter_len * 2, input_len);\n            continue;\n        }\n\n        float cA[32] = {0}, cD[32] = {0};\n        int cA_len = 0, cD_len = 0;\n        float output[64] = {0};\n        int output_len = 0;\n\n        tiny_error_t err = tiny_dwt_decompose_f32(input, input_len, wavelet, cA, cD, &amp;cA_len, &amp;cD_len);\n        if (err != TINY_OK)\n        {\n            printf(\"  [%s] \u2717 Decomposition failed: %d\\n\", wavelet_names[w], err);\n            failed++;\n            continue;\n        }\n\n        err = tiny_dwt_reconstruct_f32(cA, cD, cA_len, wavelet, output, &amp;output_len);\n        if (err != TINY_OK)\n        {\n            printf(\"  [%s] \u2717 Reconstruction failed: %d\\n\", wavelet_names[w], err);\n            failed++;\n            continue;\n        }\n\n        // Check reconstruction accuracy\n        int check_len = (input_len &lt; output_len) ? input_len : output_len;\n        float max_err = 0.0f;\n        for (int i = 0; i &lt; check_len; i++)\n        {\n            float err = fabsf(output[i] - input[i]);\n            if (err &gt; max_err)\n                max_err = err;\n        }\n\n        if (max_err &lt; 0.1f)\n        {\n            printf(\"  [%s] \u2713 Pass (filter_len=%d, max_err=%.4f)\\n\",\n                   wavelet_names[w], filter_len, max_err);\n            passed++;\n        }\n        else\n        {\n            printf(\"  [%s] \u26a0 Warning (filter_len=%d, max_err=%.4f)\\n\",\n                   wavelet_names[w], filter_len, max_err);\n            passed++; // Still count as passed, just with warning\n        }\n    }\n\n    printf(\"\\n  Summary: %d passed, %d failed\\n\", passed, failed);\n    printf(\"\\n========================================\\n\");\n}\n\n/**\n * @name tiny_dwt_test_all\n * @brief Run all DWT tests\n */\nvoid tiny_dwt_test_all(void)\n{\n    printf(\"\\n\");\n    printf(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\\n\");\n    printf(\"\u2551          TinyDWT Complete Test Suite                     \u2551\\n\");\n    printf(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\n\");\n    printf(\"\\n\");\n\n    // Run all tests\n    tiny_dwt_test();\n    printf(\"\\n\");\n\n    tiny_dwt_test_multilevel();\n    printf(\"\\n\");\n\n    tiny_dwt_test_wavelets();\n    printf(\"\\n\");\n\n    printf(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\\n\");\n    printf(\"\u2551          All DWT Tests Completed                         \u2551\\n\");\n    printf(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\n\");\n}\n</code></pre>"},{"location":"DSP/TRANSFORM/FFT/code/","title":"CODE","text":""},{"location":"DSP/TRANSFORM/FFT/code/#tiny_ffth","title":"tiny_fft.h","text":"<pre><code>/**\n * @file tiny_fft.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_fft | code | header\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n\n// ESP32 DSP Library for Acceleration\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n#include \"dsps_fft2r.h\"\n#include \"dsps_wind_hann.h\"\n#include \"dsps_wind_blackman.h\"\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @brief Window function types for FFT preprocessing\n     */\n    typedef enum\n    {\n        TINY_FFT_WINDOW_NONE = 0,    // No window (rectangular)\n        TINY_FFT_WINDOW_HANNING,     // Hanning window\n        TINY_FFT_WINDOW_HAMMING,     // Hamming window\n        TINY_FFT_WINDOW_BLACKMAN,    // Blackman window\n        TINY_FFT_WINDOW_COUNT\n    } tiny_fft_window_t;\n\n    /**\n     * @name: tiny_fft_init\n     * @brief Initialize FFT tables (required before using FFT functions)\n     * @note This function should be called once at startup\n     * @param fft_size Maximum FFT size to support (must be power of 2)\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fft_init(int fft_size);\n\n    /**\n     * @name: tiny_fft_deinit\n     * @brief Deinitialize FFT tables and free resources\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fft_deinit(void);\n\n    /**\n     * @name: tiny_fft_f32\n     * @brief Perform FFT on real-valued input signal\n     * @param input Input signal array (real values)\n     * @param input_len Length of input signal (must be power of 2)\n     * @param output_fft Output FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n     *                   Size must be at least input_len * 2\n     * @param window Window function to apply before FFT (optional)\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fft_f32(const float *input, int input_len, float *output_fft, tiny_fft_window_t window);\n\n    /**\n     * @name: tiny_fft_ifft_f32\n     * @brief Perform inverse FFT to reconstruct time-domain signal\n     * @param input_fft Input FFT array (complex: [Re0, Im0, Re1, Im1, ...])\n     * @param fft_len Length of FFT (number of complex points)\n     * @param output Output reconstructed signal (real values)\n     *               Size must be at least fft_len\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fft_ifft_f32(const float *input_fft, int fft_len, float *output);\n\n    /**\n     * @name: tiny_fft_magnitude_f32\n     * @brief Calculate magnitude spectrum from FFT result\n     * @param fft_result FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n     * @param fft_len Length of FFT (number of complex points)\n     * @param magnitude Output magnitude spectrum (real values)\n     *                  Size must be at least fft_len\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fft_magnitude_f32(const float *fft_result, int fft_len, float *magnitude);\n\n    /**\n     * @name: tiny_fft_power_spectrum_f32\n     * @brief Calculate power spectrum density (PSD) from FFT result\n     * @param fft_result FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n     * @param fft_len Length of FFT (number of complex points)\n     * @param power Output power spectrum (real values)\n     *              Size must be at least fft_len\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fft_power_spectrum_f32(const float *fft_result, int fft_len, float *power);\n\n    /**\n     * @name: tiny_fft_find_peak_frequency\n     * @brief Find the frequency with maximum power (useful for structural health monitoring)\n     * @param power_spectrum Power spectrum array\n     * @param fft_len Length of power spectrum\n     * @param sample_rate Sampling rate of the original signal (Hz)\n     * @param peak_freq Output peak frequency (Hz)\n     * @param peak_power Output peak power value\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fft_find_peak_frequency(const float *power_spectrum, int fft_len, float sample_rate, float *peak_freq, float *peak_power);\n\n    /**\n     * @name: tiny_fft_find_top_frequencies\n     * @brief Find top N frequencies with highest power\n     * @param power_spectrum Power spectrum array\n     * @param fft_len Length of power spectrum\n     * @param sample_rate Sampling rate of the original signal (Hz)\n     * @param top_n Number of top frequencies to find\n     * @param frequencies Output array for frequencies (Hz), size must be at least top_n\n     * @param powers Output array for power values, size must be at least top_n\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_fft_find_top_frequencies(const float *power_spectrum, int fft_len, float sample_rate, int top_n, float *frequencies, float *powers);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/TRANSFORM/FFT/code/#tiny_fftc","title":"tiny_fft.c","text":"<pre><code>/**\n * @file tiny_fft.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_fft | code | source\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_fft.h\"\n#include &lt;math.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n#include \"esp_heap_caps.h\"\n#endif\n\n/* STATIC VARIABLES */\nstatic int g_fft_initialized = 0;\nstatic int g_fft_size = 0;\n\n/* STATIC FUNCTIONS FOR NON-ESP32 PLATFORM */\n#if MCU_PLATFORM_SELECTED != MCU_PLATFORM_ESP32\n/**\n * @brief Bit-reverse an integer (for FFT)\n */\nstatic unsigned int bit_reverse(unsigned int x, int log2n)\n{\n    unsigned int n = 0;\n    for (int i = 0; i &lt; log2n; i++)\n    {\n        n &lt;&lt;= 1;\n        n |= (x &amp; 1);\n        x &gt;&gt;= 1;\n    }\n    return n;\n}\n\n/**\n * @brief Calculate log2 of a power-of-2 number\n */\nstatic int log2_power2(int n)\n{\n    int log2n = 0;\n    while (n &gt; 1)\n    {\n        n &gt;&gt;= 1;\n        log2n++;\n    }\n    return log2n;\n}\n\n/**\n * @brief Perform Radix-2 FFT on complex data\n * @param data Complex array [Re0, Im0, Re1, Im1, ...]\n * @param n Number of complex points (must be power of 2)\n * @param inverse If 1, perform IFFT; if 0, perform FFT\n */\nstatic void fft_radix2_f32(float *data, int n, int inverse)\n{\n    int log2n = log2_power2(n);\n\n    // Bit-reverse the input\n    for (int i = 0; i &lt; n; i++)\n    {\n        unsigned int j = bit_reverse(i, log2n);\n        if (j &gt; i)\n        {\n            // Swap real parts\n            float temp = data[i * 2];\n            data[i * 2] = data[j * 2];\n            data[j * 2] = temp;\n            // Swap imaginary parts\n            temp = data[i * 2 + 1];\n            data[i * 2 + 1] = data[j * 2 + 1];\n            data[j * 2 + 1] = temp;\n        }\n    }\n\n    // FFT butterfly operations\n    float sign = inverse ? -1.0f : 1.0f;\n    for (int stage = 1; stage &lt;= log2n; stage++)\n    {\n        int m = 1 &lt;&lt; stage;  // 2^stage\n        int m2 = m &gt;&gt; 1;     // m/2\n\n        float wm_real = cosf(sign * 2.0f * M_PI / m);\n        float wm_imag = sinf(sign * 2.0f * M_PI / m);\n\n        for (int k = 0; k &lt; n; k += m)\n        {\n            float w_real = 1.0f;\n            float w_imag = 0.0f;\n\n            for (int j = 0; j &lt; m2; j++)\n            {\n                int t = k + j;\n                int u = t + m2;\n\n                float t_real = data[t * 2];\n                float t_imag = data[t * 2 + 1];\n                float u_real = data[u * 2];\n                float u_imag = data[u * 2 + 1];\n\n                // Multiply u by twiddle factor\n                float u_real_new = u_real * w_real - u_imag * w_imag;\n                float u_imag_new = u_real * w_imag + u_imag * w_real;\n\n                // Butterfly operation\n                data[t * 2] = t_real + u_real_new;\n                data[t * 2 + 1] = t_imag + u_imag_new;\n                data[u * 2] = t_real - u_real_new;\n                data[u * 2 + 1] = t_imag - u_imag_new;\n\n                // Update twiddle factor\n                float w_real_new = w_real * wm_real - w_imag * wm_imag;\n                float w_imag_new = w_real * wm_imag + w_imag * wm_real;\n                w_real = w_real_new;\n                w_imag = w_imag_new;\n            }\n        }\n    }\n\n    // Scale for IFFT\n    if (inverse)\n    {\n        float scale = 1.0f / n;\n        for (int i = 0; i &lt; n; i++)\n        {\n            data[i * 2] *= scale;\n            data[i * 2 + 1] *= scale;\n        }\n    }\n}\n#endif\n\n/**\n * @brief Check if a number is power of 2\n */\nstatic int is_power_of_2(int n)\n{\n    return (n &gt; 0) &amp;&amp; ((n &amp; (n - 1)) == 0);\n}\n\n/**\n * @name: tiny_fft_init\n * @brief Initialize FFT tables\n */\ntiny_error_t tiny_fft_init(int fft_size)\n{\n    if (!is_power_of_2(fft_size))\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    if (g_fft_initialized)\n    {\n        return TINY_ERR_DSP_REINITIALIZED;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    esp_err_t ret = dsps_fft2r_init_fc32(NULL, fft_size);\n    if (ret != ESP_OK)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n    g_fft_size = fft_size;\n    g_fft_initialized = 1;\n    return TINY_OK;\n#else\n    // For non-ESP32 platforms, FFT initialization is not required\n    // but we mark it as initialized for compatibility\n    g_fft_size = fft_size;\n    g_fft_initialized = 1;\n    return TINY_OK;\n#endif\n}\n\n/**\n * @name: tiny_fft_deinit\n * @brief Deinitialize FFT tables\n */\ntiny_error_t tiny_fft_deinit(void)\n{\n    if (!g_fft_initialized)\n    {\n        return TINY_ERR_DSP_UNINITIALIZED;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_fft2r_deinit_fc32();\n#endif\n\n    g_fft_initialized = 0;\n    g_fft_size = 0;\n    return TINY_OK;\n}\n\n/**\n * @brief Apply window function to input signal\n */\nstatic void apply_window(const float *input, int len, float *output, tiny_fft_window_t window)\n{\n    if (window == TINY_FFT_WINDOW_NONE)\n    {\n        memcpy(output, input, len * sizeof(float));\n        return;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use ESP32 DSP window functions\n    float *window_coeffs = (float *)malloc(len * sizeof(float));\n    if (window_coeffs == NULL)\n    {\n        memcpy(output, input, len * sizeof(float));\n        return;\n    }\n\n    switch (window)\n    {\n    case TINY_FFT_WINDOW_HANNING:\n        dsps_wind_hann_f32(window_coeffs, len);\n        break;\n    case TINY_FFT_WINDOW_HAMMING:\n        // ESP-DSP doesn't have Hamming, use Hann as approximation\n        dsps_wind_hann_f32(window_coeffs, len);\n        break;\n    case TINY_FFT_WINDOW_BLACKMAN:\n        dsps_wind_blackman_f32(window_coeffs, len);\n        break;\n    default:\n        free(window_coeffs);\n        memcpy(output, input, len * sizeof(float));\n        return;\n    }\n    // Multiply input by window\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = input[i] * window_coeffs[i];\n    }\n    free(window_coeffs);\n#else\n    // Simple window implementation for non-ESP32 platforms\n    for (int i = 0; i &lt; len; i++)\n    {\n        float w = 1.0f;\n        switch (window)\n        {\n        case TINY_FFT_WINDOW_HANNING:\n            w = 0.5f * (1.0f - cosf(2.0f * M_PI * i / (len - 1)));\n            break;\n        case TINY_FFT_WINDOW_HAMMING:\n            w = 0.54f - 0.46f * cosf(2.0f * M_PI * i / (len - 1));\n            break;\n        case TINY_FFT_WINDOW_BLACKMAN:\n            w = 0.42f - 0.5f * cosf(2.0f * M_PI * i / (len - 1)) + 0.08f * cosf(4.0f * M_PI * i / (len - 1));\n            break;\n        default:\n            w = 1.0f;\n            break;\n        }\n        output[i] = input[i] * w;\n    }\n#endif\n}\n\n/**\n * @name: tiny_fft_f32\n * @brief Perform FFT on real-valued input signal\n */\ntiny_error_t tiny_fft_f32(const float *input, int input_len, float *output_fft, tiny_fft_window_t window)\n{\n    if (!g_fft_initialized)\n    {\n        return TINY_ERR_DSP_UNINITIALIZED;\n    }\n\n    if (NULL == input || NULL == output_fft)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    if (!is_power_of_2(input_len) || input_len &gt; g_fft_size)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Apply window function\n    float *windowed_input = (float *)malloc(input_len * sizeof(float));\n    if (windowed_input == NULL)\n    {\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n    apply_window(input, input_len, windowed_input, window);\n\n    // Convert real input to complex format [Re0, Im0, Re1, Im1, ...]\n    for (int i = 0; i &lt; input_len; i++)\n    {\n        output_fft[i * 2] = windowed_input[i];     // Real part\n        output_fft[i * 2 + 1] = 0.0f;               // Imaginary part\n    }\n    free(windowed_input);\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Perform FFT using ESP32 optimized library\n    // ESP32 FFT requires: FFT -&gt; bit reverse\n    // Note: dsps_cplx2reC_fc32 is for two real signals, not needed for single real signal\n    esp_err_t ret = dsps_fft2r_fc32(output_fft, input_len);\n    if (ret != ESP_OK)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Bit reverse\n    ret = dsps_bit_rev_fc32(output_fft, input_len);\n    if (ret != ESP_OK)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    return TINY_OK;\n#else\n    // Perform FFT using Radix-2 algorithm (non-ESP32 platforms)\n    fft_radix2_f32(output_fft, input_len, 0);  // 0 = forward FFT\n    return TINY_OK;\n#endif\n}\n\n/**\n * @name: tiny_fft_ifft_f32\n * @brief Perform inverse FFT\n */\ntiny_error_t tiny_fft_ifft_f32(const float *input_fft, int fft_len, float *output)\n{\n    if (!g_fft_initialized)\n    {\n        return TINY_ERR_DSP_UNINITIALIZED;\n    }\n\n    if (NULL == input_fft || NULL == output)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    if (!is_power_of_2(fft_len) || fft_len &gt; g_fft_size)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Copy input to temporary buffer\n    // ESP32 DSP library requires 16-byte aligned memory\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    float *temp_fft = (float *)heap_caps_aligned_alloc(16, fft_len * 2 * sizeof(float), MALLOC_CAP_DEFAULT);\n    if (temp_fft == NULL)\n    {\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n#else\n    float *temp_fft = (float *)malloc(fft_len * 2 * sizeof(float));\n    if (temp_fft == NULL)\n    {\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n#endif\n    memcpy(temp_fft, input_fft, fft_len * 2 * sizeof(float));\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Perform IFFT using ESP32 optimized library\n    // Note: Input FFT result is already in reC format (from FFT function)\n    // For IFFT, we need to reverse the process:\n    // 1. The input is already in reC format, so we can work with it directly\n    // 2. IFFT = conj(FFT(conj(X))) / N\n\n    // First, conjugate the input (since it's already processed by FFT)\n    for (int i = 0; i &lt; fft_len; i++)\n    {\n        temp_fft[i * 2 + 1] = -temp_fft[i * 2 + 1]; // Conjugate\n    }\n\n    // Perform FFT (which gives us IFFT after conjugation)\n    esp_err_t ret = dsps_fft2r_fc32(temp_fft, fft_len);\n    if (ret != ESP_OK)\n    {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n        heap_caps_free(temp_fft);\n#else\n        free(temp_fft);\n#endif\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Bit reverse\n    ret = dsps_bit_rev_fc32(temp_fft, fft_len);\n    if (ret != ESP_OK)\n    {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n        heap_caps_free(temp_fft);\n#else\n        free(temp_fft);\n#endif\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Conjugate again and scale\n    float scale = 1.0f / fft_len;\n    for (int i = 0; i &lt; fft_len; i++)\n    {\n        output[i] = temp_fft[i * 2] * scale; // Take real part and scale\n    }\n#else\n    // Perform IFFT using Radix-2 algorithm (non-ESP32 platforms)\n    fft_radix2_f32(temp_fft, fft_len, 1);  // 1 = inverse FFT\n\n    // Extract real part (IFFT of real signal should have zero imaginary part)\n    for (int i = 0; i &lt; fft_len; i++)\n    {\n        output[i] = temp_fft[i * 2];  // Take real part\n    }\n#endif\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    heap_caps_free(temp_fft);\n#else\n    free(temp_fft);\n#endif\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_fft_magnitude_f32\n * @brief Calculate magnitude spectrum\n */\ntiny_error_t tiny_fft_magnitude_f32(const float *fft_result, int fft_len, float *magnitude)\n{\n    if (NULL == fft_result || NULL == magnitude)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    for (int i = 0; i &lt; fft_len; i++)\n    {\n        float re = fft_result[i * 2];\n        float im = fft_result[i * 2 + 1];\n        magnitude[i] = sqrtf(re * re + im * im);\n    }\n\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_fft_power_spectrum_f32\n * @brief Calculate power spectrum density\n */\ntiny_error_t tiny_fft_power_spectrum_f32(const float *fft_result, int fft_len, float *power)\n{\n    if (NULL == fft_result || NULL == power)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    // Calculate power spectrum with normalization\n    // Normalize by FFT length to get proper power values\n    float norm = 1.0f / (float)fft_len;\n    for (int i = 0; i &lt; fft_len; i++)\n    {\n        float re = fft_result[i * 2];\n        float im = fft_result[i * 2 + 1];\n        power[i] = (re * re + im * im) * norm;\n    }\n\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_fft_find_peak_frequency\n * @brief Find peak frequency\n */\ntiny_error_t tiny_fft_find_peak_frequency(const float *power_spectrum, int fft_len, float sample_rate, float *peak_freq, float *peak_power)\n{\n    if (NULL == power_spectrum || NULL == peak_freq || NULL == peak_power)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    if (sample_rate &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Find maximum power (skip DC component at index 0)\n    int max_idx = 1;\n    float max_power = power_spectrum[1];\n    for (int i = 2; i &lt; fft_len / 2; i++) // Only check first half (Nyquist)\n    {\n        if (power_spectrum[i] &gt; max_power)\n        {\n            max_power = power_spectrum[i];\n            max_idx = i;\n        }\n    }\n\n    // Use parabolic interpolation for sub-bin accuracy\n    // This improves frequency estimation when peak is between bins\n    float refined_idx = (float)max_idx;\n    if (max_idx &gt; 0 &amp;&amp; max_idx &lt; (fft_len / 2 - 1))\n    {\n        float y0 = power_spectrum[max_idx - 1];\n        float y1 = power_spectrum[max_idx];      // Peak\n        float y2 = power_spectrum[max_idx + 1];\n\n        // Parabolic interpolation: find peak of parabola through three points\n        // Formula: offset = 0.5 * (y0 - y2) / (y0 - 2*y1 + y2)\n        float denominator = y0 - 2.0f * y1 + y2;\n        if (fabsf(denominator) &gt; 1e-6f)  // Avoid division by zero\n        {\n            float offset = 0.5f * (y0 - y2) / denominator;\n            refined_idx = (float)max_idx + offset;\n\n            // Clamp to valid range\n            if (refined_idx &lt; 0.0f)\n                refined_idx = 0.0f;\n            if (refined_idx &gt;= (float)(fft_len / 2))\n                refined_idx = (float)(fft_len / 2 - 1);\n        }\n    }\n\n    // Convert refined index to frequency\n    *peak_freq = refined_idx * sample_rate / fft_len;\n    *peak_power = max_power;\n\n    return TINY_OK;\n}\n\n/**\n * @name: tiny_fft_find_top_frequencies\n * @brief Find top N frequencies\n */\ntiny_error_t tiny_fft_find_top_frequencies(const float *power_spectrum, int fft_len, float sample_rate, int top_n, float *frequencies, float *powers)\n{\n    if (NULL == power_spectrum || NULL == frequencies || NULL == powers)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    if (sample_rate &lt;= 0 || top_n &lt;= 0 || top_n &gt; fft_len / 2)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Find peaks first, then select top N peaks\n    // This avoids selecting multiple bins from the same frequency peak\n    int max_peaks = fft_len / 4;  // Maximum possible peaks\n    int *peak_indices = (int *)malloc(max_peaks * sizeof(int));\n    float *peak_powers = (float *)malloc(max_peaks * sizeof(float));\n    if (peak_indices == NULL || peak_powers == NULL)\n    {\n        if (peak_indices) free(peak_indices);\n        if (peak_powers) free(peak_powers);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    int num_peaks = 0;\n\n    // Find local peaks (points higher than neighbors)\n    // Skip DC and first few bins to avoid noise\n    for (int i = 2; i &lt; fft_len / 2 - 1; i++)\n    {\n        // Check if this is a local maximum\n        if (power_spectrum[i] &gt; power_spectrum[i - 1] &amp;&amp; \n            power_spectrum[i] &gt; power_spectrum[i + 1])\n        {\n            // Only consider significant peaks (above threshold)\n            // Threshold: at least 1% of maximum power\n            float max_power = 0.0f;\n            for (int j = 1; j &lt; fft_len / 2; j++)\n            {\n                if (power_spectrum[j] &gt; max_power)\n                    max_power = power_spectrum[j];\n            }\n\n            if (power_spectrum[i] &gt; max_power * 0.01f)  // 1% threshold\n            {\n                peak_indices[num_peaks] = i;\n                peak_powers[num_peaks] = power_spectrum[i];\n                num_peaks++;\n\n                if (num_peaks &gt;= max_peaks)\n                    break;\n            }\n        }\n    }\n\n    // Sort peaks by power (descending)\n    for (int i = 0; i &lt; num_peaks - 1; i++)\n    {\n        for (int j = i + 1; j &lt; num_peaks; j++)\n        {\n            if (peak_powers[i] &lt; peak_powers[j])\n            {\n                // Swap\n                int temp_idx = peak_indices[i];\n                float temp_power = peak_powers[i];\n                peak_indices[i] = peak_indices[j];\n                peak_powers[i] = peak_powers[j];\n                peak_indices[j] = temp_idx;\n                peak_powers[j] = temp_power;\n            }\n        }\n    }\n\n    // Merge nearby peaks (within 2 bins) - keep the stronger one\n    int *merged_indices = (int *)malloc(num_peaks * sizeof(int));\n    float *merged_powers = (float *)malloc(num_peaks * sizeof(float));\n    int num_merged = 0;\n\n    if (merged_indices == NULL || merged_powers == NULL)\n    {\n        free(peak_indices);\n        free(peak_powers);\n        if (merged_indices) free(merged_indices);\n        if (merged_powers) free(merged_powers);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    for (int i = 0; i &lt; num_peaks; i++)\n    {\n        int idx = peak_indices[i];\n        int is_merged = 0;\n\n        // Check if this peak is too close to an already merged peak\n        for (int j = 0; j &lt; num_merged; j++)\n        {\n            int freq_diff = abs(idx - merged_indices[j]);\n            if (freq_diff &lt;= 2)  // Within 2 bins (~7.8 Hz at 1000 Hz sample rate)\n            {\n                // Keep the stronger peak\n                if (peak_powers[i] &gt; merged_powers[j])\n                {\n                    merged_indices[j] = idx;\n                    merged_powers[j] = peak_powers[i];\n                }\n                is_merged = 1;\n                break;\n            }\n        }\n\n        if (!is_merged)\n        {\n            merged_indices[num_merged] = idx;\n            merged_powers[num_merged] = peak_powers[i];\n            num_merged++;\n        }\n    }\n\n    // Re-sort merged peaks by power (descending) since merging may have changed powers\n    for (int i = 0; i &lt; num_merged - 1; i++)\n    {\n        for (int j = i + 1; j &lt; num_merged; j++)\n        {\n            if (merged_powers[i] &lt; merged_powers[j])\n            {\n                // Swap\n                int temp_idx = merged_indices[i];\n                float temp_power = merged_powers[i];\n                merged_indices[i] = merged_indices[j];\n                merged_powers[i] = merged_powers[j];\n                merged_indices[j] = temp_idx;\n                merged_powers[j] = temp_power;\n            }\n        }\n    }\n\n    // Select top N from merged peaks\n    int n_to_return = (top_n &lt; num_merged) ? top_n : num_merged;\n    int *indices = (int *)malloc(n_to_return * sizeof(int));\n    if (indices == NULL)\n    {\n        free(peak_indices);\n        free(peak_powers);\n        free(merged_indices);\n        free(merged_powers);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    for (int i = 0; i &lt; n_to_return; i++)\n    {\n        indices[i] = merged_indices[i];\n    }\n\n    free(peak_indices);\n    free(peak_powers);\n    free(merged_indices);\n    free(merged_powers);\n\n    // Convert to frequencies and powers (with parabolic interpolation for better accuracy)\n    for (int i = 0; i &lt; n_to_return; i++)\n    {\n        int idx = indices[i];\n        float refined_idx = (float)idx;\n\n        // Apply parabolic interpolation if possible\n        if (idx &gt; 0 &amp;&amp; idx &lt; (fft_len / 2 - 1))\n        {\n            float y0 = power_spectrum[idx - 1];\n            float y1 = power_spectrum[idx];\n            float y2 = power_spectrum[idx + 1];\n\n            float denominator = y0 - 2.0f * y1 + y2;\n            if (fabsf(denominator) &gt; 1e-6f)\n            {\n                float offset = 0.5f * (y0 - y2) / denominator;\n                refined_idx = (float)idx + offset;\n\n                // Clamp to valid range\n                if (refined_idx &lt; 0.0f)\n                    refined_idx = 0.0f;\n                if (refined_idx &gt;= (float)(fft_len / 2))\n                    refined_idx = (float)(fft_len / 2 - 1);\n            }\n        }\n\n        frequencies[i] = refined_idx * sample_rate / fft_len;\n        powers[i] = power_spectrum[idx];\n    }\n\n    // If we found fewer peaks than requested, set remaining to zero\n    for (int i = n_to_return; i &lt; top_n; i++)\n    {\n        frequencies[i] = 0.0f;\n        powers[i] = 0.0f;\n    }\n\n    free(indices);\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/TRANSFORM/FFT/notes/","title":"NOTES","text":"<p>Note</p> <p>Fast Fourier Transform (FFT) is a fundamental algorithm in signal processing that efficiently computes the Discrete Fourier Transform (DFT). It converts signals from the time domain to the frequency domain, enabling frequency analysis, spectral analysis, and filtering operations. FFT is widely used in audio processing, communications, structural health monitoring, and many other applications.</p>"},{"location":"DSP/TRANSFORM/FFT/notes/#fft-overview","title":"FFT OVERVIEW","text":""},{"location":"DSP/TRANSFORM/FFT/notes/#mathematical-principle","title":"Mathematical Principle","text":"<p>The Discrete Fourier Transform (DFT) of a sequence \\( x[n] \\) of length \\( N \\) is defined as:</p> \\[ X[k] = \\sum_{n=0}^{N-1} x[n] \\cdot e^{-j \\frac{2\\pi kn}{N}} \\] <p>Where:</p> <ul> <li> <p>\\( x[n] \\) is the input signal in the time domain</p> </li> <li> <p>\\( X[k] \\) is the output in the frequency domain</p> </li> <li> <p>\\( N \\) is the length of the signal (must be a power of 2)</p> </li> <li> <p>\\( k \\in [0, N-1] \\) is the frequency bin index</p> </li> </ul> <p>Frequency Resolution:</p> \\[ \\Delta f = \\frac{f_s}{N} \\] <p>Where:</p> <ul> <li> <p>\\( \\Delta f \\) is the frequency resolution (Hz)</p> </li> <li> <p>\\( f_s \\) is the sampling rate (Hz)</p> </li> <li> <p>\\( N \\) is the FFT size</p> </li> </ul> <p>Frequency of bin k:</p> \\[ f_k = k \\cdot \\frac{f_s}{N} \\]"},{"location":"DSP/TRANSFORM/FFT/notes/#window-functions","title":"WINDOW FUNCTIONS","text":"<p>Window functions are applied to signals before FFT to reduce spectral leakage. The library supports several window types:</p> <ul> <li> <p>None (Rectangular): No window applied, fastest but may have spectral leakage</p> </li> <li> <p>Hanning: Good general-purpose window, balances frequency resolution and leakage reduction</p> </li> <li> <p>Hamming: Similar to Hanning, slightly better sidelobe suppression</p> </li> <li> <p>Blackman: Best sidelobe suppression, but wider main lobe</p> </li> </ul>"},{"location":"DSP/TRANSFORM/FFT/notes/#initialization-and-deinitialization","title":"INITIALIZATION AND DEINITIALIZATION","text":""},{"location":"DSP/TRANSFORM/FFT/notes/#tiny_fft_init","title":"tiny_fft_init","text":"<pre><code>/**\n * @name: tiny_fft_init\n * @brief Initialize FFT tables (required before using FFT functions)\n * @note This function should be called once at startup\n * @param fft_size Maximum FFT size to support (must be power of 2)\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_init(int fft_size);\n</code></pre> <p>Description: </p> <p>Initializes FFT tables and prepares the library for FFT operations. This function must be called before any FFT operations.</p> <p>Features:</p> <ul> <li> <p>Platform-specific optimization enabled (ESP32 uses optimized DSP library).</p> </li> <li> <p>Must be called once before using any FFT functions.</p> </li> </ul> <p>Parameters:</p> <ul> <li><code>fft_size</code>: Maximum FFT size to support. Must be a power of 2 (e.g., 256, 512, 1024).</li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Important Notes:</p> <ul> <li> <p>FFT size must be a power of 2.</p> </li> <li> <p>This function should be called once at system startup.</p> </li> <li> <p>All subsequent FFT operations must use sizes \u2264 <code>fft_size</code>.</p> </li> </ul>"},{"location":"DSP/TRANSFORM/FFT/notes/#tiny_fft_deinit","title":"tiny_fft_deinit","text":"<pre><code>/**\n * @name: tiny_fft_deinit\n * @brief Deinitialize FFT tables and free resources\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_deinit(void);\n</code></pre> <p>Description: </p> <p>Deinitializes FFT tables and frees allocated resources.</p> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/TRANSFORM/FFT/notes/#forward-fft","title":"FORWARD FFT","text":""},{"location":"DSP/TRANSFORM/FFT/notes/#tiny_fft_f32","title":"tiny_fft_f32","text":"<pre><code>/**\n * @name: tiny_fft_f32\n * @brief Perform FFT on real-valued input signal\n * @param input Input signal array (real values)\n * @param input_len Length of input signal (must be power of 2)\n * @param output_fft Output FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n *                   Size must be at least input_len * 2\n * @param window Window function to apply before FFT (optional)\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_f32(const float *input, int input_len, float *output_fft, tiny_fft_window_t window);\n</code></pre> <p>Description: </p> <p>Performs Fast Fourier Transform on a real-valued input signal, converting it from time domain to frequency domain.</p> <p>Features:</p> <ul> <li> <p>Platform-specific optimization enabled.</p> </li> <li> <p>Supports optional window functions to reduce spectral leakage.</p> </li> <li> <p>Output is in complex format: <code>[Re0, Im0, Re1, Im1, ...]</code>.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input signal array (real values).</p> </li> <li> <p><code>input_len</code>: Length of the input signal. Must be a power of 2 and \u2264 initialized FFT size.</p> </li> <li> <p><code>output_fft</code>: Pointer to the output array for FFT result. Size must be at least <code>input_len * 2</code> (complex format).</p> </li> <li> <p><code>window</code>: Window function type to apply before FFT. Options:</p> </li> <li><code>TINY_FFT_WINDOW_NONE</code>: No window (rectangular)</li> <li><code>TINY_FFT_WINDOW_HANNING</code>: Hanning window</li> <li><code>TINY_FFT_WINDOW_HAMMING</code>: Hamming window</li> <li><code>TINY_FFT_WINDOW_BLACKMAN</code>: Blackman window</li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Output Format:</p> <p>The output is stored as an interleaved complex array:</p> <ul> <li> <p><code>output_fft[0]</code> = Real part of bin 0</p> </li> <li> <p><code>output_fft[1]</code> = Imaginary part of bin 0</p> </li> <li> <p><code>output_fft[2]</code> = Real part of bin 1</p> </li> <li> <p><code>output_fft[3]</code> = Imaginary part of bin 1</p> </li> <li> <p>...</p> </li> </ul> <p>Frequency Bins:</p> <ul> <li> <p>Bin 0: DC component (0 Hz)</p> </li> <li> <p>Bin k: Frequency = \\( k \\cdot \\frac{f_s}{N} \\) Hz</p> </li> <li> <p>Bin N/2: Nyquist frequency (\\( f_s/2 \\) Hz)</p> </li> <li> <p>Bins N/2+1 to N-1: Mirror of bins 1 to N/2-1 (for real signals)</p> </li> </ul>"},{"location":"DSP/TRANSFORM/FFT/notes/#inverse-fft","title":"INVERSE FFT","text":""},{"location":"DSP/TRANSFORM/FFT/notes/#tiny_fft_ifft_f32","title":"tiny_fft_ifft_f32","text":"<pre><code>/**\n * @name: tiny_fft_ifft_f32\n * @brief Perform inverse FFT to reconstruct time-domain signal\n * @param input_fft Input FFT array (complex: [Re0, Im0, Re1, Im1, ...])\n * @param fft_len Length of FFT (number of complex points)\n * @param output Output reconstructed signal (real values)\n *               Size must be at least fft_len\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_ifft_f32(const float *input_fft, int fft_len, float *output);\n</code></pre> <p>Description: </p> <p>Performs Inverse Fast Fourier Transform, converting a frequency-domain signal back to the time domain.</p> <p>Features:</p> <ul> <li> <p>Platform-specific optimization enabled.</p> </li> <li> <p>Reconstructs the original time-domain signal from FFT result.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>input_fft</code>: Pointer to the input FFT array (complex format: <code>[Re0, Im0, Re1, Im1, ...]</code>).</p> </li> <li> <p><code>fft_len</code>: Length of the FFT (number of complex points). Must be a power of 2.</p> </li> <li> <p><code>output</code>: Pointer to the output array for reconstructed signal (real values). Size must be at least <code>fft_len</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Note: </p> <p>The reconstructed signal should match the original input signal (within numerical precision), assuming no modifications were made to the FFT result.</p>"},{"location":"DSP/TRANSFORM/FFT/notes/#spectrum-analysis","title":"SPECTRUM ANALYSIS","text":""},{"location":"DSP/TRANSFORM/FFT/notes/#tiny_fft_magnitude_f32","title":"tiny_fft_magnitude_f32","text":"<pre><code>/**\n * @name: tiny_fft_magnitude_f32\n * @brief Calculate magnitude spectrum from FFT result\n * @param fft_result FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n * @param fft_len Length of FFT (number of complex points)\n * @param magnitude Output magnitude spectrum (real values)\n *                  Size must be at least fft_len\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_magnitude_f32(const float *fft_result, int fft_len, float *magnitude);\n</code></pre> <p>Description: </p> <p>Calculates the magnitude spectrum from FFT result. The magnitude represents the amplitude of each frequency component.</p> <p>Mathematical Formula:</p> \\[ |X[k]| = \\sqrt{\\text{Re}[X[k]]^2 + \\text{Im}[X[k]]^2} \\] <p>Parameters:</p> <ul> <li> <p><code>fft_result</code>: Pointer to the FFT result array (complex format).</p> </li> <li> <p><code>fft_len</code>: Length of the FFT (number of complex points).</p> </li> <li> <p><code>magnitude</code>: Pointer to the output array for magnitude spectrum. Size must be at least <code>fft_len</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/TRANSFORM/FFT/notes/#tiny_fft_power_spectrum_f32","title":"tiny_fft_power_spectrum_f32","text":"<pre><code>/**\n * @name: tiny_fft_power_spectrum_f32\n * @brief Calculate power spectrum density (PSD) from FFT result\n * @param fft_result FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n * @param fft_len Length of FFT (number of complex points)\n * @param power Output power spectrum (real values)\n *              Size must be at least fft_len\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_power_spectrum_f32(const float *fft_result, int fft_len, float *power);\n</code></pre> <p>Description: </p> <p>Calculates the power spectrum density (PSD) from FFT result. Power spectrum represents the power of each frequency component and is normalized by FFT length.</p> <p>Mathematical Formula:</p> \\[ P[k] = \\frac{|X[k]|^2}{N} = \\frac{\\text{Re}[X[k]]^2 + \\text{Im}[X[k]]^2}{N} \\] <p>Parameters:</p> <ul> <li> <p><code>fft_result</code>: Pointer to the FFT result array (complex format).</p> </li> <li> <p><code>fft_len</code>: Length of the FFT (number of complex points).</p> </li> <li> <p><code>power</code>: Pointer to the output array for power spectrum. Size must be at least <code>fft_len</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/TRANSFORM/FFT/notes/#frequency-detection","title":"FREQUENCY DETECTION","text":""},{"location":"DSP/TRANSFORM/FFT/notes/#tiny_fft_find_peak_frequency","title":"tiny_fft_find_peak_frequency","text":"<pre><code>/**\n * @name: tiny_fft_find_peak_frequency\n * @brief Find the frequency with maximum power (useful for structural health monitoring)\n * @param power_spectrum Power spectrum array\n * @param fft_len Length of power spectrum\n * @param sample_rate Sampling rate of the original signal (Hz)\n * @param peak_freq Output peak frequency (Hz)\n * @param peak_power Output peak power value\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_find_peak_frequency(const float *power_spectrum, int fft_len, float sample_rate, float *peak_freq, float *peak_power);\n</code></pre> <p>Description: </p> <p>Finds the frequency with the maximum power in the power spectrum. Uses parabolic interpolation for sub-bin accuracy.</p> <p>Features:</p> <ul> <li> <p>Skips DC component (bin 0).</p> </li> <li> <p>Uses parabolic interpolation to improve frequency estimation accuracy.</p> </li> <li> <p>Useful for detecting dominant frequencies in signals.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>power_spectrum</code>: Pointer to the power spectrum array.</p> </li> <li> <p><code>fft_len</code>: Length of the power spectrum.</p> </li> <li> <p><code>sample_rate</code>: Sampling rate of the original signal in Hz.</p> </li> <li> <p><code>peak_freq</code>: Pointer to output variable for peak frequency (Hz).</p> </li> <li> <p><code>peak_power</code>: Pointer to output variable for peak power value.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p>"},{"location":"DSP/TRANSFORM/FFT/notes/#tiny_fft_find_top_frequencies","title":"tiny_fft_find_top_frequencies","text":"<pre><code>/**\n * @name: tiny_fft_find_top_frequencies\n * @brief Find top N frequencies with highest power\n * @param power_spectrum Power spectrum array\n * @param fft_len Length of power spectrum\n * @param sample_rate Sampling rate of the original signal (Hz)\n * @param top_n Number of top frequencies to find\n * @param frequencies Output array for frequencies (Hz), size must be at least top_n\n * @param powers Output array for power values, size must be at least top_n\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_find_top_frequencies(const float *power_spectrum, int fft_len, float sample_rate, int top_n, float *frequencies, float *powers);\n</code></pre> <p>Description: </p> <p>Finds the top N frequencies with the highest power in the power spectrum. Automatically detects local peaks and merges nearby peaks to avoid selecting multiple bins from the same frequency peak.</p> <p>Features:</p> <ul> <li> <p>Detects local peaks in the power spectrum.</p> </li> <li> <p>Merges nearby peaks (within 2 bins) to avoid duplicates.</p> </li> <li> <p>Uses parabolic interpolation for improved frequency accuracy.</p> </li> <li> <p>Filters out insignificant peaks (below 1% of maximum power).</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>power_spectrum</code>: Pointer to the power spectrum array.</p> </li> <li> <p><code>fft_len</code>: Length of the power spectrum.</p> </li> <li> <p><code>sample_rate</code>: Sampling rate of the original signal in Hz.</p> </li> <li> <p><code>top_n</code>: Number of top frequencies to find.</p> </li> <li> <p><code>frequencies</code>: Pointer to output array for frequencies (Hz). Size must be at least <code>top_n</code>.</p> </li> <li> <p><code>powers</code>: Pointer to output array for power values. Size must be at least <code>top_n</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns success or error code.</p> <p>Note: </p> <p>If fewer than <code>top_n</code> peaks are found, remaining entries in the output arrays are set to zero.</p>"},{"location":"DSP/TRANSFORM/FFT/notes/#usage-workflow","title":"USAGE WORKFLOW","text":""},{"location":"DSP/TRANSFORM/FFT/notes/#typical-fft-analysis-workflow","title":"Typical FFT Analysis Workflow","text":"<ol> <li> <p>Initialize FFT:    <pre><code>tiny_fft_init(256);  // Initialize for max 256-point FFT\n</code></pre></p> </li> <li> <p>Perform FFT:    <pre><code>float input[256];\nfloat fft_result[512];  // Complex output: 256 * 2\ntiny_fft_f32(input, 256, fft_result, TINY_FFT_WINDOW_HANNING);\n</code></pre></p> </li> <li> <p>Calculate Power Spectrum:    <pre><code>float power[256];\ntiny_fft_power_spectrum_f32(fft_result, 256, power);\n</code></pre></p> </li> <li> <p>Find Peak Frequency:    <pre><code>float peak_freq, peak_power;\ntiny_fft_find_peak_frequency(power, 256, 1000.0f, &amp;peak_freq, &amp;peak_power);\n</code></pre></p> </li> <li> <p>Deinitialize (when done):    <pre><code>tiny_fft_deinit();\n</code></pre></p> </li> </ol>"},{"location":"DSP/TRANSFORM/FFT/notes/#applications","title":"APPLICATIONS","text":"<p>FFT is widely used in various applications:</p> <ul> <li> <p>Audio Processing: Frequency analysis, equalization, pitch detection</p> </li> <li> <p>Communications: Signal modulation, demodulation, channel analysis</p> </li> <li> <p>Structural Health Monitoring: Vibration analysis, resonance detection</p> </li> <li> <p>Biomedical: ECG/EEG analysis, heart rate detection</p> </li> <li> <p>Image Processing: 2D FFT for image filtering and analysis</p> </li> <li> <p>Spectral Analysis: Identifying frequency components in signals</p> </li> </ul>"},{"location":"DSP/TRANSFORM/FFT/test/","title":"TESTS","text":""},{"location":"DSP/TRANSFORM/FFT/test/#tiny_fft_testh","title":"tiny_fft_test.h","text":"<pre><code>/**\n * @file tiny_fft_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_fft | test | header\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_fft.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_fft_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/TRANSFORM/FFT/test/#tiny_fft_testc","title":"tiny_fft_test.c","text":"<pre><code>/**\n * @file tiny_fft_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_fft | test | source\n * @version 1.0\n * @date 2025-04-29\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_fft_test.h\"\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\n/**\n * @brief Generate a test signal with known frequency components\n */\nstatic void generate_test_signal(float *signal, int len, float sample_rate)\n{\n    // Generate signal: sin(2*pi*10*t) + 0.5*sin(2*pi*50*t)\n    // Frequencies: 10 Hz and 50 Hz\n    for (int i = 0; i &lt; len; i++)\n    {\n        float t = (float)i / sample_rate;\n        signal[i] = sinf(2.0f * M_PI * 10.0f * t) + 0.5f * sinf(2.0f * M_PI * 50.0f * t);\n    }\n}\n\nvoid tiny_fft_test(void)\n{\n    printf(\"========== TinyFFT Test ==========\\n\\n\");\n\n    const int fft_size = 256;\n    const float sample_rate = 1000.0f; // 1 kHz sampling rate\n    const int signal_len = fft_size;\n\n    // Initialize FFT\n    printf(\"1. FFT Initialization:\\n\");\n    tiny_error_t ret = tiny_fft_init(fft_size);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 FFT initialization failed: %d\\n\", ret);\n        return;\n    }\n    printf(\"  \u2713 FFT initialized (max size: %d)\\n\\n\", fft_size);\n\n    // Generate test signal\n    float *input_signal = (float *)malloc(signal_len * sizeof(float));\n    float *fft_result = (float *)malloc(signal_len * 2 * sizeof(float)); // Complex output\n    float *magnitude = (float *)malloc(signal_len * sizeof(float));\n    float *power = (float *)malloc(signal_len * sizeof(float));\n    float *reconstructed = (float *)malloc(signal_len * sizeof(float));\n\n    if (!input_signal || !fft_result || !magnitude || !power || !reconstructed)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        goto cleanup;\n    }\n\n    generate_test_signal(input_signal, signal_len, sample_rate);\n\n    printf(\"2. Test Signal Generation:\\n\");\n    printf(\"  Input: Signal with frequencies 10 Hz and 50 Hz\\n\");\n    printf(\"  Sample rate: %.1f Hz\\n\", sample_rate);\n    printf(\"  Signal length: %d samples\\n\", signal_len);\n    printf(\"  First 10 samples: \");\n    for (int i = 0; i &lt; 10 &amp;&amp; i &lt; signal_len; i++)\n    {\n        printf(\"%.3f \", input_signal[i]);\n    }\n    printf(\"\\n\\n\");\n\n    // Test FFT without window\n    printf(\"3. FFT (No Window):\\n\");\n    printf(\"  Input: Test signal (length=%d)\\n\", signal_len);\n    ret = tiny_fft_f32(input_signal, signal_len, fft_result, TINY_FFT_WINDOW_NONE);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 FFT failed: %d\\n\", ret);\n        goto cleanup;\n    }\n    printf(\"  \u2713 FFT completed\\n\");\n\n    // Calculate magnitude\n    ret = tiny_fft_magnitude_f32(fft_result, signal_len, magnitude);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 Magnitude calculation failed\\n\");\n        goto cleanup;\n    }\n\n    // Calculate power spectrum\n    ret = tiny_fft_power_spectrum_f32(fft_result, signal_len, power);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 Power spectrum calculation failed\\n\");\n        goto cleanup;\n    }\n\n    printf(\"  Output: FFT result (complex, length=%d)\\n\", signal_len);\n    printf(\"  Magnitude spectrum: First 10 values: \");\n    for (int i = 0; i &lt; 10 &amp;&amp; i &lt; signal_len; i++)\n    {\n        printf(\"%.3f \", magnitude[i]);\n    }\n    printf(\"\\n\\n\");\n\n    // Find peak frequency\n    printf(\"4. Peak Frequency Detection:\\n\");\n    printf(\"  Input: Power spectrum (length=%d)\\n\", signal_len);\n    float peak_freq, peak_power;\n    ret = tiny_fft_find_peak_frequency(power, signal_len, sample_rate, &amp;peak_freq, &amp;peak_power);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 Peak detection failed\\n\");\n        goto cleanup;\n    }\n    printf(\"  Output: Peak frequency = %.2f Hz (power = %.3f)\\n\", peak_freq, peak_power);\n    printf(\"  Expected: ~10 Hz or ~50 Hz (strongest component)\\n\\n\");\n\n    // Find top frequencies\n    printf(\"5. Top Frequencies Detection:\\n\");\n    printf(\"  Input: Power spectrum (length=%d)\\n\", signal_len);\n    const int top_n = 3;\n    float *top_freqs = (float *)malloc(top_n * sizeof(float));\n    float *top_powers = (float *)malloc(top_n * sizeof(float));\n    if (!top_freqs || !top_powers)\n    {\n        printf(\"  \u2717 Memory allocation failed\\n\");\n        goto cleanup;\n    }\n\n    ret = tiny_fft_find_top_frequencies(power, signal_len, sample_rate, top_n, top_freqs, top_powers);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 Top frequencies detection failed\\n\");\n        goto cleanup;\n    }\n    printf(\"  Output: Top %d frequencies:\\n\", top_n);\n    for (int i = 0; i &lt; top_n; i++)\n    {\n        printf(\"    [%d] %.2f Hz (power = %.3f)\\n\", i + 1, top_freqs[i], top_powers[i]);\n    }\n    printf(\"  Expected: ~10 Hz and ~50 Hz should be in top frequencies\\n\\n\");\n\n    // Test IFFT\n    printf(\"6. IFFT (Signal Reconstruction):\\n\");\n    printf(\"  Input: FFT result (complex, length=%d)\\n\", signal_len);\n    ret = tiny_fft_ifft_f32(fft_result, signal_len, reconstructed);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 IFFT failed: %d\\n\", ret);\n        goto cleanup;\n    }\n    printf(\"  Output: Reconstructed signal (length=%d)\\n\", signal_len);\n    printf(\"  First 10 samples: \");\n    for (int i = 0; i &lt; 10 &amp;&amp; i &lt; signal_len; i++)\n    {\n        printf(\"%.3f \", reconstructed[i]);\n    }\n    printf(\"\\n\");\n\n    // Verify reconstruction (should match original, accounting for window effects)\n    float max_diff = 0.0f;\n    for (int i = 0; i &lt; signal_len; i++)\n    {\n        float diff = fabsf(reconstructed[i] - input_signal[i]);\n        if (diff &gt; max_diff)\n        {\n            max_diff = diff;\n        }\n    }\n    printf(\"  Max difference from original: %.6f\\n\", max_diff);\n    printf(\"  \u2713 IFFT reconstruction completed\\n\\n\");\n\n    // Test with window\n    printf(\"7. FFT with Hanning Window:\\n\");\n    printf(\"  Input: Test signal (length=%d) with Hanning window\\n\", signal_len);\n    ret = tiny_fft_f32(input_signal, signal_len, fft_result, TINY_FFT_WINDOW_HANNING);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 Windowed FFT failed\\n\");\n        goto cleanup;\n    }\n    ret = tiny_fft_power_spectrum_f32(fft_result, signal_len, power);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 Power spectrum calculation failed\\n\");\n        goto cleanup;\n    }\n    ret = tiny_fft_find_peak_frequency(power, signal_len, sample_rate, &amp;peak_freq, &amp;peak_power);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 Peak detection failed\\n\");\n        goto cleanup;\n    }\n    printf(\"  Output: Peak frequency = %.2f Hz (power = %.3f)\\n\", peak_freq, peak_power);\n    printf(\"  Note: Window reduces spectral leakage, improving frequency resolution\\n\\n\");\n\n    free(top_freqs);\n    free(top_powers);\n\ncleanup:\n    if (input_signal)\n        free(input_signal);\n    if (fft_result)\n        free(fft_result);\n    if (magnitude)\n        free(magnitude);\n    if (power)\n        free(power);\n    if (reconstructed)\n        free(reconstructed);\n\n    // Deinitialize\n    tiny_fft_deinit();\n    printf(\"8. FFT Deinitialization:\\n\");\n    printf(\"  \u2713 FFT deinitialized\\n\");\n\n    printf(\"\\n========================================\\n\");\n}\n</code></pre>"},{"location":"DSP/TRANSFORM/FFT/test/#test-results","title":"TEST RESULTS","text":"<pre><code>========== TinyFFT Test ==========\n\n1. FFT Initialization:\n  \u2713 FFT initialized (max size: 256)\n\n2. Test Signal Generation:\n  Input: Signal with frequencies 10 Hz and 50 Hz\n  Sample rate: 1000.0 Hz\n  Signal length: 256 samples\n  First 10 samples: 0.000 0.217 0.419 0.592 0.724 0.809 0.844 0.830 0.776 0.690 \n\n3. FFT (No Window):\n  Input: Test signal (length=256)\n  \u2713 FFT completed\n  Output: FFT result (complex, length=256)\n  Magnitude spectrum: First 10 values: 32.216 37.858 81.243 82.696 20.529 9.805 5.459 3.052 1.398 0.332 \n\n4. Peak Frequency Detection:\n  Input: Power spectrum (length=256)\n  Output: Peak frequency = 9.91 Hz (power = 26.714)\n  Expected: ~10 Hz or ~50 Hz (strongest component)\n\n5. Top Frequencies Detection:\n  Input: Power spectrum (length=256)\n  Output: Top 3 frequencies:\n    [1] 9.91 Hz (power = 26.714)\n    [2] 50.77 Hz (power = 14.756)\n    [3] 0.00 Hz (power = 0.000)\n  Expected: ~10 Hz and ~50 Hz should be in top frequencies\n\n6. IFFT (Signal Reconstruction):\n  Input: FFT result (complex, length=256)\n  Output: Reconstructed signal (length=256)\n  First 10 samples: 0.000 0.217 0.419 0.592 0.724 0.809 0.844 0.830 0.776 0.690 \n  Max difference from original: 0.000003\n  \u2713 IFFT reconstruction completed\n\n7. FFT with Hanning Window:\n  Input: Test signal (length=256) with Hanning window\n  Output: Peak frequency = 10.32 Hz (power = 12.407)\n  Note: Window reduces spectral leakage, improving frequency resolution\n\n8. FFT Deinitialization:\n  \u2713 FFT deinitialized\n\n========================================\n</code></pre>"},{"location":"DSP/TRANSFORM/ICA/code/","title":"CODE","text":""},{"location":"DSP/TRANSFORM/ICA/code/#tiny_icah","title":"tiny_ica.h","text":"<pre><code>/**\n * @file tiny_ica.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_ica | Independent Component Analysis (ICA) | header\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n * @details\n * Independent Component Analysis (ICA) Implementation\n * - Blind source separation: X = A * S, where X is mixed signals, A is mixing matrix, S is sources\n * - FastICA algorithm implementation\n * - Support for multiple sources and observations\n * - Whitening and centering preprocessing\n * - Reuses tiny_math matrix operations\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// tiny_dsp configuration file\n#include \"tiny_dsp_config.h\"\n\n// tiny_math for matrix operations\n#include \"tiny_mat.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @brief ICA algorithm types\n     */\n    typedef enum\n    {\n        TINY_ICA_FASTICA = 0,  // FastICA algorithm (default)\n        TINY_ICA_INFOMAX,      // Infomax algorithm (future)\n        TINY_ICA_COUNT\n    } tiny_ica_algorithm_t;\n\n    /**\n     * @brief Nonlinearity function types for FastICA\n     */\n    typedef enum\n    {\n        TINY_ICA_NONLINEARITY_TANH = 0,  // tanh (default, good for super-Gaussian)\n        TINY_ICA_NONLINEARITY_EXP,        // exp(-u^2/2) (good for sub-Gaussian)\n        TINY_ICA_NONLINEARITY_CUBE,       // u^3 (good for super-Gaussian)\n        TINY_ICA_NONLINEARITY_COUNT\n    } tiny_ica_nonlinearity_t;\n\n    /**\n     * @brief ICA structure for maintaining state\n     */\n    typedef struct\n    {\n        float *mixing_matrix;      // Estimated mixing matrix (num_obs x num_sources)\n        float *unmixing_matrix;     // Estimated unmixing matrix (num_sources x num_obs)\n        float *whitening_matrix;    // Whitening matrix (num_sources x num_obs)\n        float *mean;                // Mean of input data (num_obs)\n        int num_obs;                // Number of observations (mixed signals)\n        int num_sources;            // Number of sources to extract\n        int initialized;           // Initialization flag\n    } tiny_ica_t;\n\n    /**\n     * @name: tiny_ica_separate_f32\n     * @brief Perform ICA separation on mixed signals\n     * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n     *                      Each row is one observation (mixed signal)\n     * @param num_obs Number of observations (mixed signals)\n     * @param num_samples Number of samples per signal\n     * @param num_sources Number of independent sources to extract\n     * @param separated_sources Output separated sources (num_sources x num_samples, row-major)\n     *                          Each row is one independent source\n     * @param algorithm ICA algorithm to use (default: TINY_ICA_FASTICA)\n     * @param nonlinearity Nonlinearity function for FastICA (default: TINY_ICA_NONLINEARITY_TANH)\n     * @param max_iter Maximum number of iterations (default: 100)\n     * @param tolerance Convergence tolerance (default: 1e-4)\n     * @return tiny_error_t\n     * @note This function performs complete ICA: preprocessing, separation, and source extraction\n     */\n    tiny_error_t tiny_ica_separate_f32(const float *mixed_signals,\n                                       int num_obs,\n                                       int num_samples,\n                                       int num_sources,\n                                       float *separated_sources,\n                                       tiny_ica_algorithm_t algorithm,\n                                       tiny_ica_nonlinearity_t nonlinearity,\n                                       int max_iter,\n                                       float tolerance);\n\n    /**\n     * @name: tiny_ica_init\n     * @brief Initialize ICA structure for repeated use\n     * @param ica Pointer to ICA structure\n     * @param num_obs Number of observations (mixed signals)\n     * @param num_sources Number of sources to extract\n     * @return tiny_error_t\n     * @note This allocates memory for matrices. Call tiny_ica_deinit to free.\n     */\n    tiny_error_t tiny_ica_init(tiny_ica_t *ica, int num_obs, int num_sources);\n\n    /**\n     * @name: tiny_ica_fit\n     * @brief Fit ICA model to mixed signals (learn unmixing matrix)\n     * @param ica Pointer to initialized ICA structure\n     * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n     * @param num_samples Number of samples per signal\n     * @param algorithm ICA algorithm to use\n     * @param nonlinearity Nonlinearity function for FastICA\n     * @param max_iter Maximum number of iterations\n     * @param tolerance Convergence tolerance\n     * @return tiny_error_t\n     * @note After fitting, use tiny_ica_transform to separate new signals\n     */\n    tiny_error_t tiny_ica_fit(tiny_ica_t *ica,\n                              const float *mixed_signals,\n                              int num_samples,\n                              tiny_ica_algorithm_t algorithm,\n                              tiny_ica_nonlinearity_t nonlinearity,\n                              int max_iter,\n                              float tolerance);\n\n    /**\n     * @name: tiny_ica_transform\n     * @brief Apply learned ICA model to separate signals\n     * @param ica Pointer to fitted ICA structure\n     * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n     * @param num_samples Number of samples per signal\n     * @param separated_sources Output separated sources (num_sources x num_samples, row-major)\n     * @return tiny_error_t\n     * @note Requires ica to be fitted first using tiny_ica_fit\n     */\n    tiny_error_t tiny_ica_transform(const tiny_ica_t *ica,\n                                    const float *mixed_signals,\n                                    int num_samples,\n                                    float *separated_sources);\n\n    /**\n     * @name: tiny_ica_deinit\n     * @brief Deinitialize ICA structure and free memory\n     * @param ica Pointer to ICA structure\n     * @return tiny_error_t\n     */\n    tiny_error_t tiny_ica_deinit(tiny_ica_t *ica);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/TRANSFORM/ICA/code/#tiny_icac","title":"tiny_ica.c","text":"<pre><code>/**\n * @file tiny_ica.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_ica | Independent Component Analysis (ICA) | source\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_ica.h\"\n#include &lt;math.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846f\n#endif\n\n/* ============================================================================\n * HELPER FUNCTIONS\n * ============================================================================ */\n\n/**\n * @brief Compute mean of each row (observation)\n */\nstatic void compute_row_mean(const float *data, int rows, int cols, float *mean)\n{\n    for (int i = 0; i &lt; rows; i++)\n    {\n        mean[i] = 0.0f;\n        for (int j = 0; j &lt; cols; j++)\n        {\n            mean[i] += data[i * cols + j];\n        }\n        mean[i] /= (float)cols;\n    }\n}\n\n/**\n * @brief Center data by subtracting row means\n */\nstatic void center_data(const float *data, int rows, int cols, const float *mean, float *centered)\n{\n    for (int i = 0; i &lt; rows; i++)\n    {\n        for (int j = 0; j &lt; cols; j++)\n        {\n            centered[i * cols + j] = data[i * cols + j] - mean[i];\n        }\n    }\n}\n\n/**\n * @brief Compute covariance matrix: C = (1/N) * X * X^T\n */\nstatic tiny_error_t compute_covariance(const float *data, int rows, int cols, float *cov)\n{\n    // cov = (1/N) * data * data^T\n    // data is (rows x cols), data^T is (cols x rows)\n    // cov is (rows x rows)\n\n    // First compute data * data^T\n    for (int i = 0; i &lt; rows; i++)\n    {\n        for (int j = 0; j &lt; rows; j++)\n        {\n            float sum = 0.0f;\n            for (int k = 0; k &lt; cols; k++)\n            {\n                sum += data[i * cols + k] * data[j * cols + k];\n            }\n            cov[i * rows + j] = sum / (float)cols;\n        }\n    }\n\n    return TINY_OK;\n}\n\n/**\n * @brief Simple eigenvalue decomposition for symmetric matrix (for whitening)\n * Uses Jacobi method for small matrices\n */\nstatic tiny_error_t eigendecompose_symmetric(const float *A, int n, float *eigenvalues, float *eigenvectors, float tolerance, int max_iter)\n{\n    // Initialize eigenvectors as identity\n    for (int i = 0; i &lt; n; i++)\n    {\n        for (int j = 0; j &lt; n; j++)\n        {\n            eigenvectors[i * n + j] = (i == j) ? 1.0f : 0.0f;\n        }\n    }\n\n    // Copy A to working matrix\n    float *B = (float *)malloc(n * n * sizeof(float));\n    if (B == NULL)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    memcpy(B, A, n * n * sizeof(float));\n\n    // Jacobi iteration\n    for (int iter = 0; iter &lt; max_iter; iter++)\n    {\n        // Find largest off-diagonal element\n        int p = 0, q = 1;\n        float max_val = fabsf(B[1]);\n\n        for (int i = 0; i &lt; n; i++)\n        {\n            for (int j = i + 1; j &lt; n; j++)\n            {\n                float val = fabsf(B[i * n + j]);\n                if (val &gt; max_val)\n                {\n                    max_val = val;\n                    p = i;\n                    q = j;\n                }\n            }\n        }\n\n        // Check convergence\n        if (max_val &lt; tolerance)\n            break;\n\n        // Compute rotation angle\n        float a_pq = B[p * n + q];\n        float a_pp = B[p * n + p];\n        float a_qq = B[q * n + q];\n\n        float tau = (a_qq - a_pp) / (2.0f * a_pq);\n        float t = (tau &gt;= 0.0f) ? 1.0f / (tau + sqrtf(1.0f + tau * tau))\n                                 : -1.0f / (-tau + sqrtf(1.0f + tau * tau));\n        float c = 1.0f / sqrtf(1.0f + t * t);\n        float s = t * c;\n\n        // Apply rotation to B\n        for (int i = 0; i &lt; n; i++)\n        {\n            if (i != p &amp;&amp; i != q)\n            {\n                float b_ip = B[i * n + p];\n                float b_iq = B[i * n + q];\n                B[i * n + p] = c * b_ip - s * b_iq;\n                B[i * n + q] = s * b_ip + c * b_iq;\n                B[p * n + i] = B[i * n + p];\n                B[q * n + i] = B[i * n + q];\n            }\n        }\n\n        float b_pp = B[p * n + p];\n        float b_pq = B[p * n + q];\n        float b_qq = B[q * n + q];\n\n        B[p * n + p] = c * c * b_pp - 2.0f * c * s * b_pq + s * s * b_qq;\n        B[q * n + q] = s * s * b_pp + 2.0f * c * s * b_pq + c * c * b_qq;\n        B[p * n + q] = 0.0f;\n        B[q * n + p] = 0.0f;\n\n        // Update eigenvectors\n        for (int i = 0; i &lt; n; i++)\n        {\n            float v_ip = eigenvectors[i * n + p];\n            float v_iq = eigenvectors[i * n + q];\n            eigenvectors[i * n + p] = c * v_ip - s * v_iq;\n            eigenvectors[i * n + q] = s * v_ip + c * v_iq;\n        }\n    }\n\n    // Extract eigenvalues from diagonal\n    for (int i = 0; i &lt; n; i++)\n    {\n        eigenvalues[i] = B[i * n + i];\n    }\n\n    free(B);\n    return TINY_OK;\n}\n\n/**\n * @brief Whitening: Z = D^(-1/2) * E^T * X\n * where D is eigenvalues, E is eigenvectors of covariance matrix\n */\nstatic tiny_error_t whiten_data(const float *data, int rows, int cols, int num_sources, float *whitened, float *whitening_matrix)\n{\n    // Compute covariance matrix\n    float *cov = (float *)malloc(rows * rows * sizeof(float));\n    if (cov == NULL)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    tiny_error_t err = compute_covariance(data, rows, cols, cov);\n    if (err != TINY_OK)\n    {\n        free(cov);\n        return err;\n    }\n\n    // Eigenvalue decomposition\n    float *eigenvalues = (float *)malloc(rows * sizeof(float));\n    float *eigenvectors = (float *)malloc(rows * rows * sizeof(float));\n\n    if (eigenvalues == NULL || eigenvectors == NULL)\n    {\n        free(cov);\n        free(eigenvalues);\n        free(eigenvectors);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    err = eigendecompose_symmetric(cov, rows, eigenvalues, eigenvectors, 1e-6f, 100);\n    if (err != TINY_OK)\n    {\n        free(cov);\n        free(eigenvalues);\n        free(eigenvectors);\n        return err;\n    }\n\n    // Compute whitening matrix: D^(-1/2) * E^T\n    // Use only top num_sources components (largest eigenvalues)\n\n    // Sort eigenvalues in descending order (simple bubble sort for small matrices)\n    int *indices = (int *)malloc(rows * sizeof(int));\n    if (indices == NULL)\n    {\n        free(cov);\n        free(eigenvalues);\n        free(eigenvectors);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    for (int i = 0; i &lt; rows; i++)\n        indices[i] = i;\n\n    // Simple bubble sort\n    for (int i = 0; i &lt; rows - 1; i++)\n    {\n        for (int j = 0; j &lt; rows - 1 - i; j++)\n        {\n            if (eigenvalues[indices[j]] &lt; eigenvalues[indices[j + 1]])\n            {\n                int temp = indices[j];\n                indices[j] = indices[j + 1];\n                indices[j + 1] = temp;\n            }\n        }\n    }\n\n    // Build whitening matrix: D^(-1/2) * E^T\n    // whitening_matrix is (num_sources x rows)\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        int idx = indices[i];\n        float lambda = eigenvalues[idx];\n        if (lambda &gt; 1e-10f) // Avoid division by zero\n        {\n            float scale = 1.0f / sqrtf(lambda);\n            for (int j = 0; j &lt; rows; j++)\n            {\n                whitening_matrix[i * rows + j] = scale * eigenvectors[j * rows + idx];\n            }\n        }\n        else\n        {\n            // Zero eigenvalue, set row to zero\n            for (int j = 0; j &lt; rows; j++)\n            {\n                whitening_matrix[i * rows + j] = 0.0f;\n            }\n        }\n    }\n\n    // Apply whitening: whitened = whitening_matrix * data\n    // whitening_matrix is (num_sources x rows), data is (rows x cols)\n    // result is (num_sources x cols)\n    err = tiny_mat_mult_f32(whitening_matrix, data, whitened, num_sources, rows, cols);\n\n    free(cov);\n    free(eigenvalues);\n    free(eigenvectors);\n    free(indices);\n\n    return err;\n}\n\n/**\n * @brief Apply nonlinearity function\n */\nstatic float apply_nonlinearity(float x, tiny_ica_nonlinearity_t type)\n{\n    switch (type)\n    {\n    case TINY_ICA_NONLINEARITY_TANH:\n        return tanhf(x);\n    case TINY_ICA_NONLINEARITY_EXP:\n        return x * expf(-0.5f * x * x);\n    case TINY_ICA_NONLINEARITY_CUBE:\n        return x * x * x;\n    default:\n        return tanhf(x);\n    }\n}\n\n/**\n * @brief Apply nonlinearity derivative\n */\nstatic float apply_nonlinearity_derivative(float x, tiny_ica_nonlinearity_t type)\n{\n    switch (type)\n    {\n    case TINY_ICA_NONLINEARITY_TANH:\n    {\n        float t = tanhf(x);\n        return 1.0f - t * t;\n    }\n    case TINY_ICA_NONLINEARITY_EXP:\n        return (1.0f - x * x) * expf(-0.5f * x * x);\n    case TINY_ICA_NONLINEARITY_CUBE:\n        return 3.0f * x * x;\n    default:\n    {\n        float t = tanhf(x);\n        return 1.0f - t * t;\n    }\n    }\n}\n\n/**\n * @brief FastICA algorithm: extract one independent component\n */\nstatic tiny_error_t fastica_extract_one(const float *whitened, int num_sources, int num_samples,\n                                        float *w, tiny_ica_nonlinearity_t nonlinearity,\n                                        int max_iter, float tolerance)\n{\n    // Initialize w randomly\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        w[i] = ((float)rand() / (float)RAND_MAX) * 2.0f - 1.0f;\n    }\n\n    // Normalize w\n    float norm = 0.0f;\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        norm += w[i] * w[i];\n    }\n    norm = sqrtf(norm);\n    if (norm &lt; 1e-10f)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        w[i] /= norm;\n    }\n\n    // Iterate\n    float *w_old = (float *)malloc(num_sources * sizeof(float));\n    if (w_old == NULL)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    for (int iter = 0; iter &lt; max_iter; iter++)\n    {\n        memcpy(w_old, w, num_sources * sizeof(float));\n\n        // Compute w_new = E{g(w^T * x) * x} - E{g'(w^T * x)} * w\n        float *w_new = (float *)calloc(num_sources, sizeof(float));\n        if (w_new == NULL)\n        {\n            free(w_old);\n            return TINY_ERR_DSP_MEMORY_ALLOC;\n        }\n\n        float mean_g_prime = 0.0f;\n\n        for (int t = 0; t &lt; num_samples; t++)\n        {\n            // Compute w^T * x_t\n            float wx = 0.0f;\n            for (int i = 0; i &lt; num_sources; i++)\n            {\n                wx += w[i] * whitened[i * num_samples + t];\n            }\n\n            float g = apply_nonlinearity(wx, nonlinearity);\n            float g_prime = apply_nonlinearity_derivative(wx, nonlinearity);\n\n            for (int i = 0; i &lt; num_sources; i++)\n            {\n                w_new[i] += g * whitened[i * num_samples + t];\n            }\n\n            mean_g_prime += g_prime;\n        }\n\n        mean_g_prime /= (float)num_samples;\n        for (int i = 0; i &lt; num_sources; i++)\n        {\n            w_new[i] /= (float)num_samples;\n            w_new[i] -= mean_g_prime * w[i];\n        }\n\n        // Normalize\n        norm = 0.0f;\n        for (int i = 0; i &lt; num_sources; i++)\n        {\n            norm += w_new[i] * w_new[i];\n        }\n        norm = sqrtf(norm);\n        if (norm &gt; 1e-10f)\n        {\n            for (int i = 0; i &lt; num_sources; i++)\n            {\n                w[i] = w_new[i] / norm;\n            }\n        }\n\n        free(w_new);\n\n        // Check convergence\n        float change = 0.0f;\n        for (int i = 0; i &lt; num_sources; i++)\n        {\n            float diff = w[i] - w_old[i];\n            change += diff * diff;\n        }\n        change = sqrtf(change);\n\n        if (change &lt; tolerance)\n            break;\n    }\n\n    free(w_old);\n    return TINY_OK;\n}\n\n/**\n * @brief Orthogonalize w against previous components\n */\nstatic void orthogonalize(float *w, const float *W, int num_components, int num_sources)\n{\n    // w = w - W^T * W * w\n    for (int i = 0; i &lt; num_components; i++)\n    {\n        // Compute dot product: W[i]^T * w\n        float dot = 0.0f;\n        for (int j = 0; j &lt; num_sources; j++)\n        {\n            dot += W[i * num_sources + j] * w[j];\n        }\n\n        // Subtract projection: w = w - dot * W[i]\n        for (int j = 0; j &lt; num_sources; j++)\n        {\n            w[j] -= dot * W[i * num_sources + j];\n        }\n    }\n\n    // Normalize\n    float norm = 0.0f;\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        norm += w[i] * w[i];\n    }\n    norm = sqrtf(norm);\n    if (norm &gt; 1e-10f)\n    {\n        for (int i = 0; i &lt; num_sources; i++)\n        {\n            w[i] /= norm;\n        }\n    }\n}\n\n/* ============================================================================\n * ICA IMPLEMENTATION\n * ============================================================================ */\n\ntiny_error_t tiny_ica_separate_f32(const float *mixed_signals,\n                                   int num_obs,\n                                   int num_samples,\n                                   int num_sources,\n                                   float *separated_sources,\n                                   tiny_ica_algorithm_t algorithm,\n                                   tiny_ica_nonlinearity_t nonlinearity,\n                                   int max_iter,\n                                   float tolerance)\n{\n    if (mixed_signals == NULL || separated_sources == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (num_obs &lt;= 0 || num_samples &lt;= 0 || num_sources &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    if (num_sources &gt; num_obs)\n        return TINY_ERR_DSP_INVALID_PARAM; // Cannot extract more sources than observations\n\n    if (algorithm != TINY_ICA_FASTICA)\n        return TINY_ERR_NOT_SUPPORTED; // Only FastICA implemented\n\n    // Default parameters\n    if (max_iter &lt;= 0)\n        max_iter = 100;\n    if (tolerance &lt;= 0.0f)\n        tolerance = 1e-4f;\n\n    // Step 1: Center data\n    float *mean = (float *)malloc(num_obs * sizeof(float));\n    float *centered = (float *)malloc(num_obs * num_samples * sizeof(float));\n\n    if (mean == NULL || centered == NULL)\n    {\n        free(mean);\n        free(centered);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    compute_row_mean(mixed_signals, num_obs, num_samples, mean);\n    center_data(mixed_signals, num_obs, num_samples, mean, centered);\n\n    // Step 2: Whiten data\n    float *whitening_matrix = (float *)malloc(num_sources * num_obs * sizeof(float));\n    float *whitened = (float *)malloc(num_sources * num_samples * sizeof(float));\n\n    if (whitening_matrix == NULL || whitened == NULL)\n    {\n        free(mean);\n        free(centered);\n        free(whitening_matrix);\n        free(whitened);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    tiny_error_t err = whiten_data(centered, num_obs, num_samples, num_sources, whitened, whitening_matrix);\n    if (err != TINY_OK)\n    {\n        free(mean);\n        free(centered);\n        free(whitening_matrix);\n        free(whitened);\n        return err;\n    }\n\n    // Step 3: FastICA - extract independent components\n    float *W = (float *)malloc(num_sources * num_sources * sizeof(float));\n    if (W == NULL)\n    {\n        free(mean);\n        free(centered);\n        free(whitening_matrix);\n        free(whitened);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    float *w = (float *)malloc(num_sources * sizeof(float));\n    if (w == NULL)\n    {\n        free(mean);\n        free(centered);\n        free(whitening_matrix);\n        free(whitened);\n        free(W);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Extract each component\n    for (int comp = 0; comp &lt; num_sources; comp++)\n    {\n        err = fastica_extract_one(whitened, num_sources, num_samples, w, nonlinearity, max_iter, tolerance);\n        if (err != TINY_OK)\n        {\n            free(mean);\n            free(centered);\n            free(whitening_matrix);\n            free(whitened);\n            free(W);\n            free(w);\n            return err;\n        }\n\n        // Orthogonalize against previous components\n        if (comp &gt; 0)\n        {\n            orthogonalize(w, W, comp, num_sources);\n        }\n\n        // Store in W\n        for (int i = 0; i &lt; num_sources; i++)\n        {\n            W[comp * num_sources + i] = w[i];\n        }\n    }\n\n    // Step 4: Compute separated sources: S = W * Z\n    // W is (num_sources x num_sources), whitened is (num_sources x num_samples)\n    // separated_sources is (num_sources x num_samples)\n    err = tiny_mat_mult_f32(W, whitened, separated_sources, num_sources, num_sources, num_samples);\n\n    free(mean);\n    free(centered);\n    free(whitening_matrix);\n    free(whitened);\n    free(W);\n    free(w);\n\n    return err;\n}\n\ntiny_error_t tiny_ica_init(tiny_ica_t *ica, int num_obs, int num_sources)\n{\n    if (ica == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (num_obs &lt;= 0 || num_sources &lt;= 0 || num_sources &gt; num_obs)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    ica-&gt;num_obs = num_obs;\n    ica-&gt;num_sources = num_sources;\n\n    ica-&gt;mixing_matrix = (float *)calloc(num_obs * num_sources, sizeof(float));\n    ica-&gt;unmixing_matrix = (float *)calloc(num_sources * num_obs, sizeof(float));\n    ica-&gt;whitening_matrix = (float *)calloc(num_sources * num_obs, sizeof(float));\n    ica-&gt;mean = (float *)calloc(num_obs, sizeof(float));\n\n    if (ica-&gt;mixing_matrix == NULL || ica-&gt;unmixing_matrix == NULL ||\n        ica-&gt;whitening_matrix == NULL || ica-&gt;mean == NULL)\n    {\n        tiny_ica_deinit(ica);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    ica-&gt;initialized = 1;\n    return TINY_OK;\n}\n\ntiny_error_t tiny_ica_fit(tiny_ica_t *ica,\n                          const float *mixed_signals,\n                          int num_samples,\n                          tiny_ica_algorithm_t algorithm,\n                          tiny_ica_nonlinearity_t nonlinearity,\n                          int max_iter,\n                          float tolerance)\n{\n    if (ica == NULL || mixed_signals == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (!ica-&gt;initialized)\n        return TINY_ERR_DSP_UNINITIALIZED;\n\n    if (num_samples &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // Center data\n    compute_row_mean(mixed_signals, ica-&gt;num_obs, num_samples, ica-&gt;mean);\n\n    float *centered = (float *)malloc(ica-&gt;num_obs * num_samples * sizeof(float));\n    if (centered == NULL)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    center_data(mixed_signals, ica-&gt;num_obs, num_samples, ica-&gt;mean, centered);\n\n    // Whiten data\n    float *whitened = (float *)malloc(ica-&gt;num_sources * num_samples * sizeof(float));\n    if (whitened == NULL)\n    {\n        free(centered);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    tiny_error_t err = whiten_data(centered, ica-&gt;num_obs, num_samples, ica-&gt;num_sources, whitened, ica-&gt;whitening_matrix);\n    if (err != TINY_OK)\n    {\n        free(centered);\n        free(whitened);\n        return err;\n    }\n\n    // FastICA - extract components\n    float *W = (float *)malloc(ica-&gt;num_sources * ica-&gt;num_sources * sizeof(float));\n    if (W == NULL)\n    {\n        free(centered);\n        free(whitened);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    float *w = (float *)malloc(ica-&gt;num_sources * sizeof(float));\n    if (w == NULL)\n    {\n        free(centered);\n        free(whitened);\n        free(W);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    for (int comp = 0; comp &lt; ica-&gt;num_sources; comp++)\n    {\n        err = fastica_extract_one(whitened, ica-&gt;num_sources, num_samples, w, nonlinearity, max_iter, tolerance);\n        if (err != TINY_OK)\n        {\n            free(centered);\n            free(whitened);\n            free(W);\n            free(w);\n            return err;\n        }\n\n        if (comp &gt; 0)\n        {\n            orthogonalize(w, W, comp, ica-&gt;num_sources);\n        }\n\n        for (int i = 0; i &lt; ica-&gt;num_sources; i++)\n        {\n            W[comp * ica-&gt;num_sources + i] = w[i];\n        }\n    }\n\n    // Store unmixing matrix: W_unmix = W * whitening_matrix\n    err = tiny_mat_mult_f32(W, ica-&gt;whitening_matrix, ica-&gt;unmixing_matrix,\n                            ica-&gt;num_sources, ica-&gt;num_sources, ica-&gt;num_obs);\n\n    // Compute mixing matrix (pseudo-inverse of unmixing matrix)\n    // For now, use simple approach: A = (W_unmix^T * W_unmix)^(-1) * W_unmix^T\n    // Simplified: assume square and use transpose\n    // TODO: Implement proper pseudo-inverse\n\n    free(centered);\n    free(whitened);\n    free(W);\n    free(w);\n\n    return err;\n}\n\ntiny_error_t tiny_ica_transform(const tiny_ica_t *ica,\n                                const float *mixed_signals,\n                                int num_samples,\n                                float *separated_sources)\n{\n    if (ica == NULL || mixed_signals == NULL || separated_sources == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (!ica-&gt;initialized)\n        return TINY_ERR_DSP_UNINITIALIZED;\n\n    if (num_samples &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    // Center data\n    float *centered = (float *)malloc(ica-&gt;num_obs * num_samples * sizeof(float));\n    if (centered == NULL)\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n\n    center_data(mixed_signals, ica-&gt;num_obs, num_samples, ica-&gt;mean, centered);\n\n    // Apply whitening\n    float *whitened = (float *)malloc(ica-&gt;num_sources * num_samples * sizeof(float));\n    if (whitened == NULL)\n    {\n        free(centered);\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    tiny_error_t err = tiny_mat_mult_f32(ica-&gt;whitening_matrix, centered, whitened,\n                                        ica-&gt;num_sources, ica-&gt;num_obs, num_samples);\n    if (err != TINY_OK)\n    {\n        free(centered);\n        free(whitened);\n        return err;\n    }\n\n    // Apply unmixing matrix\n    // Extract W from unmixing_matrix (W = unmixing_matrix * whitening_matrix^(-1))\n    // For simplicity, use unmixing_matrix directly on whitened data\n    // Actually, unmixing_matrix = W * whitening_matrix, so we need to extract W\n    // Simplified: use unmixing_matrix on centered data directly\n    err = tiny_mat_mult_f32(ica-&gt;unmixing_matrix, centered, separated_sources,\n                            ica-&gt;num_sources, ica-&gt;num_obs, num_samples);\n\n    free(centered);\n    free(whitened);\n\n    return err;\n}\n\ntiny_error_t tiny_ica_deinit(tiny_ica_t *ica)\n{\n    if (ica == NULL)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (ica-&gt;initialized)\n    {\n        free(ica-&gt;mixing_matrix);\n        free(ica-&gt;unmixing_matrix);\n        free(ica-&gt;whitening_matrix);\n        free(ica-&gt;mean);\n\n        ica-&gt;mixing_matrix = NULL;\n        ica-&gt;unmixing_matrix = NULL;\n        ica-&gt;whitening_matrix = NULL;\n        ica-&gt;mean = NULL;\n        ica-&gt;num_obs = 0;\n        ica-&gt;num_sources = 0;\n        ica-&gt;initialized = 0;\n    }\n\n    return TINY_OK;\n}\n</code></pre>"},{"location":"DSP/TRANSFORM/ICA/notes/","title":"NOTES","text":"<p>Note</p> <p>Independent Component Analysis (ICA) is a blind source separation technique that separates mixed signals into their independent source components. It assumes that the observed signals are linear mixtures of statistically independent sources. ICA is widely used in signal processing, neuroscience, image processing, and audio source separation applications.</p>"},{"location":"DSP/TRANSFORM/ICA/notes/#ica-overview","title":"ICA OVERVIEW","text":""},{"location":"DSP/TRANSFORM/ICA/notes/#mathematical-principle","title":"Mathematical Principle","text":"<p>ICA addresses the blind source separation problem:</p> \\[ \\mathbf{X} = \\mathbf{A} \\cdot \\mathbf{S} \\] <p>Where:</p> <ul> <li> <p>\\( \\mathbf{X} \\) is the matrix of observed (mixed) signals (num_obs \u00d7 num_samples)</p> </li> <li> <p>\\( \\mathbf{A} \\) is the unknown mixing matrix (num_obs \u00d7 num_sources)</p> </li> <li> <p>\\( \\mathbf{S} \\) is the matrix of independent source signals (num_sources \u00d7 num_samples)</p> </li> </ul> <p>Goal: Find the unmixing matrix \\( \\mathbf{W} \\) such that:</p> \\[ \\mathbf{S} = \\mathbf{W} \\cdot \\mathbf{X} \\] <p>Key Assumptions:</p> <ol> <li> <p>Statistical Independence: Source signals are statistically independent</p> </li> <li> <p>Non-Gaussianity: At most one source can be Gaussian (for identifiability)</p> </li> <li> <p>Linear Mixing: Observations are linear combinations of sources</p> </li> <li> <p>Square or Overdetermined: Number of observations \u2265 number of sources</p> </li> </ol>"},{"location":"DSP/TRANSFORM/ICA/notes/#ica-vs-pca","title":"ICA vs PCA","text":"<ul> <li>PCA: Finds orthogonal directions of maximum variance (second-order statistics)</li> <li>ICA: Finds statistically independent directions (higher-order statistics)</li> <li>PCA: Decorrelates data (removes linear dependencies)</li> <li>ICA: Separates independent sources (removes all dependencies)</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/notes/#algorithms","title":"ALGORITHMS","text":""},{"location":"DSP/TRANSFORM/ICA/notes/#fastica","title":"FastICA","text":"<p>The library implements the FastICA algorithm, which is based on maximizing non-Gaussianity:</p> <p>Objective Function: Maximize non-Gaussianity of \\( \\mathbf{w}^T \\mathbf{x} \\)</p> <p>Nonlinearity Functions:</p> <ul> <li> <p>tanh: \\( g(u) = \\tanh(u) \\) - Good for super-Gaussian sources</p> </li> <li> <p>exp: \\( g(u) = u \\cdot e^{-u^2/2} \\) - Good for sub-Gaussian sources</p> </li> <li> <p>cube: \\( g(u) = u^3 \\) - Good for super-Gaussian sources</p> </li> </ul> <p>Algorithm Steps:</p> <ol> <li> <p>Center data: \\( \\mathbf{x}_c = \\mathbf{x} - \\text{mean}(\\mathbf{x}) \\)</p> </li> <li> <p>Whiten data: \\( \\mathbf{z} = \\mathbf{D}^{-1/2} \\mathbf{E}^T \\mathbf{x}_c \\)</p> </li> <li> <p>Extract components using fixed-point iteration</p> </li> <li> <p>Orthogonalize components (Gram-Schmidt)</p> </li> </ol>"},{"location":"DSP/TRANSFORM/ICA/notes/#preprocessing","title":"PREPROCESSING","text":""},{"location":"DSP/TRANSFORM/ICA/notes/#centering","title":"Centering","text":"<p>Subtract the mean from each observation:</p> \\[ \\mathbf{x}_c = \\mathbf{x} - \\bar{\\mathbf{x}} \\] <p>Where \\( \\bar{\\mathbf{x}} \\) is the mean vector.</p>"},{"location":"DSP/TRANSFORM/ICA/notes/#whitening","title":"Whitening","text":"<p>Transform data to have unit variance and zero correlation:</p> \\[ \\mathbf{z} = \\mathbf{D}^{-1/2} \\mathbf{E}^T \\mathbf{x}_c \\] <p>Where:</p> <ul> <li> <p>\\( \\mathbf{E} \\) are eigenvectors of covariance matrix</p> </li> <li> <p>\\( \\mathbf{D} \\) are eigenvalues of covariance matrix</p> </li> </ul> <p>Whitening Matrix:</p> \\[ \\mathbf{W}_{whiten} = \\mathbf{D}^{-1/2} \\mathbf{E}^T \\]"},{"location":"DSP/TRANSFORM/ICA/notes/#functions","title":"FUNCTIONS","text":""},{"location":"DSP/TRANSFORM/ICA/notes/#tiny_ica_separate_f32","title":"tiny_ica_separate_f32","text":"<pre><code>/**\n * @name tiny_ica_separate_f32\n * @brief Perform ICA separation on mixed signals\n * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n * @param num_obs Number of observations (mixed signals)\n * @param num_samples Number of samples per signal\n * @param num_sources Number of independent sources to extract\n * @param separated_sources Output separated sources (num_sources x num_samples, row-major)\n * @param algorithm ICA algorithm to use (default: TINY_ICA_FASTICA)\n * @param nonlinearity Nonlinearity function for FastICA (default: TINY_ICA_NONLINEARITY_TANH)\n * @param max_iter Maximum number of iterations (default: 100)\n * @param tolerance Convergence tolerance (default: 1e-4)\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_separate_f32(const float *mixed_signals,\n                                   int num_obs,\n                                   int num_samples,\n                                   int num_sources,\n                                   float *separated_sources,\n                                   tiny_ica_algorithm_t algorithm,\n                                   tiny_ica_nonlinearity_t nonlinearity,\n                                   int max_iter,\n                                   float tolerance);\n</code></pre> <p>Description: </p> <p>Performs complete ICA separation in one function call. This is the simplest interface for ICA.</p> <p>Parameters:</p> <ul> <li> <p><code>mixed_signals</code>: Pointer to input mixed signals array. Data layout is row-major: <code>mixed_signals[i * num_samples + j]</code> is sample <code>j</code> of observation <code>i</code>.</p> </li> <li> <p><code>num_obs</code>: Number of observations (mixed signals). Must be \u2265 <code>num_sources</code>.</p> </li> <li> <p><code>num_samples</code>: Number of samples per signal.</p> </li> <li> <p><code>num_sources</code>: Number of independent sources to extract. Must be \u2264 <code>num_obs</code>.</p> </li> <li> <p><code>separated_sources</code>: Pointer to output array for separated sources. Data layout is row-major: <code>separated_sources[i * num_samples + j]</code> is sample <code>j</code> of source <code>i</code>. Size must be at least <code>num_sources * num_samples</code>.</p> </li> <li> <p><code>algorithm</code>: ICA algorithm type. Currently only <code>TINY_ICA_FASTICA</code> is supported.</p> </li> <li> <p><code>nonlinearity</code>: Nonlinearity function for FastICA:</p> </li> <li><code>TINY_ICA_NONLINEARITY_TANH</code>: tanh (default, good for super-Gaussian)</li> <li><code>TINY_ICA_NONLINEARITY_EXP</code>: exp(-u\u00b2/2) (good for sub-Gaussian)</li> <li> <p><code>TINY_ICA_NONLINEARITY_CUBE</code>: u\u00b3 (good for super-Gaussian)</p> </li> <li> <p><code>max_iter</code>: Maximum number of iterations for FastICA. Default: 100 if \u2264 0.</p> </li> <li> <p><code>tolerance</code>: Convergence tolerance. Algorithm stops when change &lt; tolerance. Default: 1e-4 if \u2264 0.</p> </li> </ul> <p>Return Value: </p> <p>Returns <code>TINY_OK</code> on success, or error code on failure.</p> <p>Processing Steps:</p> <ol> <li>Center data: Subtract mean from each observation</li> <li>Whiten data: Decorrelate and normalize variance using eigenvalue decomposition</li> <li>Extract components: Use FastICA to find independent components</li> <li>Reconstruct sources: Apply unmixing matrix to whitened data</li> </ol> <p>Note: </p> <p>This function performs all steps internally. For repeated separations, use the structure-based API (<code>tiny_ica_init</code>, <code>tiny_ica_fit</code>, <code>tiny_ica_transform</code>) to avoid recomputing whitening matrix.</p>"},{"location":"DSP/TRANSFORM/ICA/notes/#tiny_ica_init","title":"tiny_ica_init","text":"<pre><code>/**\n * @name tiny_ica_init\n * @brief Initialize ICA structure for repeated use\n * @param ica Pointer to ICA structure\n * @param num_obs Number of observations (mixed signals)\n * @param num_sources Number of sources to extract\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_init(tiny_ica_t *ica, int num_obs, int num_sources);\n</code></pre> <p>Description: </p> <p>Initializes an ICA structure for repeated use. Allocates memory for mixing matrix, unmixing matrix, whitening matrix, and mean vector.</p> <p>Parameters:</p> <ul> <li> <p><code>ica</code>: Pointer to <code>tiny_ica_t</code> structure.</p> </li> <li> <p><code>num_obs</code>: Number of observations (mixed signals). Must be \u2265 <code>num_sources</code>.</p> </li> <li> <p><code>num_sources</code>: Number of sources to extract. Must be \u2264 <code>num_obs</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns <code>TINY_OK</code> on success, or error code on failure.</p> <p>Memory Management: </p> <p>Function allocates memory internally. Call <code>tiny_ica_deinit()</code> to free it.</p>"},{"location":"DSP/TRANSFORM/ICA/notes/#tiny_ica_fit","title":"tiny_ica_fit","text":"<pre><code>/**\n * @name tiny_ica_fit\n * @brief Fit ICA model to mixed signals (learn unmixing matrix)\n * @param ica Pointer to initialized ICA structure\n * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n * @param num_samples Number of samples per signal\n * @param algorithm ICA algorithm to use\n * @param nonlinearity Nonlinearity function for FastICA\n * @param max_iter Maximum number of iterations\n * @param tolerance Convergence tolerance\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_fit(tiny_ica_t *ica,\n                          const float *mixed_signals,\n                          int num_samples,\n                          tiny_ica_algorithm_t algorithm,\n                          tiny_ica_nonlinearity_t nonlinearity,\n                          int max_iter,\n                          float tolerance);\n</code></pre> <p>Description: </p> <p>Fits an ICA model to the training data. Learns the unmixing matrix and whitening matrix. After fitting, use <code>tiny_ica_transform()</code> to separate new signals.</p> <p>Parameters:</p> <ul> <li> <p><code>ica</code>: Pointer to initialized <code>tiny_ica_t</code> structure.</p> </li> <li> <p><code>mixed_signals</code>: Pointer to input mixed signals array (row-major layout).</p> </li> <li> <p><code>num_samples</code>: Number of samples per signal.</p> </li> <li> <p><code>algorithm</code>: ICA algorithm type. Currently only <code>TINY_ICA_FASTICA</code> is supported.</p> </li> <li> <p><code>nonlinearity</code>: Nonlinearity function for FastICA.</p> </li> <li> <p><code>max_iter</code>: Maximum number of iterations. Default: 100 if \u2264 0.</p> </li> <li> <p><code>tolerance</code>: Convergence tolerance. Default: 1e-4 if \u2264 0.</p> </li> </ul> <p>Return Value: </p> <p>Returns <code>TINY_OK</code> on success, or error code on failure.</p> <p>Note: </p> <p>After fitting, the ICA structure contains the learned unmixing matrix and whitening matrix. These can be reused for transforming new data.</p>"},{"location":"DSP/TRANSFORM/ICA/notes/#tiny_ica_transform","title":"tiny_ica_transform","text":"<pre><code>/**\n * @name tiny_ica_transform\n * @brief Apply learned ICA model to separate signals\n * @param ica Pointer to fitted ICA structure\n * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n * @param num_samples Number of samples per signal\n * @param separated_sources Output separated sources (num_sources x num_samples, row-major)\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_transform(const tiny_ica_t *ica,\n                                const float *mixed_signals,\n                                int num_samples,\n                                float *separated_sources);\n</code></pre> <p>Description: </p> <p>Applies a previously fitted ICA model to separate new signals. Much faster than <code>tiny_ica_separate_f32()</code> since it reuses the learned unmixing matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>ica</code>: Pointer to fitted <code>tiny_ica_t</code> structure.</p> </li> <li> <p><code>mixed_signals</code>: Pointer to input mixed signals array (row-major layout).</p> </li> <li> <p><code>num_samples</code>: Number of samples per signal.</p> </li> <li> <p><code>separated_sources</code>: Pointer to output array for separated sources (row-major layout). Size must be at least <code>num_sources * num_samples</code>.</p> </li> </ul> <p>Return Value: </p> <p>Returns <code>TINY_OK</code> on success, or error code on failure.</p> <p>Note: </p> <p>Requires <code>ica</code> to be fitted first using <code>tiny_ica_fit()</code>. The input signals are centered using the mean from the training data.</p>"},{"location":"DSP/TRANSFORM/ICA/notes/#tiny_ica_deinit","title":"tiny_ica_deinit","text":"<pre><code>/**\n * @name tiny_ica_deinit\n * @brief Deinitialize ICA structure and free memory\n * @param ica Pointer to ICA structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_deinit(tiny_ica_t *ica);\n</code></pre> <p>Description: </p> <p>Deinitializes an ICA structure and frees all allocated memory.</p> <p>Parameters:</p> <ul> <li><code>ica</code>: Pointer to <code>tiny_ica_t</code> structure.</li> </ul> <p>Return Value: </p> <p>Returns <code>TINY_OK</code> on success, or error code on failure.</p>"},{"location":"DSP/TRANSFORM/ICA/notes/#usage-workflow","title":"USAGE WORKFLOW","text":""},{"location":"DSP/TRANSFORM/ICA/notes/#simple-one-shot-separation","title":"Simple One-Shot Separation","text":"<pre><code>float mixed_signals[2 * 512];  // 2 observations, 512 samples each\nfloat separated_sources[2 * 512];  // 2 sources, 512 samples each\n\n// Perform ICA separation\ntiny_error_t ret = tiny_ica_separate_f32(\n    mixed_signals, 2, 512, 2, separated_sources,\n    TINY_ICA_FASTICA, TINY_ICA_NONLINEARITY_TANH, 100, 1e-4f);\n</code></pre>"},{"location":"DSP/TRANSFORM/ICA/notes/#repeated-separations-structure-api","title":"Repeated Separations (Structure API)","text":"<pre><code>tiny_ica_t ica;\n\n// Initialize\ntiny_ica_init(&amp;ica, 2, 2);  // 2 observations, 2 sources\n\n// Fit model to training data\ntiny_ica_fit(&amp;ica, training_mixed, 512,\n             TINY_ICA_FASTICA, TINY_ICA_NONLINEARITY_TANH, 100, 1e-4f);\n\n// Transform new data (can be called multiple times)\ntiny_ica_transform(&amp;ica, new_mixed, 512, separated);\n\n// Cleanup\ntiny_ica_deinit(&amp;ica);\n</code></pre>"},{"location":"DSP/TRANSFORM/ICA/notes/#applications","title":"APPLICATIONS","text":"<p>ICA is widely used in:</p> <ul> <li>Audio Source Separation: Separating individual instruments or voices from mixed audio</li> <li>Biomedical Signal Processing: Separating EEG/ECG signals from artifacts</li> <li>Image Processing: Feature extraction, denoising</li> <li>Communications: Blind channel equalization</li> <li>Neuroscience: Analyzing brain signals, fMRI data</li> <li>Sensor Array Processing: Separating signals from multiple sensors</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/notes/#advantages","title":"ADVANTAGES","text":"<ul> <li>Blind Separation: No prior knowledge of mixing matrix needed</li> <li>Statistical Independence: Finds truly independent sources</li> <li>Non-Gaussian Sources: Works well with non-Gaussian signals</li> <li>Flexible: Can handle different numbers of sources and observations</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/notes/#disadvantages","title":"DISADVANTAGES","text":"<ul> <li>Ambiguity: Scale and sign of separated sources are ambiguous</li> <li>Order Ambiguity: Order of separated sources is arbitrary</li> <li>Non-Gaussian Requirement: At most one source can be Gaussian</li> <li>Computational Cost: Whitening and eigenvalue decomposition can be expensive</li> <li>Convergence: May not converge for some signal types</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/notes/#design-considerations","title":"DESIGN CONSIDERATIONS","text":""},{"location":"DSP/TRANSFORM/ICA/notes/#number-of-sources-vs-observations","title":"Number of Sources vs Observations","text":"<ul> <li>Square Case (num_obs = num_sources): Standard ICA problem</li> <li>Overdetermined (num_obs &gt; num_sources): Can use PCA to reduce dimensionality first</li> <li>Underdetermined (num_obs &lt; num_sources): Not supported (cannot extract more sources than observations)</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/notes/#nonlinearity-selection","title":"Nonlinearity Selection","text":"<ul> <li>tanh: Default choice, works well for most super-Gaussian sources (speech, music)</li> <li>exp: Use for sub-Gaussian sources (uniform noise, some image signals)</li> <li>cube: Alternative for super-Gaussian sources, simpler but less robust</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/notes/#convergence-parameters","title":"Convergence Parameters","text":"<ul> <li>max_iter: Typically 50-200 iterations. More iterations for difficult cases.</li> <li>tolerance: Typically 1e-4 to 1e-6. Smaller tolerance = more accurate but slower.</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/notes/#data-requirements","title":"Data Requirements","text":"<ul> <li>Sample Size: More samples = better separation quality</li> <li>Independence: Sources must be statistically independent</li> <li>Non-Gaussianity: At most one source can be Gaussian</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/notes/#notes_1","title":"NOTES","text":"<ul> <li>ICA can only separate sources up to a scaling factor and permutation</li> <li>The order of separated sources may not match the original order</li> <li>ICA works best when sources have different statistical properties</li> <li>Whitening is a critical preprocessing step for ICA</li> <li>FastICA is a popular algorithm due to its speed and simplicity</li> </ul>"},{"location":"DSP/TRANSFORM/ICA/test/","title":"TESTS","text":""},{"location":"DSP/TRANSFORM/ICA/test/#tiny_ica_testh","title":"tiny_ica_test.h","text":"<pre><code>/**\n * @file tiny_ica_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_ica | test | header\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_ica.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_ica_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"DSP/TRANSFORM/ICA/test/#tiny_ica_testc","title":"tiny_ica_test.c","text":"<pre><code>/**\n * @file tiny_ica_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_ica | test | source\n * @version 1.0\n * @date 2025-11-16\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_ica_test.h\"\n#include \"tiny_view.h\"\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846f\n#endif\n\n/**\n * @brief Generate source signals for testing\n */\nstatic void generate_source_signals(float *sources, int num_sources, int num_samples, float sample_rate)\n{\n    // Source 1: Sinusoid at 10 Hz\n    // Source 2: Sinusoid at 30 Hz\n    // Source 3: Square wave (if num_sources &gt; 2)\n\n    for (int t = 0; t &lt; num_samples; t++)\n    {\n        float time = (float)t / sample_rate;\n\n        // Source 1: 10 Hz sine\n        sources[0 * num_samples + t] = sinf(2.0f * M_PI * 10.0f * time);\n\n        // Source 2: 30 Hz sine\n        sources[1 * num_samples + t] = sinf(2.0f * M_PI * 30.0f * time);\n\n        // Source 3: Square wave (if exists)\n        if (num_sources &gt; 2)\n        {\n            sources[2 * num_samples + t] = (sinf(2.0f * M_PI * 5.0f * time) &gt; 0.0f) ? 1.0f : -1.0f;\n        }\n    }\n}\n\n/**\n * @brief Mix source signals with a mixing matrix\n */\nstatic void mix_signals(const float *sources, int num_sources, int num_samples,\n                       const float *mixing_matrix, int num_obs, float *mixed)\n{\n    // mixed = mixing_matrix * sources\n    // mixing_matrix: (num_obs x num_sources)\n    // sources: (num_sources x num_samples)\n    // mixed: (num_obs x num_samples)\n\n    for (int i = 0; i &lt; num_obs; i++)\n    {\n        for (int j = 0; j &lt; num_samples; j++)\n        {\n            mixed[i * num_samples + j] = 0.0f;\n            for (int k = 0; k &lt; num_sources; k++)\n            {\n                mixed[i * num_samples + j] += mixing_matrix[i * num_sources + k] * sources[k * num_samples + j];\n            }\n        }\n    }\n}\n\n/**\n * @brief Compute correlation coefficient between two signals\n */\nstatic float compute_correlation(const float *x, const float *y, int len)\n{\n    float mean_x = 0.0f, mean_y = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        mean_x += x[i];\n        mean_y += y[i];\n    }\n    mean_x /= (float)len;\n    mean_y /= (float)len;\n\n    float cov = 0.0f, var_x = 0.0f, var_y = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        float dx = x[i] - mean_x;\n        float dy = y[i] - mean_y;\n        cov += dx * dy;\n        var_x += dx * dx;\n        var_y += dy * dy;\n    }\n\n    if (var_x &lt; 1e-10f || var_y &lt; 1e-10f)\n        return 0.0f;\n\n    return cov / sqrtf(var_x * var_y);\n}\n\n/**\n * @brief Find best matching source for each separated component\n */\nstatic void match_sources(const float *separated, const float *original_sources,\n                         int num_sources, int num_samples, int *matches)\n{\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        float best_corr = -1.0f;\n        int best_match = -1;\n\n        for (int j = 0; j &lt; num_sources; j++)\n        {\n            float corr = fabsf(compute_correlation(\n                &amp;separated[i * num_samples],\n                &amp;original_sources[j * num_samples],\n                num_samples));\n\n            if (corr &gt; best_corr)\n            {\n                best_corr = corr;\n                best_match = j;\n            }\n        }\n\n        matches[i] = best_match;\n    }\n}\n\n/**\n * @brief Compute signal statistics\n */\nstatic void compute_statistics(const float *signal, int len, float *mean, float *std, float *min, float *max)\n{\n    *mean = 0.0f;\n    *min = signal[0];\n    *max = signal[0];\n\n    for (int i = 0; i &lt; len; i++)\n    {\n        *mean += signal[i];\n        if (signal[i] &lt; *min) *min = signal[i];\n        if (signal[i] &gt; *max) *max = signal[i];\n    }\n    *mean /= (float)len;\n\n    float variance = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        float diff = signal[i] - *mean;\n        variance += diff * diff;\n    }\n    variance /= (float)len;\n    *std = sqrtf(variance);\n}\n\n/**\n * @brief Print signal samples (first and last N samples)\n */\nstatic void print_signal_samples(const float *signal, int len, int num_samples, const char *name)\n{\n    printf(\"  %s samples (first %d and last %d):\\n\", name, num_samples, num_samples);\n    printf(\"    First %d: \", num_samples);\n    for (int i = 0; i &lt; num_samples &amp;&amp; i &lt; len; i++)\n    {\n        printf(\"%.4f \", signal[i]);\n    }\n    printf(\"\\n    Last %d:  \", num_samples);\n    int start = (len &gt; num_samples) ? len - num_samples : 0;\n    for (int i = start; i &lt; len; i++)\n    {\n        printf(\"%.4f \", signal[i]);\n    }\n    printf(\"\\n\");\n}\n\nvoid tiny_ica_test(void)\n{\n    // Initialize all pointers to NULL at function start for safe cleanup\n    float *source_signals = NULL;\n    float *mixing_matrix = NULL;\n    float *mixed_signals = NULL;\n    float *separated_sources = NULL;\n    int *matches = NULL;\n\n    printf(\"========== TinyICA Test ==========\\n\\n\");\n\n    const int num_sources = 2;\n    const int num_obs = 2;\n    const int num_samples = 512;\n    const float sample_rate = 1000.0f; // 1 kHz\n\n    // Allocate memory\n\n    source_signals = (float *)malloc(num_sources * num_samples * sizeof(float));\n    mixing_matrix = (float *)malloc(num_obs * num_sources * sizeof(float));\n    mixed_signals = (float *)malloc(num_obs * num_samples * sizeof(float));\n    separated_sources = (float *)malloc(num_sources * num_samples * sizeof(float));\n\n    if (!source_signals || !mixing_matrix || !mixed_signals || !separated_sources)\n    {\n        printf(\"\u2717 Memory allocation failed\\n\");\n        goto cleanup;\n    }\n\n    // Generate source signals\n    printf(\"========================================\\n\");\n    printf(\"STEP 1: Generating Source Signals\\n\");\n    printf(\"========================================\\n\");\n    printf(\"Configuration:\\n\");\n    printf(\"  - Number of sources: %d\\n\", num_sources);\n    printf(\"  - Number of samples: %d\\n\", num_samples);\n    printf(\"  - Sample rate: %.1f Hz\\n\", sample_rate);\n    printf(\"  - Duration: %.3f seconds\\n\\n\", (float)num_samples / sample_rate);\n\n    generate_source_signals(source_signals, num_sources, num_samples, sample_rate);\n\n    printf(\"Source Signal Details:\\n\");\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        float freq = (i == 0) ? 10.0f : 30.0f;\n        printf(\"  Source %d: %.1f Hz sinusoid (sin(2\u03c0*%.1f*t))\\n\", i + 1, freq, freq);\n\n        float mean, std, min, max;\n        compute_statistics(&amp;source_signals[i * num_samples], num_samples, &amp;mean, &amp;std, &amp;min, &amp;max);\n        printf(\"    Statistics: mean=%.4f, std=%.4f, min=%.4f, max=%.4f\\n\", mean, std, min, max);\n        print_signal_samples(&amp;source_signals[i * num_samples], num_samples, 8, \"Source\");\n\n        // Visualize source signal\n        char title[64];\n        snprintf(title, sizeof(title), \"Source %d (%.1f Hz)\", i + 1, freq);\n        tiny_view_signal_f32(&amp;source_signals[i * num_samples], num_samples, 64, 12, 0.0f, 0.0f, title);\n        printf(\"\\n\");\n    }\n\n    // Create mixing matrix\n    printf(\"========================================\\n\");\n    printf(\"STEP 2: Creating Mixing Matrix\\n\");\n    printf(\"========================================\\n\");\n    // Mixing matrix: [0.8, 0.3; 0.2, 0.7]\n    mixing_matrix[0 * num_sources + 0] = 0.8f; // obs1 = 0.8*s1 + 0.3*s2\n    mixing_matrix[0 * num_sources + 1] = 0.3f;\n    mixing_matrix[1 * num_sources + 0] = 0.2f; // obs2 = 0.2*s1 + 0.7*s2\n    mixing_matrix[1 * num_sources + 1] = 0.7f;\n\n    printf(\"Mixing Matrix A (num_obs x num_sources = %d x %d):\\n\", num_obs, num_sources);\n    printf(\"  [%.3f  %.3f]\\n\", mixing_matrix[0 * num_sources + 0], mixing_matrix[0 * num_sources + 1]);\n    printf(\"  [%.3f  %.3f]\\n\", mixing_matrix[1 * num_sources + 0], mixing_matrix[1 * num_sources + 1]);\n    printf(\"\\nMixing Equation:\\n\");\n    printf(\"  Observation 1 = %.3f * Source 1 + %.3f * Source 2\\n\", \n           mixing_matrix[0 * num_sources + 0], mixing_matrix[0 * num_sources + 1]);\n    printf(\"  Observation 2 = %.3f * Source 1 + %.3f * Source 2\\n\\n\", \n           mixing_matrix[1 * num_sources + 0], mixing_matrix[1 * num_sources + 1]);\n\n    // Mix signals\n    printf(\"========================================\\n\");\n    printf(\"STEP 3: Mixing Signals (X = A * S)\\n\");\n    printf(\"========================================\\n\");\n    printf(\"Process: Multiplying mixing matrix by source signals\\n\");\n    mix_signals(source_signals, num_sources, num_samples, mixing_matrix, num_obs, mixed_signals);\n    printf(\"\u2713 Mixed %d sources into %d observations\\n\\n\", num_sources, num_obs);\n\n    printf(\"Mixed Signal Details:\\n\");\n    for (int i = 0; i &lt; num_obs; i++)\n    {\n        printf(\"  Observation %d:\\n\", i + 1);\n        float mean, std, min, max;\n        compute_statistics(&amp;mixed_signals[i * num_samples], num_samples, &amp;mean, &amp;std, &amp;min, &amp;max);\n        printf(\"    Statistics: mean=%.4f, std=%.4f, min=%.4f, max=%.4f\\n\", mean, std, min, max);\n        print_signal_samples(&amp;mixed_signals[i * num_samples], num_samples, 8, \"Mixed\");\n\n        // Visualize mixed signal\n        char title[64];\n        snprintf(title, sizeof(title), \"Mixed Observation %d\", i + 1);\n        tiny_view_signal_f32(&amp;mixed_signals[i * num_samples], num_samples, 64, 12, 0.0f, 0.0f, title);\n        printf(\"\\n\");\n    }\n\n    // Test ICA separation\n    printf(\"========================================\\n\");\n    printf(\"STEP 4: ICA Separation (FastICA Algorithm)\\n\");\n    printf(\"========================================\\n\");\n    printf(\"Algorithm: FastICA\\n\");\n    printf(\"Nonlinearity: tanh (for super-Gaussian sources)\\n\");\n    printf(\"Max iterations: 100\\n\");\n    printf(\"Convergence tolerance: 1e-4\\n\");\n    printf(\"Process:\\n\");\n    printf(\"  1. Center data (subtract mean)\\n\");\n    printf(\"  2. Whiten data (decorrelate and normalize variance)\\n\");\n    printf(\"  3. Extract independent components using FastICA\\n\");\n    printf(\"  4. Reconstruct separated sources\\n\\n\");\n\n    tiny_error_t ret = tiny_ica_separate_f32(\n        mixed_signals, num_obs, num_samples, num_sources, separated_sources,\n        TINY_ICA_FASTICA, TINY_ICA_NONLINEARITY_TANH, 100, 1e-4f);\n\n    if (ret != TINY_OK)\n    {\n        printf(\"\u2717 ICA separation failed with error code: %d\\n\", ret);\n        goto cleanup;\n    }\n    printf(\"\u2713 ICA separation completed successfully\\n\\n\");\n\n    // Evaluate results\n    printf(\"========================================\\n\");\n    printf(\"STEP 5: Evaluating Separation Quality\\n\");\n    printf(\"========================================\\n\");\n\n    matches = (int *)malloc(num_sources * sizeof(int));\n    if (matches == NULL)\n    {\n        printf(\"\u2717 Memory allocation failed\\n\");\n        goto cleanup;\n    }\n\n    match_sources(separated_sources, source_signals, num_sources, num_samples, matches);\n\n    printf(\"Separated Signal Details:\\n\");\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        int match = matches[i];\n        float corr = compute_correlation(\n            &amp;separated_sources[i * num_samples],\n            &amp;source_signals[match * num_samples],\n            num_samples);\n\n        printf(\"\\n  Separated Component %d (matches Source %d):\\n\", i + 1, match + 1);\n        printf(\"    Correlation with original: %.6f\\n\", corr);\n\n        float mean, std, min, max;\n        compute_statistics(&amp;separated_sources[i * num_samples], num_samples, &amp;mean, &amp;std, &amp;min, &amp;max);\n        printf(\"    Statistics: mean=%.4f, std=%.4f, min=%.4f, max=%.4f\\n\", mean, std, min, max);\n\n        // Compare with original source\n        float orig_mean, orig_std, orig_min, orig_max;\n        compute_statistics(&amp;source_signals[match * num_samples], num_samples, &amp;orig_mean, &amp;orig_std, &amp;orig_min, &amp;orig_max);\n        printf(\"    Original Source %d: mean=%.4f, std=%.4f, min=%.4f, max=%.4f\\n\", \n               match + 1, orig_mean, orig_std, orig_min, orig_max);\n\n        print_signal_samples(&amp;separated_sources[i * num_samples], num_samples, 8, \"Separated\");\n\n        // Visualize separated signal\n        char title[64];\n        snprintf(title, sizeof(title), \"Separated Component %d (matches Source %d)\", i + 1, match + 1);\n        tiny_view_signal_f32(&amp;separated_sources[i * num_samples], num_samples, 64, 12, 0.0f, 0.0f, title);\n\n        // Visualize original for comparison\n        snprintf(title, sizeof(title), \"Original Source %d (for comparison)\", match + 1);\n        tiny_view_signal_f32(&amp;source_signals[match * num_samples], num_samples, 64, 12, 0.0f, 0.0f, title);\n\n        // Compute normalized error\n        float mse = 0.0f;\n        float scale = (orig_std &gt; 1e-10f) ? (std / orig_std) : 1.0f;\n        for (int j = 0; j &lt; num_samples; j++)\n        {\n            float normalized_sep = (separated_sources[i * num_samples + j] - mean) / (std + 1e-10f);\n            float normalized_orig = (source_signals[match * num_samples + j] - orig_mean) / (orig_std + 1e-10f);\n            float diff = normalized_sep - normalized_orig;\n            mse += diff * diff;\n        }\n        mse /= (float)num_samples;\n        float rmse = sqrtf(mse);\n        printf(\"    Normalized RMSE: %.6f\\n\", rmse);\n        printf(\"    Quality: %s\\n\", (corr &gt; 0.9f) ? \"Excellent\" : (corr &gt; 0.7f) ? \"Good\" : (corr &gt; 0.5f) ? \"Fair\" : \"Poor\");\n    }\n    printf(\"\\n\");\n\n    // Test ICA structure API\n    printf(\"========================================\\n\");\n    printf(\"STEP 6: Testing ICA Structure API\\n\");\n    printf(\"========================================\\n\");\n    printf(\"This tests the reusable ICA structure for multiple separations:\\n\");\n    printf(\"  1. Initialize ICA structure\\n\");\n    printf(\"  2. Fit model to training data\\n\");\n    printf(\"  3. Transform new data using learned model\\n\");\n    printf(\"  4. Compare with direct separation\\n\\n\");\n    tiny_ica_t ica;\n    ret = tiny_ica_init(&amp;ica, num_obs, num_sources);\n    if (ret != TINY_OK)\n    {\n        printf(\"  \u2717 ICA initialization failed: %d\\n\", ret);\n    }\n    else\n    {\n        printf(\"  \u2713 ICA structure initialized\\n\");\n\n        ret = tiny_ica_fit(&amp;ica, mixed_signals, num_samples,\n                          TINY_ICA_FASTICA, TINY_ICA_NONLINEARITY_TANH, 100, 1e-4f);\n        if (ret != TINY_OK)\n        {\n            printf(\"  \u2717 ICA fitting failed: %d\\n\", ret);\n        }\n        else\n        {\n            printf(\"  \u2713 ICA model fitted\\n\");\n\n            // Test transform\n            float *separated2 = (float *)malloc(num_sources * num_samples * sizeof(float));\n            if (separated2 != NULL)\n            {\n                ret = tiny_ica_transform(&amp;ica, mixed_signals, num_samples, separated2);\n                if (ret != TINY_OK)\n                {\n                    printf(\"  \u2717 ICA transform failed: %d\\n\", ret);\n                }\n                else\n                {\n                    printf(\"  \u2713 ICA transform completed\\n\");\n\n                    // Compare with direct separation\n                    float diff_sum = 0.0f;\n                    for (int i = 0; i &lt; num_sources * num_samples; i++)\n                    {\n                        float diff = separated_sources[i] - separated2[i];\n                        diff_sum += diff * diff;\n                    }\n                    float rmse = sqrtf(diff_sum / (float)(num_sources * num_samples));\n                    printf(\"  RMSE between direct and structure API: %.6f\\n\", rmse);\n                }\n                free(separated2);\n            }\n        }\n\n        tiny_ica_deinit(&amp;ica);\n        printf(\"  \u2713 ICA structure deinitialized\\n\");\n    }\n    printf(\"\\n\");\n\n    // Final summary\n    printf(\"========================================\\n\");\n    printf(\"SUMMARY: ICA Test Results\\n\");\n    printf(\"========================================\\n\");\n    printf(\"Test Configuration:\\n\");\n    printf(\"  - Sources: %d independent signals\\n\", num_sources);\n    printf(\"  - Observations: %d mixed signals\\n\", num_obs);\n    printf(\"  - Samples: %d per signal\\n\", num_samples);\n    printf(\"  - Sample rate: %.1f Hz\\n\", sample_rate);\n    printf(\"\\nSeparation Quality Summary:\\n\");\n    for (int i = 0; i &lt; num_sources; i++)\n    {\n        int match = matches[i];\n        float corr = compute_correlation(\n            &amp;separated_sources[i * num_samples],\n            &amp;source_signals[match * num_samples],\n            num_samples);\n        printf(\"  Component %d \u2192 Source %d: Correlation = %.6f (%s)\\n\", \n               i + 1, match + 1, corr,\n               (corr &gt; 0.9f) ? \"Excellent\" : (corr &gt; 0.7f) ? \"Good\" : (corr &gt; 0.5f) ? \"Fair\" : \"Poor\");\n    }\n    printf(\"\\nExpected vs Actual:\\n\");\n    printf(\"  Expected: Separated signals should match original sources\\n\");\n    printf(\"  Actual: ICA successfully extracted independent components\\n\");\n    printf(\"  Note: ICA may recover sources with different scale/sign, which is normal\\n\");\n    printf(\"        (correlation measures similarity regardless of scale)\\n\");\n    printf(\"\\n\");\n\n    printf(\"========== TinyICA Test Complete ==========\\n\\n\");\n\ncleanup:\n    free(source_signals);\n    free(mixing_matrix);\n    free(mixed_signals);\n    free(separated_sources);\n    // matches is always initialized to NULL at function start (line 139), safe to free\n    // Suppress false positive uninitialized variable warning\n    #pragma GCC diagnostic push\n    #pragma GCC diagnostic ignored \"-Wmaybe-uninitialized\"\n    if (matches != NULL)\n    {\n        free(matches);\n    }\n    #pragma GCC diagnostic pop\n}\n</code></pre>"},{"location":"DSP/TRANSFORM/ICA/test/#outputs","title":"OUTPUTS","text":"<pre><code>========== TinyICA Test ==========\n\n========================================\nSTEP 1: Generating Source Signals\n========================================\nConfiguration:\n  - Number of sources: 2\n  - Number of samples: 512\n  - Sample rate: 1000.0 Hz\n  - Duration: 0.512 seconds\n\nSource Signal Details:\n  Source 1: 10.0 Hz sinusoid (sin(2\u03c0*10.0*t))\n    Statistics: mean=0.0078, std=0.7012, min=-1.0000, max=1.0000\n  Source samples (first 8 and last 8):\n    First 8: 0.0000 0.0628 0.1253 0.1874 0.2487 0.3090 0.3681 0.4258 \n    Last 8:  0.2487 0.3090 0.3681 0.4258 0.4818 0.5358 0.5878 0.6374 \n\nSource 1 (10.0 Hz)\nValue\n  1.20 |                                                                \n  0.98 |   **          **          **           **          **          \n  0.76 |  * *         *  *        *  *         * *         *  *         \n  0.55 | *   *       *   *        *  *        *   *       *   *        *\n  0.33 |*    *       *    *      *    *      *    *       *    *      * \n  0.11 |*     *     *     *      *    *      *     *     *     *      * \n -0.11 |*     *     *     *     *      *    *      *     *     *     *  \n -0.33 |       *   *       *    *      *    *       *   *       *    *  \n -0.55 |       *   *       *   *        *   *       *   *       *   *   \n -0.76 |        * *         *  *        *  *         * *         *  *   \n -0.98 |         **          **          **           **          **    \n -1.20 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.200, 1.200], Length: 512\n\n\n  Source 2: 30.0 Hz sinusoid (sin(2\u03c0*30.0*t))\n    Statistics: mean=0.0162, std=0.7083, min=-1.0000, max=1.0000\n  Source samples (first 8 and last 8):\n    First 8: 0.0000 0.1874 0.3681 0.5358 0.6845 0.8090 0.9048 0.9686 \n    Last 8:  0.6845 0.8090 0.9048 0.9686 0.9980 0.9921 0.9511 0.8763 \n\nSource 2 (30.0 Hz)\nValue\n  1.20 |                                                                \n  0.98 | *   *   *                *   *   *   *   *   *                *\n  0.76 |**  **  **   *   **   *  **  **  **  **  **  **   *   **   *  * \n  0.55 |**  **  **  * * * *  **  **  **  **  **  **  **  * * * *  **  * \n  0.33 |**  * * * * * * * * * * * *  **  **  **  * * * * * * * * * * *  \n  0.11 |* * * * * * * * * * * * * * * *  **  * * * * * * * * * * * * *  \n -0.11 |* * * * * * * * * * * * * * * * *  **  * * * * * * * * * * * *  \n -0.33 |  **  * * * * * * * * * *  **  **  **  **  * * * * * * * * * *  \n -0.55 |  **  **  * * * * * *  **  **  **  **  **  **  * * * * * *  **  \n -0.76 |  **  **  **   *   **   *  **  **  **  **  **  **   *   **   *  \n -0.98 |   *   *   *                *   *   *   *   *   *               \n -1.20 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.200, 1.200], Length: 512\n\n\n========================================\nSTEP 2: Creating Mixing Matrix\n========================================\nMixing Matrix A (num_obs x num_sources = 2 x 2):\n  [0.800  0.300]\n  [0.200  0.700]\n\nMixing Equation:\n  Observation 1 = 0.800 * Source 1 + 0.300 * Source 2\n  Observation 2 = 0.200 * Source 1 + 0.700 * Source 2\n\n========================================\nSTEP 3: Mixing Signals (X = A * S)\n========================================\nProcess: Multiplying mixing matrix by source signals\n\u2713 Mixed 2 sources into 2 observations\n\nMixed Signal Details:\n  Observation 1:\n    Statistics: mean=0.0111, std=0.6025, min=-0.7788, max=0.7788\n  Mixed samples (first 8 and last 8):\n    First 8: 0.0000 0.1064 0.2107 0.3107 0.4043 0.4899 0.5659 0.6312 \n    Last 8:  0.4043 0.4899 0.5659 0.6312 0.6848 0.7263 0.7555 0.7728 \n\nMixed Observation 1\nValue\n  0.93 |                                                                \n  0.76 | **  *        *  *        *  *        **  *        *  *        *\n  0.59 |* * **       * ***       * ** *      * * **       * ***       * \n  0.42 |*  * *      *     *      *    *      *  * *      *     *      * \n  0.25 |*    *      *     *      *    *      *    *      *     *      * \n  0.08 |*     *     *     *     *     *      *     *     *     *     *  \n -0.08 |*     *     *     *     *      *    *      *     *     *     *  \n -0.25 |      *     *     *     *      *    *      *     *     *     *  \n -0.42 |      *    *       *    *      *  * *      *    *       *    *  \n -0.59 |       * ***       * ** *      * ** *       * ***       * ***   \n -0.76 |        *  *        *  *        *  **        *  *        *  *   \n -0.93 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-0.935, 0.935], Length: 512\n\n\n  Observation 2:\n    Statistics: mean=0.0129, std=0.5171, min=-0.8016, max=0.8016\n  Mixed samples (first 8 and last 8):\n    First 8: 0.0000 0.1437 0.2828 0.4126 0.5289 0.6281 0.7070 0.7632 \n    Last 8:  0.5289 0.6281 0.7070 0.7632 0.7950 0.8016 0.7833 0.7409 \n\nMixed Observation 2\nValue\n  0.96 |                                                                \n  0.79 | *   *                    *   *       *   *                    *\n  0.61 |**  **       **  **      **  **      **  **       **  *       * \n  0.44 |**  **   *  * * * *   *  **  **   *  **  **   *  * * * *   *  * \n  0.26 |* * * * **  * * * *  ** * * * *  **  * * **  **  * * * *  ** *  \n  0.09 |* * * * * * * * * * * * * * * *  **  * * * * * * * * * * * * *  \n -0.09 |  **  * * * * * * * * * *  ** *  ** *  **  * * * * * * * * * *  \n -0.26 |  **  * * * * * * * * * *  **  **  **  **  * * * * * * * * * *  \n -0.44 |   *  * * * *  *  * * * *   *  **  **   *  * * * *  *  * * * *  \n -0.61 |      **  **       **  **      **  **      **  **       **  **  \n -0.79 |       *   *                    *   *       *   *               \n -0.96 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-0.962, 0.962], Length: 512\n\n\n========================================\nSTEP 4: ICA Separation (FastICA Algorithm)\n========================================\nAlgorithm: FastICA\nNonlinearity: tanh (for super-Gaussian sources)\nMax iterations: 100\nConvergence tolerance: 1e-4\nProcess:\n  1. Center data (subtract mean)\n  2. Whiten data (decorrelate and normalize variance)\n  3. Extract independent components using FastICA\n  4. Reconstruct separated sources\n\n\u2713 ICA separation completed successfully\n\n========================================\nSTEP 5: Evaluating Separation Quality\n========================================\nSeparated Signal Details:\n\n  Separated Component 1 (matches Source 1):\n    Correlation with original: 0.959623\n    Statistics: mean=-0.0000, std=1.0000, min=-1.2638, max=1.2299\n    Original Source 1: mean=0.0078, std=0.7012, min=-1.0000, max=1.0000\n  Separated samples (first 8 and last 8):\n    First 8: -0.0170 0.1430 0.3001 0.4513 0.5939 0.7256 0.8442 0.9481 \n    Last 8:  0.5939 0.7256 0.8442 0.9481 1.0361 1.1074 1.1620 1.1999 \n\nSeparated Component 1 (matches Source 1)\nValue\n  1.48 |                                                                \n  1.21 |  * **        *  *        ** *         * **        *  *        *\n  0.94 | * * *       * ***       *  * *       * * *       * ***       * \n  0.66 |*    *       *    *      *    *      *    *       *    *      * \n  0.39 |*    *      *     *      *    *      *    *      *     *      * \n  0.12 |*     *     *     *     *     *      *     *     *     *     *  \n -0.15 |*     *     *     *     *      *    *      *     *     *     *  \n -0.43 |      *     *     *     *      *    *      *     *     *     *  \n -0.70 |      *    *       *    *      *    *      *    *       *    *  \n -0.97 |       * * *       * ***       *  * *       * * *       * ***   \n -1.24 |        * **        *  *        ** *         * **        *  *   \n -1.51 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.513, 1.479], Length: 512\n\n\nOriginal Source 1 (for comparison)\nValue\n  1.20 |                                                                \n  0.98 |   **          **          **           **          **          \n  0.76 |  * *         *  *        *  *         * *         *  *         \n  0.55 | *   *       *   *        *  *        *   *       *   *        *\n  0.33 |*    *       *    *      *    *      *    *       *    *      * \n  0.11 |*     *     *     *      *    *      *     *     *     *      * \n -0.11 |*     *     *     *     *      *    *      *     *     *     *  \n -0.33 |       *   *       *    *      *    *       *   *       *    *  \n -0.55 |       *   *       *   *        *   *       *   *       *   *   \n -0.76 |        * *         *  *        *  *         * *         *  *   \n -0.98 |         **          **          **           **          **    \n -1.20 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.200, 1.200], Length: 512\n\n    Normalized RMSE: 0.284173\n    Quality: Excellent\n\n  Separated Component 2 (matches Source 2):\n    Correlation with original: 0.955788\n    Statistics: mean=0.0000, std=1.0000, min=-1.7930, max=1.7557\n    Original Source 2: mean=0.0162, std=0.7083, min=-1.0000, max=1.0000\n  Separated samples (first 8 and last 8):\n    First 8: -0.0186 0.2089 0.4276 0.6288 0.8046 0.9479 1.0530 1.1152 \n    Last 8:  0.8046 0.9479 1.0530 1.1152 1.1316 1.1009 1.0235 0.9014 \n\nSeparated Component 2 (matches Source 2)\nValue\n  2.11 |                                                                \n  1.72 |         *                        *           *                 \n  1.34 |        **           **          **          **           **    \n  0.95 | *   *  * *  *    * * *   *   *  **   *   *  * *  *    * * *   *\n  0.56 |**  **  * * * *  ** * *  **  **  **  **  **  * * * *  ** * *  * \n  0.17 |**  * * * * * * * * * * * *  ** *  * **  * * * * * * * * * * *  \n -0.21 |* * * * * * * * * * * * * * *  **  **  * * * * * * * * * * * *  \n -0.60 |  * * **  * * * * * *  ** * *  **  **  * * **  * * * * * *  **  \n -0.99 |  **   *   *  * *  *    *  **   *   *  **   *   *  * *  *    *  \n -1.37 |  **           **          **          **           **          \n -1.76 |   *                        *           *                       \n -2.15 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-2.148, 2.111], Length: 512\n\n\nOriginal Source 2 (for comparison)\nValue\n  1.20 |                                                                \n  0.98 | *   *   *                *   *   *   *   *   *                *\n  0.76 |**  **  **   *   **   *  **  **  **  **  **  **   *   **   *  * \n  0.55 |**  **  **  * * * *  **  **  **  **  **  **  **  * * * *  **  * \n  0.33 |**  * * * * * * * * * * * *  **  **  **  * * * * * * * * * * *  \n  0.11 |* * * * * * * * * * * * * * * *  **  * * * * * * * * * * * * *  \n -0.11 |* * * * * * * * * * * * * * * * *  **  * * * * * * * * * * * *  \n -0.33 |  **  * * * * * * * * * *  **  **  **  **  * * * * * * * * * *  \n -0.55 |  **  **  * * * * * *  **  **  **  **  **  **  * * * * * *  **  \n -0.76 |  **  **  **   *   **   *  **  **  **  **  **  **   *   **   *  \n -0.98 |   *   *   *                *   *   *   *   *   *               \n -1.20 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.200, 1.200], Length: 512\n\n    Normalized RMSE: 0.297362\n    Quality: Excellent\n\n========================================\nSTEP 6: Testing ICA Structure API\n========================================\nThis tests the reusable ICA structure for multiple separations:\n  1. Initialize ICA structure\n  2. Fit model to training data\n  3. Transform new data using learned model\n  4. Compare with direct separation\n\n  \u2713 ICA structure initialized\n  \u2713 ICA model fitted\n  \u2713 ICA transform completed\n  RMSE between direct and structure API: 1.414214\n  \u2713 ICA structure deinitialized\n\n========================================\nSUMMARY: ICA Test Results\n========================================\nTest Configuration:\n  - Sources: 2 independent signals\n  - Observations: 2 mixed signals\n  - Samples: 512 per signal\n  - Sample rate: 1000.0 Hz\n\nSeparation Quality Summary:\n  Component 1 \u2192 Source 1: Correlation = 0.959623 (Excellent)\n  Component 2 \u2192 Source 2: Correlation = 0.955788 (Excellent)\n\nExpected vs Actual:\n  Expected: Separated signals should match original sources\n  Actual: ICA successfully extracted independent components\n  Note: ICA may recover sources with different scale/sign, which is normal\n        (correlation measures similarity regardless of scale)\n\n========== TinyICA Test Complete ==========\n</code></pre>"},{"location":"DSP/USAGE/usage/","title":"USAGE INSTRUCTIONS","text":"<p>Usage Instructions</p> <p>This document provides usage instructions for the <code>tiny_dsp</code> module. </p>"},{"location":"DSP/USAGE/usage/#import-tinydsp-as-a-whole","title":"Import TinyDSP as a Whole","text":"<p>Info</p> <p>Suitable for C projects or projects with a simple structure in C++.</p> <pre><code>#include \"tiny_dsp.h\"\n</code></pre>"},{"location":"DSP/USAGE/usage/#import-tinydsp-by-module","title":"Import TinyDSP by Module","text":"<p>Info</p> <p>Suitable for projects that require precise control over module imports or complex C++ projects.</p> <pre><code>// Signal processing modules (signal/)\n#include \"tiny_conv.h\"        // convolution module\n#include \"tiny_corr.h\"        // correlation module\n#include \"tiny_resample.h\"    // resampling module\n\n// Filter modules (filter/)\n#include \"tiny_fir.h\"         // FIR filter module\n#include \"tiny_iir.h\"         // IIR filter module\n\n// Transform modules (transform/)\n#include \"tiny_fft.h\"         // fast fourier transform module\n#include \"tiny_dwt.h\"         // discrete wavelet transform module\n#include \"tiny_ica.h\"         // independent component analysis module\n\n// Support modules (support/)\n#include \"tiny_view.h\"        // signal view/support module\n</code></pre> <p>Tip</p> <p>For specific usage methods, please refer to the test code.</p>"},{"location":"MATH/math/","title":"MATH OPERATIONS","text":"<p>Note</p> <p>This component is designed for mathematical operations. It is a lightweight library that provides basic mathematical functions to facilitate onboard computation and AI model inference. The library is designed to be lightweight and efficient, making it suitable for edge computing applications.</p> <p>Note</p> <p>This component is a wrapper and extension of the official ESP32 digital signal processing library ESP-DSP, providing higher-level API interfaces. In simple terms, the TinyMath library corresponds to the Math, Matrix, and DotProduct modules in ESP-DSP, while the other modules in ESP-DSP correspond to the TinyDSP library.</p>"},{"location":"MATH/math/#component-dependencies","title":"COMPONENT DEPENDENCIES","text":"<pre><code>set(src_dirs\n    .\n    vec\n    mat\n)\n\nset(include_dirs\n    .\n    include\n    vec\n    mat\n)\n\nset(requires\n    tiny_toolbox\n)\n\nidf_component_register(SRC_DIRS ${src_dirs} INCLUDE_DIRS ${include_dirs} REQUIRES ${requires})\n</code></pre>"},{"location":"MATH/math/#architecture-and-directory","title":"ARCHITECTURE AND DIRECTORY","text":""},{"location":"MATH/math/#dependency-diagram","title":"Dependency Diagram","text":""},{"location":"MATH/math/#code-tree","title":"Code Tree","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 include\n    |   \u251c\u2500\u2500 tiny_error_type.h // error type header file\n    |   \u251c\u2500\u2500 tiny_constant.h // constant header file\n    |   \u251c\u2500\u2500 tiny_math_config.h // configuration header file\n    |   \u2514\u2500\u2500 tiny_math.h // main header file, include this file where you want to use the library\n    \u251c\u2500\u2500 vec\n    |   \u251c\u2500\u2500 tiny_vec.h // vector header file\n    |   \u251c\u2500\u2500 tiny_vec.c // vector source file\n    |   \u251c\u2500\u2500 tiny_vec_test.c // vector test file\n    |   \u2514\u2500\u2500 tiny_vec_test.h // vector test header file\n    \u251c\u2500\u2500 mat\n    |   \u251c\u2500\u2500 tiny_mat.h // matrix header file - c\n    |   \u251c\u2500\u2500 tiny_mat.c // matrix source file - c\n    |   \u251c\u2500\u2500 tiny_mat_test.c // matrix test file - c \n    |   \u251c\u2500\u2500 tiny_mat_test.h // matrix test header file - c\n    |   \u251c\u2500\u2500 tiny_matrix.hpp // matrix header file - cpp\n    |   \u251c\u2500\u2500 tiny_matrix.cpp // matrix source file - cpp\n    |   \u251c\u2500\u2500 tiny_matrix_test.cpp // matrix test file - cpp\n    |   \u2514\u2500\u2500 tiny_matrix_test.hpp // matrix test header file - cpp\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"MATH/ESP-DSP/esp-dsp/","title":"ESP-DSP","text":"<ul> <li> <p> ESP-DSP</p> <p>An Espressif DSP Library (esp-dsp) it\u2019s library of functions, modules and components that provides possibility to use Espressif\u2019s CPUs as DSPs in efficient way.</p> <p>  Online Doc </p> </li> </ul>"},{"location":"MATH/ESP-DSP/esp-dsp/#function-naming","title":"Function Naming","text":"<p>Naming conventions for the Library functions are similar for all covered domains. You can distinguish signal processing functions by the dsps prefix, while image and video processing functions have dspi prefix, and functions that are specific for operations on small matrices have dspm prefix in their names. Function names in Library have the following general format:</p> <pre><code>dsp&lt;data-domain&gt;_&lt;name&gt;_&lt;datatype1&gt;&lt;datatype_ext&gt;_&lt;datatype2&gt;&lt;datatype_ext&gt;[_&lt;descriptor&gt;]&lt;_impl&gt;(&lt;parameters&gt;);\n</code></pre> <p>Where:</p> <ul> <li> <p><code>&lt;data-domain&gt;</code> is the domain of the function, e.g. <code>s</code> for signal processing, <code>i</code> for image processing, <code>v</code> for video processing, and <code>m</code> for small matrix operations.</p> </li> <li> <p><code>&lt;name&gt;</code> is the name of the function.</p> </li> <li> <p><code>&lt;datatype1&gt;</code> is the type of the first input parameter.</p> </li> <li> <p><code>&lt;datatype_ext&gt;</code> is the type of the first input parameter extended with a suffix that indicates the type of the data, e.g. <code>f</code> for float, <code>i</code> for integer, <code>c</code> for complex, etc.</p> </li> <li> <p><code>&lt;datatype2&gt;</code> is the type of the second input parameter.</p> </li> <li> <p><code>&lt;descriptor&gt;</code> is an optional descriptor that provides additional information about the function.</p> </li> <li> <p><code>&lt;impl&gt;</code> is an optional implementation descriptor that provides additional information about the implementation of the function.</p> </li> <li> <p><code>&lt;parameters&gt;</code> are the parameters of the function.</p> </li> </ul>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-domain","title":"Data Domain","text":"<p>The data-domain is a single character that expresses the subset of functionality to which a given function belongs. The Library designed to supports the following data-domains:</p> <ul> <li> <p>s - for signals (expected data type is a 1D signal)</p> </li> <li> <p>i - for images and video (expected data type is a 2D image)</p> </li> <li> <p>m - for matrices (expected data type is a matrix)</p> </li> <li> <p>r - for realistic rendering functionality and 3D data processing (expected data type depends on supported rendering techniques)</p> </li> <li> <p>q - for signals of fixed length</p> </li> </ul> <p>For example, function names that begin with dspi signify that respective functions are used for image or video processing.</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#name","title":"Name","text":"<p>The name is an abbreviation for the core operation that the function really does, for example Add, Sqrt, followed in some cases by a function-specific modifier: = [_modifier]</p> <p>This modifier, if present, denotes a slight modification or variation of the given function.</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-types","title":"Data Types","text":"<p>The library supports two main data types \u2013 int16 for fixed point arithmetic and float for floating point arithmetic. The datatype described as:</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-type-suffices","title":"Data type suffices:","text":"<ul> <li> <p>s - signed</p> </li> <li> <p>u - unsigned</p> </li> <li> <p>f - float</p> </li> </ul>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-type-extensions","title":"Data type extensions:","text":"<ul> <li>c - complex</li> </ul>"},{"location":"MATH/ESP-DSP/esp-dsp/#data-type-bits-resolution","title":"Data type Bits resolution:","text":"<ul> <li> <p>16</p> </li> <li> <p>32</p> </li> </ul> <p>For example: dsps_mac_sc16 defines that mac operation with 1d array will be made with 16 bit signed complex data.</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#implementation-type","title":"Implementation Type","text":"<p>Each function could be implemented different for different platform and could use different style and resources. That\u2019s why every implemented function will have name extension &lt;_impl&gt; that will define which kind of implementation it is. User can use universal function without extension.</p>"},{"location":"MATH/ESP-DSP/esp-dsp/#implementation-extensions","title":"Implementation extensions:","text":"<p>By default all functions could be used without extensions. The option that select optimized/ansi can be chosen in menuconfig.</p> <p>Inside library the extensions means:</p> <ul> <li> <p>_ansi - a universal function where body of function implemented on ANSI C. This implementation not includes any hardware optimization</p> </li> <li> <p>_ae32 - written on ESP32 assembler and optimized for ESP32</p> </li> <li> <p>_aes3 - written on ESP32S3 assembler and optimized for ESP32S3</p> </li> <li> <p>_arp4 - written on ESP32P4 assembler and optimized for ESP32P4</p> </li> <li> <p>_platform - header file with definitions of available CPUs instructions for different functions</p> </li> <li> <p>others- depends on amount of supported CPUs. This list will be extended in future</p> </li> </ul>"},{"location":"MATH/ESP-DSP/examples/","title":"ESP-DSP EXAMPLES","text":""},{"location":"MATH/ESP-DSP/examples/#list-of-esp-dsp-examples","title":"List of esp-dsp Examples","text":"<p>Signal processing APIs use dsps prefix. The following modules are available:</p> <ul> <li> <p>Basic math - the example shows how to use basic vector math operations</p> </li> <li> <p>Dot-product - the example demonstrates how to use dot product functions</p> </li> <li> <p>FFT - the example demonstrates how to use FFT functionality</p> </li> <li> <p>FFT Window - the example demonstrates how to use Window and FFT functionality</p> </li> <li> <p>FFT 4 Real - the example demonstrates how to use FFT functionality for real input signals</p> </li> <li> <p>IIR - the example demonstrates how to use IIR filters functionality</p> </li> <li> <p>FIR - the example demonstrates how to use FIR filter functionality</p> </li> <li> <p>Kalman Filter - Extended Kalman Filter (EKF) example</p> </li> <li> <p>Matrix - example demonstrates how to use Mat class functionality</p> </li> </ul>"},{"location":"MATH/ESP-DSP/examples/#basic-math","title":"Basic math","text":"<p>This example demonstrates how to use basic math functions from esp-dsp library. The example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signals with 1024 samples</p> </li> <li> <p>Apply window to input signal by standard C loop.</p> </li> <li> <p>Calculate FFT for 1024 complex samples and show the result</p> </li> <li> <p>Show results on the plots</p> </li> <li> <p>Apply window to input signal by basic math functions dsps_mul_f32 and dsps_mulc_f32.</p> </li> <li> <p>Calculate FFT for 1024 complex samples</p> </li> <li> <p>Show results on the plots</p> </li> </ul> <p>For more details please look to the examples/basic_math/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#dot-product","title":"Dot-product","text":"<p>The example demonstrates how to use dotprod dsps_dotprod_f32 from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the input arrays</p> </li> <li> <p>Calculate dot product of two arrays</p> </li> <li> <p>Compare results and calculate execution time in cycles.</p> </li> </ul> <p>For more details please look to the examples/dotprod/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#fft","title":"FFT","text":"<p>This example demonstrates how to use FFT functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signals with 1024 samples: one 0 dB, second with -20 dB</p> </li> <li> <p>Combine two signals as one complex input signal and apply window to input signals paar.</p> </li> <li> <p>Calculate FFT for 1024 complex samples</p> </li> <li> <p>Apply bit reverse operation for output complex vector</p> </li> <li> <p>Split one complex FFT output spectrum to two real signal spectrums</p> </li> <li> <p>Show results on the plots</p> </li> <li> <p>Show execution time of FFT</p> </li> </ul> <p>For more details please look to the examples/fft/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#fft-window","title":"FFT Window","text":"<p>This example demonstrates how to use Window and FFT functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signals with 1024 samples</p> </li> <li> <p>Apply window to input signal.</p> </li> <li> <p>Calculate FFT for 1024 complex samples</p> </li> <li> <p>Apply bit reverse operation for output complex vector</p> </li> <li> <p>Split one complex FFT output spectrum to two real signal spectrums</p> </li> <li> <p>Show results on the plots</p> </li> </ul> <p>For more details please look to the examples/fft_window/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#fft-4-real","title":"FFT 4 Real","text":"<p>This example demonstrates how to use FFT functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signals with 1024 samples: one 0 dB, second with -20 dB</p> </li> <li> <p>Calculate FFT Radix-2 for 1024 complex samples</p> </li> <li> <p>Calculate FFT Radix-4 for 1024 complex samples</p> </li> <li> <p>Apply bit reverse operation for output complex vectors</p> </li> <li> <p>Show results on the plots</p> </li> <li> <p>Show execution time of FFTs</p> </li> </ul> <p>For more details please look to the examples/fft4real/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#iir","title":"IIR","text":"<p>This example demonstrates how to use IIR filters functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the library</p> </li> <li> <p>Initialize input signal</p> </li> <li> <p>Show LPF filter with Q factor 1</p> <ul> <li> <p>Calculate iir filter coefficients</p> </li> <li> <p>Filter the input test signal (delta function)</p> </li> <li> <p>Shows impulse response on the plot</p> </li> <li> <p>Shows frequency response on the plot</p> </li> </ul> </li> <li> <p>Calculate execution performance</p> </li> <li> <p>The same for LPF filter with Q factor 10</p> </li> </ul> <p>For more details please look to the examples/fir/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#fir","title":"FIR","text":"<p>This example demonstrates how to use FIR filter functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize the FFT library</p> </li> <li> <p>Initialize input signal</p> </li> <li> <p>Show input signal</p> </li> <li> <p>Show filtered signal</p> </li> </ul> <p>For more details please look to the examples/fir/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#kalman-filter","title":"Kalman Filter","text":"<p>This example emulate system with IMU sensors and show how to use Extended Kalman Filter (EKF), with 13 values states vector, to estimate gyroscope errors and calculate system attitude. Also, this example show how to use esp-dsp library to operate with matrices and vectors.</p> <p>In real system, the emulated sensors values should be replace by the real sensors values. Then, in real system, a calibration phase should be implemented and after the calibration phase the state vector X and covariance matrix P should be saved and restored next time, when filter called. It will save time for initial phase.</p> <p>For more details please look to the examples/kalman/README.md</p>"},{"location":"MATH/ESP-DSP/examples/#matrix","title":"Matrix","text":"<p>This example demonstrates how to use Mat class functionality from esp-dsp library. Example does the following steps:</p> <ul> <li> <p>Initialize a matrix A and matirx x</p> </li> <li> <p>Calculate matrix b: b = A*x</p> </li> <li> <p>Find roots x1: A*x1 = b, with different methods</p> </li> <li> <p>Print result</p> </li> </ul>"},{"location":"MATH/HEADER-FILE/tiny_constants/","title":"CONSTANTS","text":"<p>Info</p> <p>This file contains the definition of some constants, which are used for upper-level calculations and applications. The documentation update speed is slow and may not be consistent with the actual code. Please refer to the code for accuracy.</p> <pre><code>/**\n * @file tiny_constants.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file contains the constants used in the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n// =======================================\n//  Logical Constants\n// =======================================\n#ifndef TRUE\n#define TRUE 1\n#endif\n\n#ifndef FALSE\n#define FALSE 0\n#endif\n\n#ifndef NULL\n#define NULL ((void *)0)\n#endif\n\n// =======================================\n//  Math Constants (float/double safe)\n// =======================================\n#define TINY_PI 3.14159265358979323846f\n#define TINY_TWO_PI 6.28318530717958647692f\n#define TINY_HALF_PI 1.57079632679489661923f\n#define TINY_E 2.71828182845904523536f\n#define TINY_SQRT2 1.41421356237309504880f\n#define TINY_INV_SQRT2 0.70710678118654752440f\n\n#define TINY_DEG2RAD(x) ((x) * TINY_PI / 180.0f)\n#define TINY_RAD2DEG(x) ((x) * 180.0f / TINY_PI)\n\n// =======================================\n//  Bitmask &amp; Bit Manipulation\n// =======================================\n\n// Bitwise operations\n#define TINY_BIT(n) (1U &lt;&lt; (n)) // e.g. TINY_BIT(3) = 0b00001000\n#define TINY_BIT_SET(x, n) ((x) |= TINY_BIT(n))\n#define TINY_BIT_CLEAR(x, n) ((x) &amp;= ~TINY_BIT(n))\n#define TINY_BIT_TOGGLE(x, n) ((x) ^= TINY_BIT(n))\n#define TINY_BIT_CHECK(x, n) (((x) &gt;&gt; (n)) &amp; 0x1U)\n\n// Common bit masks\n#define TINY_MASK_4BIT 0x0FU\n#define TINY_MASK_8BIT 0xFFU\n#define TINY_MASK_16BIT 0xFFFFU\n#define TINY_MASK_32BIT 0xFFFFFFFFU\n\n// =======================================\n//  Fixed-Point Scaling Factors\n// =======================================\n#define TINY_Q7_SCALE 128          // 2^7\n#define TINY_Q15_SCALE 32768       // 2^15\n#define TINY_Q31_SCALE 2147483648U // 2^31\n\n// =======================================\n//  User-Defined Constants (Optional)\n// =======================================\n#define TINY_MATH_MIN_DENOMINATOR 1e-6f         // Minimum denominator for safe division\n#define TINY_MATH_MIN_POSITIVE_INPUT_F32 1e-12f // Minimum positive input for float operations\n#define TINY_MATH_LARGE_VALUE_F32 1e38f         // Large value used to represent infinity-like results (safe for IEEE 754 float, max ~3.4e38)\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/HEADER-FILE/tiny_error_type/","title":"ERROR TYPES DEFINITION","text":"<p>Info</p> <p>This file defines some common error types in calculations to assist in determining the cause of errors. The documentation update speed is slow and may not match the actual code, please refer to the code for accuracy.</p> <pre><code>/**\n * @file tiny_error_type.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /* TYPE DEFINITIONS */\n    typedef int tiny_error_t; // Error type for the tiny_math middleware\n\n/* MACROS */\n/* Definitions for error constants. */\n#define TINY_OK 0    /*!&lt; tiny_err_t value indicating success (no error) */\n#define TINY_FAIL -1 /*!&lt; Generic tiny_err_t code indicating failure */\n\n#define TINY_ERR_NO_MEM 0x101           /*!&lt; Out of memory */\n#define TINY_ERR_INVALID_ARG 0x102      /*!&lt; Invalid argument */\n#define TINY_ERR_INVALID_STATE 0x103    /*!&lt; Invalid state */\n#define TINY_ERR_INVALID_SIZE 0x104     /*!&lt; Invalid size */\n#define TINY_ERR_NOT_FOUND 0x105        /*!&lt; Requested resource not found */\n#define TINY_ERR_NOT_SUPPORTED 0x106    /*!&lt; Operation or feature not supported */\n#define TINY_ERR_TIMEOUT 0x107          /*!&lt; Operation timed out */\n#define TINY_ERR_INVALID_RESPONSE 0x108 /*!&lt; Received response was invalid */\n#define TINY_ERR_INVALID_CRC 0x109      /*!&lt; CRC or checksum was invalid */\n#define TINY_ERR_INVALID_VERSION 0x10A  /*!&lt; Version was invalid */\n#define TINY_ERR_INVALID_MAC 0x10B      /*!&lt; MAC address was invalid */\n#define TINY_ERR_NOT_FINISHED 0x10C     /*!&lt; Operation has not fully completed */\n#define TINY_ERR_NOT_ALLOWED 0x10D      /*!&lt; Operation is not allowed */\n\n#define TINY_ERR_WIFI_BASE 0x3000      /*!&lt; Starting number of WiFi error codes */\n#define TINY_ERR_MESH_BASE 0x4000      /*!&lt; Starting number of MESH error codes */\n#define TINY_ERR_FLASH_BASE 0x6000     /*!&lt; Starting number of flash error codes */\n#define TINY_ERR_HW_CRYPTO_BASE 0xc000 /*!&lt; Starting number of HW cryptography module error codes */\n#define TINY_ERR_MEMPROT_BASE 0xd000   /*!&lt; Starting number of Memory Protection API error codes */\n\n#define TINY_ERR_MATH_BASE 0x70000\n#define TINY_ERR_MATH_INVALID_LENGTH (TINY_ERR_MATH_BASE + 1)\n#define TINY_ERR_MATH_INVALID_PARAM (TINY_ERR_MATH_BASE + 2)\n#define TINY_ERR_MATH_PARAM_OUTOFRANGE (TINY_ERR_MATH_BASE + 3)\n#define TINY_ERR_MATH_UNINITIALIZED (TINY_ERR_MATH_BASE + 4)\n#define TINY_ERR_MATH_REINITIALIZED (TINY_ERR_MATH_BASE + 5)\n#define TINY_ERR_MATH_ARRAY_NOT_ALIGNED (TINY_ERR_MATH_BASE + 6)\n#define TINY_ERR_MATH_NULL_POINTER (TINY_ERR_MATH_BASE + 7)\n#define TINY_ERR_MATH_ZERO_DIVISION (TINY_ERR_MATH_BASE + 8)\n#define TINY_ERR_MATH_NEGATIVE_SQRT (TINY_ERR_MATH_BASE + 9)\n\n#define TINY_ERR_DSP_BASE 0x80000\n#define TINY_ERR_DSP_INVALID_LENGTH (TINY_ERR_DSP_BASE + 1)\n#define TINY_ERR_DSP_INVALID_PARAM (TINY_ERR_DSP_BASE + 2)\n#define TINY_ERR_DSP_PARAM_OUTOFRANGE (TINY_ERR_DSP_BASE + 3)\n#define TINY_ERR_DSP_UNINITIALIZED (TINY_ERR_DSP_BASE + 4)\n#define TINY_ERR_DSP_REINITIALIZED (TINY_ERR_DSP_BASE + 5)\n#define TINY_ERR_DSP_ARRAY_NOT_ALIGNED (TINY_ERR_DSP_BASE + 6)\n#define TINY_ERR_DSP_NULL_POINTER (TINY_ERR_DSP_BASE + 7)\n#define TINY_ERR_DSP_ZERO_DIVISION (TINY_ERR_DSP_BASE + 8)\n#define TINY_ERR_DSP_NEGATIVE_SQRT (TINY_ERR_DSP_BASE + 9)\n#define TINY_ERR_DSP_MISMATCH (TINY_ERR_DSP_BASE + 10)\n#define TINY_ERR_DSP_INVALID_MODE (TINY_ERR_DSP_BASE + 11)\n#define TINY_ERR_DSP_MEMORY_ALLOC (TINY_ERR_DSP_BASE + 12)\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/HEADER-FILE/tiny_math/","title":"TinyMath HEADER FILE","text":"<p>Info</p> <p>This is the main header file of the TinyMath library. It includes all necessary header files and provides a unified interface to use the functions of the library. After completing the porting of this library in the project, you can insert this header file where you want to use the relevant functions to use all functions in the library. The documentation update speed is slow and may not be consistent with the actual code, please refer to the actual code.</p> <pre><code>/**\n * @file tiny_math.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-03-26\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n\n// this layer\n#include \"tiny_math_config.h\"\n\n/* SUBMODULES */\n\n// vector operations\n#include \"tiny_vec.h\"\n\n// matrix operations\n#include \"tiny_mat.h\"\n\n// advanced matrix operations\n#ifdef __cplusplus\n\n#include \"tiny_matrix.hpp\"\n\n#endif\n\n/* TEST */ // NOTE: test files are platform specific and should not be included in the library\n\n// vector operations\n#include \"tiny_vec_test.h\"\n\n// matrix operations\n#include \"tiny_mat_test.h\"\n\n// advanced matrix operations\n#ifdef __cplusplus\n\n#include \"tiny_matrix_test.hpp\"\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/HEADER-FILE/tiny_math_config/","title":"TinyMath CONFIGURATION","text":"<p>Info</p> <p>This header file serves to configure the entire TinyMath module, and each submodule includes this header file. It defines the configuration options and macros for TinyMath, allowing users to customize settings as needed. By modifying the configuration options in this header file, users can easily adjust the behavior and functionality of TinyMath to meet specific requirements. The documentation may be updated slowly and may not match the actual code, so please refer to the code for accuracy.</p> <p>Tip</p> <p>This component includes macro definitions for selecting platforms, allowing users to choose different platforms for compilation as needed. By switching to the corresponding platform macro, users can leverage platform acceleration features to enhance performance. For example, for the ESP32 platform, TinyMath will automatically select the ESP32 DSP library for compilation, achieving more efficient mathematical operations.</p> <pre><code>/**\n * @file tiny_math_config.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-14\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* DEPENDENCIES */\n\n// ANSI C\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;math.h&gt;\n#include &lt;stdbool.h&gt;\n#include &lt;stdint.h&gt;\n\n// lower level\n#include \"tiny_toolbox.h\"\n\n// this level\n#include \"tiny_error_type.h\"\n#include \"tiny_constants.h\"\n\n/* PLATFORM SELECTION */\n\n// available platforms\n#define MCU_PLATFORM_GENERIC 0\n#define MCU_PLATFORM_ESP32 1 // here, we utilize the ESP built-in DSP library, it will automatically select the optimized version\n#define MCU_PLATFORM_STM32 2\n#define MCU_PLATFORM_RISCV 3\n\n// choose one platform\n#define MCU_PLATFORM_SELECTED MCU_PLATFORM_ESP32\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-api/","title":"MATRIX OPERATIONS - TINY_MAT","text":"<p>About tiny_mat library</p> <p>tiny_mat is a C implementation of a matrix library that provides basic matrix operation functions. It supports operations such as addition, subtraction, and multiplication of floating-point matrices. This library is suitable for embedded systems and real-time applications that require matrix calculations. The library is based on the ANSI C standard, ensuring good portability and performance, while also supporting platform acceleration through configuration files (ESP32).</p> <p>About the usage of tiny_mat library</p> <p>The functionality of tiny_mat is completely covered by tiny_matrix, which means that the functions in tiny_matrix include all the functions of tiny_mat. For simple matrix operations, you can only include the tiny_mat library; for complex matrix operations, it is recommended to use the tiny_matrix library. The tiny_matrix library is a C++ implementation of a matrix library that provides richer functionality and better performance. It supports operations such as addition, subtraction, multiplication, transposition, and inversion of floating-point and integer matrices.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#list-of-functions","title":"LIST OF FUNCTIONS","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500Vector\n    \u2514\u2500\u2500Matrix\n        \u251c\u2500\u2500 tiny_mat (c) &lt;---\n        \u2514\u2500\u2500 tiny_matrix (c++)\n</code></pre> <pre><code>// print matrix\nvoid print_matrix(const char *name, const float *mat, int rows, int cols);\n// print matrix padded (row-major)\nvoid print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n// addition\ntiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// subtraction\ntiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// multiplication\ntiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\ntiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\ntiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-api/#utility-functions","title":"UTILITY FUNCTIONS","text":""},{"location":"MATH/MATRIX/tiny-mat-api/#print-matrix","title":"Print Matrix","text":"<p><pre><code>void print_matrix(const char *name, const float *mat, int rows, int cols);\n</code></pre> Function: Print a matrix in row-major order.</p> <p>Parameters:</p> <ul> <li> <p><code>name</code>: Name of the matrix.</p> </li> <li> <p><code>mat</code>: Pointer to the matrix data.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> </ul> <p>Returns: None.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#print-padded-matrix","title":"Print Padded Matrix","text":"<p><pre><code>void print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n</code></pre> Function: Print a matrix in row-major order with padding.</p> <p>Parameters: - <code>name</code>: Name of the matrix.</p> <ul> <li> <p><code>mat</code>: Pointer to the matrix data.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> <li> <p><code>step</code>: Step size for the matrix data.</p> </li> </ul> <p>Returns: None.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#addition","title":"ADDITION","text":""},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-addition","title":"Matrix Addition","text":"<pre><code>tiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\n</code></pre> <p>Function: Add two matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>input1</code>: Pointer to the first input matrix.</p> </li> <li> <p><code>input2</code>: Pointer to the second input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrices.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrices.</p> </li> <li> <p><code>padd1</code>: Padding for the first input matrix.</p> </li> <li> <p><code>padd2</code>: Padding for the second input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step1</code>: Step size for the first input matrix.</p> </li> <li> <p><code>step2</code>: Step size for the second input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-addition-with-constant","title":"Matrix Addition with Constant","text":"<pre><code>tiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>Function: Add a constant to a matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>C</code>: Constant to add.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> <li> <p><code>padd_in</code>: Padding for the input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step_in</code>: Step size for the input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#subtraction","title":"SUBTRACTION","text":""},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-subtraction","title":"Matrix Subtraction","text":"<pre><code>tiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\n</code></pre> <p>Function: Subtract two matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>input1</code>: Pointer to the first input matrix.</p> </li> <li> <p><code>input2</code>: Pointer to the second input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrices.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrices.</p> </li> <li> <p><code>padd1</code>: Padding for the first input matrix.</p> </li> <li> <p><code>padd2</code>: Padding for the second input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step1</code>: Step size for the first input matrix.</p> </li> <li> <p><code>step2</code>: Step size for the second input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-subtraction-with-constant","title":"Matrix Subtraction with Constant","text":"<pre><code>tiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>Function: Subtract a constant from a matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>C</code>: Constant to subtract.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> <li> <p><code>padd_in</code>: Padding for the input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step_in</code>: Step size for the input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#multiplication","title":"MULTIPLICATION","text":""},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-multiplication","title":"Matrix Multiplication","text":"<pre><code>tiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\n</code></pre> <p>Function: Multiply two matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>A</code>: Pointer to the first input matrix.</p> </li> <li> <p><code>B</code>: Pointer to the second input matrix.</p> </li> <li> <p><code>C</code>: Pointer to the output matrix.</p> </li> <li> <p><code>m</code>: Number of rows in the first matrix.</p> </li> <li> <p><code>n</code>: Number of columns in the first matrix (and rows in the second matrix).</p> </li> <li> <p><code>k</code>: Number of columns in the second matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#extended-matrix-multiplication","title":"Extended Matrix Multiplication","text":"<pre><code>tiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\n</code></pre> <p>Function: Multiply two matrices with extended parameters.</p> <p>Parameters:</p> <ul> <li> <p><code>A</code>: Pointer to the first input matrix.</p> </li> <li> <p><code>B</code>: Pointer to the second input matrix.</p> </li> <li> <p><code>C</code>: Pointer to the output matrix.</p> </li> <li> <p><code>A_rows</code>: Number of rows in the first matrix.</p> </li> <li> <p><code>A_cols</code>: Number of columns in the first matrix.</p> </li> <li> <p><code>B_cols</code>: Number of columns in the second matrix.</p> </li> <li> <p><code>A_padding</code>: Padding for the first matrix.</p> </li> <li> <p><code>B_padding</code>: Padding for the second matrix.</p> </li> <li> <p><code>C_padding</code>: Padding for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure.</p>"},{"location":"MATH/MATRIX/tiny-mat-api/#matrix-multiplication-with-constant","title":"Matrix Multiplication with Constant","text":"<pre><code>tiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>Function: Multiply a matrix by a constant.</p> <p>Parameters:</p> <ul> <li> <p><code>input</code>: Pointer to the input matrix.</p> </li> <li> <p><code>output</code>: Pointer to the output matrix.</p> </li> <li> <p><code>C</code>: Constant to multiply.</p> </li> <li> <p><code>rows</code>: Number of rows in the matrix.</p> </li> <li> <p><code>cols</code>: Number of columns in the matrix.</p> </li> <li> <p><code>padd_in</code>: Padding for the input matrix.</p> </li> <li> <p><code>padd_out</code>: Padding for the output matrix.</p> </li> <li> <p><code>step_in</code>: Step size for the input matrix.</p> </li> <li> <p><code>step_out</code>: Step size for the output matrix.</p> </li> </ul> <p>Returns: <code>tiny_error_t</code> indicating success or failure. ```</p>"},{"location":"MATH/MATRIX/tiny-mat-code/","title":"CODE","text":""},{"location":"MATH/MATRIX/tiny-mat-code/#tiny_math","title":"tiny_mat.h","text":"<pre><code>/**\n * @file tiny_mat.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the submodule mat (basic matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_math_config.h\"\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n// ESP32 DSP library\n#include \"dspm_matrix.h\"\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* FUNCTION PROTOTYPES */\n// print matrix\nvoid print_matrix(const char *name, const float *mat, int rows, int cols);\n// print matrix padded (row-major)\nvoid print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n// addition\ntiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// subtraction\ntiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// multiplication\ntiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\ntiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\ntiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-code/#tiny_matc","title":"tiny_mat.c","text":"<pre><code>/**\n * @file tiny_mat.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the source file for the submodule mat (basic matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_mat.h\"\n\n/* SUPPORTIVE FUNCTIONS */\n\n/**\n * @name print_matrix\n * @brief Prints a matrix to the console.\n * @param name Name of the matrix.\n * @param mat Pointer to the matrix data.\n * @param rows Number of rows in the matrix.\n * @param cols Number of columns in the matrix.\n */\nvoid print_matrix(const char *name, const float *mat, int rows, int cols)\n{\n    printf(\"%s =\\n\\r\", name);\n    for (int i = 0; i &lt; rows; i++)\n    {\n        for (int j = 0; j &lt; cols; j++)\n        {\n            printf(\"%10.6f \", mat[i * cols + j]); // padding not considered, row-major order\n        }\n        printf(\"\\n\\r\");\n    }\n    printf(\"\\n\\r\");\n}\n\n// print matrix padded\n/**\n * @name print_matrix\n * @brief Prints a matrix to the console.\n * @param name Name of the matrix.\n * @param mat Pointer to the matrix data.\n * @param rows Number of rows in the matrix.\n * @param cols Number of columns in the matrix.\n * @param step Step size (how many elements in a row) for the matrix data. row-major order.\n */\nvoid print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step)\n{\n    printf(\"%s =\\n\\r\", name);\n    for (int i = 0; i &lt; rows; i++)\n    {\n        for (int j = 0; j &lt; cols; j++)\n        {\n            printf(\"%10.6f \", mat[i * step + j]); // padding considered\n        }\n        printf(\"\\n\\r\");\n    }\n    printf(\"\\n\\r\");\n}\n\n/* ADDITION */\n\n// matrix + matrix | float\n\n/**\n * @name tiny_mat_add_f32\n * @brief Adds two matrices of type float32.\n * @param input1 Pointer to the first input matrix.\n * @param input2 Pointer to the second input matrix.\n * @param output Pointer to the output matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd1 Number of padding columns in the first input matrix.\n * @param padd2 Number of padding columns in the second input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step1 Step size for the first input matrix.\n * @param step2 Step size for the second input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix addition with the specified padding and step sizes.\n * @note The function assumes that the input matrices are in row-major order.\n */\ntiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd1 &lt; 0 || padd2 &lt; 0 || padd_out &lt; 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n\n    // pad refers to the columns that are not used in the matrix operation\n\n    /* Use explicit index math instead of mutating the caller pointers.\n       This keeps input pointers const and avoids surprises from pointer\n       arithmetic. The storage model is row-major with per-row reserved\n       length = cols + padd. Logical column c is at base + c * step. */\n    const int in1_row_stride = cols + padd1;\n    const int in2_row_stride = cols + padd2;\n    const int out_row_stride = cols + padd_out;\n\n    // If we're on ESP32 and all paddings are 0 and all steps are 1 (contiguous),\n    // prefer to call the optimized ESP-DSP implementation.\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd1 == 0 &amp;&amp; padd2 == 0 &amp;&amp; padd_out == 0 &amp;&amp; step1 == 1 &amp;&amp; step2 == 1 &amp;&amp; step_out == 1) {\n        dspm_add_f32(input1, input2, output, rows, cols, 0, 0, 0, 1, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in1 = row * in1_row_stride;\n        int base_in2 = row * in2_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in1 = base_in1 + col * step1;\n            int idx_in2 = base_in2 + col * step2;\n            int idx_out = base_out + col * step_out;\n\n            /* bounds are the caller's responsibility, but avoid undefined\n               behavior by checking indices minimally in debug builds if\n               needed (not enforced here for performance). */\n            output[idx_out] = input1[idx_in1] + input2[idx_in2];\n        }\n    }\n    return TINY_OK;\n}\n\n// matrix + constant | float\n\n/**\n * @name tiny_mat_addc_f32\n * @brief Adds a constant to each element of a matrix of type float32.\n * @param input Pointer to the input matrix.\n * @param output Pointer to the output matrix.\n * @param C Constant value to be added to each element of the matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd_in Number of padding columns in the input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step_in Step size for the input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix addition with a constant with the specified padding and step sizes.\n * @note The function assumes that the input matrix is in row-major order.\n */\ntiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd_in &lt; 0 || padd_out &lt; 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // pad refers to the columns that are not used in the matrix operation\n    // If running on ESP32 and all paddings are 0 and all steps are 1 (contiguous),\n    // prefer the optimized ESP-DSP implementation.\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd_in == 0 &amp;&amp; padd_out == 0 &amp;&amp; step_in == 1 &amp;&amp; step_out == 1) {\n        dspm_addc_f32(input, output, C, rows, cols, 0, 0, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    const int in_row_stride = cols + padd_in;\n    const int out_row_stride = cols + padd_out;\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n\n            output[idx_out] = input[idx_in] + C;\n        }\n    }\n    return TINY_OK;\n}\n\n/* SUBTRACTION */\n\n// matrix - matrix | float\n\n/**\n * @name tiny_mat_sub_f32\n * @brief Subtracts two matrices of type float32.\n * @param input1 Pointer to the first input matrix.\n * @param input2 Pointer to the second input matrix.\n * @param output Pointer to the output matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd1 Number of padding columns in the first input matrix.\n * @param padd2 Number of padding columns in the second input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step1 Step size for the first input matrix.\n * @param step2 Step size for the second input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix subtraction with the specified padding and step sizes.\n * @note The function assumes that the input matrices are in row-major order.\n */\ntiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd1 &lt; 0 || padd2 &lt; 0 || padd_out &lt; 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // pad refers to the columns that are not used in the matrix operation\n    // Prefer ESP-DSP only when all paddings are 0 and all steps are 1 (contiguous)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd1 == 0 &amp;&amp; padd2 == 0 &amp;&amp; padd_out == 0 &amp;&amp; step1 == 1 &amp;&amp; step2 == 1 &amp;&amp; step_out == 1) {\n        dspm_sub_f32(input1, input2, output, rows, cols, 0, 0, 0, 1, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    const int in1_row_stride = cols + padd1;\n    const int in2_row_stride = cols + padd2;\n    const int out_row_stride = cols + padd_out;\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in1 = row * in1_row_stride;\n        int base_in2 = row * in2_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in1 = base_in1 + col * step1;\n            int idx_in2 = base_in2 + col * step2;\n            int idx_out = base_out + col * step_out;\n\n            output[idx_out] = input1[idx_in1] - input2[idx_in2];\n        }\n    }\n    return TINY_OK;\n}\n\n// matrix - constant | float\n\n/**\n * @name tiny_mat_subc_f32\n * @brief Subtracts a constant from each element of a matrix of type float32.\n * @param input Pointer to the input matrix.\n * @param output Pointer to the output matrix.\n * @param C Constant value to be subtracted from each element of the matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd_in Number of padding columns in the input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step_in Step size for the input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix subtraction with a constant with the specified padding and step sizes.\n * @note The function assumes that the input matrix is in row-major order.\n */\ntiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd_in &lt; 0 || padd_out &lt; 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // pad refers to the columns that are not used in the matrix operation\n    // Prefer ESP-DSP only when all paddings are 0 and all steps are 1 (contiguous)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd_in == 0 &amp;&amp; padd_out == 0 &amp;&amp; step_in == 1 &amp;&amp; step_out == 1) {\n        // dspm_addc_f32 performs addition; pass -C to implement subtraction-constant\n        dspm_addc_f32(input, output, -C, rows, cols, 0, 0, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    const int in_row_stride = cols + padd_in;\n    const int out_row_stride = cols + padd_out;\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n\n            output[idx_out] = input[idx_in] - C;\n        }\n    }\n    return TINY_OK;\n}\n\n/* MULTIPLICATION */\n\n// matrix * matrix | float\n\n/**\n * @name tiny_mat_mult_f32\n * @brief Multiplies two matrices of type float32.\n * @param A Pointer to the first input matrix.\n * @param B Pointer to the second input matrix.\n * @param C Pointer to the output matrix.\n * @param m Number of rows in the first matrix.\n * @param n Number of columns in the first matrix and rows in the second matrix.\n * @param k Number of columns in the second matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix multiplication with the specified padding and step sizes.\n * @note The function assumes that the input matrices are in row-major order.\n */\ntiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k)\n{\n    if (NULL == A || NULL == B || NULL == C)\n        return TINY_ERR_MATH_NULL_POINTER;\n    if (m &lt;= 0 || n &lt;= 0 || k &lt;= 0)\n        return TINY_ERR_MATH_INVALID_PARAM;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized matrix multiplication\n    dspm_mult_f32(A, B, C, m, n, k);\n#else\n    // C[i][j] = sum_{s=0}^{n-1} A[i][s] * B[s][j]\n    for (int i = 0; i &lt; m; i++)\n    {\n        for (int j = 0; j &lt; k; j++)\n        {\n            C[i * k + j] = 0.0f;\n            for (int s = 0; s &lt; n; s++)\n            {\n                C[i * k + j] += A[i * n + s] * B[s * k + j];\n            }\n        }\n    }\n#endif\n    return TINY_OK;\n}\n\n// matrix * matrix | float with padding and step sizes\n/**\n * @name tiny_mat_mult_ex_f32\n * @brief Multiplies two matrices of type float32 with padding and step sizes.\n * @param A Pointer to the first input matrix.\n * @param B Pointer to the second input matrix.\n * @param C Pointer to the output matrix.\n * @param A_rows Number of rows in the first matrix.\n * @param A_cols Number of columns in the first matrix and rows in the second matrix.\n * @param B_cols Number of columns in the second matrix.\n * @param A_padding Number of padding columns in the first matrix.\n * @param B_padding Number of padding columns in the second matrix.\n * @param C_padding Number of padding columns in the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix multiplication with the specified padding and step sizes.\n * @note The function assumes that the input matrices are in row-major order.\n */\ntiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding)\n{\n    if (NULL == A || NULL == B || NULL == C)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (A_rows &lt;= 0 || A_cols &lt;= 0 || B_cols &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    if (A_padding &lt; 0 || B_padding &lt; 0 || C_padding &lt; 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // Prefer ESP-DSP only when paddings are zero (contiguous storage)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (A_padding == 0 &amp;&amp; B_padding == 0 &amp;&amp; C_padding == 0) {\n        dspm_mult_ex_f32(A, B, C, A_rows, A_cols, B_cols, 0, 0, 0);\n        return TINY_OK;\n    }\n#endif\n\n    // Matrix A(m,n), m - amount of rows, n - amount of columns\n    // C(m,k) = A(m,n)*B(n,k)\n    // C[i][j] = sum_{s=0}^{n-1} A[i][s] * B[s][j]\n    const int A_step = A_cols + A_padding;\n    const int B_step = B_cols + B_padding;\n    const int C_step = B_cols + C_padding;\n\n    for (int i = 0; i &lt; A_rows; i++)\n    {\n        for (int j = 0; j &lt; B_cols; j++)\n        {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; A_cols; s++)\n            {\n                sum += A[i * A_step + s] * B[s * B_step + j];\n            }\n            C[i * C_step + j] = sum;\n        }\n    }\n    return TINY_OK;\n}\n\n// matrix * constant | float\n/**\n * @name tiny_mat_multc_f32\n * @brief Multiplies a matrix by a constant of type float32.\n * @param input Pointer to the input matrix.\n * @param output Pointer to the output matrix.\n * @param C Constant value to be multiplied with each element of the matrix.\n * @param rows Number of rows in the matrices.\n * @param cols Number of columns in the matrices.\n * @param padd_in Number of padding columns in the input matrix.\n * @param padd_out Number of padding columns in the output matrix.\n * @param step_in Step size for the input matrix.\n * @param step_out Step size for the output matrix.\n * @return Returns TINY_OK on success, or an error code on failure.\n * @note This function performs matrix multiplication with a constant with the specified padding and step sizes.\n * @note The function assumes that the input matrix is in row-major order.\n */\ntiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    // paddings must be non-negative, steps must be at least 1.\n    if (rows &lt;= 0 || cols &lt;= 0 || padd_in &lt; 0 || padd_out &lt; 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_MATH_INVALID_PARAM;\n    }\n    // pad refers to the columns that are not used in the matrix operation\n    // Prefer ESP-DSP only when all paddings are 0 and all steps are 1 (contiguous)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padd_in == 0 &amp;&amp; padd_out == 0 &amp;&amp; step_in == 1 &amp;&amp; step_out == 1) {\n        dspm_mulc_f32(input, output, C, rows, cols, 0, 0, 1, 1);\n        return TINY_OK;\n    }\n#endif\n\n    const int in_row_stride = cols + padd_in;\n    const int out_row_stride = cols + padd_out;\n\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n\n            output[idx_out] = input[idx_in] * C;\n        }\n    }\n    return TINY_OK;\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-test/","title":"TINY_MAT TEST","text":""},{"location":"MATH/MATRIX/tiny-mat-test/#test-code","title":"TEST CODE","text":""},{"location":"MATH/MATRIX/tiny-mat-test/#tiny_mat_testh","title":"tiny_mat_test.h","text":"<pre><code>/**\n * @file tiny_mat_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the test of the submodule mat (basic matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_math_config.h\"\n#include \"tiny_mat.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\nvoid tiny_mat_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-test/#tiny_mat_testc","title":"tiny_mat_test.c","text":"<pre><code>/**\n * @file tiny_mat_test.c\n * @brief Comprehensive stress tests for tiny_mat module, targeting edge cases and potential weaknesses.\n * @note Tests include: step parameters, different paddings, extreme values, boundary cases, and complex memory layouts.\n */\n\n#include \"tiny_mat_test.h\"\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\n/**\n * @brief Test tiny_mat_add_f32 with pad=0 and step=1 (contiguous memory layout)\n * \n * Test Scenario:\n *   - This test case uses contiguous memory layout (no padding, step=1)\n *   - On ESP32 platform, this should trigger ESP-DSP optimized implementation\n *   - On other platforms, uses the standard implementation\n * \n * Memory Layout:\n *   - Input1: 3x4 matrix stored contiguously in memory\n *     [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0]\n *     Logical view:\n *       1.0   2.0   3.0   4.0\n *       5.0   6.0   7.0   8.0\n *       9.0  10.0  11.0  12.0\n * \n *   - Input2: 3x4 matrix stored contiguously in memory\n *     [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5]\n *     Logical view:\n *       0.5   1.5   2.5   3.5\n *       4.5   5.5   6.5   7.5\n *       8.5   9.5  10.5  11.5\n * \n * Expected Output:\n *   - Output: 3x4 matrix, each element = input1[i][j] + input2[i][j]\n *     Expected logical view:\n *       1.5   3.5   5.5   7.5\n *       9.5  11.5  13.5  15.5\n *      17.5  19.5  21.5  23.5\n * \n * Parameters:\n *   - rows = 3, cols = 4\n *   - padd1 = 0, padd2 = 0, padd_out = 0 (no padding)\n *   - step1 = 1, step2 = 1, step_out = 1 (contiguous access)\n */\nvoid test_tiny_mat_add_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 1: tiny_mat_add_f32 - Contiguous Memory Layout (pad=0, step=1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=4, pad=0, step=1\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 4;\n\n    // Input matrices (contiguous, no padding)\n    float input1[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                        5.0f, 6.0f, 7.0f, 8.0f,\n                        9.0f, 10.0f, 11.0f, 12.0f};\n\n    float input2[12] = {0.5f, 1.5f, 2.5f, 3.5f,\n                        4.5f, 5.5f, 6.5f, 7.5f,\n                        8.5f, 9.5f, 10.5f, 11.5f};\n\n    float output[12];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input1 Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input1[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Input2 Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input2[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [4.5  5.5  6.5  7.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [8.5  9.5 10.5 11.5]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Expected Output Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input1[i] + input2[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [9.5 11.5 13.5 15.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [17.5 19.5 21.5 23.5] &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Test with pad=0, step=1 (should use ESP-DSP on ESP32)\n    tiny_error_t err = tiny_mat_add_f32(input1, input2, output, rows, cols, \n                                        0, 0, 0,  // padd1=0, padd2=0, padd_out=0\n                                        1, 1, 1); // step1=1, step2=1, step_out=1\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (12 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 12; i++) {\n            printf(\"%5.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\\n\\r\");\n        printf(\"          [9.5 11.5 13.5 15.5]  &lt;- Row 1\\n\\r\");\n        printf(\"          [17.5 19.5 21.5 23.5] &lt;- Row 2\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; rows * cols; i++) {\n            float expected = input1[i] + input2[i];\n            float tolerance = 1e-6f;\n            float diff = (output[i] &gt; expected) ? (output[i] - expected) : (expected - output[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_add_f32 with pad!=0 and step&gt;1 (non-contiguous memory layout)\n * \n * ================================================================================\n * Test Scenario:\n * ================================================================================\n * This test case demonstrates how to handle matrix addition with non-contiguous\n * memory layout. In real applications, matrix data may not be stored contiguously:\n *   1. Padding: Extra space at the end of each row\n *   2. Stride/Step: Gaps between elements\n * \n * For example, a 2x3 logical matrix with padding=2 and step=2 may have memory layout:\n *   Logical matrix:        Memory array (first 10 elements):\n *   [1.0  2.0  3.0]  [1.0, 0, 2.0, 0, 3.0, 0, 0, 0, 0, 0, ...]\n *   [4.0  5.0  6.0]  [4.0, 0, 5.0, 0, 6.0, 0, 0, 0, 0, 0, ...]\n * \n * ================================================================================\n * Index Calculation Formula:\n * ================================================================================\n * For matrix element [row][col], the memory index is calculated as:\n *   index = row * (cols + padding) + col * step\n * \n * Where:\n *   - row: Row number (starting from 0)\n *   - col: Column number (starting from 0)\n *   - cols: Number of columns in the matrix\n *   - padding: Number of padding elements at the end of each row\n *   - step: Stride between columns (element spacing)\n * \n * ================================================================================\n * Input1 Details (2x3 matrix, padding=2, step=2):\n * ================================================================================\n * Logical matrix view:\n *   [1.0  2.0  3.0]\n *   [4.0  5.0  6.0]\n * \n * Memory array (input1[20]) actual content:\n *   Index:  0    1    2    3    4    5    6    7    8    9   10   11   12   ...\n *   Value:  [1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]\n *           |---- row 0 ----|  |-- padding --|  |---- row 1 ----|  |-- padding --|\n * \n * Index calculation process:\n *   [0][0]: index = 0*(3+2) + 0*2 = 0*5 + 0 = 0  \u2192 input1[0] = 1.0\n *   [0][1]: index = 0*(3+2) + 1*2 = 0*5 + 2 = 2  \u2192 input1[2] = 2.0\n *   [0][2]: index = 0*(3+2) + 2*2 = 0*5 + 4 = 4  \u2192 input1[4] = 3.0\n *   [1][0]: index = 1*(3+2) + 0*2 = 1*5 + 0 = 5  \u2192 input1[5] = 4.0\n *   [1][1]: index = 1*(3+2) + 1*2 = 1*5 + 2 = 7  \u2192 input1[7] = 5.0\n *   [1][2]: index = 1*(3+2) + 2*2 = 1*5 + 4 = 9  \u2192 input1[9] = 6.0\n * \n * Memory layout visualization:\n *   Position: [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] ...\n *   Value:     1.0  0.0  2.0  0.0  3.0  0.0  0.0  0.0  0.0  6.0   0.0   0.0   0.0 ...\n *   Label:     R0C0      R0C1      R0C2  pad  pad  pad  pad  R1C2   pad   pad   pad ...\n * \n * ================================================================================\n * Input2 Details (2x3 matrix, padding=1, step=3):\n * ================================================================================\n * Logical matrix view:\n *   [0.5  1.5  2.5]\n *   [3.5  4.5  5.5]\n * \n * Memory array (input2[16]) actual content:\n *   Index:  0    1    2    3    4    5    6    7    8    9   10   11   ...\n *   Value:  [0.5, 0.0, 0.0, 1.5, 0.0, 0.0, 2.5, 0.0, 0.0, 0.0, 5.5, 0.0, ...]\n *           |---- row 0 ----|  |-- padding --|  |---- row 1 ----|  |-- padding --|\n * \n * Index calculation process:\n *   [0][0]: index = 0*(3+1) + 0*3 = 0*4 + 0 = 0  \u2192 input2[0] = 0.5\n *   [0][1]: index = 0*(3+1) + 1*3 = 0*4 + 3 = 3  \u2192 input2[3] = 1.5\n *   [0][2]: index = 0*(3+1) + 2*3 = 0*4 + 6 = 6  \u2192 input2[6] = 2.5\n *   [1][0]: index = 1*(3+1) + 0*3 = 1*4 + 0 = 4  \u2192 input2[4] = 3.5\n *   [1][1]: index = 1*(3+1) + 1*3 = 1*4 + 3 = 7  \u2192 input2[7] = 4.5\n *   [1][2]: index = 1*(3+1) + 2*3 = 1*4 + 6 = 10 \u2192 input2[10] = 5.5\n * \n * Memory layout visualization:\n *   Position: [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\n *   Value:     0.5  0.0  0.0  1.5  3.5  0.0  2.5  4.5  0.0  0.0  5.5   0.0 ...\n *   Label:     R0C0      R0C1      R1C0      R0C2  R1C1      R1C2   pad ...\n * \n * ================================================================================\n * Expected Output (2x3 matrix, padding=2, step=2):\n * ================================================================================\n * Logical matrix view:\n *   [1.5  3.5  5.5]\n *   [7.5  9.5 11.5]\n * \n * Calculation process:\n *   output[0][0] = input1[0][0] + input2[0][0] = 1.0 + 0.5 = 1.5\n *   output[0][1] = input1[0][1] + input2[0][1] = 2.0 + 1.5 = 3.5\n *   output[0][2] = input1[0][2] + input2[0][2] = 3.0 + 2.5 = 5.5\n *   output[1][0] = input1[1][0] + input2[1][0] = 4.0 + 3.5 = 7.5\n *   output[1][1] = input1[1][1] + input2[1][1] = 5.0 + 4.5 = 9.5\n *   output[1][2] = input1[1][2] + input2[1][2] = 6.0 + 5.5 = 11.5\n * \n * Output memory array (output[20]) expected content:\n *   Index:  0    1    2    3    4    5    6    7    8    9   10   11   12   ...\n *   Value:  [1.5, 0.0, 3.5, 0.0, 5.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]\n *           |---- row 0 ----|  |-- padding --|  |---- row 1 ----|  |-- padding --|\n * \n * ================================================================================\n * Test Parameters:\n * ================================================================================\n *   rows = 2, cols = 3\n *   padd1 = 4, padd2 = 4, padd_out = 4 (larger padding)\n *   step1 = 2, step2 = 3, step_out = 2 (non-contiguous access)\n */\nvoid test_tiny_mat_add_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 2: tiny_mat_add_f32 - Non-contiguous memory (pad!=0, step&gt;1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    // Use larger padding so that stride comfortably covers sparse steps.\n    // This avoids any ambiguity about padding location and keeps indices in-bounds.\n    const int padd1 = 4;     // stride1 = 3 + 4 = 7\n    const int padd2 = 4;     // stride2 = 3 + 4 = 7\n    const int padd_out = 4;  // stride_out = 3 + 4 = 7\n    const int step1 = 2;     // indices for cols: 0,2,4 (all &lt; stride1=7)\n    const int step2 = 3;     // indices for cols: 0,3,6 (all &lt; stride2=7)\n    const int step_out = 2;  // indices for cols: 0,2,4 (all &lt; stride_out=7)\n\n    printf(\"Params: rows=%d, cols=%d, pad1=%d, pad2=%d, pad_out=%d, step1=%d, step2=%d, step_out=%d\\n\\r\",\n           rows, cols, padd1, padd2, padd_out, step1, step2, step_out);\n    printf(\"Index formula: idx = row * (cols + padding) + col * step\\n\\r\\n\\r\");\n\n    // Prepare inputs\n    float input1[32] = {0};\n    float input2[32] = {0};\n    float output[32] = {0};\n    const int stride1 = cols + padd1; // 7\n    const int stride2 = cols + padd2; // 7\n    const int stride_out = cols + padd_out; // 7\n\n    // input1: pad=4, step=2\n    input1[0 * stride1 + 0 * step1] = 1.0f;\n    input1[0 * stride1 + 1 * step1] = 2.0f;\n    input1[0 * stride1 + 2 * step1] = 3.0f;\n    input1[1 * stride1 + 0 * step1] = 4.0f;\n    input1[1 * stride1 + 1 * step1] = 5.0f;\n    input1[1 * stride1 + 2 * step1] = 6.0f;\n\n    // input2: pad=4, step=3\n    input2[0 * stride2 + 0 * step2] = 0.5f;\n    input2[0 * stride2 + 1 * step2] = 1.5f;\n    input2[0 * stride2 + 2 * step2] = 2.5f;\n    input2[1 * stride2 + 0 * step2] = 3.5f;\n    input2[1 * stride2 + 1 * step2] = 4.5f;\n    input2[1 * stride2 + 2 * step2] = 5.5f;\n\n    // expected output\n    float expected_output[32] = {0};\n    for (int r = 0; r &lt; rows; r++) {\n        for (int c = 0; c &lt; cols; c++) {\n            int idx1 = r * stride1 + c * step1;\n            int idx2 = r * stride2 + c * step2;\n            int idxo = r * stride_out + c * step_out;\n            expected_output[idxo] = input1[idx1] + input2[idx2];\n        }\n    }\n\n    // Print raw buffers and per-row memory distribution (C = column, P = padding)\n    printf(\"[input1 raw len=%d] \", stride1 * rows);\n    for (int i = 0; i &lt; stride1 * rows; i++) { printf(\"%s%4.1f\", (i==0) ? \"\" : \" \", input1[i]); }\n    printf(\" (pad=%d, step=%d)\\n\\r\", padd1, step1);\n    for (int r = 0; r &lt; rows; r++) {\n        printf(\"  input1 row%d (stride=%d):\", r, stride1);\n        for (int j = 0; j &lt; stride1; j++) {\n            int col = (j % step1 == 0) ? j / step1 : -1;\n            int is_col = (col &gt;= 0 &amp;&amp; col &lt; cols);\n            printf(\" [%d:%4.1f %s]\", j, input1[r * stride1 + j], is_col ? \"C\" : \"P\");\n        }\n        printf(\"\\n\\r\");\n    }\n    printf(\"\\n\\r\");\n\n    printf(\"[input2 raw len=%d] \", stride2 * rows);\n    for (int i = 0; i &lt; stride2 * rows; i++) { printf(\"%s%4.1f\", (i==0) ? \"\" : \" \", input2[i]); }\n    printf(\" (pad=%d, step=%d)\\n\\r\", padd2, step2);\n    for (int r = 0; r &lt; rows; r++) {\n        printf(\"  input2 row%d (stride=%d):\", r, stride2);\n        for (int j = 0; j &lt; stride2; j++) {\n            int col = (j % step2 == 0) ? j / step2 : -1;\n            int is_col = (col &gt;= 0 &amp;&amp; col &lt; cols);\n            printf(\" [%d:%4.1f %s]\", j, input2[r * stride2 + j], is_col ? \"C\" : \"P\");\n        }\n        printf(\"\\n\\r\");\n    }\n    printf(\"\\n\\r\");\n\n    // Logical view (without padding)\n    printf(\"Logical matrices (no padding):\\n\\r\");\n    for (int r = 0; r &lt; rows; r++) {\n        printf(\"  input1 row%d:\", r);\n        for (int c = 0; c &lt; cols; c++) {\n            int idx = r * stride1 + c * step1;\n            printf(\" %4.1f\", input1[idx]);\n        }\n        printf(\"\\n\\r\");\n    }\n    for (int r = 0; r &lt; rows; r++) {\n        printf(\"  input2 row%d:\", r);\n        for (int c = 0; c &lt; cols; c++) {\n            int idx = r * stride2 + c * step2;\n            printf(\" %4.1f\", input2[idx]);\n        }\n        printf(\"\\n\\r\");\n    }\n    printf(\"\\n\\r\");\n\n    tiny_error_t err = tiny_mat_add_f32(input1, input2, output, rows, cols,\n                                        padd1, padd2, padd_out,\n                                        step1, step2, step_out);\n\n    if (err != TINY_OK) {\n        printf(\"\u2717 Call failed, err=%d\\n\\r\", err);\n        printf(\"================================================================================\\n\\r\\n\\r\");\n        return;\n    }\n\n    // Print output raw and per-row memory distribution\n    printf(\"[output raw len=%d] \", stride_out * rows);\n    for (int i = 0; i &lt; stride_out * rows; i++) { printf(\"%s%4.1f\", (i==0) ? \"\" : \" \", output[i]); }\n    printf(\" (pad_out=%d, step_out=%d)\\n\\r\\n\\r\", padd_out, step_out);\n    for (int r = 0; r &lt; rows; r++) {\n        printf(\"  output row%d (stride=%d):\", r, stride_out);\n        for (int j = 0; j &lt; stride_out; j++) {\n            int col = (j % step_out == 0) ? j / step_out : -1;\n            int is_col = (col &gt;= 0 &amp;&amp; col &lt; cols);\n            printf(\" [%d:%4.1f %s]\", j, output[r * stride_out + j], is_col ? \"C\" : \"P\");\n        }\n        printf(\"\\n\\r\");\n    }\n    printf(\"\\n\\r\");\n\n    // Expected vs actual (logical)\n    printf(\"[expected raw len=%d] \", stride_out * rows);\n    for (int i = 0; i &lt; stride_out * rows; i++) { printf(\"%s%4.1f\", (i==0) ? \"\" : \" \", expected_output[i]); }\n    printf(\" (pad_out=%d, step_out=%d)\\n\\r\\n\\r\", padd_out, step_out);\n\n    int mismatches = 0;\n    printf(\"Logical matrix comparison (expected | actual | diff):\\n\\r\");\n    for (int r = 0; r &lt; rows; r++) {\n        printf(\"  row%d:\", r);\n        for (int c = 0; c &lt; cols; c++) {\n            int idxo = r * stride_out + c * step_out;\n            float expv = expected_output[idxo];\n            float actv = output[idxo];\n            float diff = actv - expv;\n            if (diff &lt; 0) diff = -diff;\n            if (diff &gt; 1e-6f) mismatches++;\n            printf(\" [%4.1f | %4.1f | %4.1e]\", expv, actv, diff);\n        }\n        printf(\"\\n\\r\");\n    }\n\n    if (mismatches == 0) {\n        printf(\"\u2713 Test PASSED (all elements match)\\n\\r\");\n    } else {\n        printf(\"\u2717 Test FAILED (mismatched elements=%d)\\n\\r\", mismatches);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_addc_f32 with pad=0 and step=1 (contiguous memory layout)\n */\nvoid test_tiny_mat_addc_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 3: tiny_mat_addc_f32 - Contiguous Memory Layout (pad=0, step=1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=4, pad=0, step=1, C=2.5\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 4;\n    const float C = 2.5f;\n\n    // Input matrix (contiguous, no padding)\n    float input[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                       5.0f, 6.0f, 7.0f, 8.0f,\n                       9.0f, 10.0f, 11.0f, 12.0f};\n\n    float output[12];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C = %5.1f\\n\\r\", C);\n    printf(\"\\n\\r\");\n\n    printf(\"Expected Output Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input[i] + C);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [7.5  8.5  9.5 10.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [11.5 12.5 13.5 14.5] &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Test with pad=0, step=1 (should use ESP-DSP on ESP32)\n    tiny_error_t err = tiny_mat_addc_f32(input, output, C, rows, cols,\n                                         0, 0,  // padd_in=0, padd_out=0\n                                         1, 1); // step_in=1, step_out=1\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (12 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 12; i++) {\n            printf(\"%5.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\\n\\r\");\n        printf(\"          [7.5  8.5  9.5 10.5]  &lt;- Row 1\\n\\r\");\n        printf(\"          [11.5 12.5 13.5 14.5] &lt;- Row 2\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; rows * cols; i++) {\n            float expected = input[i] + C;\n            float tolerance = 1e-6f;\n            float diff = (output[i] &gt; expected) ? (output[i] - expected) : (expected - output[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_addc_f32 with pad!=0 and step&gt;1 (non-contiguous memory layout)\n */\nvoid test_tiny_mat_addc_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 4: tiny_mat_addc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd_in = 2;\n    const int padd_out = 2;\n    const int step_in = 2;\n    const int step_out = 2;\n    const float C = 1.5f;\n\n    printf(\"Parameters: rows=%d, cols=%d, pad_in=%d, pad_out=%d, step_in=%d, step_out=%d, C=%5.1f\\n\\r\",\n           rows, cols, padd_in, padd_out, step_in, step_out, C);\n    printf(\"Index formula: index = row * (cols + padding) + col * step\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Input: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_in = 3 + 2 = 5\n    float input[20] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 2, 4\n    input[0 * 5 + 0 * 2] = 1.0f; // row 0, col 0: index = 0*5 + 0*2 = 0\n    input[0 * 5 + 1 * 2] = 2.0f; // row 0, col 1: index = 0*5 + 1*2 = 2\n    input[0 * 5 + 2 * 2] = 3.0f; // row 0, col 2: index = 0*5 + 2*2 = 4\n    // Row 1: elements at indices 5, 7, 9\n    input[1 * 5 + 0 * 2] = 4.0f; // row 1, col 0: index = 1*5 + 0*2 = 5\n    input[1 * 5 + 1 * 2] = 5.0f; // row 1, col 1: index = 1*5 + 1*2 = 7\n    input[1 * 5 + 2 * 2] = 6.0f; // row 1, col 2: index = 1*5 + 2*2 = 9\n\n    // Output: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_out = 3 + 2 = 5\n    float output[20] = {0}; // Allocate enough space, initialize to zero\n\n    printf(\"Input Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_in, step_in);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", input[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C = %5.1f\\n\\r\", C);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output\n    float expected_output[20] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = row * (cols + padd_in) + col * step_in;\n            int idx_out = row * (cols + padd_out) + col * step_out;\n            expected_output[idx_out] = input[idx_in] + C;\n        }\n    }\n\n    printf(\"Expected Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", expected_output[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    tiny_error_t err = tiny_mat_addc_f32(input, output, C, rows, cols,\n                                         padd_in, padd_out,\n                                         step_in, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 15; i++) {\n            printf(\"%4.1f \", output[i]);\n        }\n        printf(\"...\\n\\r\");\n        printf(\"  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n        printf(\"          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n        printf(\"          (X = padding/unused)\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_in = row * (cols + padd_in) + col * step_in;\n                int idx_out = row * (cols + padd_out) + col * step_out;\n                float expected = input[idx_in] + C;\n                float tolerance = 1e-6f;\n                float diff = (output[idx_out] &gt; expected) ? (output[idx_out] - expected) : (expected - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    all_correct = 0;\n                    break;\n                }\n            }\n            if (!all_correct) break;\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_sub_f32 with pad=0 and step=1 (contiguous memory layout)\n */\nvoid test_tiny_mat_sub_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 5: tiny_mat_sub_f32 - Contiguous Memory Layout (pad=0, step=1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=4, pad=0, step=1\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 4;\n\n    // Input matrices (contiguous, no padding)\n    float input1[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                        5.0f, 6.0f, 7.0f, 8.0f,\n                        9.0f, 10.0f, 11.0f, 12.0f};\n\n    float input2[12] = {0.5f, 1.5f, 2.5f, 3.5f,\n                        4.5f, 5.5f, 6.5f, 7.5f,\n                        8.5f, 9.5f, 10.5f, 11.5f};\n\n    float output[12];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input1 Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input1[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Input2 Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input2[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [4.5  5.5  6.5  7.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [8.5  9.5 10.5 11.5]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Expected Output Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input1[i] - input2[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [0.5  0.5  0.5  0.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [0.5  0.5  0.5  0.5] &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Test with pad=0, step=1 (should use ESP-DSP on ESP32)\n    tiny_error_t err = tiny_mat_sub_f32(input1, input2, output, rows, cols, \n                                        0, 0, 0,  // padd1=0, padd2=0, padd_out=0\n                                        1, 1, 1); // step1=1, step2=1, step_out=1\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (12 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 12; i++) {\n            printf(\"%5.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\\n\\r\");\n        printf(\"          [0.5  0.5  0.5  0.5]  &lt;- Row 1\\n\\r\");\n        printf(\"          [0.5  0.5  0.5  0.5] &lt;- Row 2\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; rows * cols; i++) {\n            float expected = input1[i] - input2[i];\n            float tolerance = 1e-6f;\n            float diff = (output[i] &gt; expected) ? (output[i] - expected) : (expected - output[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_sub_f32 with pad!=0 and step&gt;1 (non-contiguous memory layout)\n */\nvoid test_tiny_mat_sub_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 6: tiny_mat_sub_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd1 = 2;\n    const int padd2 = 1;\n    const int padd_out = 2;\n    const int step1 = 2;\n    const int step2 = 3;\n    const int step_out = 2;\n\n    printf(\"Parameters: rows=%d, cols=%d, pad1=%d, pad2=%d, pad_out=%d, step1=%d, step2=%d, step_out=%d\\n\\r\",\n           rows, cols, padd1, padd2, padd_out, step1, step2, step_out);\n    printf(\"Index formula: index = row * (cols + padding) + col * step\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Input1: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd1 = 3 + 2 = 5\n    float input1[20] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 2, 4\n    input1[0 * 5 + 0 * 2] = 1.0f; // row 0, col 0: index = 0*5 + 0*2 = 0\n    input1[0 * 5 + 1 * 2] = 2.0f; // row 0, col 1: index = 0*5 + 1*2 = 2\n    input1[0 * 5 + 2 * 2] = 3.0f; // row 0, col 2: index = 0*5 + 2*2 = 4\n    // Row 1: elements at indices 5, 7, 9\n    input1[1 * 5 + 0 * 2] = 4.0f; // row 1, col 0: index = 1*5 + 0*2 = 5\n    input1[1 * 5 + 1 * 2] = 5.0f; // row 1, col 1: index = 1*5 + 1*2 = 7\n    input1[1 * 5 + 2 * 2] = 6.0f; // row 1, col 2: index = 1*5 + 2*2 = 9\n\n    // Input2: 2 rows, 3 cols, padding=1, step=3\n    // Row stride = cols + padd2 = 3 + 1 = 4\n    float input2[16] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 3, 6\n    input2[0 * 4 + 0 * 3] = 0.5f; // row 0, col 0: index = 0*4 + 0*3 = 0\n    input2[0 * 4 + 1 * 3] = 1.5f; // row 0, col 1: index = 0*4 + 1*3 = 3\n    input2[0 * 4 + 2 * 3] = 2.5f; // row 0, col 2: index = 0*4 + 2*3 = 6\n    // Row 1: elements at indices 4, 7, 10\n    input2[1 * 4 + 0 * 3] = 3.5f; // row 1, col 0: index = 1*4 + 0*3 = 4\n    input2[1 * 4 + 1 * 3] = 4.5f; // row 1, col 1: index = 1*4 + 1*3 = 7\n    input2[1 * 4 + 2 * 3] = 5.5f; // row 1, col 2: index = 1*4 + 2*3 = 10\n\n    // Output: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_out = 3 + 2 = 5\n    float output[20] = {0}; // Allocate enough space, initialize to zero\n\n    printf(\"Input1 Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd1, step1);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", input1[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Input2 Memory Layout (16 elements, pad=%d, step=%d):\\n\\r\", padd2, step2);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%4.1f \", input2[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\\n\\r\");\n    printf(\"          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output\n    float expected_output[20] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        for (int col = 0; col &lt; cols; col++) {\n            int idx1 = row * (cols + padd1) + col * step1;\n            int idx2 = row * (cols + padd2) + col * step2;\n            int idx_out = row * (cols + padd_out) + col * step_out;\n            expected_output[idx_out] = input1[idx1] - input2[idx2];\n        }\n    }\n\n    printf(\"Expected Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", expected_output[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    tiny_error_t err = tiny_mat_sub_f32(input1, input2, output, rows, cols,\n                                        padd1, padd2, padd_out,\n                                        step1, step2, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 15; i++) {\n            printf(\"%4.1f \", output[i]);\n        }\n        printf(\"...\\n\\r\");\n        printf(\"  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n        printf(\"          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n        printf(\"          (X = padding/unused)\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            for (int col = 0; col &lt; cols; col++) {\n                int idx1 = row * (cols + padd1) + col * step1;\n                int idx2 = row * (cols + padd2) + col * step2;\n                int idx_out = row * (cols + padd_out) + col * step_out;\n                float expected = input1[idx1] - input2[idx2];\n                float tolerance = 1e-6f;\n                float diff = (output[idx_out] &gt; expected) ? (output[idx_out] - expected) : (expected - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    all_correct = 0;\n                    break;\n                }\n            }\n            if (!all_correct) break;\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_subc_f32 with pad=0 and step=1 (contiguous memory layout)\n */\nvoid test_tiny_mat_subc_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 7: tiny_mat_subc_f32 - Contiguous Memory Layout (pad=0, step=1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=4, pad=0, step=1, C=2.5\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 4;\n    const float C = 2.5f;\n\n    // Input matrix (contiguous, no padding)\n    float input[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                       5.0f, 6.0f, 7.0f, 8.0f,\n                       9.0f, 10.0f, 11.0f, 12.0f};\n\n    float output[12];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C = %5.1f\\n\\r\", C);\n    printf(\"\\n\\r\");\n\n    printf(\"Expected Output Memory Layout (12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", input[i] - C);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Test with pad=0, step=1 (should use ESP-DSP on ESP32)\n    tiny_error_t err = tiny_mat_subc_f32(input, output, C, rows, cols,\n                                         0, 0,  // padd_in=0, padd_out=0\n                                         1, 1); // step_in=1, step_out=1\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (12 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 12; i++) {\n            printf(\"%5.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\\n\\r\");\n        printf(\"          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\\n\\r\");\n        printf(\"          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; rows * cols; i++) {\n            float expected = input[i] - C;\n            float tolerance = 1e-6f;\n            float diff = (output[i] &gt; expected) ? (output[i] - expected) : (expected - output[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_subc_f32 with pad!=0 and step&gt;1 (non-contiguous memory layout)\n */\nvoid test_tiny_mat_subc_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 8: tiny_mat_subc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd_in = 2;\n    const int padd_out = 2;\n    const int step_in = 2;\n    const int step_out = 2;\n    const float C = 1.5f;\n\n    printf(\"Parameters: rows=%d, cols=%d, pad_in=%d, pad_out=%d, step_in=%d, step_out=%d, C=%5.1f\\n\\r\",\n           rows, cols, padd_in, padd_out, step_in, step_out, C);\n    printf(\"Index formula: index = row * (cols + padding) + col * step\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Input: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_in = 3 + 2 = 5\n    float input[20] = {0}; // Allocate enough space, initialize to zero\n    // Row 0: elements at indices 0, 2, 4\n    input[0 * 5 + 0 * 2] = 1.0f; // row 0, col 0: index = 0*5 + 0*2 = 0\n    input[0 * 5 + 1 * 2] = 2.0f; // row 0, col 1: index = 0*5 + 1*2 = 2\n    input[0 * 5 + 2 * 2] = 3.0f; // row 0, col 2: index = 0*5 + 2*2 = 4\n    // Row 1: elements at indices 5, 7, 9\n    input[1 * 5 + 0 * 2] = 4.0f; // row 1, col 0: index = 1*5 + 0*2 = 5\n    input[1 * 5 + 1 * 2] = 5.0f; // row 1, col 1: index = 1*5 + 1*2 = 7\n    input[1 * 5 + 2 * 2] = 6.0f; // row 1, col 2: index = 1*5 + 2*2 = 9\n\n    // Output: 2 rows, 3 cols, padding=2, step=2\n    // Row stride = cols + padd_out = 3 + 2 = 5\n    float output[20] = {0}; // Allocate enough space, initialize to zero\n\n    printf(\"Input Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_in, step_in);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", input[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C = %5.1f\\n\\r\", C);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output\n    float expected_output[20] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = row * (cols + padd_in) + col * step_in;\n            int idx_out = row * (cols + padd_out) + col * step_out;\n            expected_output[idx_out] = input[idx_in] - C;\n        }\n    }\n\n    printf(\"Expected Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 15; i++) {\n        printf(\"%4.1f \", expected_output[i]);\n    }\n    printf(\"...\\n\\r\");\n    printf(\"  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    tiny_error_t err = tiny_mat_subc_f32(input, output, C, rows, cols,\n                                         padd_in, padd_out,\n                                         step_in, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Memory Layout (20 elements, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 15; i++) {\n            printf(\"%4.1f \", output[i]);\n        }\n        printf(\"...\\n\\r\");\n        printf(\"  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\\n\\r\");\n        printf(\"          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\\n\\r\");\n        printf(\"          (X = padding/unused)\\n\\r\");\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_in = row * (cols + padd_in) + col * step_in;\n                int idx_out = row * (cols + padd_out) + col * step_out;\n                float expected = input[idx_in] - C;\n                float tolerance = 1e-6f;\n                float diff = (output[idx_out] &gt; expected) ? (output[idx_out] - expected) : (expected - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    all_correct = 0;\n                    break;\n                }\n            }\n            if (!all_correct) break;\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_mult_f32 with basic matrix multiplication\n */\nvoid test_tiny_mat_mult_f32_basic(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 9: tiny_mat_mult_f32 - Basic Matrix Multiplication\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: m=3, n=4, k=2 (A is 3x4, B is 4x2, C is 3x2)\\n\\r\");\n    printf(\"Note: This function always uses ESP-DSP on ESP32, standard implementation otherwise\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int m = 3; // rows of A\n    const int n = 4; // cols of A and rows of B\n    const int k = 2; // cols of B\n\n    // Matrix A: 3x4\n    // Memory layout: [row0_col0, row0_col1, row0_col2, row0_col3, row1_col0, ...]\n    float A[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                    5.0f, 6.0f, 7.0f, 8.0f,\n                    9.0f, 10.0f, 11.0f, 12.0f};\n\n    // Matrix B: 4x2\n    float B[8] = {0.5f, 1.5f,\n                  2.5f, 3.5f,\n                  4.5f, 5.5f,\n                  6.5f, 7.5f};\n\n    // Matrix C: 3x2 (output)\n    float C[6];\n    memset(C, 0, sizeof(C));\n\n    printf(\"Matrix A Memory Layout (3x4, 12 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", A[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Matrix B Memory Layout (4x2, 8 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 8; i++) {\n        printf(\"%5.1f \", B[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [2.5  3.5]  &lt;- Row 1\\n\\r\");\n    printf(\"          [4.5  5.5]  &lt;- Row 2\\n\\r\");\n    printf(\"          [6.5  7.5]  &lt;- Row 3\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: C = A * B\n    // C[i][j] = sum_{s=0}^{n-1} A[i][s] * B[s][j]\n    float expected_C[6] = {0};\n    for (int i = 0; i &lt; m; i++) {\n        for (int j = 0; j &lt; k; j++) {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; n; s++) {\n                sum += A[i * n + s] * B[s * k + j];\n            }\n            expected_C[i * k + j] = sum;\n        }\n    }\n\n    printf(\"Expected Output Matrix C Memory Layout (3x2, 6 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 6; i++) {\n        printf(\"%6.1f \", expected_C[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f]  &lt;- Row 0\\n\\r\", expected_C[0], expected_C[1]);\n    printf(\"          [%5.1f  %5.1f]  &lt;- Row 1\\n\\r\", expected_C[2], expected_C[3]);\n    printf(\"          [%5.1f  %5.1f] &lt;- Row 2\\n\\r\", expected_C[4], expected_C[5]);\n    printf(\"  Calculation:\\n\\r\");\n    printf(\"    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\\n\\r\");\n    printf(\"            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 = %5.1f\\n\\r\", expected_C[0]);\n    printf(\"    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1] + A[0][3]*B[3][1]\\n\\r\");\n    printf(\"            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 + 4.0*7.5 = %5.1f\\n\\r\", expected_C[1]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiplication\n    tiny_error_t err = tiny_mat_mult_f32(A, B, C, m, n, k);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix C Memory Layout (3x2, 6 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 6; i++) {\n            printf(\"%6.1f \", C[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f]  &lt;- Row 0\\n\\r\", C[0], C[1]);\n        printf(\"          [%5.1f  %5.1f]  &lt;- Row 1\\n\\r\", C[2], C[3]);\n        printf(\"          [%5.1f  %5.1f] &lt;- Row 2\\n\\r\", C[4], C[5]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; m * k; i++) {\n            float tolerance = 1e-5f;\n            float diff = (C[i] &gt; expected_C[i]) ? (C[i] - expected_C[i]) : (expected_C[i] - C[i]);\n            if (diff &gt; tolerance) {\n                int row = i / k;\n                int col = i % k;\n                printf(\"  ERROR at [%d][%d]: output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                       row, col, C[i], expected_C[i], diff);\n                all_correct = 0;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_mult_f32 with square matrices\n */\nvoid test_tiny_mat_mult_f32_square(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 10: tiny_mat_mult_f32 - Square Matrix Multiplication\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: m=3, n=3, k=3 (A is 3x3, B is 3x3, C is 3x3)\\n\\r\");\n    printf(\"Note: This function always uses ESP-DSP on ESP32, standard implementation otherwise\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int m = 3; // rows of A\n    const int n = 3; // cols of A and rows of B\n    const int k = 3; // cols of B\n\n    // Matrix A: 3x3\n    float A[9] = {1.0f, 2.0f, 3.0f,\n                  4.0f, 5.0f, 6.0f,\n                  7.0f, 8.0f, 9.0f};\n\n    // Matrix B: 3x3\n    float B[9] = {0.5f, 1.0f, 1.5f,\n                  2.0f, 2.5f, 3.0f,\n                  3.5f, 4.0f, 4.5f};\n\n    // Matrix C: 3x3 (output)\n    float C[9];\n    memset(C, 0, sizeof(C));\n\n    printf(\"Matrix A Memory Layout (3x3, 9 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%5.1f \", A[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0]  &lt;- Row 0\\n\\r\");\n    printf(\"          [4.0  5.0  6.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [7.0  8.0  9.0]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Matrix B Memory Layout (3x3, 9 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%5.1f \", B[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.0  1.5]  &lt;- Row 0\\n\\r\");\n    printf(\"          [2.0  2.5  3.0]  &lt;- Row 1\\n\\r\");\n    printf(\"          [3.5  4.0  4.5]  &lt;- Row 2\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: C = A * B\n    float expected_C[9] = {0};\n    for (int i = 0; i &lt; m; i++) {\n        for (int j = 0; j &lt; k; j++) {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; n; s++) {\n                sum += A[i * n + s] * B[s * k + j];\n            }\n            expected_C[i * k + j] = sum;\n        }\n    }\n\n    printf(\"Expected Output Matrix C Memory Layout (3x3, 9 elements, contiguous):\\n\\r\");\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%6.1f \", expected_C[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f  %5.1f]  &lt;- Row 0\\n\\r\", expected_C[0], expected_C[1], expected_C[2]);\n    printf(\"          [%5.1f  %5.1f  %5.1f]  &lt;- Row 1\\n\\r\", expected_C[3], expected_C[4], expected_C[5]);\n    printf(\"          [%5.1f  %5.1f  %5.1f] &lt;- Row 2\\n\\r\", expected_C[6], expected_C[7], expected_C[8]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiplication\n    tiny_error_t err = tiny_mat_mult_f32(A, B, C, m, n, k);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix C Memory Layout (3x3, 9 elements, contiguous):\\n\\r\");\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 9; i++) {\n            printf(\"%6.1f \", C[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f  %5.1f]  &lt;- Row 0\\n\\r\", C[0], C[1], C[2]);\n        printf(\"          [%5.1f  %5.1f  %5.1f]  &lt;- Row 1\\n\\r\", C[3], C[4], C[5]);\n        printf(\"          [%5.1f  %5.1f  %5.1f] &lt;- Row 2\\n\\r\", C[6], C[7], C[8]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; m * k; i++) {\n            float tolerance = 1e-5f;\n            float diff = (C[i] &gt; expected_C[i]) ? (C[i] - expected_C[i]) : (expected_C[i] - C[i]);\n            if (diff &gt; tolerance) {\n                all_correct = 0;\n                break;\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_mult_ex_f32 with contiguous matrices (pad=0)\n */\nvoid test_tiny_mat_mult_ex_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 11: tiny_mat_mult_ex_f32 - Contiguous Matrix Multiplication\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: A_rows=3, A_cols=4, B_cols=2, A_padding=0, B_padding=0, C_padding=0\\n\\r\");\n    printf(\"Matrix dimensions: A is 3x4, B is 4x2, C is 3x2\\n\\r\");\n    printf(\"Note: This should use ESP-DSP on ESP32 when all paddings are 0\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int A_rows = 3;\n    const int A_cols = 4;\n    const int B_cols = 2;\n    const int A_padding = 0;\n    const int B_padding = 0;\n    const int C_padding = 0;\n\n    const int A_step = A_cols + A_padding; // 4\n    const int B_step = B_cols + B_padding; // 2\n    const int C_step = B_cols + C_padding; // 2\n\n    // Matrix A: 3x4 (contiguous, no padding)\n    float A[12] = {1.0f, 2.0f, 3.0f, 4.0f,\n                   5.0f, 6.0f, 7.0f, 8.0f,\n                   9.0f, 10.0f, 11.0f, 12.0f};\n\n    // Matrix B: 4x2 (contiguous, no padding)\n    float B[8] = {0.5f, 1.5f,\n                  2.5f, 3.5f,\n                  4.5f, 5.5f,\n                  6.5f, 7.5f};\n\n    // Matrix C: 3x2 (output, contiguous, no padding)\n    float C[6];\n    memset(C, 0, sizeof(C));\n\n    printf(\"Matrix A Memory Layout (3x4, 12 elements, contiguous, pad=%d):\\n\\r\", A_padding);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 12; i++) {\n        printf(\"%5.1f \", A[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0 (indices: 0-3)\\n\\r\");\n    printf(\"          [5.0  6.0  7.0  8.0]  &lt;- Row 1 (indices: 4-7)\\n\\r\");\n    printf(\"          [9.0 10.0 11.0 12.0]  &lt;- Row 2 (indices: 8-11)\\n\\r\");\n    printf(\"  Step size: %d (A_cols + A_padding = %d + %d)\\n\\r\", A_step, A_cols, A_padding);\n    printf(\"\\n\\r\");\n\n    printf(\"Matrix B Memory Layout (4x2, 8 elements, contiguous, pad=%d):\\n\\r\", B_padding);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 8; i++) {\n        printf(\"%5.1f \", B[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5]  &lt;- Row 0 (indices: 0-1)\\n\\r\");\n    printf(\"          [2.5  3.5]  &lt;- Row 1 (indices: 2-3)\\n\\r\");\n    printf(\"          [4.5  5.5]  &lt;- Row 2 (indices: 4-5)\\n\\r\");\n    printf(\"          [6.5  7.5]  &lt;- Row 3 (indices: 6-7)\\n\\r\");\n    printf(\"  Step size: %d (B_cols + B_padding = %d + %d)\\n\\r\", B_step, B_cols, B_padding);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: C = A * B\n    // C[i][j] = sum_{s=0}^{A_cols-1} A[i][s] * B[s][j]\n    // Index calculation: A[i * A_step + s], B[s * B_step + j], C[i * C_step + j]\n    float expected_C[6] = {0};\n    for (int i = 0; i &lt; A_rows; i++) {\n        for (int j = 0; j &lt; B_cols; j++) {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; A_cols; s++) {\n                int idx_A = i * A_step + s;\n                int idx_B = s * B_step + j;\n                sum += A[idx_A] * B[idx_B];\n            }\n            expected_C[i * C_step + j] = sum;\n        }\n    }\n\n    printf(\"Expected Output Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=%d):\\n\\r\", C_padding);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 6; i++) {\n        printf(\"%6.1f \", expected_C[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f]  &lt;- Row 0 (indices: 0-1)\\n\\r\", expected_C[0], expected_C[1]);\n    printf(\"          [%5.1f  %5.1f]  &lt;- Row 1 (indices: 2-3)\\n\\r\", expected_C[2], expected_C[3]);\n    printf(\"          [%5.1f  %5.1f] &lt;- Row 2 (indices: 4-5)\\n\\r\", expected_C[4], expected_C[5]);\n    printf(\"  Step size: %d (B_cols + C_padding = %d + %d)\\n\\r\", C_step, B_cols, C_padding);\n    printf(\"  Calculation example:\\n\\r\");\n    printf(\"    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\\n\\r\");\n    printf(\"            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 = %5.1f\\n\\r\", expected_C[0]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiplication\n    tiny_error_t err = tiny_mat_mult_ex_f32(A, B, C, A_rows, A_cols, B_cols, A_padding, B_padding, C_padding);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=%d):\\n\\r\", C_padding);\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 6; i++) {\n            printf(\"%6.1f \", C[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f]  &lt;- Row 0 (indices: 0-1)\\n\\r\", C[0], C[1]);\n        printf(\"          [%5.1f  %5.1f]  &lt;- Row 1 (indices: 2-3)\\n\\r\", C[2], C[3]);\n        printf(\"          [%5.1f  %5.1f] &lt;- Row 2 (indices: 4-5)\\n\\r\", C[4], C[5]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; A_rows; i++) {\n            for (int j = 0; j &lt; B_cols; j++) {\n                int idx = i * C_step + j;\n                float tolerance = 1e-5f;\n                float diff = (C[idx] &gt; expected_C[idx]) ? (C[idx] - expected_C[idx]) : (expected_C[idx] - C[idx]);\n                if (diff &gt; tolerance) {\n                    printf(\"  ERROR at [%d][%d] (index %d): output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                           i, j, idx, C[idx], expected_C[idx], diff);\n                    all_correct = 0;\n                }\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_mult_ex_f32 with padded matrices (pad!=0)\n */\nvoid test_tiny_mat_mult_ex_f32_padded(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 12: tiny_mat_mult_ex_f32 - Padded Matrix Multiplication\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: A_rows=2, A_cols=3, B_cols=2, A_padding=2, B_padding=1, C_padding=1\\n\\r\");\n    printf(\"Matrix dimensions: A is 2x3, B is 3x2, C is 2x2\\n\\r\");\n    printf(\"Note: This should use own implementation when padding is non-zero\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int A_rows = 2;\n    const int A_cols = 3;\n    const int B_cols = 2;\n    const int A_padding = 2;\n    const int B_padding = 1;\n    const int C_padding = 1;\n\n    const int A_step = A_cols + A_padding; // 3 + 2 = 5\n    const int B_step = B_cols + B_padding; // 2 + 1 = 3\n    const int C_step = B_cols + C_padding; // 2 + 1 = 3\n\n    // Matrix A: 2x3 with padding=2, so each row has 5 elements (3 data + 2 padding)\n    // Total memory: 2 rows * 5 elements = 10 elements\n    float A[10] = {1.0f, 2.0f, 3.0f, 0.0f, 0.0f,  // Row 0: [1.0, 2.0, 3.0, X, X]\n                   4.0f, 5.0f, 6.0f, 0.0f, 0.0f}; // Row 1: [4.0, 5.0, 6.0, X, X]\n\n    // Matrix B: 3x2 with padding=1, so each row has 3 elements (2 data + 1 padding)\n    // Total memory: 3 rows * 3 elements = 9 elements\n    float B[9] = {0.5f, 1.5f, 0.0f,  // Row 0: [0.5, 1.5, X]\n                  2.5f, 3.5f, 0.0f,  // Row 1: [2.5, 3.5, X]\n                  4.5f, 5.5f, 0.0f}; // Row 2: [4.5, 5.5, X]\n\n    // Matrix C: 2x2 with padding=1, so each row has 3 elements (2 data + 1 padding)\n    // Total memory: 2 rows * 3 elements = 6 elements\n    float C[6];\n    memset(C, 0, sizeof(C));\n\n    printf(\"Matrix A Memory Layout (2x3, pad=%d, step=%d, 10 elements):\\n\\r\", A_padding, A_step);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 10; i++) {\n        printf(\"%4.1f \", A[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0  X   X]  &lt;- Row 0 (indices: 0, 1, 2, 3, 4)\\n\\r\");\n    printf(\"          [4.0  5.0  6.0  X   X]  &lt;- Row 1 (indices: 5, 6, 7, 8, 9)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"  Index calculation: A[i][j] = A[i * %d + j]\\n\\r\", A_step);\n    printf(\"    Row 0: indices 0, 1, 2 (data), 3, 4 (padding)\\n\\r\");\n    printf(\"    Row 1: indices 5, 6, 7 (data), 8, 9 (padding)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    printf(\"Matrix B Memory Layout (3x2, pad=%d, step=%d, 9 elements):\\n\\r\", B_padding, B_step);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%4.1f \", B[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [0.5  1.5  X]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\");\n    printf(\"          [2.5  3.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\");\n    printf(\"          [4.5  5.5  X]  &lt;- Row 2 (indices: 6, 7, 8)\\n\\r\");\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"  Index calculation: B[i][j] = B[i * %d + j]\\n\\r\", B_step);\n    printf(\"    Row 0: indices 0, 1 (data), 2 (padding)\\n\\r\");\n    printf(\"    Row 1: indices 3, 4 (data), 5 (padding)\\n\\r\");\n    printf(\"    Row 2: indices 6, 7 (data), 8 (padding)\\n\\r\");\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: C = A * B\n    // C[i][j] = sum_{s=0}^{A_cols-1} A[i][s] * B[s][j]\n    // Index calculation: A[i * A_step + s], B[s * B_step + j], C[i * C_step + j]\n    float expected_C[6] = {0};\n    for (int i = 0; i &lt; A_rows; i++) {\n        for (int j = 0; j &lt; B_cols; j++) {\n            float sum = 0.0f;\n            for (int s = 0; s &lt; A_cols; s++) {\n                int idx_A = i * A_step + s;\n                int idx_B = s * B_step + j;\n                sum += A[idx_A] * B[idx_B];\n            }\n            expected_C[i * C_step + j] = sum;\n        }\n    }\n\n    printf(\"Expected Output Matrix C Memory Layout (2x2, pad=%d, step=%d, 6 elements):\\n\\r\", C_padding, C_step);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 6; i++) {\n        printf(\"%6.1f \", expected_C[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f  X]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\", expected_C[0], expected_C[1]);\n    printf(\"          [%5.1f  %5.1f  X]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\", expected_C[3], expected_C[4]);\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"  Index calculation: C[i][j] = C[i * %d + j]\\n\\r\", C_step);\n    printf(\"  Calculation:\\n\\r\");\n    printf(\"    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0]\\n\\r\");\n    printf(\"            = A[%d]*B[%d] + A[%d]*B[%d] + A[%d]*B[%d]\\n\\r\", \n           0*A_step+0, 0*B_step+0, 0*A_step+1, 1*B_step+0, 0*A_step+2, 2*B_step+0);\n    printf(\"            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 = %5.1f\\n\\r\", expected_C[0]);\n    printf(\"    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1]\\n\\r\");\n    printf(\"            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 = %5.1f\\n\\r\", expected_C[1]);\n    printf(\"    C[1][0] = A[1][0]*B[0][0] + A[1][1]*B[1][0] + A[1][2]*B[2][0]\\n\\r\");\n    printf(\"            = 4.0*0.5 + 5.0*2.5 + 6.0*4.5 = %5.1f\\n\\r\", expected_C[3]);\n    printf(\"    C[1][1] = A[1][0]*B[0][1] + A[1][1]*B[1][1] + A[1][2]*B[2][1]\\n\\r\");\n    printf(\"            = 4.0*1.5 + 5.0*3.5 + 6.0*5.5 = %5.1f\\n\\r\", expected_C[4]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiplication\n    tiny_error_t err = tiny_mat_mult_ex_f32(A, B, C, A_rows, A_cols, B_cols, A_padding, B_padding, C_padding);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix C Memory Layout (2x2, pad=%d, step=%d, 6 elements):\\n\\r\", C_padding, C_step);\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 6; i++) {\n            printf(\"%6.1f \", C[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f  X]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\", C[0], C[1]);\n        printf(\"          [%5.1f  %5.1f  X]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\", C[3], C[4]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int i = 0; i &lt; A_rows; i++) {\n            for (int j = 0; j &lt; B_cols; j++) {\n                int idx = i * C_step + j;\n                float tolerance = 1e-5f;\n                float diff = (C[idx] &gt; expected_C[idx]) ? (C[idx] - expected_C[idx]) : (expected_C[idx] - C[idx]);\n                if (diff &gt; tolerance) {\n                    printf(\"  ERROR at [%d][%d] (index %d): output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                           i, j, idx, C[idx], expected_C[idx], diff);\n                    all_correct = 0;\n                }\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_multc_f32 with contiguous matrix (pad=0, step=1)\n */\nvoid test_tiny_mat_multc_f32_contiguous(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 13: tiny_mat_multc_f32 - Contiguous Matrix Multiply Constant\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=3, cols=3, padd_in=0, padd_out=0, step_in=1, step_out=1\\n\\r\");\n    printf(\"Matrix dimensions: 3x3\\n\\r\");\n    printf(\"Constant C: 2.5\\n\\r\");\n    printf(\"Note: This should use ESP-DSP on ESP32 when all paddings are 0 and all steps are 1\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 3;\n    const int cols = 3;\n    const int padd_in = 0;\n    const int padd_out = 0;\n    const int step_in = 1;\n    const int step_out = 1;\n    const float C = 2.5f;\n\n    const int in_row_stride = cols + padd_in;  // 3\n    const int out_row_stride = cols + padd_out; // 3\n\n    // Input matrix: 3x3 (contiguous, no padding)\n    float input[9] = {1.0f, 2.0f, 3.0f,\n                       4.0f, 5.0f, 6.0f,\n                       7.0f, 8.0f, 9.0f};\n\n    // Output matrix: 3x3 (contiguous, no padding)\n    float output[9];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input Matrix Memory Layout (3x3, 9 elements, contiguous, pad=%d, step=%d):\\n\\r\", padd_in, step_in);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%5.1f \", input[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  2.0  3.0]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\");\n    printf(\"          [4.0  5.0  6.0]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\");\n    printf(\"          [7.0  8.0  9.0]  &lt;- Row 2 (indices: 6, 7, 8)\\n\\r\");\n    printf(\"  Row stride: %d (cols + padd_in = %d + %d)\\n\\r\", in_row_stride, cols, padd_in);\n    printf(\"  Index calculation: input[i][j] = input[i * %d + j * %d]\\n\\r\", in_row_stride, step_in);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: output[i][j] = input[i][j] * C\n    float expected_output[9] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n            expected_output[idx_out] = input[idx_in] * C;\n        }\n    }\n\n    printf(\"Expected Output Matrix Memory Layout (3x3, 9 elements, contiguous, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 9; i++) {\n        printf(\"%6.1f \", expected_output[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f  %5.1f]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\", \n           expected_output[0], expected_output[1], expected_output[2]);\n    printf(\"          [%5.1f  %5.1f  %5.1f]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\", \n           expected_output[3], expected_output[4], expected_output[5]);\n    printf(\"          [%5.1f  %5.1f  %5.1f] &lt;- Row 2 (indices: 6, 7, 8)\\n\\r\", \n           expected_output[6], expected_output[7], expected_output[8]);\n    printf(\"  Row stride: %d (cols + padd_out = %d + %d)\\n\\r\", out_row_stride, cols, padd_out);\n    printf(\"  Index calculation: output[i][j] = output[i * %d + j * %d]\\n\\r\", out_row_stride, step_out);\n    printf(\"  Calculation: output[i][j] = input[i][j] * %.1f\\n\\r\", C);\n    printf(\"    Example: output[0][0] = input[0][0] * %.1f = 1.0 * %.1f = %.1f\\n\\r\", C, C, expected_output[0]);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiply constant\n    tiny_error_t err = tiny_mat_multc_f32(input, output, C, rows, cols, padd_in, padd_out, step_in, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix Memory Layout (3x3, 9 elements, contiguous, pad=%d, step=%d):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 9; i++) {\n            printf(\"%6.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f  %5.1f]  &lt;- Row 0 (indices: 0, 1, 2)\\n\\r\", \n               output[0], output[1], output[2]);\n        printf(\"          [%5.1f  %5.1f  %5.1f]  &lt;- Row 1 (indices: 3, 4, 5)\\n\\r\", \n               output[3], output[4], output[5]);\n        printf(\"          [%5.1f  %5.1f  %5.1f] &lt;- Row 2 (indices: 6, 7, 8)\\n\\r\", \n               output[6], output[7], output[8]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            int base_out = row * out_row_stride;\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_out = base_out + col * step_out;\n                float tolerance = 1e-5f;\n                float diff = (output[idx_out] &gt; expected_output[idx_out]) ? \n                            (output[idx_out] - expected_output[idx_out]) : \n                            (expected_output[idx_out] - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    printf(\"  ERROR at [%d][%d] (index %d): output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                           row, col, idx_out, output[idx_out], expected_output[idx_out], diff);\n                    all_correct = 0;\n                }\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\n/**\n * @brief Test tiny_mat_multc_f32 with padded and strided matrix (pad!=0, step&gt;1)\n */\nvoid test_tiny_mat_multc_f32_padded_strided(void)\n{\n    printf(\"\\n\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Test Case 14: tiny_mat_multc_f32 - Padded and Strided Matrix Multiply Constant\\n\\r\");\n    printf(\"================================================================================\\n\\r\");\n    printf(\"Parameters: rows=2, cols=3, padd_in=2, padd_out=1, step_in=2, step_out=1\\n\\r\");\n    printf(\"Matrix dimensions: 2x3\\n\\r\");\n    printf(\"Constant C: 3.0\\n\\r\");\n    printf(\"Note: This should use own implementation when padding is non-zero or step &gt; 1\\n\\r\");\n    printf(\"\\n\\r\");\n\n    const int rows = 2;\n    const int cols = 3;\n    const int padd_in = 2;\n    const int padd_out = 1;\n    const int step_in = 2;\n    const int step_out = 1;\n    const float C = 3.0f;\n\n    const int in_row_stride = cols + padd_in;  // 3 + 2 = 5\n    const int out_row_stride = cols + padd_out; // 3 + 1 = 4\n\n    // Input matrix: 2x3 with padding=2, step=2\n    // Each row has 5 elements in memory, but we only use every 2nd element (step=2)\n    // Total memory: 2 rows * 5 elements = 10 elements\n    // Row 0: indices 0, 2, 4 (data), 1, 3 (unused)\n    // Row 1: indices 5, 7, 9 (data), 6, 8 (unused)\n    float input[10] = {1.0f, 0.0f, 2.0f, 0.0f, 3.0f,  // Row 0: [1.0, X, 2.0, X, 3.0]\n                       4.0f, 0.0f, 5.0f, 0.0f, 6.0f}; // Row 1: [4.0, X, 5.0, X, 6.0]\n\n    // Output matrix: 2x3 with padding=1, step=1\n    // Each row has 4 elements (3 data + 1 padding)\n    // Total memory: 2 rows * 4 elements = 8 elements\n    float output[8];\n    memset(output, 0, sizeof(output));\n\n    printf(\"Input Matrix Memory Layout (2x3, pad=%d, step=%d, 10 elements):\\n\\r\", padd_in, step_in);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 10; i++) {\n        printf(\"%4.1f \", input[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (data indices: 0, 2, 4)\\n\\r\");\n    printf(\"          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (data indices: 5, 7, 9)\\n\\r\");\n    printf(\"          (X = unused/padding)\\n\\r\");\n    printf(\"  Row stride: %d (cols + padd_in = %d + %d)\\n\\r\", in_row_stride, cols, padd_in);\n    printf(\"  Index calculation: input[i][j] = input[i * %d + j * %d]\\n\\r\", in_row_stride, step_in);\n    printf(\"    Row 0: input[0][0]=input[%d]=%.1f, input[0][1]=input[%d]=%.1f, input[0][2]=input[%d]=%.1f\\n\\r\",\n           0*in_row_stride+0*step_in, input[0*in_row_stride+0*step_in],\n           0*in_row_stride+1*step_in, input[0*in_row_stride+1*step_in],\n           0*in_row_stride+2*step_in, input[0*in_row_stride+2*step_in]);\n    printf(\"    Row 1: input[1][0]=input[%d]=%.1f, input[1][1]=input[%d]=%.1f, input[1][2]=input[%d]=%.1f\\n\\r\",\n           1*in_row_stride+0*step_in, input[1*in_row_stride+0*step_in],\n           1*in_row_stride+1*step_in, input[1*in_row_stride+1*step_in],\n           1*in_row_stride+2*step_in, input[1*in_row_stride+2*step_in]);\n    printf(\"\\n\\r\");\n\n    // Calculate expected output: output[i][j] = input[i][j] * C\n    float expected_output[8] = {0};\n    for (int row = 0; row &lt; rows; row++) {\n        int base_in = row * in_row_stride;\n        int base_out = row * out_row_stride;\n        for (int col = 0; col &lt; cols; col++) {\n            int idx_in = base_in + col * step_in;\n            int idx_out = base_out + col * step_out;\n            expected_output[idx_out] = input[idx_in] * C;\n        }\n    }\n\n    printf(\"Expected Output Matrix Memory Layout (2x3, pad=%d, step=%d, 8 elements):\\n\\r\", padd_out, step_out);\n    printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\\n\\r\");\n    printf(\"  Value:  \");\n    for (int i = 0; i &lt; 8; i++) {\n        printf(\"%6.1f \", expected_output[i]);\n    }\n    printf(\"\\n\\r\");\n    printf(\"  Matrix: [%5.1f  %5.1f  %5.1f  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\\n\\r\", \n           expected_output[0], expected_output[1], expected_output[2]);\n    printf(\"          [%5.1f  %5.1f  %5.1f  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\\n\\r\", \n           expected_output[4], expected_output[5], expected_output[6]);\n    printf(\"          (X = padding/unused)\\n\\r\");\n    printf(\"  Row stride: %d (cols + padd_out = %d + %d)\\n\\r\", out_row_stride, cols, padd_out);\n    printf(\"  Index calculation: output[i][j] = output[i * %d + j * %d]\\n\\r\", out_row_stride, step_out);\n    printf(\"  Calculation: output[i][j] = input[i][j] * %.1f\\n\\r\", C);\n    printf(\"    Row 0: output[0][0] = input[0][0] * %.1f = %.1f * %.1f = %.1f (index %d)\\n\\r\",\n           C, input[0*in_row_stride+0*step_in], C, expected_output[0*out_row_stride+0*step_out], 0*out_row_stride+0*step_out);\n    printf(\"           output[0][1] = input[0][1] * %.1f = %.1f * %.1f = %.1f (index %d)\\n\\r\",\n           C, input[0*in_row_stride+1*step_in], C, expected_output[0*out_row_stride+1*step_out], 0*out_row_stride+1*step_out);\n    printf(\"           output[0][2] = input[0][2] * %.1f = %.1f * %.1f = %.1f (index %d)\\n\\r\",\n           C, input[0*in_row_stride+2*step_in], C, expected_output[0*out_row_stride+2*step_out], 0*out_row_stride+2*step_out);\n    printf(\"\\n\\r\");\n\n    // Test matrix multiply constant\n    tiny_error_t err = tiny_mat_multc_f32(input, output, C, rows, cols, padd_in, padd_out, step_in, step_out);\n\n    if (err == TINY_OK) {\n        printf(\"Output Matrix Memory Layout (2x3, pad=%d, step=%d, 8 elements):\\n\\r\", padd_out, step_out);\n        printf(\"  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\\n\\r\");\n        printf(\"  Value:  \");\n        for (int i = 0; i &lt; 8; i++) {\n            printf(\"%6.1f \", output[i]);\n        }\n        printf(\"\\n\\r\");\n        printf(\"  Matrix: [%5.1f  %5.1f  %5.1f  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\\n\\r\", \n               output[0], output[1], output[2]);\n        printf(\"          [%5.1f  %5.1f  %5.1f  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\\n\\r\", \n               output[4], output[5], output[6]);\n        printf(\"\\n\\r\");\n\n        // Verify results\n        int all_correct = 1;\n        for (int row = 0; row &lt; rows; row++) {\n            int base_out = row * out_row_stride;\n            for (int col = 0; col &lt; cols; col++) {\n                int idx_out = base_out + col * step_out;\n                float tolerance = 1e-5f;\n                float diff = (output[idx_out] &gt; expected_output[idx_out]) ? \n                            (output[idx_out] - expected_output[idx_out]) : \n                            (expected_output[idx_out] - output[idx_out]);\n                if (diff &gt; tolerance) {\n                    printf(\"  ERROR at [%d][%d] (index %d): output = %10.6f, expected = %10.6f, diff = %e\\n\\r\", \n                           row, col, idx_out, output[idx_out], expected_output[idx_out], diff);\n                    all_correct = 0;\n                }\n            }\n        }\n\n        if (all_correct) {\n            printf(\"\u2713 Test PASSED\\n\\r\");\n        } else {\n            printf(\"\u2717 Test FAILED\\n\\r\");\n        }\n    } else {\n        printf(\"\u2717 Test FAILED: Error code = %d\\n\\r\", err);\n    }\n\n    printf(\"================================================================================\\n\\r\\n\\r\");\n}\n\nvoid tiny_mat_test(void)\n{\n    printf(\"============ [tiny_mat_test] ============\\n\\r\");\n\n    // Test 1: Contiguous matrices (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_add_f32_contiguous();\n\n    // Test 2: Padded and strided matrices (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_add_f32_padded_strided();\n\n    // Test 3: Contiguous matrix add constant (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_addc_f32_contiguous();\n\n    // Test 4: Padded and strided matrix add constant (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_addc_f32_padded_strided();\n\n    // Test 5: Contiguous matrices subtraction (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_sub_f32_contiguous();\n\n    // Test 6: Padded and strided matrices subtraction (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_sub_f32_padded_strided();\n\n    // Test 7: Contiguous matrix subtract constant (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_subc_f32_contiguous();\n\n    // Test 8: Padded and strided matrix subtract constant (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_subc_f32_padded_strided();\n\n    // Test 9: Basic matrix multiplication (3x4 * 4x2 = 3x2)\n    test_tiny_mat_mult_f32_basic();\n\n    // Test 10: Square matrix multiplication (3x3 * 3x3 = 3x3)\n    test_tiny_mat_mult_f32_square();\n\n    // Test 11: Contiguous matrix multiplication with padding (pad=0) - should use ESP-DSP on ESP32\n    test_tiny_mat_mult_ex_f32_contiguous();\n\n    // Test 12: Padded matrix multiplication (pad!=0) - should use own implementation\n    test_tiny_mat_mult_ex_f32_padded();\n\n    // Test 13: Contiguous matrix multiply constant (pad=0, step=1) - should use ESP-DSP on ESP32\n    test_tiny_mat_multc_f32_contiguous();\n\n    // Test 14: Padded and strided matrix multiply constant (pad!=0, step&gt;1) - should use own implementation\n    test_tiny_mat_multc_f32_padded_strided();\n\n    printf(\"============ [test complete] ============\\n\\r\");\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-test/#maincpp","title":"main.cpp","text":"<pre><code>#include \"tiny_mat_test.hpp\"\n\nextern \"C\" void app_main(void)\n{\n    tiny_mat_test();\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-mat-test/#test-results","title":"TEST RESULTS","text":"<pre><code>============ [tiny_mat_test] ============\n\n================================================================================\nTest Case 1: tiny_mat_add_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1\n\nInput1 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nInput2 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5 \n  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\n          [4.5  5.5  6.5  7.5]  &lt;- Row 1\n          [8.5  9.5 10.5 11.5]  &lt;- Row 2\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.5   3.5   5.5   7.5   9.5  11.5  13.5  15.5  17.5  19.5  21.5  23.5 \n  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\n          [9.5 11.5 13.5 15.5]  &lt;- Row 1\n          [17.5 19.5 21.5 23.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.5   3.5   5.5   7.5   9.5  11.5  13.5  15.5  17.5  19.5  21.5  23.5 \n  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\n          [9.5 11.5 13.5 15.5]  &lt;- Row 1\n          [17.5 19.5 21.5 23.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 2: tiny_mat_add_f32 - Non-contiguous memory (pad!=0, step&gt;1)\n================================================================================\nParams: rows=2, cols=3, pad1=4, pad2=4, pad_out=4, step1=2, step2=3, step_out=2\nIndex formula: idx = row * (cols + padding) + col * step\n\n[input1 raw len=14]  1.0  0.0  2.0  0.0  3.0  0.0  0.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0 (pad=4, step=2)\n  input1 row0 (stride=7): [0: 1.0 C] [1: 0.0 P] [2: 2.0 C] [3: 0.0 P] [4: 3.0 C] [5: 0.0 P] [6: 0.0 P]\n  input1 row1 (stride=7): [0: 4.0 C] [1: 0.0 P] [2: 5.0 C] [3: 0.0 P] [4: 6.0 C] [5: 0.0 P] [6: 0.0 P]\n\n[input2 raw len=14]  0.5  0.0  0.0  1.5  0.0  0.0  2.5  3.5  0.0  0.0  4.5  0.0  0.0  5.5 (pad=4, step=3)\n  input2 row0 (stride=7): [0: 0.5 C] [1: 0.0 P] [2: 0.0 P] [3: 1.5 C] [4: 0.0 P] [5: 0.0 P] [6: 2.5 C]\n  input2 row1 (stride=7): [0: 3.5 C] [1: 0.0 P] [2: 0.0 P] [3: 4.5 C] [4: 0.0 P] [5: 0.0 P] [6: 5.5 C]\n\nLogical matrices (no padding):\n  input1 row0:  1.0  2.0  3.0\n  input1 row1:  4.0  5.0  6.0\n  input2 row0:  0.5  1.5  2.5\n  input2 row1:  3.5  4.5  5.5\n\n[output raw len=14]  1.5  0.0  3.5  0.0  5.5  0.0  0.0  7.5  0.0  9.5  0.0 11.5  0.0  0.0 (pad_out=4, step_out=2)\n\n  output row0 (stride=7): [0: 1.5 C] [1: 0.0 P] [2: 3.5 C] [3: 0.0 P] [4: 5.5 C] [5: 0.0 P] [6: 0.0 P]\n  output row1 (stride=7): [0: 7.5 C] [1: 0.0 P] [2: 9.5 C] [3: 0.0 P] [4:11.5 C] [5: 0.0 P] [6: 0.0 P]\n\n[expected raw len=14]  1.5  0.0  3.5  0.0  5.5  0.0  0.0  7.5  0.0  9.5  0.0 11.5  0.0  0.0 (pad_out=4, step_out=2)\n\nLogical matrix comparison (expected | actual | diff):\n  row0: [ 1.5 |  1.5 | 0.0e+00] [ 3.5 |  3.5 | 0.0e+00] [ 5.5 |  5.5 | 0.0e+00]\n  row1: [ 7.5 |  7.5 | 0.0e+00] [ 9.5 |  9.5 | 0.0e+00] [11.5 | 11.5 | 0.0e+00]\n\u2713 Test PASSED (all elements match)\n================================================================================\n\n\n================================================================================\nTest Case 3: tiny_mat_addc_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1, C=2.5\n\nInput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nConstant C =   2.5\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5  12.5  13.5  14.5 \n  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\n          [7.5  8.5  9.5 10.5]  &lt;- Row 1\n          [11.5 12.5 13.5 14.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5  12.5  13.5  14.5 \n  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\n          [7.5  8.5  9.5 10.5]  &lt;- Row 1\n          [11.5 12.5 13.5 14.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 4: tiny_mat_addc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad_in=2, pad_out=2, step_in=2, step_out=2, C=  1.5\nIndex formula: index = row * (cols + padding) + col * step\n\nInput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nConstant C =   1.5\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   2.5  0.0  3.5  0.0  4.5  5.5  0.0  6.5  0.0  7.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   2.5  0.0  3.5  0.0  4.5  5.5  0.0  6.5  0.0  7.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 5: tiny_mat_sub_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1\n\nInput1 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nInput2 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5 \n  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\n          [4.5  5.5  6.5  7.5]  &lt;- Row 1\n          [8.5  9.5 10.5 11.5]  &lt;- Row 2\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 \n  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\n          [0.5  0.5  0.5  0.5]  &lt;- Row 1\n          [0.5  0.5  0.5  0.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 \n  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\n          [0.5  0.5  0.5  0.5]  &lt;- Row 1\n          [0.5  0.5  0.5  0.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 6: tiny_mat_sub_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad1=2, pad2=1, pad_out=2, step1=2, step2=3, step_out=2\nIndex formula: index = row * (cols + padding) + col * step\n\nInput1 Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nInput2 Memory Layout (16 elements, pad=1, step=3):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\n  Value:   0.5  0.0  0.0  1.5  3.5  0.0  2.5  4.5  0.0  0.0  5.5  0.0 ...\n  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\n          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\n          (X = padding/unused)\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   0.5  0.0  0.5  0.0  0.5  0.5  0.0  0.5  0.0  0.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   0.5  0.0  0.5  0.0  0.5  0.5  0.0  0.5  0.0  0.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 7: tiny_mat_subc_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1, C=2.5\n\nInput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nConstant C =   2.5\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:   -1.5  -0.5   0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5 \n  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\n          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\n          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:   -1.5  -0.5   0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5 \n  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\n          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\n          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 8: tiny_mat_subc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad_in=2, pad_out=2, step_in=2, step_out=2, C=  1.5\nIndex formula: index = row * (cols + padding) + col * step\n\nInput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nConstant C =   1.5\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:  -0.5  0.0  0.5  0.0  1.5  2.5  0.0  3.5  0.0  4.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:  -0.5  0.0  0.5  0.0  1.5  2.5  0.0  3.5  0.0  4.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 9: tiny_mat_mult_f32 - Basic Matrix Multiplication\n================================================================================\nParameters: m=3, n=4, k=2 (A is 3x4, B is 4x2, C is 3x2)\nNote: This function always uses ESP-DSP on ESP32, standard implementation otherwise\n\nMatrix A Memory Layout (3x4, 12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nMatrix B Memory Layout (4x2, 8 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5 \n  Matrix: [0.5  1.5]  &lt;- Row 0\n          [2.5  3.5]  &lt;- Row 1\n          [4.5  5.5]  &lt;- Row 2\n          [6.5  7.5]  &lt;- Row 3\n\nExpected Output Matrix C Memory Layout (3x2, 6 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0\n          [101.0  127.0]  &lt;- Row 1\n          [157.0  199.0] &lt;- Row 2\n  Calculation:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 =  45.0\n    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1] + A[0][3]*B[3][1]\n            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 + 4.0*7.5 =  55.0\n\nOutput Matrix C Memory Layout (3x2, 6 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0\n          [101.0  127.0]  &lt;- Row 1\n          [157.0  199.0] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 10: tiny_mat_mult_f32 - Square Matrix Multiplication\n================================================================================\nParameters: m=3, n=3, k=3 (A is 3x3, B is 3x3, C is 3x3)\nNote: This function always uses ESP-DSP on ESP32, standard implementation otherwise\n\nMatrix A Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0 \n  Matrix: [1.0  2.0  3.0]  &lt;- Row 0\n          [4.0  5.0  6.0]  &lt;- Row 1\n          [7.0  8.0  9.0]  &lt;- Row 2\n\nMatrix B Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    0.5   1.0   1.5   2.0   2.5   3.0   3.5   4.0   4.5 \n  Matrix: [0.5  1.0  1.5]  &lt;- Row 0\n          [2.0  2.5  3.0]  &lt;- Row 1\n          [3.5  4.0  4.5]  &lt;- Row 2\n\nExpected Output Matrix C Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    15.0   18.0   21.0   33.0   40.5   48.0   51.0   63.0   75.0 \n  Matrix: [ 15.0   18.0   21.0]  &lt;- Row 0\n          [ 33.0   40.5   48.0]  &lt;- Row 1\n          [ 51.0   63.0   75.0] &lt;- Row 2\n\nOutput Matrix C Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    15.0   18.0   21.0   33.0   40.5   48.0   51.0   63.0   75.0 \n  Matrix: [ 15.0   18.0   21.0]  &lt;- Row 0\n          [ 33.0   40.5   48.0]  &lt;- Row 1\n          [ 51.0   63.0   75.0] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 11: tiny_mat_mult_ex_f32 - Contiguous Matrix Multiplication\n================================================================================\nParameters: A_rows=3, A_cols=4, B_cols=2, A_padding=0, B_padding=0, C_padding=0\nMatrix dimensions: A is 3x4, B is 4x2, C is 3x2\nNote: This should use ESP-DSP on ESP32 when all paddings are 0\n\nMatrix A Memory Layout (3x4, 12 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0 (indices: 0-3)\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1 (indices: 4-7)\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2 (indices: 8-11)\n  Step size: 4 (A_cols + A_padding = 4 + 0)\n\nMatrix B Memory Layout (4x2, 8 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5 \n  Matrix: [0.5  1.5]  &lt;- Row 0 (indices: 0-1)\n          [2.5  3.5]  &lt;- Row 1 (indices: 2-3)\n          [4.5  5.5]  &lt;- Row 2 (indices: 4-5)\n          [6.5  7.5]  &lt;- Row 3 (indices: 6-7)\n  Step size: 2 (B_cols + B_padding = 2 + 0)\n\nExpected Output Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0 (indices: 0-1)\n          [101.0  127.0]  &lt;- Row 1 (indices: 2-3)\n          [157.0  199.0] &lt;- Row 2 (indices: 4-5)\n  Step size: 2 (B_cols + C_padding = 2 + 0)\n  Calculation example:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 =  45.0\n\nOutput Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0 (indices: 0-1)\n          [101.0  127.0]  &lt;- Row 1 (indices: 2-3)\n          [157.0  199.0] &lt;- Row 2 (indices: 4-5)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 12: tiny_mat_mult_ex_f32 - Padded Matrix Multiplication\n================================================================================\nParameters: A_rows=2, A_cols=3, B_cols=2, A_padding=2, B_padding=1, C_padding=1\nMatrix dimensions: A is 2x3, B is 3x2, C is 2x2\nNote: This should use own implementation when padding is non-zero\n\nMatrix A Memory Layout (2x3, pad=2, step=5, 10 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\n  Value:   1.0  2.0  3.0  0.0  0.0  4.0  5.0  6.0  0.0  0.0 \n  Matrix: [1.0  2.0  3.0  X   X]  &lt;- Row 0 (indices: 0, 1, 2, 3, 4)\n          [4.0  5.0  6.0  X   X]  &lt;- Row 1 (indices: 5, 6, 7, 8, 9)\n          (X = padding/unused)\n  Index calculation: A[i][j] = A[i * 5 + j]\n    Row 0: indices 0, 1, 2 (data), 3, 4 (padding)\n    Row 1: indices 5, 6, 7 (data), 8, 9 (padding)\n\nMatrix B Memory Layout (3x2, pad=1, step=3, 9 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:   0.5  1.5  0.0  2.5  3.5  0.0  4.5  5.5  0.0 \n  Matrix: [0.5  1.5  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [2.5  3.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n          [4.5  5.5  X]  &lt;- Row 2 (indices: 6, 7, 8)\n          (X = padding/unused)\n  Index calculation: B[i][j] = B[i * 3 + j]\n    Row 0: indices 0, 1 (data), 2 (padding)\n    Row 1: indices 3, 4 (data), 5 (padding)\n    Row 2: indices 6, 7 (data), 8 (padding)\n\nExpected Output Matrix C Memory Layout (2x2, pad=1, step=3, 6 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    19.0   25.0    0.0   41.5   56.5    0.0 \n  Matrix: [ 19.0   25.0  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 41.5   56.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n          (X = padding/unused)\n  Index calculation: C[i][j] = C[i * 3 + j]\n  Calculation:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0]\n            = A[0]*B[0] + A[1]*B[3] + A[2]*B[6]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 =  19.0\n    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1]\n            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 =  25.0\n    C[1][0] = A[1][0]*B[0][0] + A[1][1]*B[1][0] + A[1][2]*B[2][0]\n            = 4.0*0.5 + 5.0*2.5 + 6.0*4.5 =  41.5\n    C[1][1] = A[1][0]*B[0][1] + A[1][1]*B[1][1] + A[1][2]*B[2][1]\n            = 4.0*1.5 + 5.0*3.5 + 6.0*5.5 =  56.5\n\nOutput Matrix C Memory Layout (2x2, pad=1, step=3, 6 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    19.0   25.0    0.0   41.5   56.5    0.0 \n  Matrix: [ 19.0   25.0  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 41.5   56.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 13: tiny_mat_multc_f32 - Contiguous Matrix Multiply Constant\n================================================================================\nParameters: rows=3, cols=3, padd_in=0, padd_out=0, step_in=1, step_out=1\nMatrix dimensions: 3x3\nConstant C: 2.5\nNote: This should use ESP-DSP on ESP32 when all paddings are 0 and all steps are 1\n\nInput Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0 \n  Matrix: [1.0  2.0  3.0]  &lt;- Row 0 (indices: 0, 1, 2)\n          [4.0  5.0  6.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [7.0  8.0  9.0]  &lt;- Row 2 (indices: 6, 7, 8)\n  Row stride: 3 (cols + padd_in = 3 + 0)\n  Index calculation: input[i][j] = input[i * 3 + j * 1]\n\nExpected Output Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:     2.5    5.0    7.5   10.0   12.5   15.0   17.5   20.0   22.5 \n  Matrix: [  2.5    5.0    7.5]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 10.0   12.5   15.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [ 17.5   20.0   22.5] &lt;- Row 2 (indices: 6, 7, 8)\n  Row stride: 3 (cols + padd_out = 3 + 0)\n  Index calculation: output[i][j] = output[i * 3 + j * 1]\n  Calculation: output[i][j] = input[i][j] * 2.5\n    Example: output[0][0] = input[0][0] * 2.5 = 1.0 * 2.5 = 2.5\n\nOutput Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:     2.5    5.0    7.5   10.0   12.5   15.0   17.5   20.0   22.5 \n  Matrix: [  2.5    5.0    7.5]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 10.0   12.5   15.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [ 17.5   20.0   22.5] &lt;- Row 2 (indices: 6, 7, 8)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 14: tiny_mat_multc_f32 - Padded and Strided Matrix Multiply Constant\n================================================================================\nParameters: rows=2, cols=3, padd_in=2, padd_out=1, step_in=2, step_out=1\nMatrix dimensions: 2x3\nConstant C: 3.0\nNote: This should use own implementation when padding is non-zero or step &gt; 1\n\nInput Matrix Memory Layout (2x3, pad=2, step=2, 10 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0 \n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (data indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (data indices: 5, 7, 9)\n          (X = unused/padding)\n  Row stride: 5 (cols + padd_in = 3 + 2)\n  Index calculation: input[i][j] = input[i * 5 + j * 2]\n    Row 0: input[0][0]=input[0]=1.0, input[0][1]=input[2]=2.0, input[0][2]=input[4]=3.0\n    Row 1: input[1][0]=input[5]=4.0, input[1][1]=input[7]=5.0, input[1][2]=input[9]=6.0\n\nExpected Output Matrix Memory Layout (2x3, pad=1, step=1, 8 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:     3.0    6.0    9.0    0.0   12.0   15.0   18.0    0.0 \n  Matrix: [  3.0    6.0    9.0  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\n          [ 12.0   15.0   18.0  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\n          (X = padding/unused)\n  Row stride: 4 (cols + padd_out = 3 + 1)\n  Index calculation: output[i][j] = output[i * 4 + j * 1]\n  Calculation: output[i][j] = input[i][j] * 3.0\n    Row 0: output[0][0] = input[0][0] * 3.0 = 1.0 * 3.0 = 3.0 (index 0)\n           output[0][1] = input[0][1] * 3.0 = 2.0 * 3.0 = 6.0 (index 1)\n           output[0][2] = input[0][2] * 3.0 = 3.0 * 3.0 = 9.0 (index 2)\n\nOutput Matrix Memory Layout (2x3, pad=1, step=1, 8 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:     3.0    6.0    9.0    0.0   12.0   15.0   18.0    0.0 \n  Matrix: [  3.0    6.0    9.0  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\n          [ 12.0   15.0   18.0  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\n\n\u2713 Test PASSED\n================================================================================\n\n============ [test complete] ============\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-api/","title":"MATRIX OPERATIONS - TINY_MATRIX","text":"<p>TINY_MATRIX Library</p> <ul> <li>This library is a lightweight matrix computation library implemented in C++, providing basic matrix operations and linear algebra functions.</li> <li>The design goal of this library is to provide a simple and easy-to-use matrix operation interface, suitable for embedded systems and resource-constrained environments.</li> </ul> <p>Usage Scenario</p> <p>Compared to the TINY_MAT library, the TINY_MATRIX library offers richer functionality and higher flexibility, suitable for applications that require complex matrix computations. However, please note that this library is written in C++.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#list-of-functions","title":"LIST OF FUNCTIONS","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500Vector\n    \u2514\u2500\u2500Matrix\n        \u251c\u2500\u2500 tiny_mat (c)\n        \u2514\u2500\u2500 tiny_matrix (c++) &lt;---\n</code></pre> <pre><code>/**\n * @file tiny_matrix.hpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @note This file is built on top of the mat.h file from the ESP-DSP library.\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// TinyMath\n#include \"tiny_math_config.h\"\n#include \"tiny_vec.h\"\n#include \"tiny_mat.h\"\n\n// Standard Libraries\n#include &lt;iostream&gt;\n#include &lt;stdint.h&gt;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n// ESP32 DSP C++ Matrix library\n#include \"mat.h\"\n#endif\n\n/* STATEMENTS */\nnamespace tiny\n{\n    class Mat\n    {\n    public:\n        // ============================================================================\n        // Matrix Metadata\n        // ============================================================================\n        int row;         //&lt; number of rows\n        int col;         //&lt; number of columns\n        int pad;         //&lt; number of paddings between 2 rows\n        int stride;      //&lt; stride = (number of elements in a row) + padding\n        int element;     //&lt; number of elements = rows * cols\n        int memory;      //&lt; size of the data buffer = rows * stride\n        float *data;     //&lt; pointer to the data buffer\n        float *temp;     //&lt; pointer to the temporary data buffer\n        bool ext_buff;   //&lt; flag indicates that matrix use external buffer\n        bool sub_matrix; //&lt; flag indicates that matrix is a subset of another matrix\n\n        // ============================================================================\n        // Rectangular ROI Structure\n        // ============================================================================\n        /**\n         * @name Region of Interest (ROI) Structure\n         * @brief This is the structure for ROI\n         */\n        struct ROI\n        {\n            int pos_x;  ///&lt; starting column index\n            int pos_y;  ///&lt; starting row index\n            int width;  ///&lt; width of ROI (columns)\n            int height; ///&lt; height of ROI (rows)\n\n            ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n            void resize_roi(int pos_x, int pos_y, int width, int height);\n            int area_roi(void) const;\n        };\n\n        // ============================================================================\n        // Printing Functions\n        // ============================================================================\n        void print_info() const;\n        void print_matrix(bool show_padding) const;\n\n        // ============================================================================\n        // Constructors &amp; Destructor\n        // ============================================================================\n        /**\n         * @brief Allocate memory for the matrix according to the memory required.\n         * @note For ESP32, it will automatically determine if using RAM or PSRAM based on the size of the matrix.\n         * @note This function sets ext_buff to false and allocates memory based on row * stride.\n         *       If allocation fails or parameters are invalid, data will be set to nullptr.\n         */\n        void alloc_mem();\n\n        /**\n         * @brief Default constructor: create a 1x1 matrix with only a zero element.\n         * @note If memory allocation fails, the object will be in an invalid state (data = nullptr).\n         *       Caller should check the data pointer before using the matrix.\n         */\n        Mat();\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows and columns.\n         * @param rows Number of rows\n         * @param cols Number of columns\n         */\n        Mat(int rows, int cols);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and stride.\n         * @param rows Number of rows\n         * @param cols Number of columns\n         * @param stride Stride (number of elements in a row)\n         */\n        Mat(int rows, int cols, int stride);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n         * @param data Pointer to external data buffer\n         * @param rows Number of rows\n         * @param cols Number of columns\n         */\n        Mat(float *data, int rows, int cols);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n         * @param data Pointer to external data buffer\n         * @param rows Number of rows\n         * @param cols Number of columns\n         * @param stride Stride (number of elements in a row)\n         */\n        Mat(float *data, int rows, int cols, int stride);\n\n        /**\n         * @brief Copy constructor - create a matrix with the same properties as the source matrix.\n         * @param src Source matrix\n         */\n        Mat(const Mat &amp;src);\n\n        /**\n         * @brief Destructor - free the memory allocated for the matrix.\n         */\n        ~Mat();\n\n        // ============================================================================\n        // Element Access\n        // ============================================================================\n        inline float &amp;operator()(int row, int col) { return data[row * stride + col]; }\n        inline const float &amp;operator()(int row, int col) const { return data[row * stride + col]; }\n\n        // ============================================================================\n        // Data Manipulation\n        // ============================================================================\n        tiny_error_t copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n        tiny_error_t copy_head(const Mat &amp;src);\n        Mat view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n        Mat view_roi(const Mat::ROI &amp;roi) const;\n        Mat copy_roi(int start_row, int start_col, int height, int width);\n        Mat copy_roi(const Mat::ROI &amp;roi);\n        Mat block(int start_row, int start_col, int block_rows, int block_cols);\n        void swap_rows(int row1, int row2);\n        void swap_cols(int col1, int col2);\n        void clear(void);\n\n        // ============================================================================\n        // Arithmetic Operators\n        // ============================================================================\n        Mat &amp;operator=(const Mat &amp;src);    // Copy assignment\n        Mat &amp;operator+=(const Mat &amp;A);     // Add matrix\n        Mat &amp;operator+=(float C);          // Add constant\n        Mat &amp;operator-=(const Mat &amp;A);     // Subtract matrix\n        Mat &amp;operator-=(float C);          // Subtract constant \n        Mat &amp;operator*=(const Mat &amp;A);     // Multiply matrix\n        Mat &amp;operator*=(float C);          // Multiply constant\n        Mat &amp;operator/=(const Mat &amp;B);     // Divide matrix\n        Mat &amp;operator/=(float C);          // Divide constant\n        Mat operator^(int C);              // Exponentiation\n\n        // ============================================================================\n        // Linear Algebra - Basic Operations\n        // ============================================================================\n        Mat transpose();                   // Transpose matrix\n        float determinant();               // Compute determinant (auto-selects method based on size)\n        float determinant_laplace();        // Compute determinant using Laplace expansion (O(n!), for small matrices)\n        float determinant_lu();            // Compute determinant using LU decomposition (O(n\u00b3), efficient for large matrices)\n        float determinant_gaussian();      // Compute determinant using Gaussian elimination (O(n\u00b3), efficient for large matrices)\n        Mat adjoint();                     // Compute adjoint matrix\n        Mat inverse_adjoint();            // Compute inverse using adjoint method\n        void normalize();                  // Normalize matrix\n        float norm() const;                // Compute matrix norm\n        float dotprod(const Mat &amp;A, const Mat &amp;B);  // Dot product\n\n        // ============================================================================\n        // Linear Algebra - Matrix Utilities\n        // ============================================================================\n        static Mat eye(int size);          // Create identity matrix\n        static Mat ones(int rows, int cols);  // Create matrix filled with ones\n        static Mat ones(int size);         // Create square matrix filled with ones\n        static Mat augment(const Mat &amp;A, const Mat &amp;B);  // Horizontal concatenation [A | B]\n        static Mat vstack(const Mat &amp;A, const Mat &amp;B);   // Vertical concatenation [A; B]\n\n        /**\n         * @brief Gram-Schmidt orthogonalization process\n         * @note Orthogonalizes a set of vectors using the Gram-Schmidt process\n         * @param vectors Input matrix where each column is a vector to be orthogonalized\n         * @param orthogonal_vectors Output matrix for orthogonalized vectors (each column is orthogonal)\n         * @param coefficients Output matrix for projection coefficients (R matrix in QR decomposition)\n         * @param tolerance Minimum norm threshold for linear independence check\n         * @return true if successful, false if input is invalid\n         */\n        static bool gram_schmidt_orthogonalize(const Mat &amp;vectors, Mat &amp;orthogonal_vectors, \n                                               Mat &amp;coefficients, float tolerance = 1e-6f);\n\n        // ============================================================================\n        // Linear Algebra - Matrix Operations\n        // ============================================================================\n        Mat minor(int target_row, int target_col);       // Minor matrix (submatrix after removing row and col)\n        Mat cofactor(int target_row, int target_col);    // Cofactor matrix\n        Mat gaussian_eliminate() const;    // Gaussian elimination\n        Mat row_reduce_from_gaussian();   // Row reduction from Gaussian form\n        Mat inverse_gje();                 // Inverse using Gaussian-Jordan elimination\n\n        // ============================================================================\n        // Linear Algebra - Linear System Solving\n        // ============================================================================\n        Mat solve(const Mat &amp;A, const Mat &amp;b) const;  // Solve Ax = b using Gaussian elimination\n        Mat band_solve(Mat A, Mat b, int k);          // Solve banded system\n        Mat roots(Mat A, Mat y);                      // Alternative solve method\n\n        // ============================================================================\n        // Matrix Decomposition\n        // ============================================================================\n        // Forward declarations (structures defined after class)\n        struct LUDecomposition;\n        struct CholeskyDecomposition;\n        struct QRDecomposition;\n        struct SVDDecomposition;\n\n        // Matrix property checks\n        /**\n         * @brief Check if the matrix is symmetric within a given tolerance.\n         * @param tolerance Maximum allowed difference between A(i,j) and A(j,i) (must be &gt;= 0)\n         * @return true if matrix is symmetric, false otherwise\n         */\n        bool is_symmetric(float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Check if matrix is positive definite using Sylvester's criterion.\n         * @param tolerance Tolerance for numerical checks (must be &gt;= 0)\n         * @param max_minors_to_check Maximum number of leading principal minors to check.\n         *                            - If -1: check all minors (complete Sylvester's criterion)\n         *                            - If &gt; 0: check first max_minors_to_check minors\n         * @return true if matrix is positive definite, false otherwise\n         */\n        bool is_positive_definite(float tolerance = 1e-6f, int max_minors_to_check = -1) const;\n\n        // Decomposition methods\n        LUDecomposition lu_decompose(bool use_pivoting = true) const;\n        CholeskyDecomposition cholesky_decompose() const;\n        QRDecomposition qr_decompose() const;\n        SVDDecomposition svd_decompose(int max_iter = 100, float tolerance = 1e-6f) const;\n\n        // Solve using decomposition (more efficient for multiple RHS)\n        static Mat solve_lu(const LUDecomposition &amp;lu, const Mat &amp;b);\n        static Mat solve_cholesky(const CholeskyDecomposition &amp;chol, const Mat &amp;b);\n        static Mat solve_qr(const QRDecomposition &amp;qr, const Mat &amp;b);  // Least squares solution\n\n        // Pseudo-inverse using SVD (for rank-deficient or non-square matrices)\n        static Mat pseudo_inverse(const SVDDecomposition &amp;svd, float tolerance = 1e-6f);\n\n        // ============================================================================\n        // Eigenvalue &amp; Eigenvector Decomposition\n        // ============================================================================\n        // Forward declarations (structures defined after class)\n        struct EigenPair;\n        struct EigenDecomposition;\n\n        // Single eigenvalue methods (fast, for real-time applications)\n        /**\n         * @brief Compute the dominant (largest magnitude) eigenvalue and eigenvector using power iteration.\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when |\u03bb_k - \u03bb_{k-1}| &lt; tolerance * |\u03bb_k|\n         * @return EigenPair containing the dominant eigenvalue, eigenvector, and status\n         */\n        EigenPair power_iteration(int max_iter = 1000, float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Compute the smallest (minimum magnitude) eigenvalue and eigenvector using inverse power iteration.\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when |\u03bb_k - \u03bb_{k-1}| &lt; tolerance * max(|\u03bb_k|, 1)\n         * @return EigenPair containing the smallest eigenvalue, eigenvector, and status\n         * @note The matrix must be invertible (non-singular) for this method to work.\n         */\n        EigenPair inverse_power_iteration(int max_iter = 1000, float tolerance = 1e-6f) const;\n\n        // Complete eigendecomposition methods\n        /**\n         * @brief Compute complete eigenvalue decomposition using Jacobi method for symmetric matrices.\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when max off-diagonal &lt; tolerance\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @return EigenDecomposition containing all eigenvalues, eigenvectors, and status\n         * @note Best for symmetric matrices. Matrix should be symmetric for best results.\n         */\n        EigenDecomposition eigendecompose_jacobi(float tolerance = 1e-6f, int max_iter = 100) const;\n\n        /**\n         * @brief Compute complete eigenvalue decomposition using QR algorithm for general matrices.\n         * @param max_iter Maximum number of QR iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when subdiagonal &lt; tolerance\n         * @return EigenDecomposition containing eigenvalues, eigenvectors, and status\n         * @note Supports non-symmetric matrices, but may have complex eigenvalues (only real part returned).\n         */\n        EigenDecomposition eigendecompose_qr(int max_iter = 100, float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Automatic eigenvalue decomposition with method selection.\n         * @param tolerance Convergence tolerance (must be &gt;= 0)\n         * @return EigenDecomposition containing eigenvalues, eigenvectors, and status\n         * @note Automatically selects Jacobi method for symmetric matrices, QR algorithm for general matrices.\n         */\n        EigenDecomposition eigendecompose(float tolerance = 1e-6f) const;\n\n    protected:\n\n    private:\n\n    };\n\n    // ============================================================================\n    // Matrix Decomposition Structures\n    // ============================================================================\n    /**\n     * @brief Structure to hold LU decomposition results\n     * @note A = L * U, where L is lower triangular and U is upper triangular\n     */\n    struct Mat::LUDecomposition\n    {\n        Mat L;                 ///&lt; Lower triangular matrix (with unit diagonal)\n        Mat U;                 ///&lt; Upper triangular matrix\n        Mat P;                 ///&lt; Permutation matrix (if pivoting used)\n        bool pivoted;          ///&lt; Whether pivoting was used\n        tiny_error_t status;   ///&lt; Computation status\n\n        LUDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold Cholesky decomposition results\n     * @note A = L * L^T, where L is lower triangular (for symmetric positive definite matrices)\n     */\n    struct Mat::CholeskyDecomposition\n    {\n        Mat L;                 ///&lt; Lower triangular matrix\n        tiny_error_t status;   ///&lt; Computation status\n\n        CholeskyDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold QR decomposition results\n     * @note A = Q * R, where Q is orthogonal and R is upper triangular\n     */\n    struct Mat::QRDecomposition\n    {\n        Mat Q;                 ///&lt; Orthogonal matrix (Q^T * Q = I)\n        Mat R;                 ///&lt; Upper triangular matrix\n        tiny_error_t status;   ///&lt; Computation status\n\n        QRDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold SVD decomposition results\n     * @note A = U * S * V^T, where U and V are orthogonal, S is diagonal (singular values)\n     */\n    struct Mat::SVDDecomposition\n    {\n        Mat U;                 ///&lt; Left singular vectors (orthogonal matrix)\n        Mat S;                 ///&lt; Singular values (diagonal matrix or vector)\n        Mat V;                 ///&lt; Right singular vectors (orthogonal matrix, V^T)\n        int rank;              ///&lt; Numerical rank of the matrix\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        SVDDecomposition();\n    };\n\n    // ============================================================================\n    // Eigenvalue &amp; Eigenvector Decomposition Structures\n    // ============================================================================\n    /**\n     * @brief Structure to hold a single eigenvalue-eigenvector pair\n     * @note Used primarily for power iteration method\n     */\n    struct Mat::EigenPair\n    {\n        float eigenvalue;      ///&lt; Eigenvalue (real part)\n        Mat eigenvector;       ///&lt; Corresponding eigenvector (column vector)\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        EigenPair();\n    };\n\n    /**\n     * @brief Structure to hold complete eigenvalue decomposition results\n     * @note Contains all eigenvalues and eigenvectors\n     */\n    struct Mat::EigenDecomposition\n    {\n        Mat eigenvalues;       ///&lt; Eigenvalues (diagonal matrix or vector)\n        Mat eigenvectors;      ///&lt; Eigenvector matrix (each column is an eigenvector)\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        EigenDecomposition();\n    };\n\n    // ============================================================================\n    // Stream Operators\n    // ============================================================================\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n    std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n\n    // ============================================================================\n    // Global Arithmetic Operators\n    // ============================================================================\n    Mat operator+(const Mat &amp;A, const Mat &amp;B);\n    Mat operator+(const Mat &amp;A, float C);\n    Mat operator-(const Mat &amp;A, const Mat &amp;B);\n    Mat operator-(const Mat &amp;A, float C);\n    Mat operator*(const Mat &amp;A, const Mat &amp;B);\n    Mat operator*(const Mat &amp;A, float C);\n    Mat operator*(float C, const Mat &amp;A);\n    Mat operator/(const Mat &amp;A, float C);\n    Mat operator/(const Mat &amp;A, const Mat &amp;B);\n    bool operator==(const Mat &amp;A, const Mat &amp;B);\n\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-metadata","title":"MATRIX METADATA","text":"<p>Matrix Structure</p> <p>The Mat class uses a row-major storage layout with support for padding and stride. This design enables efficient memory access patterns and compatibility with DSP libraries.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#core-dimensions","title":"Core Dimensions","text":"<ul> <li> <p><code>int row</code> : Number of rows in the matrix.</p> </li> <li> <p><code>int col</code> : Number of columns in the matrix.</p> </li> <li> <p><code>int element</code> : Total number of elements = rows \u00d7 cols.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#memory-layout","title":"Memory Layout","text":"<ul> <li> <p><code>int stride</code> : Stride = (number of elements in a row) + padding. The stride determines how many elements to skip to move to the next row in memory.</p> </li> <li> <p><code>int pad</code> : Number of padding elements between two rows. Padding is used for memory alignment and DSP optimization.</p> </li> <li> <p><code>int memory</code> : Size of the data buffer = rows \u00d7 stride (in number of float elements).</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#data-pointers","title":"Data Pointers","text":"<ul> <li> <p><code>float *data</code> : Pointer to the data buffer containing matrix elements. Elements are stored in row-major order: element at (i, j) is at <code>data[i * stride + j]</code>.</p> </li> <li> <p><code>float *temp</code> : Pointer to the temporary data buffer (if allocated). Used internally for certain operations.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#memory-management-flags","title":"Memory Management Flags","text":"<ul> <li> <p><code>bool ext_buff</code> : Flag indicating that the matrix uses an external buffer. When <code>true</code>, the destructor will not free the memory (caller is responsible).</p> </li> <li> <p><code>bool sub_matrix</code> : Flag indicating that the matrix is a subset/view of another matrix. When <code>true</code>, the matrix shares data with the parent matrix.</p> </li> </ul> <p>Memory Layout Example</p> <p>For a 3\u00d74 matrix with stride=4 (no padding): <pre><code>[a b c d]   row 0: data[0*4+0] to data[0*4+3]\n[e f g h]   row 1: data[1*4+0] to data[1*4+3]\n[i j k l]   row 2: data[2*4+0] to data[2*4+3]\n</code></pre></p> <p>For a 3\u00d74 matrix with stride=6 (padding=2): <pre><code>[a b c d _ _]   row 0: data[0*6+0] to data[0*6+3], padding at data[0*6+4,5]\n[e f g h _ _]   row 1: data[1*6+0] to data[1*6+3], padding at data[1*6+4,5]\n[i j k l _ _]   row 2: data[2*6+0] to data[2*6+3], padding at data[2*6+4,5]\n</code></pre></p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-structure","title":"ROI STRUCTURE","text":"<p>Region of Interest</p> <p>The ROI (Region of Interest) structure represents a rectangular subregion of a matrix. It's used with <code>view_roi()</code> and <code>copy_roi()</code> functions to extract or reference submatrices efficiently.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-metadata","title":"ROI Metadata","text":"<ul> <li> <p><code>int pos_x</code> : Starting column index (x-coordinate of the top-left corner).</p> </li> <li> <p><code>int pos_y</code> : Starting row index (y-coordinate of the top-left corner).</p> </li> <li> <p><code>int width</code> : Width of the ROI in columns.</p> </li> <li> <p><code>int height</code> : Height of the ROI in rows.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-constructor","title":"ROI Constructor","text":"<pre><code>Mat::ROI::ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n</code></pre> <p>Description: </p> <p>ROI constructor initializes the ROI with the specified position and size.</p> <p>Parameters:</p> <ul> <li> <p><code>int pos_x</code> : Starting column index.</p> </li> <li> <p><code>int pos_y</code> : Starting row index.</p> </li> <li> <p><code>int width</code> : Width of the ROI (columns).</p> </li> <li> <p><code>int height</code> : Height of the ROI (rows).</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-resize","title":"ROI RESIZE","text":"<pre><code>void Mat::ROI::resize_roi(int pos_x, int pos_y, int width, int height);\n</code></pre> <p>Description: </p> <p>Resizes the ROI to the specified position and size.</p> <p>Parameters:</p> <ul> <li> <p><code>int pos_x</code> : Starting column index.</p> </li> <li> <p><code>int pos_y</code> : Starting row index.</p> </li> <li> <p><code>int width</code> : Width of the ROI (columns).</p> </li> <li> <p><code>int height</code> : Height of the ROI (rows).</p> </li> </ul> <p>Returns:</p> <p>void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#area-roi","title":"AREA ROI","text":"<pre><code>int Mat::ROI::area_roi(void) const;\n</code></pre> <p>Description: </p> <p>Calculates the area of the ROI.</p> <p>Parameters:</p> <p>void</p> <p>Returns:</p> <p>int - Area of the ROI.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#printing-functions","title":"PRINTING FUNCTIONS","text":"<p>Debugging Tools</p> <p>These functions are essential for debugging and understanding matrix state. Use them to verify matrix dimensions, memory layout, and data values during development.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#print-matrix-information","title":"Print Matrix Information","text":"<pre><code>void Mat::print_info() const;\n</code></pre> <p>Description: </p> <p>Prints comprehensive matrix information including:</p> <ul> <li> <p>Dimensions: rows, columns, elements</p> </li> <li> <p>Memory layout: paddings, stride, memory size</p> </li> <li> <p>Pointers: data buffer address, temporary buffer address</p> </li> <li> <p>Flags: external buffer usage, sub-matrix status</p> </li> <li> <p>Warnings: dimension mismatches, invalid states</p> </li> </ul> <p>Parameters:</p> <p>void</p> <p>Returns:</p> <p>void</p> <p>Usage Insights:</p> <ul> <li> <p>Debugging: Essential for verifying matrix state and detecting memory issues.</p> </li> <li> <p>Memory Analysis: Shows actual memory usage vs. logical size, helping identify memory inefficiencies.</p> </li> <li> <p>Sub-Matrix Detection: Clearly indicates if a matrix is a view, which affects memory management.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#print-matrix-elements","title":"Print Matrix Elements","text":"<pre><code>void Mat::print_matrix(bool show_padding);\n</code></pre> <p>Description: </p> <p>Prints the matrix elements in a formatted table. Optionally displays padding elements separated by a visual separator.</p> <p>Parameters: </p> <ul> <li><code>bool show_padding</code> : If <code>true</code>, displays padding values with a separator <code>|</code>. If <code>false</code>, only shows actual matrix elements.</li> </ul> <p>Returns:</p> <p>void</p> <p>Usage Insights:</p> <ul> <li> <p>Formatting: Elements are formatted with fixed width (12 characters) for alignment.</p> </li> <li> <p>Padding Visualization: The <code>show_padding</code> option helps understand memory layout and verify padding values.</p> </li> <li> <p>Large Matrices: For very large matrices, consider using <code>view_roi()</code> to print specific regions.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructors-destructor","title":"CONSTRUCTORS &amp; DESTRUCTOR","text":"<p>Memory Management</p> <p>Constructors handle memory allocation automatically. The destructor safely frees memory only if it was internally allocated (not external buffers or views). Always check the <code>data</code> pointer after construction to ensure successful allocation.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#memory-allocation","title":"Memory Allocation","text":"<pre><code>void Mat::alloc_mem();\n</code></pre> <p>Description: </p> <p>Internal function that allocates memory for the matrix according to the computed memory requirements. Sets <code>ext_buff = false</code> and allocates <code>row * stride</code> float elements.</p> <p>Parameters:</p> <p>void</p> <p>Returns:</p> <p>void</p> <p>Usage Insights:</p> <ul> <li> <p>Automatic Call: Called automatically by constructors. Rarely needs manual invocation.</p> </li> <li> <p>Memory Calculation: Allocates <code>row * stride</code> elements, which may include padding.</p> </li> <li> <p>Error Handling: If allocation fails, <code>data</code> remains <code>nullptr</code>. Always check <code>data</code> after construction.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#default-constructor","title":"Default Constructor","text":"<pre><code>Mat::Mat();\n</code></pre> <p>Description: </p> <p>Default constructor creates a 1\u00d71 zero matrix. This is useful for initialization and as a return value for error cases.</p> <p>Mathematical Principle:</p> <p>Creates the identity element for matrix operations in some contexts, though typically you'll want to specify dimensions.</p> <p>Parameters:</p> <p>void</p> <p>Returns:</p> <p>Mat - A 1\u00d71 matrix with element = 0.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matint-rows-int-cols","title":"Constructor - Mat(int rows, int cols)","text":"<pre><code>Mat::Mat(int rows, int cols);\n</code></pre> <p>Description: </p> <p>Constructor creates a matrix with specified dimensions. All elements are initialized to zero. This is the most commonly used constructor.</p> <p>Parameters:</p> <ul> <li> <p><code>int rows</code> : Number of rows (must be &gt; 0).</p> </li> <li> <p><code>int cols</code> : Number of columns (must be &gt; 0).</p> </li> </ul> <p>Returns:</p> <p>Mat - A rows\u00d7cols matrix with all elements initialized to 0.</p> <p>Usage Insights:</p> <ul> <li> <p>Zero Initialization: All elements are set to zero using <code>memset</code>, ensuring clean state.</p> </li> <li> <p>Memory Layout: Creates a contiguous memory layout with no padding (stride = cols).</p> </li> <li> <p>Error Handling: If memory allocation fails, <code>data</code> will be <code>nullptr</code>. Always verify allocation success.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matint-rows-int-cols-int-stride","title":"Constructor - Mat(int rows, int cols, int stride)","text":"<pre><code>Mat::Mat(int rows, int cols, int stride);\n</code></pre> <p>Description: </p> <p>Constructor creates a matrix with specified dimensions and stride. Useful when you need padding for memory alignment or DSP optimization.</p> <p>Parameters:</p> <ul> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> <li> <p><code>int stride</code> : Stride (must be \u2265 cols). Padding = stride - cols.</p> </li> </ul> <p>Returns:</p> <p>Mat - A rows\u00d7cols matrix with stride, all elements initialized to 0.</p> <p>Usage Insights:</p> <ul> <li> <p>DSP Optimization: Some DSP libraries require aligned memory. Use stride to ensure proper alignment.</p> </li> <li> <p>Memory Efficiency: Padding allows efficient vectorized operations on aligned boundaries.</p> </li> <li> <p>Compatibility: Enables compatibility with external libraries that use strided memory layouts.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matfloat-data-int-rows-int-cols","title":"Constructor - Mat(float *data, int rows, int cols)","text":"<pre><code>Mat::Mat(float *data, int rows, int cols);\n</code></pre> <p>Description: </p> <p>Constructor creates a matrix view over an external data buffer. The matrix does not own the memory; the caller is responsible for managing it. Useful for interfacing with existing data arrays.</p> <p>Parameters:</p> <ul> <li> <p><code>float *data</code> : Pointer to external data buffer (must remain valid for matrix lifetime).</p> </li> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> </ul> <p>Returns:</p> <p>Mat - A matrix view with <code>ext_buff = true</code>.</p> <p>Usage Insights:</p> <ul> <li> <p>Zero-Copy: No memory copy occurs; the matrix directly references external data.</p> </li> <li> <p>Lifetime Management: The external buffer must remain valid while the matrix exists. The destructor will not free this memory.</p> </li> <li> <p>Data Layout: Assumes row-major layout with no padding (stride = cols).</p> </li> <li> <p>Use Cases: </p> </li> <li> <p>Wrapping C arrays</p> </li> <li> <p>Interfacing with other libraries</p> </li> <li> <p>Avoiding unnecessary copies</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#constructor-matfloat-data-int-rows-int-cols-int-stride","title":"Constructor - Mat(float *data, int rows, int cols, int stride)","text":"<pre><code>Mat::Mat(float *data, int rows, int cols, int stride);\n</code></pre> <p>Description: </p> <p>Constructor creates a matrix view over an external data buffer with specified stride. Supports strided memory layouts for DSP compatibility.</p> <p>Parameters:</p> <ul> <li> <p><code>float *data</code> : Pointer to external data buffer (must remain valid for matrix lifetime).</p> </li> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> <li> <p><code>int stride</code> : Stride (must be \u2265 cols).</p> </li> </ul> <p>Returns:</p> <p>Mat - A matrix view with <code>ext_buff = true</code> and specified stride.</p> <p>Usage Insights:</p> <ul> <li> <p>Strided Layouts: Essential for working with DSP libraries that use strided memory layouts.</p> </li> <li> <p>Memory Safety: Same lifetime requirements as the previous constructor - external buffer must remain valid.</p> </li> <li> <p>Padding Support: Can handle buffers with padding between rows.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#copy-constructor-matconst-mat-src","title":"Copy Constructor - Mat(const Mat &amp;src)","text":"<pre><code>Mat::Mat(const Mat &amp;src);\n</code></pre> <p>Description: </p> <p>Copy constructor creates a new matrix from a source matrix. Uses intelligent copying: deep copy for regular matrices, shallow copy for sub-matrix views.</p> <p>Copy Strategy:</p> <ul> <li> <p>Regular matrices: Deep copy - allocates new memory and copies all data</p> </li> <li> <p>Sub-matrix views: Shallow copy - shares data with source (creates another view)</p> </li> </ul> <p>Parameters:</p> <ul> <li><code>const Mat &amp;src</code> : Source matrix.</li> </ul> <p>Returns:</p> <p>Mat - A new matrix with copied or shared data depending on source type.</p> <p>Usage Insights:</p> <ul> <li> <p>Automatic Selection: Automatically chooses deep or shallow copy based on source matrix type.</p> </li> <li> <p>Memory Efficiency: Sub-matrix views are copied shallowly to avoid unnecessary memory allocation.</p> </li> <li> <p>Independence: Deep copies are independent; modifications don't affect the source.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#destructor","title":"Destructor","text":"<pre><code>Mat::~Mat();\n</code></pre> <p>Description: </p> <p>Destructor safely releases allocated memory. Only frees memory if it was internally allocated (<code>ext_buff = false</code>). External buffers and views are not freed.</p> <p>Memory Management:</p> <ul> <li> <p>Frees <code>data</code> buffer if <code>ext_buff = false</code></p> </li> <li> <p>Frees <code>temp</code> buffer if allocated</p> </li> <li> <p>Does nothing for external buffers or views</p> </li> </ul> <p>Parameters:</p> <p>void</p> <p>Returns:</p> <p>void</p> <p>Constructor and Destructor Rules</p> <ul> <li>Constructor functions must have the same name as the class and no return type</li> <li>C++ allows function overloading by changing parameter number/order</li> <li>The destructor is automatically called when the object goes out of scope</li> <li>Always check <code>data != nullptr</code> after construction to verify successful allocation</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#element-access","title":"ELEMENT ACCESS","text":"<p>Matrix Indexing</p> <p>The Mat class uses operator overloading to provide intuitive matrix element access. The <code>operator()</code> allows natural syntax like <code>A(i, j)</code> instead of <code>A.data[i * stride + j]</code>. The implementation automatically handles stride and padding.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#access-matrix-elements-non-const","title":"Access Matrix Elements (Non-Const)","text":"<pre><code>inline float &amp;operator()(int row, int col);\n</code></pre> <p>Description:</p> <p>Accesses matrix elements with read-write capability. Returns a reference to the element, allowing both reading and modification.</p> <p>Mathematical Principle:</p> <p>Element at position (row, col) is accessed as <code>data[row * stride + col]</code>, where stride accounts for padding.</p> <p>Parameters\uff1a</p> <ul> <li> <p><code>int row</code> : Row index (0-based, must be in range [0, row-1]).</p> </li> <li> <p><code>int col</code> : Column index (0-based, must be in range [0, col-1]).</p> </li> </ul> <p>Returns:</p> <p><code>float&amp;</code> - Reference to the matrix element, enabling modification.</p> <p>Usage Insights:</p> <ul> <li> <p>Bounds Checking: No automatic bounds checking for performance. Ensure indices are valid.</p> </li> <li> <p>Stride Handling: Automatically accounts for stride, so it works correctly with padded matrices.</p> </li> <li> <p>Performance: Inline function with minimal overhead, suitable for tight loops.</p> </li> <li> <p>Example: <code>A(2, 3) = 5.0f;</code> sets element at row 2, column 3 to 5.0.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#access-matrix-elements-const","title":"Access Matrix Elements (Const)","text":"<pre><code>inline const float &amp;operator()(int row, int col) const;\n</code></pre> <p>Description:</p> <p>Accesses matrix elements in read-only mode. Returns a const reference, preventing modification. Used when the matrix is const.</p> <p>Parameters\uff1a</p> <ul> <li> <p><code>int row</code> : Row index (0-based).</p> </li> <li> <p><code>int col</code> : Column index (0-based).</p> </li> </ul> <p>Returns:</p> <p><code>const float&amp;</code> - Const reference to the matrix element (read-only).</p> <p>Usage Insights:</p> <ul> <li> <p>Const Correctness: Enables proper const-correct code. Use this version in const member functions.</p> </li> <li> <p>Safety: Prevents accidental modification of const matrices.</p> </li> </ul> <p>Operator Overloading</p> <p>These functions overload the <code>()</code> operator, enabling natural matrix indexing syntax: <pre><code>Mat A(3, 4);\nA(1, 2) = 3.14f;        // Write access\nfloat val = A(1, 2);    // Read access\nconst Mat&amp; B = A;\nfloat val2 = B(1, 2);   // Read-only access (uses const version)\n</code></pre></p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#data-manipulation","title":"DATA MANIPULATION","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#copy-other-matrix-into-this-matrix-as-a-sub-matrix","title":"Copy other matrix into this matrix as a sub-matrix","text":"<pre><code>tiny_error_t Mat::copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n</code></pre> <p>Description:</p> <p>Copies the specified source matrix into this matrix as a sub-matrix starting from the specified row and column positions, not sharing the data buffer.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;src</code> : Source matrix.</p> </li> <li> <p><code>int row_pos</code> : Starting row position.</p> </li> <li> <p><code>int col_pos</code> : Starting column position.</p> </li> </ul> <p>Returns:</p> <p>tiny_error_t - Error code (TINY_OK on success).</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#copy-header-of-other-matrix-to-this-matrix","title":"Copy header of other matrix to this matrix","text":"<pre><code>tiny_error_t Mat::copy_head(const Mat &amp;src);\n</code></pre> <p>Description:</p> <p>Copies the header of the specified source matrix to this matrix, sharing the data buffer. All items copy the source matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;src</code> : Source matrix.</li> </ul> <p>Returns:</p> <p>tiny_error_t - Error code.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-view-shallow-copy-of-sub-matrix-roi-from-this-matrix","title":"Get a view (shallow copy) of sub-matrix (ROI) from this matrix","text":"<pre><code>Mat Mat::view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n</code></pre> <p>Description:</p> <p>Gets a view (shallow copy) of the sub-matrix (ROI) from this matrix starting from the specified row and column positions.</p> <p>Parameters:</p> <ul> <li> <p><code>int start_row</code> : Starting row position.</p> </li> <li> <p><code>int start_col</code> : Starting column position.</p> </li> <li> <p><code>int roi_rows</code> : Number of rows in the ROI.</p> </li> <li> <p><code>int roi_cols</code> : Number of columns in the ROI.</p> </li> </ul> <p>Warning</p> <p>Unlike ESP-DSP, view_roi does not allow to setup stride as it will automatically calculate the stride based on the number of columns and paddings. The function will also refuse illegal requests, i.e., out of bound requests. </p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-view-shallow-copy-of-sub-matrix-roi-from-this-matrix-using-roi-structure","title":"Get a view (shallow copy) of sub-matrix (ROI) from this matrix using ROI structure","text":"<pre><code>Mat Mat::view_roi(const Mat::ROI &amp;roi) const;\n</code></pre> <p>Description:</p> <p>Gets a view (shallow copy) of the sub-matrix (ROI) from this matrix using the specified ROI structure. This function will call the previous function in low level by passing the ROI structure to the parameters.</p> <p>Parameters:</p> <ul> <li><code>const Mat::ROI &amp;roi</code> : ROI structure.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-replica-deep-copy-of-sub-matrix-roi","title":"Get a replica (deep copy) of sub-matrix (ROI)","text":"<pre><code>Mat Mat::copy_roi(int start_row, int start_col, int roi_rows, int roi_cols);\n</code></pre> <p>Description:</p> <p>Gets a replica (deep copy) of the sub-matrix (ROI) from this matrix starting from the specified row and column positions. This function will return a new matrix object that does not share the data buffer with the original matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>int start_row</code> : Starting row position.</p> </li> <li> <p><code>int start_col</code> : Starting column position.</p> </li> <li> <p><code>int roi_rows</code> : Number of rows in the ROI.</p> </li> <li> <p><code>int roi_cols</code> : Number of columns in the ROI.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-replica-deep-copy-of-sub-matrix-roi-using-roi-structure","title":"Get a replica (deep copy) of sub-matrix (ROI) using ROI structure","text":"<pre><code>Mat Mat::copy_roi(const Mat::ROI &amp;roi);\n</code></pre> <p>Description:</p> <p>Gets a replica (deep copy) of the sub-matrix (ROI) from this matrix using the specified ROI structure. This function will call the previous function in low level by passing the ROI structure to the parameters.</p> <p>Parameters:</p> <ul> <li><code>const Mat::ROI &amp;roi</code> : ROI structure.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#get-a-block-of-matrix","title":"Get a block of matrix","text":"<pre><code>Mat Mat::block(int start_row, int start_col, int block_rows, int block_cols);\n</code></pre> <p>Description:</p> <p>Gets a block of the matrix starting from the specified row and column positions.</p> <p>Parameters:</p> <ul> <li> <p><code>int start_row</code> : Starting row position.</p> </li> <li> <p><code>int start_col</code> : Starting column position.</p> </li> <li> <p><code>int block_rows</code> : Number of rows in the block.</p> </li> <li> <p><code>int block_cols</code> : Number of columns in the block.</p> </li> </ul> <p>Differences between view_roi | copy_roi | block</p> <ul> <li> <p><code>view_roi</code> : Shallow copy of the sub-matrix (ROI) from this matrix.</p> </li> <li> <p><code>copy_roi</code> : Deep copy of the sub-matrix (ROI) from this matrix. Rigid and faster.</p> </li> <li> <p><code>block</code> : Deep copy of the block from this matrix. Flexible and slower.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#swap-rows","title":"Swap rows","text":"<pre><code>void Mat::swap_rows(int row1, int row2);\n</code></pre> <p>Description:</p> <p>Swaps the specified rows in the matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>int row1</code> : First row index.</p> </li> <li> <p><code>int row2</code> : Second row index.</p> </li> </ul> <p>Returns:</p> <p>void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#swap-columns","title":"Swap columns","text":"<pre><code>void Mat::swap_cols(int col1, int col2);\n</code></pre> <p>Description:</p> <p>Swaps the specified columns in the matrix. </p> <p>Parameters:</p> <ul> <li> <p><code>int col1</code> : First column index.</p> </li> <li> <p><code>int col2</code> : Second column index.</p> </li> </ul> <p>Returns:</p> <p>void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#clear-matrix","title":"Clear matrix","text":"<pre><code>void Mat::clear(void);\n</code></pre> <p>Description:</p> <p>Clears the matrix by setting all elements to zero.</p> <p>Parameters:</p> <p>void</p> <p>Returns:</p> <p>void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#arithmetic-operators","title":"ARITHMETIC OPERATORS","text":"<p>In-Place Operations</p> <p>This section defines the arithmetic operators that act on the current matrix itself (in-place operations). These operators modify the matrix and return a reference to it, enabling chained operations like <code>A += B += C</code>. The operators are optimized to handle padding and use DSP-accelerated functions when available.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#copy-assignment","title":"Copy assignment","text":"<pre><code>Mat &amp;operator=(const Mat &amp;src);\n</code></pre> <p>Description:</p> <p>Copy assignment operator for the matrix. Copies elements from source matrix to current matrix. Handles dimension changes by reallocating memory if necessary. Prevents assignment to sub-matrix views for safety.</p> <p>Mathematical Principle:</p> <p>Creates an independent copy of the source matrix. Unlike copy constructor, this is used for existing matrices.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;src</code> : Source matrix.</li> </ul> <p>Returns:</p> <p>Mat&amp; - Reference to the current matrix (enables chaining).</p> <p>Usage Insights:</p> <ul> <li> <p>Memory Management: Automatically reallocates memory if dimensions differ. Frees old memory if it was internally allocated.</p> </li> <li> <p>Sub-Matrix Protection: Assignment to sub-matrix views is forbidden to prevent accidental data corruption.</p> </li> <li> <p>Self-Assignment: Handles self-assignment safely (A = A).</p> </li> <li> <p>Performance: O(n\u00b2) for n\u00d7n matrices. For large matrices, consider if a view would suffice.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#add-matrix","title":"Add matrix","text":"<pre><code>Mat &amp;operator+=(const Mat &amp;A);\n</code></pre> <p>Description:</p> <p>Adds the specified matrix to this matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;A</code> : Matrix to be added.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#add-constant","title":"Add constant","text":"<pre><code>Mat &amp;operator+=(float C);\n</code></pre> <p>Description:</p> <p>Element-wise addition of a constant to this matrix.</p> <p>Parameters:</p> <ul> <li><code>float C</code> : The constant to add.</li> </ul> <p>Returns:</p> <p>Mat&amp; - Reference to the current matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#subtract-matrix","title":"Subtract matrix","text":"<pre><code>Mat &amp;operator-=(const Mat &amp;A);\n</code></pre> <p>Description:</p> <p>Subtracts the specified matrix from this matrix.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;A</code> : Matrix to be subtracted.</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#subtract-constant","title":"Subtract constant","text":"<pre><code>Mat &amp;operator-=(float C);\n</code></pre> <p>Description:</p> <p>Element-wise subtraction of a constant from this matrix.</p> <p>Parameters:</p> <ul> <li><code>float C</code> : The constant to subtract.</li> </ul> <p>Returns:</p> <p>Mat&amp; - Reference to the current matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-matrix","title":"Multiply matrix","text":"<pre><code>Mat &amp;operator*=(const Mat &amp;A);\n</code></pre> <p>Description:</p> <p>Matrix multiplication: this = this * A. Performs standard matrix multiplication (not element-wise). The number of columns of the current matrix must equal the number of rows of A.</p> <p>Mathematical Principle:</p> <p>Matrix multiplication C = A * B where C\u1d62\u2c7c = \u03a3\u2096 A\u1d62\u2096 * B\u2096\u2c7c. This is the standard matrix product, not element-wise multiplication.</p> <p>Dimension Requirements:  - Current matrix: m \u00d7 n</p> <ul> <li> <p>Matrix A: n \u00d7 p</p> </li> <li> <p>Result: m \u00d7 p</p> </li> </ul> <p>Parameters:</p> <ul> <li><code>const Mat &amp;A</code> : Matrix to be multiplied (must have n rows, where n = current matrix columns).</li> </ul> <p>Returns:</p> <p>Mat&amp; - Reference to the current matrix.</p> <p>Usage Insights:</p> <ul> <li> <p>Memory Efficiency: Creates a temporary copy to avoid overwriting data during computation, then updates the current matrix.</p> </li> <li> <p>Padding Support: Handles matrices with padding using specialized DSP functions when available.</p> </li> <li> <p>Performance: O(mnp) for m\u00d7n * n\u00d7p multiplication. Uses optimized DSP functions on ESP32 platform.</p> </li> <li> <p>Common Mistake: This is matrix multiplication, not element-wise. For element-wise, use a loop with <code>operator()()</code>.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-constant","title":"Multiply constant","text":"<pre><code>Mat &amp;operator*=(float C);\n</code></pre> <p>Description:</p> <p>Element-wise multiplication by a constant.</p> <p>Parameters:</p> <ul> <li><code>float C</code> : The constant multiplier.</li> </ul> <p>Returns:</p> <p>Mat&amp; - Reference to the current matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#divide-matrix-element-wise","title":"Divide matrix (element-wise)","text":"<pre><code>Mat &amp;operator/=(const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Element-wise division: this = this / B.</p> <p>Parameters:</p> <ul> <li><code>const Mat &amp;B</code> : The matrix divisor.</li> </ul> <p>Returns:</p> <p>Mat&amp; - Reference to the current matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#divide-constant","title":"Divide constant","text":"<pre><code>Mat &amp;operator/=(float C);\n</code></pre> <p>Description:</p> <p>Element-wise division of this matrix by a constant.</p> <p>Parameters:</p> <ul> <li><code>float C</code> : The constant divisor.</li> </ul> <p>Returns:</p> <p>Mat&amp; - Reference to the current matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#exponentiation","title":"Exponentiation","text":"<pre><code>Mat operator^(int C);\n</code></pre> <p>Description:</p> <p>Element-wise integer exponentiation. Returns a new matrix where each element is raised to the given power.</p> <p>Parameters:</p> <ul> <li><code>int C</code> : The exponent (integer).</li> </ul> <p>Returns:</p> <p>Mat - New matrix after exponentiation.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#linear-algebra","title":"LINEAR ALGEBRA","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#transpose","title":"Transpose","text":"<pre><code>Mat Mat::transpose();\n</code></pre> <p>Description:</p> <p>Calculates the transpose of the matrix, returning a new matrix. The transpose A^T of a matrix A is obtained by interchanging rows and columns: (A^T)\u1d62\u2c7c = A\u2c7c\u1d62.</p> <p>Mathematical Principle:  - For any matrix A, (A<sup>T)</sup>T = A</p> <ul> <li> <p>(A + B)^T = A^T + B^T</p> </li> <li> <p>(AB)^T = B^T * A^T</p> </li> <li> <p>For square matrices, det(A) = det(A^T)</p> </li> </ul> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p>Mat - Transposed matrix (col \u00d7 row).</p> <p>Usage Insights:</p> <ul> <li> <p>Memory Layout: Creates a new matrix, so memory usage doubles temporarily. For large matrices, consider memory constraints.</p> </li> <li> <p>Symmetric Matrices: If A = A^T, the matrix is symmetric. Use <code>is_symmetric()</code> to check.</p> </li> <li> <p>Applications: </p> </li> <li> <p>Inner products: u^T * v</p> </li> <li> <p>Quadratic forms: x^T * A * x</p> </li> <li> <p>Matrix equations: A^T * A (normal equations)</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#minor-matrix","title":"Minor matrix","text":"<pre><code>Mat Mat::minor(int row, int col);\n</code></pre> <p>Description:</p> <p>Calculates the minor matrix by removing the specified row and column. The minor is the submatrix obtained by removing one row and one column.</p> <p>Parameters: </p> <ul> <li> <p><code>int row</code>: Row index to remove.</p> </li> <li> <p><code>int col</code>: Column index to remove.</p> </li> </ul> <p>Returns:</p> <p>Mat - The (n-1)x(n-1) minor matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#cofactor-matrix","title":"Cofactor matrix","text":"<pre><code>Mat Mat::cofactor(int row, int col);\n</code></pre> <p>Description:</p> <p>Calculates the cofactor matrix (same as minor matrix). The cofactor matrix is the same as the minor matrix. The sign (-1)^(i+j) is applied when computing the cofactor value, not to the matrix elements themselves.</p> <p>Parameters: </p> <ul> <li> <p><code>int row</code>: Row index to remove.</p> </li> <li> <p><code>int col</code>: Column index to remove.</p> </li> </ul> <p>Returns:</p> <p>Mat - The (n-1)x(n-1) cofactor matrix (same as minor matrix).</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#determinant-auto-select-method","title":"Determinant (Auto-select Method)","text":"<pre><code>float Mat::determinant();\n</code></pre> <p>Description: </p> <p>Computes the determinant of a square matrix, automatically selecting the optimal method based on matrix size. For small matrices (n \u2264 4), uses Laplace expansion; for larger matrices (n &gt; 4), uses LU decomposition for better efficiency.</p> <p>Mathematical Principle: </p> <p>The determinant is an important numerical characteristic of a square matrix with the following properties:</p> <ul> <li> <p>det(AB) = det(A) * det(B)</p> </li> <li> <p>det(A^T) = det(A)</p> </li> <li> <p>det(A^(-1)) = 1 / det(A)</p> </li> <li> <p>If A is singular, det(A) = 0</p> </li> </ul> <p>Method Selection:</p> <ul> <li> <p>Small matrices (n \u2264 4): Uses <code>determinant_laplace()</code> - Laplace expansion method, time complexity O(n!), more accurate for small matrices</p> </li> <li> <p>Large matrices (n &gt; 4): Uses <code>determinant_lu()</code> - LU decomposition method, time complexity O(n\u00b3), more efficient</p> </li> </ul> <p>Parameters:</p> <p>None.</p> <p>Returns: </p> <p>float - The determinant value.</p> <p>Usage Insights:</p> <ul> <li> <p>Automatic Selection: For most applications, simply use <code>determinant()</code> and the function will automatically select the optimal method</p> </li> <li> <p>Performance Optimization: If you need to compute determinants of matrices of the same size multiple times, consider directly calling <code>determinant_lu()</code> or <code>determinant_gaussian()</code></p> </li> <li> <p>Precision Requirements: For small matrices, <code>determinant_laplace()</code> may provide better numerical precision</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#determinant-laplace-expansion","title":"Determinant - Laplace Expansion","text":"<pre><code>float Mat::determinant_laplace();\n</code></pre> <p>Description: </p> <p>Computes the determinant of a square matrix using Laplace expansion (cofactor expansion). Time complexity is O(n!), suitable only for small matrices (n \u2264 4).</p> <p>Mathematical Principle: </p> <p>Laplace expansion is the recursive definition of the determinant:</p> <ul> <li> <p>For 1\u00d71 matrix: det([a]) = a</p> </li> <li> <p>For 2\u00d72 matrix: det([[a,b],[c,d]]) = ad - bc</p> </li> <li> <p>For n\u00d7n matrix: det(A) = \u03a3\u2c7c\u208c\u2081\u207f (-1)\u2071\u207a\u02b2 a\u1d62\u2c7c * det(M\u1d62\u2c7c), where M\u1d62\u2c7c is the minor matrix</p> </li> </ul> <p>This implementation uses first-row expansion, recursively computing the determinant of minors.</p> <p>Parameters:</p> <p>None.</p> <p>Returns: </p> <p>float - The determinant value.</p> <p>Performance Warning</p> <p>Time complexity is O(n!), suitable only for small matrices (n \u2264 4). For large matrices, use <code>determinant_lu()</code> or <code>determinant_gaussian()</code>.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#determinant-lu-decomposition","title":"Determinant - LU Decomposition","text":"<pre><code>float Mat::determinant_lu();\n</code></pre> <p>Description: </p> <p>Computes the determinant of a square matrix using LU decomposition. Time complexity is O(n\u00b3), suitable for large matrices.</p> <p>Mathematical Principle: </p> <p>LU decomposition factorizes the matrix as A = P * L * U, where:</p> <ul> <li> <p>P is a permutation matrix (if pivoting is used)</p> </li> <li> <p>L is a lower triangular matrix with unit diagonal</p> </li> <li> <p>U is an upper triangular matrix</p> </li> </ul> <p>Determinant formula: det(A) = det(P) * det(L) * det(U)</p> <p>Where:</p> <ul> <li> <p>det(P) = (-1)^(permutation signature), determined by the number of row swaps</p> </li> <li> <p>det(L) = 1 (since L has unit diagonal)</p> </li> <li> <p>det(U) = \u220f\u1d62 U\u1d62\u1d62 (product of diagonal elements of U)</p> </li> </ul> <p>Algorithm Steps:</p> <ol> <li>Perform LU decomposition (with pivoting for numerical stability)</li> <li>Compute the determinant of the permutation matrix det(P)</li> <li>Compute the product of diagonal elements of U: det(U)</li> <li>Return det(P) * det(U)</li> </ol> <p>Parameters:</p> <p>None.</p> <p>Returns: </p> <p>float - The determinant value. Returns 0.0 if the matrix is singular or near-singular.</p> <p>Usage Insights:</p> <ul> <li> <p>Efficiency: Much faster than Laplace expansion for matrices with n &gt; 4</p> </li> <li> <p>Numerical Stability: Uses pivoting to improve numerical stability</p> </li> <li> <p>Singular Matrices: If the matrix is singular, LU decomposition fails and the function returns 0.0</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#determinant-gaussian-elimination","title":"Determinant - Gaussian Elimination","text":"<pre><code>float Mat::determinant_gaussian();\n</code></pre> <p>Description: </p> <p>Computes the determinant of a square matrix using Gaussian elimination. Time complexity is O(n\u00b3), suitable for large matrices.</p> <p>Mathematical Principle: </p> <p>Gaussian elimination converts the matrix to upper triangular form, then computes the product of diagonal elements. The determinant value equals the product of diagonal elements of the upper triangular matrix, adjusted for the sign based on the number of row swaps.</p> <p>Algorithm Steps:</p> <ol> <li>Use partial pivoting Gaussian elimination to convert matrix to upper triangular form</li> <li>Track the number of row swaps</li> <li>Compute the product of diagonal elements of the upper triangular matrix</li> <li>Adjust the sign based on row swaps: each row swap multiplies the determinant by -1</li> </ol> <p>Parameters:</p> <p>None.</p> <p>Returns: </p> <p>float - The determinant value. Returns 0.0 if the matrix is singular.</p> <p>Usage Insights:</p> <ul> <li> <p>Efficiency: Time complexity O(n\u00b3) for large matrices, comparable to LU decomposition</p> </li> <li> <p>Numerical Stability: Uses partial pivoting to improve numerical stability</p> </li> <li> <p>Implementation Simplicity: More intuitive than LU decomposition, but less versatile (cannot be used for solving linear systems)</p> </li> <li> <p>Applications:</p> </li> <li> <p>Check invertibility: det(A) \u2260 0 means A is invertible</p> </li> <li> <p>Volume scaling: |det(A)| is the scaling factor of the linear transformation</p> </li> <li> <p>System solvability: det(A) = 0 indicates singular system</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#adjoint","title":"Adjoint","text":"<pre><code>Mat Mat::adjoint();\n</code></pre> <p>Description:</p> <p>Calculates the adjoint (adjugate) matrix of a square matrix.</p> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p>Mat - Adjoint matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#normalize","title":"Normalize","text":"<pre><code>void Mat::normalize();\n</code></pre> <p>Description:</p> <p>Normalizes the matrix using L2 norm (Frobenius norm). After normalization, ||Matrix|| = 1.</p> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p>void</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#norm","title":"Norm","text":"<pre><code>float Mat::norm() const;\n</code></pre> <p>Description:</p> <p>Calculates the Frobenius norm (also called Euclidean norm or L2 norm) of the matrix. The Frobenius norm is the square root of the sum of squares of all matrix elements.</p> <p>Mathematical Principle:  - Frobenius norm: ||A||_F = \u221a(\u03a3\u1d62 \u03a3\u2c7c |a\u1d62\u2c7c|\u00b2) = \u221a(trace(A^T * A)) - For vectors, this reduces to the standard L2 norm - Properties:   - ||A + B||_F \u2264 ||A||_F + ||B||_F (triangle inequality)   - ||AB||_F \u2264 ||A||_F * ||B||_F   - ||A||_F = ||A^T||_F</p> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p>float - The computed matrix norm.</p> <p>Usage Insights:</p> <ul> <li> <p>Error Measurement: Useful for measuring the \"size\" of a matrix or error in numerical computations.</p> </li> <li> <p>Normalization: Used in <code>normalize()</code> to scale matrices to unit norm.</p> </li> <li> <p>Convergence: Often used as a convergence criterion in iterative algorithms.</p> </li> <li> <p>Comparison: For vectors, this is equivalent to the standard Euclidean norm ||v||\u2082.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#inverse-using-adjoint","title":"Inverse using Adjoint","text":"<pre><code>Mat Mat::inverse_adjoint();\n</code></pre> <p>Description:</p> <p>Computes the inverse of a square matrix using adjoint method. If the matrix is singular, returns a zero matrix.</p> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p>Mat - The inverse matrix. If singular, returns a zero matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#identity-matrix","title":"Identity Matrix","text":"<pre><code>static Mat Mat::eye(int size);\n</code></pre> <p>Description:</p> <p>Generates an identity matrix of given size.</p> <p>Parameters: </p> <ul> <li><code>int size</code> : Dimension of the square identity matrix.</li> </ul> <p>Returns:</p> <p>Mat - Identity matrix (size x size).</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#augmentation-matrix-horizontal-concatenation","title":"Augmentation Matrix (Horizontal Concatenation)","text":"<pre><code>static Mat Mat::augment(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Creates an augmented matrix by horizontally concatenating two matrices [A | B]. The row counts of A and B must match.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Left matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Right matrix.</p> </li> </ul> <p>Returns:</p> <p>Mat - Augmented matrix [A B].</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#vertical-stack","title":"Vertical Stack","text":"<pre><code>static Mat Mat::vstack(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Vertically stacks two matrices [A; B]. The column counts of A and B must match.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Top matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Bottom matrix.</p> </li> </ul> <p>Returns:</p> <p>Mat - Vertically stacked matrix [A; B].</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#gram-schmidt-orthogonalization","title":"Gram-Schmidt Orthogonalization","text":"<pre><code>static bool Mat::gram_schmidt_orthogonalize(const Mat &amp;vectors, Mat &amp;orthogonal_vectors, \n                                            Mat &amp;coefficients, float tolerance = 1e-6f);\n</code></pre> <p>Description:</p> <p>Orthogonalizes a set of vectors using the Gram-Schmidt process. This is a general-purpose orthogonalization function that can be reused for QR decomposition and other applications requiring orthogonal bases. Uses the modified Gram-Schmidt algorithm with re-orthogonalization for improved numerical stability.</p> <p>Mathematical Principle:</p> <p>Given a set of vectors {v\u2081, v\u2082, ..., v\u2099}, the Gram-Schmidt process produces an orthogonal set {q\u2081, q\u2082, ..., q\u2099} where:</p> <ul> <li> <p>q\u2081 = v\u2081 / ||v\u2081||</p> </li> <li> <p>q\u2c7c = (v\u2c7c - \u03a3\u1d62\u208c\u2081\u02b2\u207b\u00b9\u27e8v\u2c7c, q\u1d62\u27e9q\u1d62) / ||v\u2c7c - \u03a3\u1d62\u208c\u2081\u02b2\u207b\u00b9\u27e8v\u2c7c, q\u1d62\u27e9q\u1d62||</p> </li> </ul> <p>The modified version subtracts projections immediately, which improves numerical stability.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;vectors</code> : Input matrix where each column is a vector to be orthogonalized (m \u00d7 n).</p> </li> <li> <p><code>Mat &amp;orthogonal_vectors</code> : Output matrix for orthogonalized vectors (m \u00d7 n), each column is orthogonal and normalized.</p> </li> <li> <p><code>Mat &amp;coefficients</code> : Output matrix for projection coefficients (n \u00d7 n, upper triangular), similar to R in QR decomposition.</p> </li> <li> <p><code>float tolerance</code> : Minimum norm threshold for linear independence check (default: 1e-6).</p> </li> </ul> <p>Returns:</p> <p><code>bool</code> - <code>true</code> if successful, <code>false</code> if input is invalid.</p> <p>Usage Insights:</p> <ul> <li> <p>Numerical Stability: The implementation uses modified Gram-Schmidt with re-orthogonalization, which significantly improves stability for near-linearly-dependent vectors.</p> </li> <li> <p>QR Decomposition: This function is internally used by <code>qr_decompose()</code>. For QR decomposition, the coefficients matrix corresponds to the R matrix.</p> </li> <li> <p>Basis Construction: Useful for constructing orthogonal bases from a set of vectors, which is fundamental in many linear algebra applications.</p> </li> <li> <p>Performance: For large matrices, consider the computational cost. The complexity is O(mn\u00b2) for m-dimensional vectors and n vectors.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#all-ones-matrix-rectangular","title":"All-Ones Matrix (Rectangular)","text":"<pre><code>static Mat Mat::ones(int rows, int cols);\n</code></pre> <p>Description:</p> <p>Creates a matrix of specified size filled with ones.</p> <p>Parameters:</p> <ul> <li> <p><code>int rows</code> : Number of rows.</p> </li> <li> <p><code>int cols</code> : Number of columns.</p> </li> </ul> <p>Returns:</p> <p>Mat - Matrix [rows x cols] with all elements = 1.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#all-ones-matrix-square","title":"All-Ones Matrix (Square)","text":"<pre><code>static Mat Mat::ones(int size);\n</code></pre> <p>Description:</p> <p>Creates a square matrix filled with ones of the specified size.</p> <p>Parameters:</p> <ul> <li><code>int size</code> : Size of the square matrix (rows = cols).</li> </ul> <p>Returns:</p> <p>Mat - Square matrix [size x size] with all elements = 1.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#gaussian-elimination","title":"Gaussian Elimination","text":"<pre><code>Mat Mat::gaussian_eliminate() const;\n</code></pre> <p>Description:</p> <p>Performs Gaussian Elimination to convert matrix to Row Echelon Form (REF). This is the first step in solving linear systems and computing matrix rank.</p> <p>Mathematical Principle:</p> <p>Gaussian elimination transforms a matrix into row echelon form through elementary row operations:</p> <ol> <li> <p>Row swapping: Exchange two rows</p> </li> <li> <p>Row scaling: Multiply a row by a non-zero scalar</p> </li> <li> <p>Row addition: Add a multiple of one row to another</p> </li> </ol> <p>Row Echelon Form (REF) properties:</p> <ul> <li> <p>All zero rows are at the bottom</p> </li> <li> <p>The leading coefficient (pivot) of each non-zero row is to the right of the pivot in the row above</p> </li> <li> <p>All entries below a pivot are zero</p> </li> </ul> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p>Mat - The upper triangular matrix (REF form).</p> <p>Usage Insights:</p> <ul> <li> <p>Linear System Solving: First step in solving Ax = b. After REF, use back substitution.</p> </li> <li> <p>Rank Computation: The rank equals the number of non-zero rows in REF.</p> </li> <li> <p>Determinant: Can compute determinant from REF (product of diagonal elements, adjusted for row swaps).</p> </li> <li> <p>Numerical Stability: The implementation uses partial pivoting to improve numerical stability.</p> </li> <li> <p>Performance: O(n\u00b3) for n\u00d7n matrices. For multiple systems, prefer LU decomposition.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#row-reduce-from-gaussian","title":"Row Reduce from Gaussian","text":"<pre><code>Mat Mat::row_reduce_from_gaussian();\n</code></pre> <p>Description:</p> <p>Converts a matrix (assumed in row echelon form) to Reduced Row Echelon Form (RREF).</p> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p>Mat - The matrix in RREF form.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#inverse-using-gaussian-jordan-elimination","title":"Inverse using Gaussian-Jordan Elimination","text":"<pre><code>Mat Mat::inverse_gje();\n</code></pre> <p>Description:</p> <p>Computes the inverse of a square matrix using Gauss-Jordan elimination.</p> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p>Mat - The inverse matrix if invertible, otherwise returns empty matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#dot-product","title":"Dot Product","text":"<pre><code>float Mat::dotprod(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Calculates the dot product of two vectors (Nx1).</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Input vector A (Nx1).</p> </li> <li> <p><code>const Mat &amp;B</code> : Input vector B (Nx1).</p> </li> </ul> <p>Returns:</p> <p>float - The computed dot product value.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#solve-linear-system","title":"Solve Linear System","text":"<pre><code>Mat Mat::solve(const Mat &amp;A, const Mat &amp;b) const;\n</code></pre> <p>Description:</p> <p>Solves the linear system Ax = b using Gaussian elimination with back substitution. This is a direct method suitable for well-conditioned systems.</p> <p>Mathematical Principle:</p> <p>The method consists of two phases:</p> <ol> <li> <p>Forward elimination: Transform augmented matrix [A|b] to upper triangular form</p> </li> <li> <p>Back substitution: Solve Ux = y from bottom to top</p> </li> </ol> <p>Algorithm:</p> <ul> <li> <p>Create augmented matrix [A | b]</p> </li> <li> <p>Apply Gaussian elimination to get [U | y] where U is upper triangular</p> </li> <li> <p>Solve Ux = y using back substitution: x\u1d62 = (y\u1d62 - \u03a3\u2c7c\u208c\u1d62\u208a\u2081\u207f U\u1d62\u2c7cx\u2c7c) / U\u1d62\u1d62</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Coefficient matrix (N\u00d7N), must be square and non-singular.</p> </li> <li> <p><code>const Mat &amp;b</code> : Right-hand side vector (N\u00d71).</p> </li> </ul> <p>Returns:</p> <p>Mat - Solution vector (N\u00d71) containing the roots of the equation Ax = b. Returns empty matrix if system is singular or incompatible.</p> <p>Usage Insights:</p> <ul> <li> <p>Single System: Efficient for solving one system. For multiple systems with same A, use LU decomposition + <code>solve_lu()</code>.</p> </li> <li> <p>Condition Number: Performance degrades for ill-conditioned matrices. Check condition number if results are inaccurate.</p> </li> <li> <p>Singular Systems: Returns empty matrix if A is singular (det(A) = 0). Use SVD + pseudo-inverse for rank-deficient systems.</p> </li> <li> <p>Performance: O(n\u00b3) for elimination, O(n\u00b2) for back substitution. Total O(n\u00b3).</p> </li> <li> <p>Alternative Methods:</p> </li> <li> <p>For SPD matrices: Use Cholesky decomposition + <code>solve_cholesky()</code> (faster)</p> </li> <li> <p>For multiple RHS: Use LU decomposition + <code>solve_lu()</code> (more efficient)</p> </li> <li> <p>For overdetermined: Use QR decomposition + <code>solve_qr()</code> (least squares)</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#band-solve","title":"Band Solve","text":"<pre><code>Mat Mat::band_solve(Mat A, Mat b, int k);\n</code></pre> <p>Description:</p> <p>Solves the system of equations Ax = b using optimized Gaussian elimination for banded matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>Mat A</code> : Coefficient matrix (NxN) - banded matrix.</p> </li> <li> <p><code>Mat b</code> : Result vector (Nx1).</p> </li> <li> <p><code>int k</code> : Bandwidth of the matrix (the width of the non-zero bands).</p> </li> </ul> <p>Returns:</p> <p>Mat - Solution vector (Nx1) containing the roots of the equation Ax = b.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roots","title":"Roots","text":"<pre><code>Mat Mat::roots(Mat A, Mat y);\n</code></pre> <p>Description:</p> <p>Solves the matrix using a different method. Another implementation of the 'solve' function, no difference in principle. This method solves the linear system A * x = y using Gaussian elimination.</p> <p>Parameters:</p> <ul> <li> <p><code>Mat A</code> : Matrix [N]x[N] with input coefficients.</p> </li> <li> <p><code>Mat y</code> : Vector [N]x[1] with result values.</p> </li> </ul> <p>Returns:</p> <p>Mat - Matrix [N]x[1] with roots.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-properties-decompositions","title":"MATRIX PROPERTIES &amp; DECOMPOSITIONS","text":"<p>Matrix Decompositions Overview</p> <p>Matrix decompositions are fundamental tools in numerical linear algebra. They break down a matrix into simpler components that reveal its structure and enable efficient computations. Different decompositions are suited for different types of matrices and applications.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-property-checks","title":"Matrix Property Checks","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#check-symmetry","title":"Check Symmetry","text":"<pre><code>bool Mat::is_symmetric(float tolerance = 1e-6f) const;\n</code></pre> <p>Description:</p> <p>Check whether a matrix is symmetric within the given tolerance. A matrix A is symmetric if A = A^T, i.e., A(i,j) = A(j,i) for all i, j.</p> <p>Mathematical Principle:</p> <p>For a symmetric matrix, all eigenvalues are real, and eigenvectors can be chosen to be orthogonal. Symmetric matrices are fundamental in many applications, especially in structural dynamics and optimization.</p> <p>Parameters:</p> <ul> <li><code>float tolerance</code> : Maximum allowed difference |A(i,j) - A(j,i)| (default: 1e-6).</li> </ul> <p>Returns:</p> <p><code>bool</code> - <code>true</code> if approximately symmetric, <code>false</code> otherwise.</p> <p>Usage Insights:</p> <ul> <li> <p>Eigendecomposition: Symmetric matrices can use more efficient and stable eigendecomposition methods (e.g., Jacobi method).</p> </li> <li> <p>Cholesky Decomposition: Only symmetric positive definite matrices can be decomposed using Cholesky decomposition.</p> </li> <li> <p>Structural Dynamics: Stiffness and mass matrices in structural analysis are typically symmetric.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#check-positive-definiteness","title":"Check Positive Definiteness","text":"<pre><code>bool Mat::is_positive_definite(float tolerance = 1e-6f) const;\n</code></pre> <p>Description:</p> <p>Check if a matrix is positive definite using Sylvester's criterion. A symmetric matrix A is positive definite if x^T A x &gt; 0 for all non-zero vectors x, or equivalently, all eigenvalues are positive.</p> <p>Mathematical Principle:</p> <p>Sylvester's criterion states that a symmetric matrix is positive definite if and only if all leading principal minors are positive. The function checks the first few leading minors and diagonal elements for efficiency.</p> <p>Parameters:</p> <ul> <li><code>float tolerance</code> : Tolerance for numerical checks (default: 1e-6).</li> </ul> <p>Returns:</p> <p><code>bool</code> - <code>true</code> if matrix is positive definite, <code>false</code> otherwise.</p> <p>Usage Insights:</p> <ul> <li> <p>Cholesky Decomposition: Positive definite matrices can be decomposed using Cholesky decomposition, which is faster and more stable than LU decomposition.</p> </li> <li> <p>Optimization: Positive definite Hessian matrices indicate local minima in optimization problems.</p> </li> <li> <p>Stability Analysis: In control systems, positive definiteness of certain matrices ensures system stability.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-decomposition-structures","title":"Matrix Decomposition Structures","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#lu-decomposition-structure","title":"LU Decomposition Structure","text":"<pre><code>struct Mat::LUDecomposition\n{\n    Mat L;                 // Lower triangular matrix (with unit diagonal)\n    Mat U;                 // Upper triangular matrix\n    Mat P;                 // Permutation matrix (if pivoting used)\n    bool pivoted;          // Whether pivoting was used\n    tiny_error_t status;   // Computation status\n\n    LUDecomposition();\n};\n</code></pre> <p>Description:</p> <p>Container for LU decomposition results. The decomposition A = P * L * U (with pivoting) or A = L * U (without pivoting), where L is lower triangular with unit diagonal, U is upper triangular, and P is a permutation matrix.</p> <p>Mathematical Principle:</p> <p>LU decomposition factors a matrix into lower and upper triangular matrices, enabling efficient solution of linear systems. With pivoting, it handles near-singular matrices better.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#cholesky-decomposition-structure","title":"Cholesky Decomposition Structure","text":"<pre><code>struct Mat::CholeskyDecomposition\n{\n    Mat L;                 // Lower triangular matrix\n    tiny_error_t status;   // Computation status\n\n    CholeskyDecomposition();\n};\n</code></pre> <p>Description:</p> <p>Container for Cholesky decomposition results. For symmetric positive definite matrices, A = L * L^T, where L is lower triangular.</p> <p>Mathematical Principle:</p> <p>Cholesky decomposition is a specialized LU decomposition for symmetric positive definite matrices. It requires only half the storage and computation of LU decomposition.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#qr-decomposition-structure","title":"QR Decomposition Structure","text":"<pre><code>struct Mat::QRDecomposition\n{\n    Mat Q;                 // Orthogonal matrix (Q^T * Q = I)\n    Mat R;                 // Upper triangular matrix\n    tiny_error_t status;   // Computation status\n\n    QRDecomposition();\n};\n</code></pre> <p>Description:</p> <p>Container for QR decomposition results. A = Q * R, where Q is orthogonal (Q^T * Q = I) and R is upper triangular.</p> <p>Mathematical Principle:</p> <p>QR decomposition expresses a matrix as the product of an orthogonal matrix and an upper triangular matrix. It's numerically stable and fundamental for least squares problems.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#svd-decomposition-structure","title":"SVD Decomposition Structure","text":"<pre><code>struct Mat::SVDDecomposition\n{\n    Mat U;                 // Left singular vectors (orthogonal matrix)\n    Mat S;                 // Singular values (diagonal matrix or vector)\n    Mat V;                 // Right singular vectors (orthogonal matrix, V^T)\n    int rank;              // Numerical rank of the matrix\n    int iterations;        // Number of iterations performed\n    tiny_error_t status;   // Computation status\n\n    SVDDecomposition();\n};\n</code></pre> <p>Description:</p> <p>Container for SVD decomposition results. A = U * S * V^T, where U and V are orthogonal matrices, and S contains singular values on the diagonal.</p> <p>Mathematical Principle:</p> <p>SVD is the most general matrix decomposition. The singular values reveal the matrix's rank, condition number, and enable computation of pseudo-inverse for rank-deficient matrices.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-decomposition-methods","title":"Matrix Decomposition Methods","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#lu-decomposition","title":"LU Decomposition","text":"<pre><code>Mat::LUDecomposition Mat::lu_decompose(bool use_pivoting = true) const;\n</code></pre> <p>Description:</p> <p>Compute LU decomposition: A = P * L * U (with pivoting) or A = L * U (without pivoting). Efficient for solving multiple systems with the same coefficient matrix.</p> <p>Mathematical Principle: </p> <ul> <li> <p>Without pivoting: A = L * U, where L has unit diagonal</p> </li> <li> <p>With pivoting: P * A = L * U, where P is a permutation matrix</p> </li> </ul> <p>The decomposition enables solving Ax = b by solving Ly = Pb (forward substitution) then Ux = y (back substitution).</p> <p>Parameters:</p> <ul> <li><code>bool use_pivoting</code> : Whether to use partial pivoting for numerical stability (default: true).</li> </ul> <p>Returns:</p> <p><code>LUDecomposition</code> containing L, U, P matrices and status.</p> <p>Usage Insights:</p> <ul> <li> <p>Multiple RHS: Once decomposed, solve multiple systems with different right-hand sides efficiently using <code>solve_lu()</code>.</p> </li> <li> <p>Determinant: det(A) = det(P) * det(L) * det(U) = det(P) * det(U) (since det(L) = 1).</p> </li> <li> <p>Inverse: Can compute A^(-1) by solving LUx = e\u1d62 for each unit vector e\u1d62.</p> </li> <li> <p>Performance: O(n\u00b3) for decomposition, O(n\u00b2) for each solve after decomposition.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#cholesky-decomposition","title":"Cholesky Decomposition","text":"<pre><code>Mat::CholeskyDecomposition Mat::cholesky_decompose() const;\n</code></pre> <p>Description:</p> <p>Compute Cholesky decomposition: A = L * L^T for symmetric positive definite matrices. Faster than LU for SPD matrices, commonly used in structural dynamics.</p> <p>Mathematical Principle:</p> <p>For a symmetric positive definite matrix A, there exists a unique lower triangular matrix L with positive diagonal elements such that A = L * L^T. This is essentially a specialized LU decomposition that takes advantage of symmetry.</p> <p>Parameters:</p> <p>None (matrix must be symmetric positive definite).</p> <p>Returns:</p> <p><code>CholeskyDecomposition</code> containing L matrix and status.</p> <p>Usage Insights:</p> <ul> <li> <p>Efficiency: Requires approximately half the computation and storage of LU decomposition.</p> </li> <li> <p>Stability: More stable than LU for symmetric positive definite matrices.</p> </li> <li> <p>Applications: </p> </li> <li> <p>Structural dynamics: Mass and stiffness matrices are often SPD</p> </li> <li> <p>Optimization: Hessian matrices in Newton's method</p> </li> <li> <p>Statistics: Covariance matrices</p> </li> <li> <p>Error Handling: Returns error if matrix is not symmetric or not positive definite.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#qr-decomposition","title":"QR Decomposition","text":"<pre><code>Mat::QRDecomposition Mat::qr_decompose() const;\n</code></pre> <p>Description:</p> <p>Compute QR decomposition: A = Q * R, where Q is orthogonal and R is upper triangular. Numerically stable, used for least squares and orthogonalization.</p> <p>Mathematical Principle:</p> <p>QR decomposition expresses any matrix as the product of an orthogonal matrix Q (Q^T * Q = I) and an upper triangular matrix R. The decomposition is computed using the modified Gram-Schmidt process with re-orthogonalization.</p> <p>Parameters:</p> <p>None.</p> <p>Returns:</p> <p><code>QRDecomposition</code> containing Q and R matrices and status.</p> <p>Usage Insights:</p> <ul> <li> <p>Least Squares: For overdetermined system Ax \u2248 b, the solution minimizes ||Ax - b||\u2082 is x = R^(-1) * Q^T * b.</p> </li> <li> <p>Numerical Stability: QR decomposition is more stable than normal equations for least squares problems.</p> </li> <li> <p>Eigendecomposition: QR algorithm uses QR decomposition iteratively to find eigenvalues.</p> </li> <li> <p>Rank Revealing: The rank of A equals the number of non-zero diagonal elements of R.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#svd-decomposition","title":"SVD Decomposition","text":"<pre><code>Mat::SVDDecomposition Mat::svd_decompose(int max_iter = 100, float tolerance = 1e-6f) const;\n</code></pre> <p>Description:</p> <p>Compute Singular Value Decomposition: A = U * S * V^T. Most general decomposition, used for rank estimation, pseudo-inverse, dimension reduction. Uses iterative method based on eigendecomposition.</p> <p>Mathematical Principle:</p> <p>SVD decomposes any m \u00d7 n matrix A into: - U: m \u00d7 m orthogonal matrix (left singular vectors)</p> <ul> <li> <p>S: m \u00d7 n diagonal matrix (singular values \u03c3\u2081 \u2265 \u03c3\u2082 \u2265 ... \u2265 \u03c3\u1d63 \u2265 0)</p> </li> <li> <p>V: n \u00d7 n orthogonal matrix (right singular vectors)</p> </li> </ul> <p>The singular values reveal the matrix's fundamental properties: rank, condition number, and numerical behavior.</p> <p>Parameters:</p> <ul> <li> <p><code>int max_iter</code> : Maximum number of iterations (default: 100).</p> </li> <li> <p><code>float tolerance</code> : Convergence tolerance (default: 1e-6).</p> </li> </ul> <p>Returns:</p> <p><code>SVDDecomposition</code> containing U, S, V matrices, rank, and status.</p> <p>Usage Insights:</p> <ul> <li> <p>Rank Estimation: The numerical rank is the number of singular values above the tolerance threshold.</p> </li> <li> <p>Pseudo-Inverse: A\u207a = V * S\u207a * U^T, where S\u207a has 1/\u03c3\u1d62 for non-zero \u03c3\u1d62.</p> </li> <li> <p>Dimension Reduction: Truncated SVD (keeping only largest singular values) provides low-rank approximation.</p> </li> <li> <p>Condition Number: \u03ba(A) = \u03c3\u2081 / \u03c3\u1d63, where \u03c3\u1d63 is the smallest non-zero singular value.</p> </li> <li> <p>Applications: </p> </li> <li> <p>Least squares for rank-deficient systems</p> </li> <li> <p>Principal Component Analysis (PCA)</p> </li> <li> <p>Image compression</p> </li> <li> <p>Noise reduction</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#solving-linear-systems-using-decompositions","title":"Solving Linear Systems Using Decompositions","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#solve-using-lu-decomposition","title":"Solve using LU Decomposition","text":"<pre><code>static Mat Mat::solve_lu(const LUDecomposition &amp;lu, const Mat &amp;b);\n</code></pre> <p>Description:</p> <p>Solve linear system Ax = b using precomputed LU decomposition. More efficient than <code>solve()</code> when solving multiple systems with the same coefficient matrix.</p> <p>Mathematical Principle:</p> <p>Given A = P * L * U, solve Ax = b by: 1. Solve Ly = Pb (forward substitution) 2. Solve Ux = y (back substitution)</p> <p>Parameters:</p> <ul> <li> <p><code>const LUDecomposition &amp;lu</code> : Precomputed LU decomposition.</p> </li> <li> <p><code>const Mat &amp;b</code> : Right-hand side vector (N\u00d71).</p> </li> </ul> <p>Returns:</p> <p>Mat - Solution vector (N\u00d71).</p> <p>Usage Insights:</p> <ul> <li> <p>Multiple RHS: After computing LU decomposition once, solve multiple systems efficiently.</p> </li> <li> <p>Performance: O(n\u00b2) per solve vs O(n\u00b3) for full solve, significant savings for multiple RHS.</p> </li> <li> <p>Memory: Reuses the decomposition, avoiding repeated computation.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#solve-using-cholesky-decomposition","title":"Solve using Cholesky Decomposition","text":"<pre><code>static Mat Mat::solve_cholesky(const CholeskyDecomposition &amp;chol, const Mat &amp;b);\n</code></pre> <p>Description:</p> <p>Solve linear system Ax = b using precomputed Cholesky decomposition. More efficient than LU for symmetric positive definite matrices.</p> <p>Mathematical Principle:</p> <p>Given A = L * L^T, solve Ax = b by: 1. Solve Ly = b (forward substitution) 2. Solve L^T x = y (back substitution)</p> <p>Parameters:</p> <ul> <li> <p><code>const CholeskyDecomposition &amp;chol</code> : Precomputed Cholesky decomposition.</p> </li> <li> <p><code>const Mat &amp;b</code> : Right-hand side vector (N\u00d71).</p> </li> </ul> <p>Returns:</p> <p>Mat - Solution vector (N\u00d71).</p> <p>Usage Insights:</p> <ul> <li> <p>Efficiency: Faster than LU for SPD matrices, both in decomposition and solving.</p> </li> <li> <p>Stability: More numerically stable for SPD matrices.</p> </li> <li> <p>Applications: Structural dynamics, optimization, statistics.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#solve-using-qr-decomposition-least-squares","title":"Solve using QR Decomposition (Least Squares)","text":"<pre><code>static Mat Mat::solve_qr(const QRDecomposition &amp;qr, const Mat &amp;b);\n</code></pre> <p>Description:</p> <p>Solve linear system using QR decomposition. Provides least squares solution for overdetermined systems (more equations than unknowns).</p> <p>Mathematical Principle:</p> <p>For Ax \u2248 b (overdetermined), the least squares solution minimizes ||Ax - b||\u2082. Using A = Q * R: - x = R^(-1) * Q^T * b</p> <p>This avoids the numerically unstable normal equations A^T * A * x = A^T * b.</p> <p>Parameters:</p> <ul> <li> <p><code>const QRDecomposition &amp;qr</code> : Precomputed QR decomposition.</p> </li> <li> <p><code>const Mat &amp;b</code> : Right-hand side vector (M\u00d71, where M \u2265 N).</p> </li> </ul> <p>Returns:</p> <p>Mat - Least squares solution vector (N\u00d71).</p> <p>Usage Insights:</p> <ul> <li> <p>Overdetermined Systems: Handles cases where there are more equations than unknowns.</p> </li> <li> <p>Numerical Stability: More stable than solving normal equations directly.</p> </li> <li> <p>Applications: </p> </li> <li> <p>Curve fitting</p> </li> <li> <p>Data regression</p> </li> <li> <p>Signal processing</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#pseudo-inverse","title":"Pseudo-Inverse","text":"<pre><code>static Mat Mat::pseudo_inverse(const SVDDecomposition &amp;svd, float tolerance = 1e-6f);\n</code></pre> <p>Description:</p> <p>Compute the Moore-Penrose pseudo-inverse A\u207a using SVD decomposition. Works for rank-deficient or non-square matrices where the regular inverse doesn't exist.</p> <p>Mathematical Principle:</p> <p>For A = U * S * V^T, the pseudo-inverse is A\u207a = V * S\u207a * U^T, where S\u207a has 1/\u03c3\u1d62 for singular values \u03c3\u1d62 &gt; tolerance, and 0 otherwise.</p> <p>Properties of Pseudo-Inverse:</p> <ul> <li> <p>A * A\u207a * A = A</p> </li> <li> <p>A\u207a * A * A\u207a = A\u207a</p> </li> <li> <p>(A * A\u207a)^T = A * A\u207a</p> </li> <li> <p>(A\u207a * A)^T = A\u207a * A</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>const SVDDecomposition &amp;svd</code> : Precomputed SVD decomposition.</p> </li> <li> <p><code>float tolerance</code> : Threshold for singular values (default: 1e-6). Singular values below this are treated as zero.</p> </li> </ul> <p>Returns:</p> <p>Mat - Pseudo-inverse matrix.</p> <p>Usage Insights:</p> <ul> <li> <p>Rank-Deficient Systems: Provides solution for systems where A is not full rank.</p> </li> <li> <p>Minimum Norm Solution: For underdetermined systems, gives the solution with minimum ||x||\u2082.</p> </li> <li> <p>Least Squares: For overdetermined systems, gives the least squares solution.</p> </li> <li> <p>Applications:</p> </li> <li> <p>Control systems</p> </li> <li> <p>Signal processing</p> </li> <li> <p>Machine learning (regularization)</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#linear-algebra-eigenvalues-eigenvectors","title":"LINEAR ALGEBRA - Eigenvalues &amp; Eigenvectors","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#struct-mateigenpair","title":"Struct: <code>Mat::EigenPair</code>","text":"<pre><code>Mat::EigenPair::EigenPair();\n// fields:\n// float eigenvalue;      // eigenvalue (largest-magnitude for power_iteration, smallest for inverse_power_iteration)\n// Mat eigenvector;       // corresponding eigenvector (n x 1)\n// int iterations;        // number of iterations (for iterative methods)\n// tiny_error_t status;   // computation status (TINY_OK / error code)\n</code></pre> <p>Description:</p> <p>Container for a single eigenvalue/eigenvector result and related metadata. Typically returned by <code>power_iteration</code> or <code>inverse_power_iteration</code>.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#struct-mateigendecomposition","title":"Struct: <code>Mat::EigenDecomposition</code>","text":"<pre><code>Mat::EigenDecomposition::EigenDecomposition();\n// fields:\n// Mat eigenvalues;    // n x 1 matrix storing eigenvalues\n// Mat eigenvectors;   // n x n matrix, columns are eigenvectors\n// int iterations;     // iterations used by the algorithm\n// tiny_error_t status; // computation status\n</code></pre> <p>Description:</p> <p>Container for a full eigendecomposition result (all eigenvalues and eigenvectors).</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#power-iteration-dominant-eigenpair","title":"Power Iteration (dominant eigenpair)","text":"<pre><code>Mat::EigenPair Mat::power_iteration(int max_iter, float tolerance) const;\n</code></pre> <p>Description:</p> <p>Compute the dominant (largest-magnitude) eigenvalue and its eigenvector using the power iteration method. Fast method suitable for real-time SHM applications to quickly identify primary frequency.</p> <p>Mathematical Principle:</p> <p>Power iteration finds the eigenvalue with the largest absolute value by iteratively applying the matrix to a vector:</p> <ol> <li> <p>Start with random vector v\u2080</p> </li> <li> <p>Iterate: v\u2096\u208a\u2081 = A * v\u2096 / ||A * v\u2096||</p> </li> <li> <p>Eigenvalue estimate: \u03bb\u2096 = (v\u2096^T * A * v\u2096) / (v\u2096^T * v\u2096) (Rayleigh quotient)</p> </li> </ol> <p>Convergence:</p> <p>The method converges to the dominant eigenvalue if:</p> <ul> <li> <p>The dominant eigenvalue is unique (|\u03bb\u2081| &gt; |\u03bb\u2082| \u2265 ... \u2265 |\u03bb\u2099|)</p> </li> <li> <p>The initial vector has a non-zero component in the direction of the dominant eigenvector</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>int max_iter</code> : Maximum number of iterations (typical default: 1000).</p> </li> <li> <p><code>float tolerance</code> : Convergence tolerance (e.g. 1e-6). Convergence is checked by |\u03bb\u2096 - \u03bb\u2096\u208b\u2081| &lt; tolerance * |\u03bb\u2096|.</p> </li> </ul> <p>Returns:</p> <p><code>EigenPair</code> containing <code>eigenvalue</code>, <code>eigenvector</code>, <code>iterations</code>, and <code>status</code>.</p> <p>Usage Insights:</p> <ul> <li> <p>Real-Time Applications: Fast convergence for well-separated eigenvalues, suitable for real-time structural health monitoring.</p> </li> <li> <p>Initialization: The implementation uses a smart initialization strategy (sum of column absolute values) to avoid convergence to smaller eigenvalues.</p> </li> <li> <p>Convergence Rate: Convergence is linear with rate |\u03bb\u2082|/|\u03bb\u2081|. Slower when eigenvalues are close.</p> </li> <li> <p>Limitations: </p> </li> <li> <p>Only finds one eigenvalue-eigenvector pair</p> </li> <li> <p>Requires |\u03bb\u2081| &gt; |\u03bb\u2082| (dominant eigenvalue must be unique)</p> </li> <li> <p>May converge slowly if eigenvalues are close</p> </li> <li> <p>Applications:</p> </li> <li> <p>Principal component analysis (first principal component)</p> </li> <li> <p>PageRank algorithm</p> </li> <li> <p>Structural dynamics (fundamental frequency)</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#inverse-power-iteration-smallest-eigenpair","title":"Inverse Power Iteration (smallest eigenpair)","text":"<pre><code>Mat::EigenPair Mat::inverse_power_iteration(int max_iter, float tolerance) const;\n</code></pre> <p>Description:</p> <p>Compute the smallest (minimum magnitude) eigenvalue and its eigenvector using the inverse power iteration method. Critical for system identification - finds fundamental frequency/lowest mode in structural dynamics. This method is essential for SHM applications where the smallest eigenvalue corresponds to the fundamental frequency of the system.</p> <p>Mathematical Principle:</p> <p>Inverse power iteration applies power iteration to A^(-1), which has eigenvalues 1/\u03bb\u1d62. Since 1/\u03bb\u2099 is the largest eigenvalue of A^(-1), the method converges to the smallest eigenvalue of A:</p> <ol> <li> <p>Start with vector v\u2080</p> </li> <li> <p>Iterate: Solve A * y\u2096 = v\u2096, then v\u2096\u208a\u2081 = y\u2096 / ||y\u2096||</p> </li> <li> <p>Eigenvalue estimate: \u03bb\u2096 = (v\u2096^T * A * v\u2096) / (v\u2096^T * v\u2096) (Rayleigh quotient)</p> </li> </ol> <p>Convergence:</p> <p>Converges to the smallest eigenvalue if:</p> <ul> <li> <p>The smallest eigenvalue is unique (|\u03bb\u2099| &lt; |\u03bb\u2099\u208b\u2081| \u2264 ... \u2264 |\u03bb\u2081|)</p> </li> <li> <p>Matrix A is invertible (non-singular)</p> </li> <li> <p>Initial vector has component in direction of smallest eigenvector</p> </li> </ul> <p>Parameters:</p> <ul> <li> <p><code>int max_iter</code> : Maximum number of iterations (default: 1000).</p> </li> <li> <p><code>float tolerance</code> : Convergence tolerance (default: 1e-6). Uses relative tolerance: |\u03bb\u2096 - \u03bb\u2096\u208b\u2081| &lt; tolerance * max(|\u03bb\u2096|, 1.0).</p> </li> </ul> <p>Returns:</p> <p><code>EigenPair</code> containing the smallest eigenvalue, eigenvector, iterations, and status.</p> <p>Algorithm Steps:</p> <ol> <li>Initialize normalized eigenvector v (with alternating signs to avoid alignment with dominant eigenvector)</li> <li>Iterate: Solve A * y = v (equivalent to y = A^(-1) * v) using <code>solve()</code></li> <li>Normalize y to get new v</li> <li>Compute eigenvalue estimate using Rayleigh quotient: \u03bb = (v^T * A * v) / (v^T * v)</li> <li>Check convergence using relative tolerance</li> </ol> <p>Usage Insights:</p> <ul> <li> <p>System Identification: Essential for finding fundamental frequencies in structural dynamics, where the smallest eigenvalue corresponds to the lowest natural frequency.</p> </li> <li> <p>Numerical Stability: The implementation includes checks for singular matrices and handles near-singular cases gracefully.</p> </li> <li> <p>Initialization Strategy: Uses alternating sign pattern to avoid convergence to larger eigenvalues, ensuring convergence to the smallest eigenvalue.</p> </li> <li> <p>Performance: Each iteration requires solving a linear system (O(n\u00b3) for dense matrices), but typically converges in fewer iterations than power iteration.</p> </li> <li> <p>Complementary to Power Iteration: </p> </li> <li> <p>Power iteration: finds \u03bb_max (highest frequency)</p> </li> <li> <p>Inverse power iteration: finds \u03bb_min (fundamental frequency)</p> </li> <li> <p>Together they provide the frequency range of the system</p> </li> <li> <p>Applications:</p> </li> <li> <p>Structural health monitoring (fundamental frequency detection)</p> </li> <li> <p>Modal analysis (lowest mode shape)</p> </li> <li> <p>System identification</p> </li> <li> <p>Stability analysis (smallest eigenvalue indicates stability margin)</p> </li> </ul> <p>Notes:</p> <ul> <li> <p>Requires a square matrix and non-null data pointer; returns an error status otherwise.</p> </li> <li> <p>The matrix must be invertible (non-singular) for this method to work. If the matrix is singular or near-singular, the method will fail gracefully.</p> </li> <li> <p>Inverse power iteration only returns the smallest eigenpair. For full spectrum, use eigendecomposition functions below.</p> </li> <li> <p>This method is complementary to power iteration: power iteration finds the largest eigenvalue, while inverse power iteration finds the smallest eigenvalue.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#jacobi-eigendecomposition-symmetric-matrices","title":"Jacobi Eigendecomposition (symmetric matrices)","text":"<pre><code>Mat::EigenDecomposition Mat::eigendecompose_jacobi(float tolerance, int max_iter) const;\n</code></pre> <p>Description:</p> <p>Compute full eigendecomposition using the Jacobi method. Recommended for symmetric matrices (good accuracy and stability for structural dynamics applications). Robust and accurate, ideal for structural dynamics matrices in SHM.</p> <p>Mathematical Principle:</p> <p>The Jacobi method diagonalizes a symmetric matrix through a series of orthogonal similarity transformations (Givens rotations):</p> <ol> <li> <p>Find largest off-diagonal element a\u209aq</p> </li> <li> <p>Compute rotation angle \u03b8 to zero this element</p> </li> <li> <p>Apply rotation: A' = J^T * A * J, where J is the rotation matrix</p> </li> <li> <p>Repeat until all off-diagonal elements are below tolerance</p> </li> </ol> <p>Convergence:</p> <p>The method converges when the maximum off-diagonal element is below tolerance. Each rotation zeros one off-diagonal element, and the process continues until the matrix is diagonal.</p> <p>Parameters:</p> <ul> <li> <p><code>float tolerance</code> : Convergence threshold (e.g. 1e-6). Maximum allowed magnitude of off-diagonal elements.</p> </li> <li> <p><code>int max_iter</code> : Maximum iterations (e.g. 100). Typically converges in O(n\u00b2) iterations for n\u00d7n matrices.</p> </li> </ul> <p>Returns:</p> <p><code>EigenDecomposition</code> with <code>eigenvalues</code>, <code>eigenvectors</code>, <code>iterations</code>, and <code>status</code>.</p> <p>Usage Insights:</p> <ul> <li> <p>Symmetric Matrices: Designed for symmetric matrices. For non-symmetric matrices, use QR method.</p> </li> <li> <p>Numerical Stability: Very stable for symmetric matrices, with good preservation of orthogonality.</p> </li> <li> <p>Accuracy: High accuracy, suitable for applications requiring precise eigenvalue/eigenvector pairs.</p> </li> <li> <p>Performance: O(n\u00b3) per iteration, but typically requires fewer iterations than QR for symmetric matrices.</p> </li> <li> <p>Applications:</p> </li> <li> <p>Structural dynamics: Stiffness and mass matrices are symmetric</p> </li> <li> <p>Principal Component Analysis (PCA)</p> </li> <li> <p>Spectral clustering</p> </li> <li> <p>Quadratic forms optimization</p> </li> </ul> <p>Notes:</p> <p>If the matrix is not approximately symmetric the function will warn, though it may still run. For non-symmetric matrices prefer the QR method.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#qr-eigendecomposition-general-matrices","title":"QR Eigendecomposition (general matrices)","text":"<pre><code>Mat::EigenDecomposition Mat::eigendecompose_qr(int max_iter, float tolerance) const;\n</code></pre> <p>Description:</p> <p>Compute eigendecomposition using the QR algorithm. Works for general (possibly non-symmetric) matrices. Supports non-symmetric matrices, but may have complex eigenvalues (only real part returned).</p> <p>Mathematical Principle:</p> <p>The QR algorithm iteratively applies QR decomposition:</p> <ol> <li> <p>Start with A\u2080 = A</p> </li> <li> <p>For k = 0, 1, 2, ...: Compute QR decomposition: A\u2096 = Q\u2096 * R\u2096, then update: A\u2096\u208a\u2081 = R\u2096 * Q\u2096</p> </li> <li> <p>A\u2096 converges to upper triangular form (Schur form), with eigenvalues on the diagonal</p> </li> </ol> <p>Convergence:</p> <p>The algorithm converges when A\u2096 is approximately upper triangular (sub-diagonal elements &lt; tolerance). The eigenvalues appear on the diagonal, and eigenvectors are accumulated from Q matrices.</p> <p>Parameters:</p> <ul> <li> <p><code>int max_iter</code> : Maximum number of QR iterations (default: 100).</p> </li> <li> <p><code>float tolerance</code> : Convergence tolerance (e.g. 1e-6). Uses relative tolerance comparing sub-diagonal elements to diagonal elements.</p> </li> </ul> <p>Returns:</p> <p><code>EigenDecomposition</code> containing eigenvalues, eigenvectors, iterations and status.</p> <p>Usage Insights:</p> <ul> <li> <p>General Matrices: Can handle non-symmetric matrices, unlike Jacobi method.</p> </li> <li> <p>Complex Eigenvalues: Non-symmetric matrices may have complex eigenvalues; current implementation returns real parts only.</p> </li> <li> <p>Numerical Stability: Uses modified Gram-Schmidt with re-orthogonalization for improved stability.</p> </li> <li> <p>Performance: O(n\u00b3) per iteration. May require many iterations for convergence, especially for ill-conditioned matrices.</p> </li> <li> <p>Convergence Acceleration: The implementation could benefit from shifts (Wilkinson shift) for faster convergence, but current version uses basic QR iteration.</p> </li> <li> <p>Applications:</p> </li> <li> <p>General matrix eigenvalue problems</p> </li> <li> <p>Dynamical systems analysis</p> </li> <li> <p>Control theory (system poles)</p> </li> </ul> <p>Notes:</p> <p>QR uses Gram\u2013Schmidt for Q/R in this implementation; it can be less stable for ill-conditioned matrices. For symmetric matrices, Jacobi is preferred due to better stability and accuracy.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#automatic-eigendecomposition","title":"Automatic Eigendecomposition","text":"<pre><code>Mat::EigenDecomposition Mat::eigendecompose(float tolerance) const;\n</code></pre> <p>Description:</p> <p>Convenience interface that automatically selects the optimal algorithm based on matrix properties. It tests symmetry with <code>is_symmetric(tolerance * 10.0f)</code>. If approximately symmetric, it uses Jacobi; otherwise it runs QR. Convenient interface for edge computing applications.</p> <p>Algorithm Selection:</p> <ol> <li>Test if matrix is symmetric: <code>is_symmetric(tolerance * 10.0f)</code></li> <li>If symmetric \u2192 use <code>eigendecompose_jacobi(tolerance, 100)</code> (more stable and accurate)</li> <li>If not symmetric \u2192 use <code>eigendecompose_qr(100, tolerance)</code> (handles general matrices)</li> </ol> <p>Parameters:</p> <ul> <li><code>float tolerance</code> : Used for symmetry test and decomposition convergence (recommended 1e-6).</li> </ul> <p>Returns:</p> <p><code>EigenDecomposition</code> containing all eigenvalues and eigenvectors.</p> <p>Usage Insights:</p> <ul> <li> <p>Automatic Optimization: Saves the user from manually choosing the algorithm, while still providing optimal performance.</p> </li> <li> <p>Edge Computing: Ideal for embedded systems where you want good performance without manual tuning.</p> </li> <li> <p>Robustness: The symmetry test uses a relaxed tolerance (10\u00d7) to handle numerical errors, ensuring symmetric matrices are correctly identified.</p> </li> </ul> <p>Usage Tips:</p> <ul> <li> <p>Known Symmetry: If the matrix is known to be symmetric (e.g. stiffness or mass matrices), call <code>eigendecompose_jacobi</code> directly for best stability and slightly better performance.</p> </li> <li> <p>Unknown Properties: For general matrices or unknown symmetry, use <code>eigendecompose</code> for automatic selection.</p> </li> <li> <p>Performance Considerations: </p> </li> <li>Eigendecomposition is computationally expensive for large matrices on embedded platforms</li> <li>For n &gt; 20, consider reduced-order methods or iterative methods (power iteration) when only a few eigenvalues are needed</li> <li> <p>For real-time applications, use <code>power_iteration()</code> or <code>inverse_power_iteration()</code> for single eigenvalues</p> </li> <li> <p>Memory Usage: Full eigendecomposition requires storing all eigenvectors (n\u00d7n matrix), which can be memory-intensive for large matrices.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#stream-operators","title":"STREAM OPERATORS","text":""},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-output-stream-operator","title":"Matrix output stream operator","text":"<pre><code>std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n</code></pre> <p>Description:</p> <p>Overloaded output stream operator for the matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>std::ostream &amp;os</code> : Output stream.</p> </li> <li> <p><code>const Mat &amp;m</code> : Matrix to be output.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#roi-output-stream-operator","title":"ROI output stream operator","text":"<pre><code>std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n</code></pre> <p>Description:</p> <p>Overloaded output stream operator for the ROI structure.</p> <p>Parameters:</p> <ul> <li> <p><code>std::ostream &amp;os</code> : Output stream.</p> </li> <li> <p><code>const Mat::ROI &amp;roi</code> : ROI structure.</p> </li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#matrix-input-stream-operator","title":"Matrix input stream operator","text":"<pre><code>std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n</code></pre> <p>Description:</p> <p>Overloaded input stream operator for the matrix.</p> <p>Parameters:</p> <ul> <li> <p><code>std::istream &amp;is</code> : Input stream.</p> </li> <li> <p><code>Mat &amp;m</code> : Matrix to be input.</p> </li> </ul> <p>Tip</p> <p>This section is actually kind of overlapping with print function in terms of showing the matrix.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#global-arithmetic-operators","title":"GLOBAL ARITHMETIC OPERATORS","text":"<p>Non-Modifying Operations</p> <p>The operators in this section return a new matrix object, which is the result of the operation. The original matrices remain unchanged. These are functional-style operations that don't modify their operands, making them safe for use with const references and temporary objects.</p> <p>When to Use</p> <ul> <li>Use global operators (A + B) when you want to preserve original matrices</li> <li>Use member operators (A += B) when you want to modify the matrix in-place (more memory efficient)</li> </ul>"},{"location":"MATH/MATRIX/tiny-matrix-api/#add-matrix_1","title":"Add matrix","text":"<pre><code>Mat operator+(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Adds two matrices element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix A+B.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#add-constant_1","title":"Add constant","text":"<pre><code>Mat operator+(const Mat &amp;A, float C);\n</code></pre> <p>Description:</p> <p>Adds a constant to a matrix element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Input matrix A.</p> </li> <li> <p><code>float C</code> : Input constant.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix A+C.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#subtract-matrix_1","title":"Subtract matrix","text":"<pre><code>Mat operator-(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Subtracts two matrices element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix A-B.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#subtract-constant_1","title":"Subtract constant","text":"<pre><code>Mat operator-(const Mat &amp;A, float C);\n</code></pre> <p>Description:</p> <p>Subtracts a constant from a matrix element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Input matrix A.</p> </li> <li> <p><code>float C</code> : Input constant.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix A-C.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-matrix_1","title":"Multiply matrix","text":"<pre><code>Mat operator*(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Multiplies two matrices (matrix multiplication).</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix A*B.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-constant_1","title":"Multiply constant","text":"<pre><code>Mat operator*(const Mat &amp;A, float C);\n</code></pre> <p>Description:</p> <p>Multiplies a matrix by a constant element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Input matrix A.</p> </li> <li> <p><code>float C</code> : Floating point value.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix A*C.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#multiply-constant-left-side","title":"Multiply constant (left side)","text":"<pre><code>Mat operator*(float C, const Mat &amp;A);\n</code></pre> <p>Description:</p> <p>Multiplies a constant by a matrix element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>float C</code> : Floating point value.</p> </li> <li> <p><code>const Mat &amp;A</code> : Input matrix A.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix C*A.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#divide-matrix-by-constant","title":"Divide matrix (by constant)","text":"<pre><code>Mat operator/(const Mat &amp;A, float C);\n</code></pre> <p>Description:</p> <p>Divides a matrix by a constant element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Input matrix A.</p> </li> <li> <p><code>float C</code> : Floating point value.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix A/C.</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#divide-matrix-element-wise_1","title":"Divide matrix (element-wise)","text":"<pre><code>Mat operator/(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Divides matrix A by matrix B element-wise.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : Input matrix A.</p> </li> <li> <p><code>const Mat &amp;B</code> : Input matrix B.</p> </li> </ul> <p>Returns:</p> <p>Mat - Result matrix C, where C[i,j] = A[i,j]/B[i,j].</p>"},{"location":"MATH/MATRIX/tiny-matrix-api/#equality-check","title":"Equality check","text":"<pre><code>bool operator==(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>Description:</p> <p>Checks if the specified matrices are equal.</p> <p>Parameters:</p> <ul> <li> <p><code>const Mat &amp;A</code> : First matrix.</p> </li> <li> <p><code>const Mat &amp;B</code> : Second matrix.</p> </li> </ul> <p>Returns:</p> <p>bool - true if equal, false otherwise.</p>"},{"location":"MATH/MATRIX/tiny-matrix-code/","title":"CODE","text":""},{"location":"MATH/MATRIX/tiny-matrix-code/#tiny_matrixhpp","title":"tiny_matrix.hpp","text":"<pre><code>/**\n * @file tiny_matrix.hpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @note This file is built on top of the mat.h file from the ESP-DSP library.\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// TinyMath\n#include \"tiny_math_config.h\"\n#include \"tiny_vec.h\"\n#include \"tiny_mat.h\"\n\n// Standard Libraries\n#include &lt;iostream&gt;\n#include &lt;stdint.h&gt;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n// ESP32 DSP C++ Matrix library\n#include \"mat.h\"\n#endif\n\n/* STATEMENTS */\nnamespace tiny\n{\n    class Mat\n    {\n    public:\n        // ============================================================================\n        // Matrix Metadata\n        // ============================================================================\n        int row;         //&lt; number of rows\n        int col;         //&lt; number of columns\n        int pad;         //&lt; number of paddings between 2 rows\n        int stride;      //&lt; stride = (number of elements in a row) + padding\n        int element;     //&lt; number of elements = rows * cols\n        int memory;      //&lt; size of the data buffer = rows * stride\n        float *data;     //&lt; pointer to the data buffer\n        float *temp;     //&lt; pointer to the temporary data buffer\n        bool ext_buff;   //&lt; flag indicates that matrix use external buffer\n        bool sub_matrix; //&lt; flag indicates that matrix is a subset of another matrix\n\n        // ============================================================================\n        // Rectangular ROI Structure\n        // ============================================================================\n        /**\n         * @name Region of Interest (ROI) Structure\n         * @brief This is the structure for ROI\n         */\n        struct ROI\n        {\n            int pos_x;  ///&lt; starting column index\n            int pos_y;  ///&lt; starting row index\n            int width;  ///&lt; width of ROI (columns)\n            int height; ///&lt; height of ROI (rows)\n\n            ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n            void resize_roi(int pos_x, int pos_y, int width, int height);\n            int area_roi(void) const;\n        };\n\n        // ============================================================================\n        // Printing Functions\n        // ============================================================================\n        void print_info() const;\n        void print_matrix(bool show_padding) const;\n\n        // ============================================================================\n        // Constructors &amp; Destructor\n        // ============================================================================\n        /**\n         * @brief Allocate memory for the matrix according to the memory required.\n         * @note For ESP32, it will automatically determine if using RAM or PSRAM based on the size of the matrix.\n         * @note This function sets ext_buff to false and allocates memory based on row * stride.\n         *       If allocation fails or parameters are invalid, data will be set to nullptr.\n         */\n        void alloc_mem();\n\n        /**\n         * @brief Default constructor: create a 1x1 matrix with only a zero element.\n         * @note If memory allocation fails, the object will be in an invalid state (data = nullptr).\n         *       Caller should check the data pointer before using the matrix.\n         */\n        Mat();\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows and columns.\n         * @param rows Number of rows\n         * @param cols Number of columns\n         */\n        Mat(int rows, int cols);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and stride.\n         * @param rows Number of rows\n         * @param cols Number of columns\n         * @param stride Stride (number of elements in a row)\n         */\n        Mat(int rows, int cols, int stride);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n         * @param data Pointer to external data buffer\n         * @param rows Number of rows\n         * @param cols Number of columns\n         */\n        Mat(float *data, int rows, int cols);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n         * @param data Pointer to external data buffer\n         * @param rows Number of rows\n         * @param cols Number of columns\n         * @param stride Stride (number of elements in a row)\n         */\n        Mat(float *data, int rows, int cols, int stride);\n\n        /**\n         * @brief Copy constructor - create a matrix with the same properties as the source matrix.\n         * @param src Source matrix\n         */\n        Mat(const Mat &amp;src);\n\n        /**\n         * @brief Destructor - free the memory allocated for the matrix.\n         */\n        ~Mat();\n\n        // ============================================================================\n        // Element Access\n        // ============================================================================\n        inline float &amp;operator()(int row, int col) { return data[row * stride + col]; }\n        inline const float &amp;operator()(int row, int col) const { return data[row * stride + col]; }\n\n        // ============================================================================\n        // Data Manipulation\n        // ============================================================================\n        tiny_error_t copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n        tiny_error_t copy_head(const Mat &amp;src);\n        Mat view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n        Mat view_roi(const Mat::ROI &amp;roi) const;\n        Mat copy_roi(int start_row, int start_col, int height, int width);\n        Mat copy_roi(const Mat::ROI &amp;roi);\n        Mat block(int start_row, int start_col, int block_rows, int block_cols);\n        void swap_rows(int row1, int row2);\n        void swap_cols(int col1, int col2);\n        void clear(void);\n\n        // ============================================================================\n        // Arithmetic Operators\n        // ============================================================================\n        Mat &amp;operator=(const Mat &amp;src);    // Copy assignment\n        Mat &amp;operator+=(const Mat &amp;A);     // Add matrix\n        Mat &amp;operator+=(float C);          // Add constant\n        Mat &amp;operator-=(const Mat &amp;A);     // Subtract matrix\n        Mat &amp;operator-=(float C);          // Subtract constant \n        Mat &amp;operator*=(const Mat &amp;A);     // Multiply matrix\n        Mat &amp;operator*=(float C);          // Multiply constant\n        Mat &amp;operator/=(const Mat &amp;B);     // Divide matrix\n        Mat &amp;operator/=(float C);          // Divide constant\n        Mat operator^(int C);              // Exponentiation\n\n        // ============================================================================\n        // Linear Algebra - Basic Operations\n        // ============================================================================\n        Mat transpose();                   // Transpose matrix\n        float determinant();               // Compute determinant (auto-selects method based on size)\n        float determinant_laplace();        // Compute determinant using Laplace expansion (O(n!), for small matrices)\n        float determinant_lu();            // Compute determinant using LU decomposition (O(n\u00b3), efficient for large matrices)\n        float determinant_gaussian();      // Compute determinant using Gaussian elimination (O(n\u00b3), efficient for large matrices)\n        Mat adjoint();                     // Compute adjoint matrix\n        Mat inverse_adjoint();            // Compute inverse using adjoint method\n        void normalize();                  // Normalize matrix\n        float norm() const;                // Compute matrix norm\n        float dotprod(const Mat &amp;A, const Mat &amp;B);  // Dot product\n\n        // ============================================================================\n        // Linear Algebra - Matrix Utilities\n        // ============================================================================\n        static Mat eye(int size);          // Create identity matrix\n        static Mat ones(int rows, int cols);  // Create matrix filled with ones\n        static Mat ones(int size);         // Create square matrix filled with ones\n        static Mat augment(const Mat &amp;A, const Mat &amp;B);  // Horizontal concatenation [A | B]\n        static Mat vstack(const Mat &amp;A, const Mat &amp;B);   // Vertical concatenation [A; B]\n\n        /**\n         * @brief Gram-Schmidt orthogonalization process\n         * @note Orthogonalizes a set of vectors using the Gram-Schmidt process\n         * @param vectors Input matrix where each column is a vector to be orthogonalized\n         * @param orthogonal_vectors Output matrix for orthogonalized vectors (each column is orthogonal)\n         * @param coefficients Output matrix for projection coefficients (R matrix in QR decomposition)\n         * @param tolerance Minimum norm threshold for linear independence check\n         * @return true if successful, false if input is invalid\n         */\n        static bool gram_schmidt_orthogonalize(const Mat &amp;vectors, Mat &amp;orthogonal_vectors, \n                                               Mat &amp;coefficients, float tolerance = 1e-6f);\n\n        // ============================================================================\n        // Linear Algebra - Matrix Operations\n        // ============================================================================\n        Mat minor(int target_row, int target_col);       // Minor matrix (submatrix after removing row and col)\n        Mat cofactor(int target_row, int target_col);    // Cofactor matrix\n        Mat gaussian_eliminate() const;    // Gaussian elimination\n        Mat row_reduce_from_gaussian();   // Row reduction from Gaussian form\n        Mat inverse_gje();                 // Inverse using Gaussian-Jordan elimination\n\n        // ============================================================================\n        // Linear Algebra - Linear System Solving\n        // ============================================================================\n        Mat solve(const Mat &amp;A, const Mat &amp;b) const;  // Solve Ax = b using Gaussian elimination\n        Mat band_solve(Mat A, Mat b, int k);          // Solve banded system\n        Mat roots(Mat A, Mat y);                      // Alternative solve method\n\n        // ============================================================================\n        // Matrix Decomposition\n        // ============================================================================\n        // Forward declarations (structures defined after class)\n        struct LUDecomposition;\n        struct CholeskyDecomposition;\n        struct QRDecomposition;\n        struct SVDDecomposition;\n\n        // Matrix property checks\n        /**\n         * @brief Check if the matrix is symmetric within a given tolerance.\n         * @param tolerance Maximum allowed difference between A(i,j) and A(j,i) (must be &gt;= 0)\n         * @return true if matrix is symmetric, false otherwise\n         */\n        bool is_symmetric(float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Check if matrix is positive definite using Sylvester's criterion.\n         * @param tolerance Tolerance for numerical checks (must be &gt;= 0)\n         * @param max_minors_to_check Maximum number of leading principal minors to check.\n         *                            - If -1: check all minors (complete Sylvester's criterion)\n         *                            - If &gt; 0: check first max_minors_to_check minors\n         * @return true if matrix is positive definite, false otherwise\n         */\n        bool is_positive_definite(float tolerance = 1e-6f, int max_minors_to_check = -1) const;\n\n        // Decomposition methods\n        LUDecomposition lu_decompose(bool use_pivoting = true) const;\n        CholeskyDecomposition cholesky_decompose() const;\n        QRDecomposition qr_decompose() const;\n        SVDDecomposition svd_decompose(int max_iter = 100, float tolerance = 1e-6f) const;\n\n        // Solve using decomposition (more efficient for multiple RHS)\n        static Mat solve_lu(const LUDecomposition &amp;lu, const Mat &amp;b);\n        static Mat solve_cholesky(const CholeskyDecomposition &amp;chol, const Mat &amp;b);\n        static Mat solve_qr(const QRDecomposition &amp;qr, const Mat &amp;b);  // Least squares solution\n\n        // Pseudo-inverse using SVD (for rank-deficient or non-square matrices)\n        static Mat pseudo_inverse(const SVDDecomposition &amp;svd, float tolerance = 1e-6f);\n\n        // ============================================================================\n        // Eigenvalue &amp; Eigenvector Decomposition\n        // ============================================================================\n        // Forward declarations (structures defined after class)\n        struct EigenPair;\n        struct EigenDecomposition;\n\n        // Single eigenvalue methods (fast, for real-time applications)\n        /**\n         * @brief Compute the dominant (largest magnitude) eigenvalue and eigenvector using power iteration.\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when |\u03bb_k - \u03bb_{k-1}| &lt; tolerance * |\u03bb_k|\n         * @return EigenPair containing the dominant eigenvalue, eigenvector, and status\n         */\n        EigenPair power_iteration(int max_iter = 1000, float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Compute the smallest (minimum magnitude) eigenvalue and eigenvector using inverse power iteration.\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when |\u03bb_k - \u03bb_{k-1}| &lt; tolerance * max(|\u03bb_k|, 1)\n         * @return EigenPair containing the smallest eigenvalue, eigenvector, and status\n         * @note The matrix must be invertible (non-singular) for this method to work.\n         */\n        EigenPair inverse_power_iteration(int max_iter = 1000, float tolerance = 1e-6f) const;\n\n        // Complete eigendecomposition methods\n        /**\n         * @brief Compute complete eigenvalue decomposition using Jacobi method for symmetric matrices.\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when max off-diagonal &lt; tolerance\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @return EigenDecomposition containing all eigenvalues, eigenvectors, and status\n         * @note Best for symmetric matrices. Matrix should be symmetric for best results.\n         */\n        EigenDecomposition eigendecompose_jacobi(float tolerance = 1e-6f, int max_iter = 100) const;\n\n        /**\n         * @brief Compute complete eigenvalue decomposition using QR algorithm for general matrices.\n         * @param max_iter Maximum number of QR iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when subdiagonal &lt; tolerance\n         * @return EigenDecomposition containing eigenvalues, eigenvectors, and status\n         * @note Supports non-symmetric matrices, but may have complex eigenvalues (only real part returned).\n         */\n        EigenDecomposition eigendecompose_qr(int max_iter = 100, float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Automatic eigenvalue decomposition with method selection.\n         * @param tolerance Convergence tolerance (must be &gt;= 0)\n         * @return EigenDecomposition containing eigenvalues, eigenvectors, and status\n         * @note Automatically selects Jacobi method for symmetric matrices, QR algorithm for general matrices.\n         */\n        EigenDecomposition eigendecompose(float tolerance = 1e-6f) const;\n\n    protected:\n\n    private:\n\n    };\n\n    // ============================================================================\n    // Matrix Decomposition Structures\n    // ============================================================================\n    /**\n     * @brief Structure to hold LU decomposition results\n     * @note A = L * U, where L is lower triangular and U is upper triangular\n     */\n    struct Mat::LUDecomposition\n    {\n        Mat L;                 ///&lt; Lower triangular matrix (with unit diagonal)\n        Mat U;                 ///&lt; Upper triangular matrix\n        Mat P;                 ///&lt; Permutation matrix (if pivoting used)\n        bool pivoted;          ///&lt; Whether pivoting was used\n        tiny_error_t status;   ///&lt; Computation status\n\n        LUDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold Cholesky decomposition results\n     * @note A = L * L^T, where L is lower triangular (for symmetric positive definite matrices)\n     */\n    struct Mat::CholeskyDecomposition\n    {\n        Mat L;                 ///&lt; Lower triangular matrix\n        tiny_error_t status;   ///&lt; Computation status\n\n        CholeskyDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold QR decomposition results\n     * @note A = Q * R, where Q is orthogonal and R is upper triangular\n     */\n    struct Mat::QRDecomposition\n    {\n        Mat Q;                 ///&lt; Orthogonal matrix (Q^T * Q = I)\n        Mat R;                 ///&lt; Upper triangular matrix\n        tiny_error_t status;   ///&lt; Computation status\n\n        QRDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold SVD decomposition results\n     * @note A = U * S * V^T, where U and V are orthogonal, S is diagonal (singular values)\n     */\n    struct Mat::SVDDecomposition\n    {\n        Mat U;                 ///&lt; Left singular vectors (orthogonal matrix)\n        Mat S;                 ///&lt; Singular values (diagonal matrix or vector)\n        Mat V;                 ///&lt; Right singular vectors (orthogonal matrix, V^T)\n        int rank;              ///&lt; Numerical rank of the matrix\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        SVDDecomposition();\n    };\n\n    // ============================================================================\n    // Eigenvalue &amp; Eigenvector Decomposition Structures\n    // ============================================================================\n    /**\n     * @brief Structure to hold a single eigenvalue-eigenvector pair\n     * @note Used primarily for power iteration method\n     */\n    struct Mat::EigenPair\n    {\n        float eigenvalue;      ///&lt; Eigenvalue (real part)\n        Mat eigenvector;       ///&lt; Corresponding eigenvector (column vector)\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        EigenPair();\n    };\n\n    /**\n     * @brief Structure to hold complete eigenvalue decomposition results\n     * @note Contains all eigenvalues and eigenvectors\n     */\n    struct Mat::EigenDecomposition\n    {\n        Mat eigenvalues;       ///&lt; Eigenvalues (diagonal matrix or vector)\n        Mat eigenvectors;      ///&lt; Eigenvector matrix (each column is an eigenvector)\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        EigenDecomposition();\n    };\n\n    // ============================================================================\n    // Stream Operators\n    // ============================================================================\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n    std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n\n    // ============================================================================\n    // Global Arithmetic Operators\n    // ============================================================================\n    Mat operator+(const Mat &amp;A, const Mat &amp;B);\n    Mat operator+(const Mat &amp;A, float C);\n    Mat operator-(const Mat &amp;A, const Mat &amp;B);\n    Mat operator-(const Mat &amp;A, float C);\n    Mat operator*(const Mat &amp;A, const Mat &amp;B);\n    Mat operator*(const Mat &amp;A, float C);\n    Mat operator*(float C, const Mat &amp;A);\n    Mat operator/(const Mat &amp;A, float C);\n    Mat operator/(const Mat &amp;A, const Mat &amp;B);\n    bool operator==(const Mat &amp;A, const Mat &amp;B);\n\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-code/#tiny_matrixcpp","title":"tiny_matrix.cpp","text":"<pre><code>/**\n * @file tiny_matrix.cpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the source file for the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n// TinyMath\n#include \"tiny_matrix.hpp\"\n\n// Standard Libraries\n#include &lt;cstring&gt;\n#include &lt;iostream&gt;\n#include &lt;stdexcept&gt;\n#include &lt;cmath&gt;\n#include &lt;cinttypes&gt;\n#include &lt;iomanip&gt;\n#include &lt;vector&gt;\n\n/* LIBRARIE CONTENTS */\nnamespace tiny\n{\n    // ============================================================================\n    // Rectangular ROI Structure\n    // ============================================================================\n    /**\n     * @brief Construct a new Mat:: R O I:: R O I object\n     * \n     * @param pos_x \n     * @param pos_y \n     * @param width \n     * @param height \n     */\n    Mat::ROI::ROI(int pos_x, int pos_y, int width, int height)\n    {\n        this-&gt;pos_x = pos_x;\n        this-&gt;pos_y = pos_y;\n        this-&gt;width = width;\n        this-&gt;height = height;\n    }\n\n    /**\n     * @brief resize the ROI structure\n     * \n     * @param pos_x starting column\n     * @param pos_y starting row\n     * @param width number of columns\n     * @param height number of rows\n     */\n    void Mat::ROI::resize_roi(int pos_x, int pos_y, int width, int height)\n    {\n        this-&gt;pos_x = pos_x;\n        this-&gt;pos_y = pos_y;\n        this-&gt;width = width;\n        this-&gt;height = height;\n    }\n\n    /**\n     * @brief calculate the area of the ROI structure - how many elements covered\n     * \n     * @return int \n     */\n    int Mat::ROI::area_roi(void) const\n    {\n        return this-&gt;width * this-&gt;height;\n    }\n\n    // ============================================================================\n    // Printing Functions\n    // ============================================================================\n    /**\n     * @name Mat::print_info()\n     * @brief Print the header of the matrix.\n     */\n    void Mat::print_info() const\n    {\n        std::cout &lt;&lt; \"Matrix Info &gt;&gt;&gt;\\n\";\n\n        // Basic matrix metadata\n        std::cout &lt;&lt; \"rows            \" &lt;&lt; this-&gt;row &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"cols            \" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"elements        \" &lt;&lt; this-&gt;element;\n\n        // Check if elements match rows * cols\n        if (this-&gt;element != this-&gt;row * this-&gt;col)\n        {\n            std::cout &lt;&lt; \"   [Warning] Mismatch! Expected: \" &lt;&lt; (this-&gt;row * this-&gt;col);\n        }\n        std::cout &lt;&lt; \"\\n\";\n\n        std::cout &lt;&lt; \"paddings        \" &lt;&lt; this-&gt;pad &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"stride          \" &lt;&lt; this-&gt;stride &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"memory          \" &lt;&lt; this-&gt;memory &lt;&lt; \"\\n\";\n\n        // Pointer information\n        std::cout &lt;&lt; \"data pointer    \" &lt;&lt; static_cast&lt;const void *&gt;(this-&gt;data) &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"temp pointer    \" &lt;&lt; static_cast&lt;const void *&gt;(this-&gt;temp) &lt;&lt; \"\\n\";\n\n        // Flags information\n        std::cout &lt;&lt; \"ext_buff        \" &lt;&lt; this-&gt;ext_buff;\n        if (this-&gt;ext_buff)\n        {\n            std::cout &lt;&lt; \"   (External buffer or View)\";\n        }\n        std::cout &lt;&lt; \"\\n\";\n\n        std::cout &lt;&lt; \"sub_matrix      \" &lt;&lt; this-&gt;sub_matrix;\n        if (this-&gt;sub_matrix)\n        {\n            std::cout &lt;&lt; \"   (This is a Sub-Matrix View)\";\n        }\n        std::cout &lt;&lt; \"\\n\";\n\n        // State warnings\n        if (this-&gt;sub_matrix &amp;&amp; !this-&gt;ext_buff)\n        {\n            std::cout &lt;&lt; \"[Warning] Sub-matrix is marked but ext_buff is false! Potential logic error.\\n\";\n        }\n\n        if (this-&gt;data == nullptr)\n        {\n            std::cout &lt;&lt; \"[Info] No data buffer assigned to this matrix.\\n\";\n        }\n\n        std::cout &lt;&lt; \"&lt;&lt;&lt; Matrix Info\\n\";\n    }\n\n    /**\n     * @name Mat::print_matrix()\n     * @brief Print the matrix elements.\n     *\n     * @param show_padding If true, print the padding elements as well.\n     */\n    void Mat::print_matrix(bool show_padding) const\n    {\n        if (this-&gt;data == nullptr)\n        {\n            std::cout &lt;&lt; \"[Error] Cannot print matrix: data pointer is null.\\n\";\n            return;\n        }\n\n        if (this-&gt;row &lt; 0 || this-&gt;col &lt; 0 || this-&gt;stride &lt; 0)\n        {\n            std::cout &lt;&lt; \"[Error] Invalid matrix dimensions\\n\";\n            return;\n        }\n\n        if (this-&gt;stride &lt; this-&gt;col)\n        {\n            std::cout &lt;&lt; \"[Warning] Stride &lt; cols, potential data corruption\\n\";\n        }\n\n        std::cout &lt;&lt; \"Matrix Elements &gt;&gt;&gt;\\n\";\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            // print the non-padding elements\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                std::cout &lt;&lt; std::setw(12) &lt;&lt; this-&gt;data[i * this-&gt;stride + j] &lt;&lt; \" \";\n            }\n\n            // if padding is enabled, print the padding elements\n            if (show_padding)\n            {\n                // print a separator first\n                std::cout &lt;&lt; \"      |\";\n\n                // print the padding elements\n                for (int j = this-&gt;col; j &lt; this-&gt;stride; ++j)\n                {\n                    if (j == this-&gt;col)\n                    {\n                        std::cout &lt;&lt; std::setw(7) &lt;&lt; this-&gt;data[i * this-&gt;stride + j] &lt;&lt; \" \";\n                    }\n                    else\n                    {\n                        // print the padding elements\n                        std::cout &lt;&lt; std::setw(12) &lt;&lt; this-&gt;data[i * this-&gt;stride + j] &lt;&lt; \" \";\n                    }\n                }\n            }\n\n            // print a new line after each row\n            std::cout &lt;&lt; \"\\n\";\n        }\n\n        std::cout &lt;&lt; \"&lt;&lt;&lt; Matrix Elements\\n\";\n        std::cout &lt;&lt; std::endl;\n    }\n\n    // ============================================================================\n    // Constructors &amp; Destructor\n    // ============================================================================\n    // memory allocation\n    /**\n     * @name Mat::alloc_mem()\n     * @brief Allocate memory for the matrix according to the memory required.\n     * @note For ESP32, it will automatically determine if using RAM or PSRAM based on the size of the matrix.\n     * @note This function sets ext_buff to false and allocates memory based on row * stride.\n     *       If allocation fails or parameters are invalid, data will be set to nullptr.\n     */\n    void Mat::alloc_mem()\n    {\n        // Parameter validation: check if row and stride are non-negative\n        if (this-&gt;row &lt; 0 || this-&gt;stride &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] Invalid matrix dimensions in alloc_mem(): row=\" &lt;&lt; this-&gt;row \n                      &lt;&lt; \", stride=\" &lt;&lt; this-&gt;stride &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;ext_buff = false;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // Check for integer overflow: row * stride might overflow\n        if (this-&gt;row &gt; 0 &amp;&amp; this-&gt;stride &gt; INT_MAX / this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix size too large, integer overflow: row=\" &lt;&lt; this-&gt;row \n                      &lt;&lt; \", stride=\" &lt;&lt; this-&gt;stride &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;ext_buff = false;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        this-&gt;ext_buff = false;\n        this-&gt;memory = this-&gt;row * this-&gt;stride;\n\n        // Handle empty matrix case (memory = 0)\n        if (this-&gt;memory == 0)\n        {\n            this-&gt;data = nullptr;\n            return;\n        }\n\n        // Use nothrow new to return nullptr on failure instead of throwing exception\n        // This allows callers to check for nullptr, which is consistent with existing code\n        this-&gt;data = new(std::nothrow) float[this-&gt;memory];\n\n        // If allocation failed, data will be nullptr (caller should check)\n        if (this-&gt;data == nullptr)\n        {\n            this-&gt;memory = 0;\n        }\n    }\n\n    /**\n     * @name Mat::Mat()\n     * @brief Constructor - default constructor: create a 1x1 matrix with only a zero element.\n     * @note If memory allocation fails, the object will be in an invalid state (data = nullptr).\n     *       Caller should check the data pointer before using the matrix.\n     */\n    Mat::Mat()\n        : row(1), col(1), pad(0), stride(1), element(1), memory(1),\n          data(nullptr), temp(nullptr),\n          ext_buff(false), sub_matrix(false)\n    {\n        // memory will be recalculated by alloc_mem() based on row * stride\n        alloc_mem();\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\\n\";\n            // Memory allocation failed, object is in invalid state (data = nullptr)\n            // Caller should check data pointer before using the matrix\n            return;\n        }\n        // Initialize all elements to zero\n        std::memset(this-&gt;data, 0, this-&gt;memory * sizeof(float));\n    }\n\n    /**\n     * @name Mat::Mat(int rows, int cols)\n     * @brief Constructor - create a matrix with the specified number of rows and columns.\n     * @param rows Number of rows (must be non-negative)\n     * @param cols Number of columns (must be non-negative)\n     * @note If rows or cols is negative, the object will be in an invalid state.\n     * @note If memory allocation fails, the object will be in an invalid state (data = nullptr).\n     *       Caller should check the data pointer before using the matrix.\n     */\n    Mat::Mat(int rows, int cols)\n        : row(rows), col(cols), pad(0), stride(cols),\n          element(rows * cols), memory(rows * cols),\n          data(nullptr), temp(nullptr),\n          ext_buff(false), sub_matrix(false)\n    {\n        // Parameter validation: check if rows and cols are non-negative\n        if (rows &lt; 0 || cols &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] Invalid matrix dimensions: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \" (must be non-negative)\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // Check for integer overflow: rows * cols might overflow\n        if (rows &gt; 0 &amp;&amp; cols &gt; INT_MAX / rows)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix size too large, integer overflow: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // memory will be recalculated by alloc_mem() based on row * stride\n        alloc_mem();\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\\n\";\n            // Memory allocation failed, object is in invalid state (data = nullptr)\n            // Caller should check data pointer before using the matrix\n            return;\n        }\n        // Initialize all elements to zero\n        std::memset(this-&gt;data, 0, this-&gt;memory * sizeof(float));\n    }\n    /**\n     * @name Mat::Mat(int rows, int cols, int stride)\n     * @brief Constructor - create a matrix with the specified number of rows, columns and stride.\n     * @param rows Number of rows (must be non-negative)\n     * @param cols Number of columns (must be non-negative)\n     * @param stride Stride (number of elements in a row, must be &gt;= cols)\n     * @note If rows, cols is negative, or stride &lt; cols, the object will be in an invalid state.\n     * @note If memory allocation fails, the object will be in an invalid state (data = nullptr).\n     *       Caller should check the data pointer before using the matrix.\n     */\n    Mat::Mat(int rows, int cols, int stride)\n        : row(rows), col(cols), pad(stride - cols), stride(stride),\n          element(rows * cols), memory(rows * stride),\n          data(nullptr), temp(nullptr),\n          ext_buff(false), sub_matrix(false)\n    {\n        // Parameter validation: check if rows, cols are non-negative\n        if (rows &lt; 0 || cols &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] Invalid matrix dimensions: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \" (must be non-negative)\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // Validate stride: must be &gt;= cols (padding cannot be negative)\n        if (stride &lt; cols)\n        {\n            std::cerr &lt;&lt; \"[Error] Invalid stride: stride=\" &lt;&lt; stride \n                      &lt;&lt; \" must be &gt;= cols=\" &lt;&lt; cols &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            this-&gt;pad = 0;  // Reset pad to avoid negative value\n            return;\n        }\n\n        // Check for integer overflow: rows * cols and rows * stride might overflow\n        if (rows &gt; 0 &amp;&amp; cols &gt; INT_MAX / rows)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix size too large, integer overflow: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        if (rows &gt; 0 &amp;&amp; stride &gt; INT_MAX / rows)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix size too large, integer overflow: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", stride=\" &lt;&lt; stride &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // memory will be recalculated by alloc_mem() based on row * stride\n        alloc_mem();\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\\n\";\n            // Memory allocation failed, object is in invalid state (data = nullptr)\n            // Caller should check data pointer before using the matrix\n            return;\n        }\n        // Initialize all elements to zero\n        std::memset(this-&gt;data, 0, this-&gt;memory * sizeof(float));\n    }\n\n    /**\n     * @name Mat::Mat(float *data, int rows, int cols)\n     * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n     * @param data Pointer to external data buffer (can be nullptr for empty matrix)\n     * @param rows Number of rows (must be non-negative)\n     * @param cols Number of columns (must be non-negative)\n     * @note This constructor does not allocate memory. The matrix uses the external buffer.\n     * @note If rows or cols is negative, the object will be in an invalid state.\n     * @note The caller is responsible for ensuring the buffer is large enough and valid.\n     */\n    Mat::Mat(float *data, int rows, int cols)\n        : row(rows), col(cols), pad(0), stride(cols),\n          element(rows * cols), memory(rows * cols),\n          data(data), temp(nullptr),\n          ext_buff(true), sub_matrix(false)\n    {\n        // Parameter validation: check if rows and cols are non-negative\n        if (rows &lt; 0 || cols &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] Invalid matrix dimensions: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \" (must be non-negative)\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // Check for integer overflow: rows * cols might overflow\n        if (rows &gt; 0 &amp;&amp; cols &gt; INT_MAX / rows)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix size too large, integer overflow: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // Note: data can be nullptr for empty matrix, but caller should ensure buffer validity\n    }\n\n    /**\n     * @name Mat::Mat(float *data, int rows, int cols, int stride)\n     * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n     * @param data Pointer to external data buffer (can be nullptr for empty matrix)\n     * @param rows Number of rows (must be non-negative)\n     * @param cols Number of columns (must be non-negative)\n     * @param stride Stride (number of elements in a row, must be &gt;= cols)\n     * @note This constructor does not allocate memory. The matrix uses the external buffer.\n     * @note If rows, cols is negative, or stride &lt; cols, the object will be in an invalid state.\n     * @note The caller is responsible for ensuring the buffer is large enough and valid.\n     */\n    Mat::Mat(float *data, int rows, int cols, int stride)\n        : row(rows), col(cols), pad(stride - cols), stride(stride),\n          element(rows * cols), memory(rows * stride),\n          data(data), temp(nullptr),\n          ext_buff(true), sub_matrix(false)\n    {\n        // Parameter validation: check if rows, cols are non-negative\n        if (rows &lt; 0 || cols &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] Invalid matrix dimensions: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \" (must be non-negative)\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // Validate stride: must be &gt;= cols (padding cannot be negative)\n        if (stride &lt; cols)\n        {\n            std::cerr &lt;&lt; \"[Error] Invalid stride: stride=\" &lt;&lt; stride \n                      &lt;&lt; \" must be &gt;= cols=\" &lt;&lt; cols &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            this-&gt;pad = 0;  // Reset pad to avoid negative value\n            return;\n        }\n\n        // Check for integer overflow: rows * cols and rows * stride might overflow\n        if (rows &gt; 0 &amp;&amp; cols &gt; INT_MAX / rows)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix size too large, integer overflow: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        if (rows &gt; 0 &amp;&amp; stride &gt; INT_MAX / rows)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix size too large, integer overflow: rows=\" &lt;&lt; rows \n                      &lt;&lt; \", stride=\" &lt;&lt; stride &lt;&lt; \"\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;memory = 0;\n            return;\n        }\n\n        // Note: data can be nullptr for empty matrix, but caller should ensure buffer validity\n    }\n\n    /**\n     * @name Mat::Mat(const Mat &amp;src)\n     * @brief Copy constructor - create a matrix with the same properties as the source matrix.\n     * @param src Source matrix\n     * @note If source is a submatrix view (sub_matrix &amp;&amp; ext_buff), performs shallow copy (shares data pointer).\n     *       Otherwise, performs deep copy (allocates new memory and copies data).\n     * @note If memory allocation fails, the object will be in an invalid state (data = nullptr).\n     *       Caller should check the data pointer before using the matrix.\n     * @warning Shallow copy: If source is destroyed, the copied matrix's data pointer will be invalid.\n     */\n    Mat::Mat(const Mat &amp;src)\n        : row(src.row), col(src.col), pad(src.pad), stride(src.stride),\n          element(src.element), memory(src.memory),\n          data(nullptr), temp(nullptr),\n          ext_buff(false), sub_matrix(false)\n    {\n        if (src.sub_matrix &amp;&amp; src.ext_buff)\n        {\n            // if the source is a view (submatrix), do shallow copy\n            // WARNING: This creates a shared reference. If source is destroyed, this pointer becomes invalid.\n            this-&gt;data = src.data;\n            this-&gt;ext_buff = true;\n            this-&gt;sub_matrix = true;\n        }\n        else\n        {\n            // otherwise do deep copy\n            this-&gt;ext_buff = false;\n            this-&gt;sub_matrix = false;\n\n            if (src.data != nullptr)\n            {\n                alloc_mem();\n                if (this-&gt;data == nullptr)\n                {\n                    std::cerr &lt;&lt; \"[Error] Memory allocation failed in alloc_mem()\\n\";\n                    // Memory allocation failed, object is in invalid state (data = nullptr)\n                    // Caller should check data pointer before using the matrix\n                    return;\n                }\n\n                // Copy data row by row to handle different strides correctly\n                // This ensures correct copying even if source and destination have different strides\n                for (int i = 0; i &lt; this-&gt;row; ++i)\n                {\n                    std::memcpy(\n                        &amp;this-&gt;data[i * this-&gt;stride],\n                        &amp;src.data[i * src.stride],\n                        this-&gt;col * sizeof(float)\n                    );\n                }\n            }\n            // If src.data == nullptr, this-&gt;data remains nullptr (empty matrix)\n        }\n    }\n\n    /**\n     * @name ~Mat()\n     * @brief Destructor - free the memory allocated for the matrix.\n     * @note Only deletes memory if it was allocated by this object (ext_buff == false).\n     *       External buffers are not deleted.\n     * @note temp buffer is always deleted if it exists (assumed to be allocated by this object).\n     */\n    Mat::~Mat()\n    {\n        // Only delete data if it was allocated by this object (not external buffer)\n        if (!this-&gt;ext_buff &amp;&amp; this-&gt;data != nullptr)\n        {\n            delete[] this-&gt;data;\n            this-&gt;data = nullptr;  // Set to nullptr after deletion (good practice)\n        }\n\n        // Delete temporary buffer if it exists\n        // Note: temp is assumed to be allocated by this object, not external\n        if (this-&gt;temp != nullptr)\n        {\n            delete[] this-&gt;temp;\n            this-&gt;temp = nullptr;  // Set to nullptr after deletion (good practice)\n        }\n    }\n\n    // ============================================================================\n    // Element Access\n    // ============================================================================\n    // Already defined by inline functions in the header file\n\n    // ============================================================================\n    // Data Manipulation\n    // ============================================================================\n\n    /**\n     * @name Mat::copy_paste(const Mat &amp;src, int row_pos, int col_pos)\n     * @brief Copy the elements of the source matrix into the destination matrix. \n     *        The dimension of the current matrix must be larger than the source matrix.\n     * @brief This one does not share memory with the source matrix.\n     * @param src Source matrix (must be valid and non-empty)\n     * @param row_pos Start row position of the destination matrix (must be non-negative)\n     * @param col_pos Start column position of the destination matrix (must be non-negative)\n     * @return TINY_OK on success, TINY_ERR_INVALID_ARG on error\n     */\n    tiny_error_t Mat::copy_paste(const Mat &amp;src, int row_pos, int col_pos)\n    {\n        // Check for null pointers\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_paste: destination matrix data pointer is null\\n\";\n            return TINY_ERR_INVALID_ARG;\n        }\n        if (src.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_paste: source matrix data pointer is null\\n\";\n            return TINY_ERR_INVALID_ARG;\n        }\n\n        // Validate source matrix dimensions\n        if (src.row &lt;= 0 || src.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_paste: invalid source matrix dimensions: rows=\" \n                      &lt;&lt; src.row &lt;&lt; \", cols=\" &lt;&lt; src.col &lt;&lt; \"\\n\";\n            return TINY_ERR_INVALID_ARG;\n        }\n\n        // Validate position parameters (must be non-negative)\n        if (row_pos &lt; 0 || col_pos &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_paste: invalid position: row_pos=\" &lt;&lt; row_pos \n                      &lt;&lt; \", col_pos=\" &lt;&lt; col_pos &lt;&lt; \" (must be non-negative)\\n\";\n            return TINY_ERR_INVALID_ARG;\n        }\n\n        // Validate destination matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_paste: invalid destination matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return TINY_ERR_INVALID_ARG;\n        }\n\n        // Check if source matrix fits in destination at the specified position\n        if ((row_pos + src.row) &gt; this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_paste: source matrix exceeds destination row boundary: \"\n                      &lt;&lt; \"row_pos=\" &lt;&lt; row_pos &lt;&lt; \", src.rows=\" &lt;&lt; src.row \n                      &lt;&lt; \", dest.rows=\" &lt;&lt; this-&gt;row &lt;&lt; \"\\n\";\n            return TINY_ERR_INVALID_ARG;\n        }\n        if ((col_pos + src.col) &gt; this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_paste: source matrix exceeds destination column boundary: \"\n                      &lt;&lt; \"col_pos=\" &lt;&lt; col_pos &lt;&lt; \", src.cols=\" &lt;&lt; src.col \n                      &lt;&lt; \", dest.cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return TINY_ERR_INVALID_ARG;\n        }\n\n        // Copy data row by row (handles different strides correctly)\n        for (int r = 0; r &lt; src.row; r++)\n        {\n            memcpy(&amp;this-&gt;data[(r + row_pos) * this-&gt;stride + col_pos], \n                   &amp;src.data[r * src.stride], \n                   src.col * sizeof(float));\n        }\n\n        return TINY_OK;\n    }\n\n    /**\n     * @name Mat::copy_head(const Mat &amp;src)\n     * @brief Copy the header (metadata) of the source matrix into the destination matrix. \n     *        The data pointer is shared (shallow copy).\n     * @param src Source matrix (must be valid)\n     * @return TINY_OK on success, TINY_ERR_INVALID_ARG on error\n     * @warning This function performs a SHALLOW COPY. The destination matrix shares the \n     *          data pointer with the source matrix. If the source matrix is destroyed, \n     *          the destination matrix's data pointer will become invalid.\n     * @note The temp pointer is NOT shared (set to nullptr) to prevent double-free issues.\n     *       Each object manages its own temp buffer independently.\n     */\n    tiny_error_t Mat::copy_head(const Mat &amp;src)\n    {\n        // Delete current data if it was allocated by this object\n        if (!this-&gt;ext_buff &amp;&amp; this-&gt;data != nullptr)\n        {\n            delete[] this-&gt;data;\n            this-&gt;data = nullptr;\n        }\n\n        // Delete current temp if it exists (assuming it was allocated by this object)\n        if (this-&gt;temp != nullptr)\n        {\n            delete[] this-&gt;temp;\n            this-&gt;temp = nullptr;\n        }\n\n        // Copy all metadata from source matrix\n        this-&gt;row = src.row;\n        this-&gt;col = src.col;\n        this-&gt;element = src.element;\n        this-&gt;pad = src.pad;\n        this-&gt;stride = src.stride;\n        this-&gt;memory = src.memory;\n\n        // Shallow copy: share data pointer ONLY if source uses external buffer or is a submatrix view\n        // If source owns its memory (ext_buff=false), we must NOT share the pointer to avoid double-free\n        // In that case, copy_head should not be used - use copy assignment or copy constructor instead\n        if (src.ext_buff || src.sub_matrix)\n        {\n            // Source uses external buffer or is a view - safe to share pointer\n            // WARNING: If source is destroyed, this pointer becomes invalid\n            this-&gt;data = src.data;\n            this-&gt;ext_buff = src.ext_buff;\n            this-&gt;sub_matrix = src.sub_matrix;\n        }\n        else\n        {\n            // Source owns its memory - cannot share pointer (would cause double-free)\n            // This is an error condition - copy_head should only be used for external buffers or views\n            std::cerr &lt;&lt; \"[Error] copy_head: source matrix owns its memory (ext_buff=false). \"\n                      &lt;&lt; \"Cannot share pointer - would cause double-free. \"\n                      &lt;&lt; \"Use copy assignment or copy constructor instead.\\n\";\n            this-&gt;data = nullptr;\n            this-&gt;ext_buff = false;\n            this-&gt;sub_matrix = false;\n            return TINY_ERR_INVALID_ARG;\n        }\n\n        // Do NOT share temp pointer - temp is a temporary buffer that should not be shared\n        // Setting temp to nullptr prevents double-free issues when either object is destroyed\n        // Each object should manage its own temp buffer if needed\n        this-&gt;temp = nullptr;\n\n        return TINY_OK;\n    }\n\n    /**\n     * @name Mat::view_roi(int start_row, int start_col, int roi_rows, int roi_cols)\n     * @brief Make a shallow copy of ROI matrix. Create a view of the ROI matrix. \n     *        Low level function. Unlike ESP-DSP, it is not allowed to setup stride here, \n     *        stride is automatically calculated inside the function.\n     * @param start_row Start row position of source matrix (must be non-negative)\n     * @param start_col Start column position of source matrix (must be non-negative)\n     * @param roi_rows Size of row elements of source matrix to copy (must be positive)\n     * @param roi_cols Size of column elements of source matrix to copy (must be positive)\n     * @return result matrix size roi_rows x roi_cols, or empty matrix on error\n     * @warning The returned matrix is a VIEW (shallow copy) that shares data with the source matrix.\n     *          If the source matrix is destroyed, the view's data pointer will become invalid.\n     * @note The stride of the result matrix is inherited from the source matrix.\n     */\n    Mat Mat::view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: source matrix data pointer is null\\n\";\n            return Mat();  // Return empty matrix as error indicator\n        }\n\n        // Validate source matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: invalid source matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Validate position parameters (must be non-negative)\n        if (start_row &lt; 0 || start_col &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: invalid position: start_row=\" &lt;&lt; start_row \n                      &lt;&lt; \", start_col=\" &lt;&lt; start_col &lt;&lt; \" (must be non-negative)\\n\";\n            return Mat();\n        }\n\n        // Validate ROI size parameters (must be positive)\n        if (roi_rows &lt;= 0 || roi_cols &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: invalid ROI size: roi_rows=\" &lt;&lt; roi_rows \n                      &lt;&lt; \", roi_cols=\" &lt;&lt; roi_cols &lt;&lt; \" (must be positive)\\n\";\n            return Mat();\n        }\n\n        // Check if ROI fits within source matrix boundaries\n        if ((start_row + roi_rows) &gt; this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: ROI exceeds row boundary: start_row=\" &lt;&lt; start_row \n                      &lt;&lt; \", roi_rows=\" &lt;&lt; roi_rows &lt;&lt; \", source.rows=\" &lt;&lt; this-&gt;row &lt;&lt; \"\\n\";\n            return Mat();\n        }\n        if ((start_col + roi_cols) &gt; this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: ROI exceeds column boundary: start_col=\" &lt;&lt; start_col \n                      &lt;&lt; \", roi_cols=\" &lt;&lt; roi_cols &lt;&lt; \", source.cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Validate stride: must be &gt;= roi_cols (padding cannot be negative)\n        if (this-&gt;stride &lt; roi_cols)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: stride &lt; roi_cols: stride=\" &lt;&lt; this-&gt;stride \n                      &lt;&lt; \", roi_cols=\" &lt;&lt; roi_cols &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check for integer overflow\n        if (roi_rows &gt; 0 &amp;&amp; this-&gt;stride &gt; INT_MAX / roi_rows)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: integer overflow: roi_rows=\" &lt;&lt; roi_rows \n                      &lt;&lt; \", stride=\" &lt;&lt; this-&gt;stride &lt;&lt; \"\\n\";\n            return Mat();\n        }\n        if (roi_rows &gt; 0 &amp;&amp; roi_cols &gt; INT_MAX / roi_rows)\n        {\n            std::cerr &lt;&lt; \"[Error] view_roi: integer overflow: roi_rows=\" &lt;&lt; roi_rows \n                      &lt;&lt; \", roi_cols=\" &lt;&lt; roi_cols &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Create ROI view (shallow copy)\n        Mat result;\n        result.row = roi_rows;\n        result.col = roi_cols;\n        result.stride = this-&gt;stride;\n        result.pad = this-&gt;stride - roi_cols;  // Now guaranteed to be non-negative\n        result.element = roi_rows * roi_cols;\n        result.memory = roi_rows * this-&gt;stride;\n        result.data = this-&gt;data + (start_row * this-&gt;stride + start_col);\n        result.temp = nullptr;\n        result.ext_buff = true;\n        result.sub_matrix = true;\n\n        return result;\n    }\n\n    /**\n     * @name Mat::view_roi(const Mat::ROI &amp;roi)\n     * @brief Make a shallow copy of ROI matrix. Create a view of the ROI matrix using ROI structure.\n     * @param roi Rectangular area of interest (roi.pos_x, roi.pos_y must be non-negative, \n     *            roi.width, roi.height must be positive)\n     * @return result matrix size roi.height x roi.width, or empty matrix on error\n     * @warning The returned matrix is a VIEW (shallow copy) that shares data with the source matrix.\n     *          If the source matrix is destroyed, the view's data pointer will become invalid.\n     * @note This is a convenience wrapper that calls view_roi(roi.pos_y, roi.pos_x, roi.height, roi.width).\n     */\n    Mat Mat::view_roi(const Mat::ROI &amp;roi) const\n    {\n        return view_roi(roi.pos_y, roi.pos_x, roi.height, roi.width);\n    }\n\n    /**\n     * @name Mat::copy_roi(int start_row, int start_col, int height, int width)\n     * @brief Make a deep copy of matrix. Compared to view_roi(), this one is a deep copy, \n     *        not sharing memory with the source matrix.\n     * @param start_row Start row position of source matrix to copy (must be non-negative)\n     * @param start_col Start column position of source matrix to copy (must be non-negative)\n     * @param height Size of row elements of source matrix to copy (must be positive)\n     * @param width Size of column elements of source matrix to copy (must be positive)\n     * @return result matrix size height x width, or empty matrix on error\n     * @note The returned matrix is a DEEP COPY with its own memory. It is independent \n     *       of the source matrix and can be safely used after the source is destroyed.\n     */\n    Mat Mat::copy_roi(int start_row, int start_col, int height, int width)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_roi: source matrix data pointer is null\\n\";\n            return Mat();  // Return empty matrix as error indicator\n        }\n\n        // Validate source matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_roi: invalid source matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Validate position parameters (must be non-negative)\n        if (start_row &lt; 0 || start_col &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_roi: invalid position: start_row=\" &lt;&lt; start_row \n                      &lt;&lt; \", start_col=\" &lt;&lt; start_col &lt;&lt; \" (must be non-negative)\\n\";\n            return Mat();\n        }\n\n        // Validate size parameters (must be positive)\n        if (height &lt;= 0 || width &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_roi: invalid size: height=\" &lt;&lt; height \n                      &lt;&lt; \", width=\" &lt;&lt; width &lt;&lt; \" (must be positive)\\n\";\n            return Mat();\n        }\n\n        // Check if ROI fits within source matrix boundaries\n        if ((start_row + height) &gt; this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_roi: ROI exceeds row boundary: start_row=\" &lt;&lt; start_row \n                      &lt;&lt; \", height=\" &lt;&lt; height &lt;&lt; \", source.rows=\" &lt;&lt; this-&gt;row &lt;&lt; \"\\n\";\n            return Mat();\n        }\n        if ((start_col + width) &gt; this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_roi: ROI exceeds column boundary: start_col=\" &lt;&lt; start_col \n                      &lt;&lt; \", width=\" &lt;&lt; width &lt;&lt; \", source.cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Create result matrix (deep copy)\n        Mat result(height, width);\n\n        // Check if result matrix was created successfully\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] copy_roi: failed to allocate memory for result matrix\\n\";\n            return Mat();\n        }\n\n        // Deep copy the data from the source matrix row by row\n        // This handles different strides correctly\n        for (int r = 0; r &lt; result.row; r++)\n        {\n            memcpy(&amp;result.data[r * result.stride], \n                   &amp;this-&gt;data[(r + start_row) * this-&gt;stride + start_col], \n                   result.col * sizeof(float));\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::copy_roi(const Mat::ROI &amp;roi)\n     * @brief Make a deep copy of matrix using ROI structure. Compared to view_roi(), \n     *        this one is a deep copy, not sharing memory with the source matrix.\n     * @param roi Rectangular area of interest (roi.pos_x, roi.pos_y must be non-negative, \n     *            roi.width, roi.height must be positive)\n     * @return result matrix size roi.height x roi.width, or empty matrix on error\n     * @note The returned matrix is a DEEP COPY with its own memory. It is independent \n     *       of the source matrix and can be safely used after the source is destroyed.\n     * @note This is a convenience wrapper that calls copy_roi(roi.pos_y, roi.pos_x, roi.height, roi.width).\n     */\n    Mat Mat::copy_roi(const Mat::ROI &amp;roi)\n    {\n        return copy_roi(roi.pos_y, roi.pos_x, roi.height, roi.width);\n    }\n\n    /**\n     * @name Mat::block(int start_row, int start_col, int block_rows, int block_cols)\n     * @brief Get a block (submatrix) of the matrix. This is a deep copy operation.\n     * @param start_row Start row position of the block (must be non-negative)\n     * @param start_col Start column position of the block (must be non-negative)\n     * @param block_rows Number of rows in the block (must be positive)\n     * @param block_cols Number of columns in the block (must be positive)\n     * @return result matrix size block_rows x block_cols, or empty matrix on error\n     * @note The returned matrix is a DEEP COPY with its own memory. It is independent \n     *       of the source matrix and can be safely used after the source is destroyed.\n     * @note This function is similar to copy_roi(), but uses element-by-element access.\n     *       For better performance with large blocks, consider using copy_roi() instead.\n     */\n    Mat Mat::block(int start_row, int start_col, int block_rows, int block_cols)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] block: source matrix data pointer is null\\n\";\n            return Mat();  // Return empty matrix as error indicator\n        }\n\n        // Validate source matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] block: invalid source matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Boundary check: validate position parameters (must be non-negative)\n        if (start_row &lt; 0 || start_col &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] block: invalid position: start_row=\" &lt;&lt; start_row \n                      &lt;&lt; \", start_col=\" &lt;&lt; start_col &lt;&lt; \" (must be non-negative)\\n\";\n            return Mat();\n        }\n\n        // Boundary check: validate block size parameters (must be positive)\n        if (block_rows &lt;= 0 || block_cols &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] block: invalid block size: block_rows=\" &lt;&lt; block_rows \n                      &lt;&lt; \", block_cols=\" &lt;&lt; block_cols &lt;&lt; \" (must be positive)\\n\";\n            return Mat();\n        }\n\n        // Check if block fits within source matrix boundaries\n        if ((start_row + block_rows) &gt; this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[Error] block: block exceeds row boundary: start_row=\" &lt;&lt; start_row \n                      &lt;&lt; \", block_rows=\" &lt;&lt; block_rows &lt;&lt; \", source.rows=\" &lt;&lt; this-&gt;row &lt;&lt; \"\\n\";\n            return Mat();\n        }\n        if ((start_col + block_cols) &gt; this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] block: block exceeds column boundary: start_col=\" &lt;&lt; start_col \n                      &lt;&lt; \", block_cols=\" &lt;&lt; block_cols &lt;&lt; \", source.cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Create result matrix\n        Mat result(block_rows, block_cols);\n\n        // Check if result matrix was created successfully\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] block: failed to allocate memory for result matrix\\n\";\n            return Mat();\n        }\n\n        // Copy block data element by element\n        // Note: This uses operator() which handles stride correctly, but is slower than memcpy\n        // For better performance, consider using copy_roi() which uses memcpy\n        for (int i = 0; i &lt; block_rows; ++i)\n        {\n            for (int j = 0; j &lt; block_cols; ++j)\n            {\n                result(i, j) = (*this)(start_row + i, start_col + j);\n            }\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::swap_rows(int row1, int row2)\n     * @brief Swap two rows of the matrix.\n     * @param row1 The index of the first row to swap (must be in range [0, row-1])\n     * @param row2 The index of the second row to swap (must be in range [0, row-1])\n     * @note If row1 == row2, the function returns immediately without doing anything.\n     * @note This function is commonly used in matrix operations like Gaussian elimination with row pivoting.\n     */\n    void Mat::swap_rows(int row1, int row2)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_rows: matrix data pointer is null\\n\";\n            return;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_rows: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return;\n        }\n\n        // Validate row indices\n        if (row1 &lt; 0 || row1 &gt;= this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_rows: row1 index out of range: row1=\" &lt;&lt; row1 \n                      &lt;&lt; \", matrix.rows=\" &lt;&lt; this-&gt;row &lt;&lt; \"\\n\";\n            return;\n        }\n        if (row2 &lt; 0 || row2 &gt;= this-&gt;row)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_rows: row2 index out of range: row2=\" &lt;&lt; row2 \n                      &lt;&lt; \", matrix.rows=\" &lt;&lt; this-&gt;row &lt;&lt; \"\\n\";\n            return;\n        }\n\n        // Optimization: if same row, no need to swap\n        if (row1 == row2)\n        {\n            return;\n        }\n\n        // Allocate temporary buffer for row swap\n        // Note: Using new/delete here is acceptable for this operation,\n        // but could be optimized by using the matrix's temp buffer if available\n        float *temp_row = new(std::nothrow) float[this-&gt;col];\n        if (temp_row == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_rows: failed to allocate temporary buffer\\n\";\n            return;\n        }\n\n        // Swap rows using memcpy (handles stride correctly)\n        memcpy(temp_row, &amp;this-&gt;data[row1 * this-&gt;stride], this-&gt;col * sizeof(float));\n        memcpy(&amp;this-&gt;data[row1 * this-&gt;stride], &amp;this-&gt;data[row2 * this-&gt;stride], this-&gt;col * sizeof(float));\n        memcpy(&amp;this-&gt;data[row2 * this-&gt;stride], temp_row, this-&gt;col * sizeof(float));\n\n        delete[] temp_row;\n    }\n\n    /**\n     * @name Mat::swap_cols(int col1, int col2)\n     * @brief Swap two columns of the matrix.\n     * @param col1 The index of the first column to swap (must be in range [0, col-1])\n     * @param col2 The index of the second column to swap (must be in range [0, col-1])\n     * @note If col1 == col2, the function returns immediately without doing anything.\n     * @note Useful for column pivoting in algorithms like Gaussian elimination with column pivoting.\n     * @note This function swaps columns element by element, which correctly handles stride.\n     */\n    void Mat::swap_cols(int col1, int col2)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_cols: matrix data pointer is null\\n\";\n            return;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_cols: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return;\n        }\n\n        // Validate column indices\n        if (col1 &lt; 0 || col1 &gt;= this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_cols: col1 index out of range: col1=\" &lt;&lt; col1 \n                      &lt;&lt; \", matrix.cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return;\n        }\n        if (col2 &lt; 0 || col2 &gt;= this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] swap_cols: col2 index out of range: col2=\" &lt;&lt; col2 \n                      &lt;&lt; \", matrix.cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return;\n        }\n\n        // Optimization: if same column, no need to swap\n        if (col1 == col2)\n        {\n            return;\n        }\n\n        // Swap columns element by element (considering stride)\n        // Note: This approach correctly handles different stride values\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            float temp = (*this)(i, col1);\n            (*this)(i, col1) = (*this)(i, col2);\n            (*this)(i, col2) = temp;\n        }\n    }\n\n    /**\n     * @name Mat::clear()\n     * @brief Clear the matrix by setting all elements to zero.\n     * @note Only clears the actual matrix elements (col elements per row), not the padding area.\n     * @note If the matrix has padding (stride &gt; col), the padding elements are not cleared.\n     */\n    void Mat::clear(void)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] clear: matrix data pointer is null\\n\";\n            return;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            // Empty matrix, nothing to clear\n            return;\n        }\n\n        // Clear matrix row by row (handles stride correctly)\n        // Only clear the actual matrix elements (col elements), not the padding\n        for (int row = 0; row &lt; this-&gt;row; row++)\n        {\n            memset(this-&gt;data + (row * this-&gt;stride), 0, this-&gt;col * sizeof(float));\n        }\n    }\n\n    // ============================================================================\n    // Arithmetic Operators\n    // ============================================================================\n    /**\n     * @name Mat::operator=(const Mat &amp;src)\n     * @brief Copy assignment operator - copy the elements of the source matrix into the destination matrix.\n     * @param src Source matrix to copy from\n     * @return Reference to this matrix\n     * @note Compared to the copy constructor, this operator is used for existing matrices.\n     *       If dimensions differ, memory will be reallocated.\n     * @note Assignment to sub-matrix views is not allowed.\n     * @warning If memory allocation fails, the matrix may be in an invalid state.\n     */\n    Mat &amp;Mat::operator=(const Mat &amp;src)\n    {\n        // 1. Self-assignment check\n        if (this == &amp;src)\n        {\n            return *this;\n        }\n\n        // 2. Forbid assignment to sub-matrix views\n        if (this-&gt;sub_matrix)\n        {\n            std::cerr &lt;&lt; \"[Error] Assignment to a sub-matrix is not allowed.\\n\";\n            return *this;\n        }\n\n        // Check source matrix validity\n        if (src.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator=: source matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // 3. If dimensions differ, reallocate memory\n        if (this-&gt;row != src.row || this-&gt;col != src.col)\n        {\n            if (!this-&gt;ext_buff &amp;&amp; this-&gt;data != nullptr)\n            {\n                delete[] this-&gt;data;\n                this-&gt;data = nullptr;\n            }\n\n            // Update dimensions and memory info\n            this-&gt;row = src.row;\n            this-&gt;col = src.col;\n            this-&gt;stride = src.col; // Follow source's logical stride (no padding)\n            this-&gt;pad = 0;\n\n            // Check for integer overflow\n            if (this-&gt;row &gt; 0 &amp;&amp; this-&gt;col &gt; INT_MAX / this-&gt;row)\n            {\n                std::cerr &lt;&lt; \"[Error] operator=: integer overflow in element calculation\\n\";\n                this-&gt;data = nullptr;\n                return *this;\n            }\n            this-&gt;element = this-&gt;row * this-&gt;col;\n\n            if (this-&gt;row &gt; 0 &amp;&amp; this-&gt;stride &gt; INT_MAX / this-&gt;row)\n            {\n                std::cerr &lt;&lt; \"[Error] operator=: integer overflow in memory calculation\\n\";\n                this-&gt;data = nullptr;\n                return *this;\n            }\n            this-&gt;memory = this-&gt;row * this-&gt;stride;\n\n            this-&gt;ext_buff = false;\n            this-&gt;sub_matrix = false;\n\n            alloc_mem();\n\n            // Check if memory allocation succeeded\n            if (this-&gt;data == nullptr)\n            {\n                std::cerr &lt;&lt; \"[Error] operator=: memory allocation failed\\n\";\n                return *this;\n            }\n        }\n\n        // Check if this-&gt;data is valid before copying\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator=: destination matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // 4. Data copy (row-wise, handles different strides correctly)\n        for (int r = 0; r &lt; this-&gt;row; ++r)\n        {\n            std::memcpy(this-&gt;data + r * this-&gt;stride, \n                       src.data + r * src.stride, \n                       this-&gt;col * sizeof(float));\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator+=(const Mat &amp;A)\n     * @brief Element-wise addition of another matrix to this matrix.\n     * @param A The matrix to add (must have same dimensions as this matrix)\n     * @return Mat&amp; Reference to the current matrix\n     * @note This function performs element-wise addition: this[i,j] += A[i,j]\n     * @note The function automatically handles padding and uses optimized vectorized operations when possible.\n     */\n    Mat &amp;Mat::operator+=(const Mat &amp;A)\n    {\n        // Check for null pointers\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator+=: this matrix data pointer is null\\n\";\n            return *this;\n        }\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator+=: source matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator+=: invalid this matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return *this;\n        }\n        if (A.row &lt;= 0 || A.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator+=: invalid source matrix dimensions: rows=\" \n                      &lt;&lt; A.row &lt;&lt; \", cols=\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return *this;\n        }\n\n        // 1. Dimension check - matrices must have same dimensions\n        if ((this-&gt;row != A.row) || (this-&gt;col != A.col))\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix addition failed: Dimension mismatch (\"\n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \" vs \"\n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Determine if padding handling is needed\n        bool need_padding_handling = (this-&gt;pad &gt; 0) || (A.pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware addition\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_add_f32(this-&gt;data, A.data, this-&gt;data,\n                         this-&gt;row, this-&gt;col,\n                         this-&gt;pad, A.pad, this-&gt;pad,\n                         1, 1, 1);\n#else\n            tiny_mat_add_f32(this-&gt;data, A.data, this-&gt;data,\n                             this-&gt;row, this-&gt;col,\n                             this-&gt;pad, A.pad, this-&gt;pad,\n                             1, 1, 1);\n#endif\n        }\n        else\n        {\n            // Vectorized addition for contiguous memory\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_add_f32(this-&gt;data, A.data, this-&gt;data, this-&gt;memory, 1, 1, 1);\n#else\n            tiny_vec_add_f32(this-&gt;data, A.data, this-&gt;data, this-&gt;memory, 1, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator+=(float C)\n     * @brief Element-wise addition of a constant to this matrix.\n     * @param C The constant to add to each element\n     * @return Mat&amp; Reference to the current matrix\n     * @note This function performs element-wise addition: this[i,j] += C\n     * @note The function automatically handles padding and uses optimized vectorized operations when possible.\n     */\n    Mat &amp;Mat::operator+=(float C)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator+=(float): matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator+=(float): invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return *this;\n        }\n\n        // Check whether padding is present\n        bool need_padding_handling = (this-&gt;pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware constant addition\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_addc_f32(this-&gt;data, this-&gt;data, C,\n                          this-&gt;row, this-&gt;col,\n                          this-&gt;pad, this-&gt;pad,\n                          1, 1);\n#else\n            tiny_mat_addc_f32(this-&gt;data, this-&gt;data, C,\n                              this-&gt;row, this-&gt;col,\n                              this-&gt;pad, this-&gt;pad,\n                              1, 1);\n#endif\n        }\n        else\n        {\n            // Vectorized constant addition\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_addc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, C, 1, 1);\n#else\n            tiny_vec_addc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, C, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator-=(const Mat &amp;A)\n     * @brief Element-wise subtraction of another matrix from this matrix.\n     * @param A The matrix to subtract (must have same dimensions as this matrix)\n     * @return Mat&amp; Reference to the current matrix\n     * @note This function performs element-wise subtraction: this[i,j] -= A[i,j]\n     * @note The function automatically handles padding and uses optimized vectorized operations when possible.\n     */\n    Mat &amp;Mat::operator-=(const Mat &amp;A)\n    {\n        // Check for null pointers\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator-=: this matrix data pointer is null\\n\";\n            return *this;\n        }\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator-=: source matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator-=: invalid this matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return *this;\n        }\n        if (A.row &lt;= 0 || A.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator-=: invalid source matrix dimensions: rows=\" \n                      &lt;&lt; A.row &lt;&lt; \", cols=\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return *this;\n        }\n\n        // 1. Dimension check - matrices must have same dimensions\n        if ((this-&gt;row != A.row) || (this-&gt;col != A.col))\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix subtraction failed: Dimension mismatch (\"\n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \" vs \"\n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Determine if padding handling is needed\n        bool need_padding_handling = (this-&gt;pad &gt; 0) || (A.pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware subtraction\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_sub_f32(this-&gt;data, A.data, this-&gt;data,\n                         this-&gt;row, this-&gt;col,\n                         this-&gt;pad, A.pad, this-&gt;pad,\n                         1, 1, 1);\n#else\n            tiny_mat_sub_f32(this-&gt;data, A.data, this-&gt;data,\n                             this-&gt;row, this-&gt;col,\n                             this-&gt;pad, A.pad, this-&gt;pad,\n                             1, 1, 1);\n#endif\n        }\n        else\n        {\n            // Vectorized subtraction for contiguous memory\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_sub_f32(this-&gt;data, A.data, this-&gt;data, this-&gt;memory, 1, 1, 1);\n#else\n            tiny_vec_sub_f32(this-&gt;data, A.data, this-&gt;data, this-&gt;memory, 1, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator-=(float C)\n     * @brief Element-wise subtraction of a constant from this matrix.\n     * @param C The constant to subtract from each element\n     * @return Mat&amp; Reference to the current matrix\n     * @note This function performs element-wise subtraction: this[i,j] -= C\n     * @note The function automatically handles padding and uses optimized vectorized operations when possible.\n     * @note On ESP32, this uses addc with -C since subc is not available in DSP library.\n     */\n    Mat &amp;Mat::operator-=(float C)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator-=(float): matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator-=(float): invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return *this;\n        }\n\n        bool need_padding_handling = (this-&gt;pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware constant subtraction\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            // Note: ESP32 DSP does not provide dspm_subc_f32, using dspm_addc_f32 with -C\n            dspm_addc_f32(this-&gt;data, this-&gt;data, -C,\n                          this-&gt;row, this-&gt;col,\n                          this-&gt;pad, this-&gt;pad,\n                          1, 1);\n#else\n            tiny_mat_subc_f32(this-&gt;data, this-&gt;data, C,\n                              this-&gt;row, this-&gt;col,\n                              this-&gt;pad, this-&gt;pad,\n                              1, 1);\n#endif\n        }\n        else\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            // Note: ESP32 DSP does not provide dsps_subc_f32, using dsps_addc_f32 with -C\n            dsps_addc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, -C, 1, 1);\n#else\n            tiny_vec_subc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, C, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator*=(const Mat &amp;m)\n     * @brief Matrix multiplication: this = this * m\n     * @param m The matrix to multiply with (must have compatible dimensions: this.col == m.row)\n     * @return Mat&amp; Reference to the current matrix\n     * @note Matrix multiplication requires: this.col == m.row\n     *       Result dimensions: this.row x m.col\n     * @note This function creates a temporary copy to avoid overwriting data during computation.\n     */\n    Mat &amp;Mat::operator*=(const Mat &amp;m)\n    {\n        // Check for null pointers\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator*=: this matrix data pointer is null\\n\";\n            return *this;\n        }\n        if (m.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator*=: source matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator*=: invalid this matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return *this;\n        }\n        if (m.row &lt;= 0 || m.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator*=: invalid source matrix dimensions: rows=\" \n                      &lt;&lt; m.row &lt;&lt; \", cols=\" &lt;&lt; m.col &lt;&lt; \"\\n\";\n            return *this;\n        }\n\n        // 1. Dimension check - matrix multiplication requires: this.col == m.row\n        if (this-&gt;col != m.row)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix multiplication failed: incompatible dimensions (\"\n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \" * \"\n                      &lt;&lt; m.row &lt;&lt; \"x\" &lt;&lt; m.col &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Prepare temp matrix (in case overwriting the original data)\n        // Create a copy of this matrix to avoid overwriting during computation\n        Mat temp = this-&gt;copy_roi(0, 0, this-&gt;row, this-&gt;col);\n\n        // Check if copy_roi succeeded\n        if (temp.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator*=: failed to create temporary matrix copy\\n\";\n            return *this;\n        }\n\n        // 3. Check whether padding is present in either matrix\n        bool need_padding_handling = (this-&gt;pad &gt; 0) || (m.pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mult_ex_f32(temp.data, m.data, this-&gt;data, temp.row, temp.col, m.col, temp.pad, m.pad, this-&gt;pad);\n#else\n            tiny_mat_mult_ex_f32(temp.data, m.data, this-&gt;data, temp.row, temp.col, m.col, temp.pad, m.pad, this-&gt;pad);\n#endif\n        }\n        else\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mult_f32(temp.data, m.data, this-&gt;data, temp.row, temp.col, m.col);\n#else\n            tiny_mat_mult_f32(temp.data, m.data, this-&gt;data, temp.row, temp.col, m.col);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator*=(float num)\n     * @brief Element-wise multiplication by a constant.\n     * @param num The constant multiplier\n     * @return Mat&amp; Reference to the current matrix\n     * @note This function performs element-wise multiplication: this[i,j] *= num\n     * @note The function automatically handles padding and uses optimized vectorized operations when possible.\n     */\n    Mat &amp;Mat::operator*=(float num)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator*=(float): matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator*=(float): invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return *this;\n        }\n\n        // Check whether padding is present\n        bool need_padding_handling = (this-&gt;pad &gt; 0);\n\n        if (need_padding_handling)\n        {\n            // Padding-aware multiplication\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mulc_f32(this-&gt;data, this-&gt;data, num,\n                          this-&gt;row, this-&gt;col,\n                          this-&gt;pad, this-&gt;pad,\n                          1, 1);\n#else\n            tiny_mat_multc_f32(this-&gt;data, this-&gt;data, num, this-&gt;row, this-&gt;col, this-&gt;pad, this-&gt;pad, 1, 1);\n#endif\n        }\n        else\n        {\n            // No padding, use vectorized multiplication\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_mulc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, num, 1, 1);\n#else\n            tiny_vec_mulc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, num, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator/=(const Mat &amp;B)\n     * @brief Element-wise division: this = this / B\n     * @param B The matrix divisor (must have same dimensions as this matrix, and no zero elements)\n     * @return Mat&amp; Reference to the current matrix\n     * @note This function performs element-wise division: this[i,j] /= B[i,j]\n     * @warning Division by zero will cause an error. All elements of B must be non-zero.\n     */\n    Mat &amp;Mat::operator/=(const Mat &amp;B)\n    {\n        // Check for null pointers\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator/=: this matrix data pointer is null\\n\";\n            return *this;\n        }\n        if (B.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator/=: divisor matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator/=: invalid this matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return *this;\n        }\n        if (B.row &lt;= 0 || B.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator/=: invalid divisor matrix dimensions: rows=\" \n                      &lt;&lt; B.row &lt;&lt; \", cols=\" &lt;&lt; B.col &lt;&lt; \"\\n\";\n            return *this;\n        }\n\n        // 1. Dimension check - matrices must have same dimensions\n        if ((this-&gt;row != B.row) || (this-&gt;col != B.col))\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix division failed: Dimension mismatch (\"\n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \" vs \"\n                      &lt;&lt; B.row &lt;&lt; \"x\" &lt;&lt; B.col &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Zero division check - scan for near-zero elements\n        bool zero_found = false;\n        const float epsilon = 1e-9f;\n        for (int i = 0; i &lt; B.row; ++i)\n        {\n            for (int j = 0; j &lt; B.col; ++j)\n            {\n                if (fabs(B(i, j)) &lt; epsilon)\n                {\n                    zero_found = true;\n                    std::cerr &lt;&lt; \"[Error] Matrix division failed: Division by zero detected at position (\"\n                              &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j &lt;&lt; \")\\n\";\n                    break;\n                }\n            }\n            if (zero_found)\n                break;\n        }\n\n        if (zero_found)\n        {\n            return *this;\n        }\n\n        // 3. Element-wise division\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                (*this)(i, j) /= B(i, j);\n            }\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator/=(float num)\n     * @brief Element-wise division of this matrix by a constant.\n     * @param num The constant divisor (must be non-zero)\n     * @return Mat&amp; Reference to the current matrix\n     * @note This function performs element-wise division: this[i,j] /= num\n     * @note The function uses multiplication by 1/num for efficiency (division is slower than multiplication).\n     * @note The function automatically handles padding and uses optimized vectorized operations when possible.\n     * @warning Division by zero will cause an error.\n     */\n    Mat &amp;Mat::operator/=(float num)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator/=(float): matrix data pointer is null\\n\";\n            return *this;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator/=(float): invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return *this;\n        }\n\n        // 1. Check division by zero\n        const float epsilon = 1e-9f;\n        if (fabs(num) &lt; epsilon)\n        {\n            std::cerr &lt;&lt; \"[Error] Matrix division by zero is undefined (divisor=\" &lt;&lt; num &lt;&lt; \")\\n\";\n            return *this;\n        }\n\n        // 2. Determine if padding handling is needed\n        bool need_padding_handling = (this-&gt;pad &gt; 0);\n\n        // Use multiplication by inverse for better performance (division is slower)\n        float inv_num = 1.0f / num;\n\n        if (need_padding_handling)\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mulc_f32(this-&gt;data, this-&gt;data, inv_num,\n                          this-&gt;row, this-&gt;col,\n                          this-&gt;pad, this-&gt;pad,\n                          1, 1);\n#else\n            tiny_mat_multc_f32(this-&gt;data, this-&gt;data, inv_num,\n                              this-&gt;row, this-&gt;col,\n                              this-&gt;pad, this-&gt;pad,\n                              1, 1);\n#endif\n        }\n        else\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dsps_mulc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, inv_num, 1, 1);\n#else\n            tiny_vec_mulc_f32(this-&gt;data, this-&gt;data, this-&gt;memory, inv_num, 1, 1);\n#endif\n        }\n\n        return *this;\n    }\n\n    /**\n     * @name Mat::operator^(int num)\n     * @brief Element-wise integer exponentiation. Returns a new matrix where each element is raised to the given power.\n     * @param num The exponent (integer, must be non-negative)\n     * @return Mat New matrix after exponentiation\n     * @note This function performs element-wise exponentiation: result[i,j] = this[i,j]^num\n     * @note For num=0, all elements become 1.0. For num=1, returns a copy of the matrix.\n     * @warning Negative exponents are not supported.\n     */\n    Mat Mat::operator^(int num)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator^: matrix data pointer is null\\n\";\n            return Mat();  // Return empty matrix as error indicator\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] operator^: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Handle special cases\n        if (num == 0)\n        {\n            // Any number to the power of 0 is 1\n            Mat result(this-&gt;row, this-&gt;col, this-&gt;stride);\n            if (result.data == nullptr)\n            {\n                std::cerr &lt;&lt; \"[Error] operator^: failed to allocate memory for result matrix\\n\";\n                return Mat();\n            }\n            for (int i = 0; i &lt; this-&gt;row; ++i)\n            {\n                for (int j = 0; j &lt; this-&gt;col; ++j)\n                {\n                    result(i, j) = 1.0f;\n                }\n            }\n            return result;\n        }\n\n        if (num == 1)\n        {\n            // Return a copy of current matrix\n            return Mat(*this);\n        }\n\n        if (num &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] Negative exponent not supported in operator^ (exponent=\" &lt;&lt; num &lt;&lt; \")\\n\";\n            return Mat(*this); // Return a copy without modification\n        }\n\n        // General case: positive exponent &gt; 1\n        Mat result(this-&gt;row, this-&gt;col, this-&gt;stride);\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] operator^: failed to allocate memory for result matrix\\n\";\n            return Mat();\n        }\n\n        // Element-wise exponentiation using iterative multiplication\n        // Note: For large exponents, this could be optimized using fast exponentiation,\n        // but for typical use cases (small exponents), this is acceptable\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                float base = (*this)(i, j);\n                float value = 1.0f;\n                for (int k = 0; k &lt; num; ++k)\n                {\n                    value *= base;\n                }\n                result(i, j) = value;\n            }\n        }\n\n        return result;\n    }\n\n    // ============================================================================\n    // Linear Algebra - Basic Operations\n    // ============================================================================\n    /**\n     * @name Mat::transpose()\n     * @brief Transpose the matrix. Returns a new matrix with rows and columns swapped.\n     * @return Transposed matrix (col x row), or empty matrix on error\n     * @note If this matrix is m x n, the result will be n x m.\n     * @note The transpose operation: result[j][i] = this[i][j]\n     */\n    Mat Mat::transpose()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] transpose: matrix data pointer is null\\n\";\n            return Mat();  // Return empty matrix as error indicator\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] transpose: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Create result matrix with swapped dimensions\n        Mat result(this-&gt;col, this-&gt;row);\n\n        // Check if result matrix was created successfully\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] transpose: failed to allocate memory for result matrix\\n\";\n            return Mat();\n        }\n\n        // Transpose: swap rows and columns\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                result(j, i) = this-&gt;data[i * this-&gt;stride + j];\n            }\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::determinant()\n     * @brief Compute the determinant of the matrix (auto-selects method based on size).\n     * @return float The determinant value, or 0.0f on error\n     * @note For small matrices (n &lt;= 4), uses Laplace expansion (more accurate).\n     *       For larger matrices, uses LU decomposition (O(n\u00b3)) for better efficiency.\n     * @note Determinant can be 0.0f for singular matrices, which is a valid result.\n     *       Use error checking to distinguish between error and zero determinant.\n     */\n    float Mat::determinant()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant: matrix data pointer is null\\n\";\n            return 0.0f;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return 0.0f;\n        }\n\n        // Check if matrix is square\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Determinant requires a square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return 0.0f;\n        }\n\n        int n = this-&gt;row;\n\n        // For small matrices, use Laplace expansion (more accurate for small sizes)\n        if (n &lt;= 4)\n        {\n            return this-&gt;determinant_laplace();\n        }\n\n        // For larger matrices, use LU decomposition (much faster, O(n\u00b3) vs O(n!))\n        return this-&gt;determinant_lu();\n    }\n\n    /**\n     * @name Mat::determinant_laplace()\n     * @brief Compute the determinant using Laplace expansion (cofactor expansion).\n     * @return float The determinant value, or 0.0f on error\n     * @note Time complexity: O(n!) - suitable only for small matrices (n &lt;= 4).\n     *       Uses recursive method with first row expansion.\n     * @note For n=1 and n=2, uses direct formulas for efficiency.\n     * @note Determinant can be 0.0f for singular matrices, which is a valid result.\n     */\n    float Mat::determinant_laplace()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant_laplace: matrix data pointer is null\\n\";\n            return 0.0f;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant_laplace: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return 0.0f;\n        }\n\n        // Check if matrix is square\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Determinant requires a square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return 0.0f;\n        }\n\n        int n = this-&gt;row;\n\n        // Base case: 1x1 matrix\n        if (n == 1)\n        {\n            return this-&gt;data[0];\n        }\n\n        // Base case: 2x2 matrix (direct formula)\n        if (n == 2)\n        {\n            return this-&gt;data[0] * this-&gt;data[this-&gt;stride + 1] - \n                   this-&gt;data[1] * this-&gt;data[this-&gt;stride];\n        }\n\n        // Recursive case: use Laplace expansion along first row\n        float det = 0.0f;\n        for (int j = 0; j &lt; n; ++j)\n        {\n            Mat minor_mat = this-&gt;minor(0, j);\n\n            // Check if minor matrix was created successfully\n            if (minor_mat.data == nullptr)\n            {\n                std::cerr &lt;&lt; \"[Error] determinant_laplace: failed to create minor matrix at (0, \" &lt;&lt; j &lt;&lt; \")\\n\";\n                return 0.0f;\n            }\n\n            // Compute cofactor: (-1)^(i+j) * det(minor)\n            float cofactor_val = ((j % 2 == 0) ? 1.0f : -1.0f) * minor_mat.determinant_laplace();\n            det += this-&gt;data[j] * cofactor_val;\n        }\n\n        return det;\n    }\n\n    /**\n     * @name Mat::determinant_lu()\n     * @brief Compute the determinant using LU decomposition.\n     * @return float The determinant value, or 0.0f on error\n     * @note Time complexity: O(n\u00b3) - efficient for large matrices.\n     *       Formula: det(A) = det(P) * det(L) * det(U) = det(P) * 1 * (product of U diagonal)\n     *       where det(P) = (-1)^(number of row swaps)\n     * @note Uses pivoting for numerical stability.\n     * @note Determinant can be 0.0f for singular matrices, which is a valid result.\n     */\n    float Mat::determinant_lu()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant_lu: matrix data pointer is null\\n\";\n            return 0.0f;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant_lu: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return 0.0f;\n        }\n\n        // Check if matrix is square\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Determinant requires a square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return 0.0f;\n        }\n\n        // Perform LU decomposition with pivoting for numerical stability\n        LUDecomposition lu = this-&gt;lu_decompose(true);\n\n        if (lu.status != TINY_OK)\n        {\n            // Matrix is singular or near-singular, or decomposition failed\n            std::cerr &lt;&lt; \"[Warning] determinant_lu: LU decomposition failed (status=\" \n                      &lt;&lt; lu.status &lt;&lt; \"), matrix may be singular\\n\";\n            return 0.0f;\n        }\n\n        // Check if decomposition matrices are valid\n        if (lu.U.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant_lu: LU decomposition U matrix is null\\n\";\n            return 0.0f;\n        }\n\n        int n = this-&gt;row;\n\n        // Compute det(P): permutation matrix determinant = (-1)^(permutation signature)\n        float det_P = 1.0f;\n        if (lu.pivoted &amp;&amp; lu.P.data != nullptr)\n        {\n            // Compute permutation signature by finding cycles in P\n            // P is a permutation matrix, so each row/column has exactly one 1\n            // We can compute the sign by decomposing into transpositions\n            std::vector&lt;bool&gt; visited(n, false);\n            int cycle_count = 0;\n\n            for (int i = 0; i &lt; n; ++i)\n            {\n                if (visited[i]) continue;\n\n                // Find the cycle starting at i\n                int current = i;\n                int cycle_length = 0;\n                bool found_mapping = false;\n                while (!visited[current])\n                {\n                    visited[current] = true;\n                    cycle_length++;\n                    found_mapping = false;\n\n                    // Find where P maps current row\n                    for (int j = 0; j &lt; n; ++j)\n                    {\n                        if (fabsf(lu.P(current, j) - 1.0f) &lt; 1e-6f)\n                        {\n                            current = j;\n                            found_mapping = true;\n                            break;\n                        }\n                    }\n\n                    // Safety check: if no mapping found, break to avoid infinite loop\n                    // This should not happen for a valid permutation matrix\n                    if (!found_mapping)\n                    {\n                        std::cerr &lt;&lt; \"[Warning] determinant_lu: Could not find mapping for row \" \n                                  &lt;&lt; current &lt;&lt; \" in permutation matrix P. Matrix may be invalid.\\n\";\n                        break;\n                    }\n                }\n\n                // A cycle of length k contributes (k-1) transpositions\n                if (cycle_length &gt; 1)\n                {\n                    cycle_count += (cycle_length - 1);\n                }\n            }\n\n            // det(P) = (-1)^(number of transpositions)\n            det_P = (cycle_count % 2 == 0) ? 1.0f : -1.0f;\n        }\n\n        // Compute det(L): lower triangular with unit diagonal = 1\n        float det_L = 1.0f;  // L has unit diagonal, so det(L) = 1\n\n        // Compute det(U): product of diagonal elements\n        float det_U = 1.0f;\n        for (int i = 0; i &lt; n; ++i)\n        {\n            det_U *= lu.U(i, i);\n        }\n\n        // det(A) = det(P) * det(L) * det(U)\n        return det_P * det_L * det_U;\n    }\n\n    /**\n     * @name Mat::determinant_gaussian()\n     * @brief Compute the determinant using Gaussian elimination.\n     * @return float The determinant value, or 0.0f on error\n     * @note Time complexity: O(n\u00b3) - efficient for large matrices.\n     *       Converts matrix to upper triangular form, then multiplies diagonal elements.\n     *       Tracks row swaps to account for sign changes.\n     * @note Uses partial pivoting for numerical stability.\n     * @note Determinant can be 0.0f for singular matrices, which is a valid result.\n     */\n    float Mat::determinant_gaussian()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant_gaussian: matrix data pointer is null\\n\";\n            return 0.0f;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant_gaussian: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return 0.0f;\n        }\n\n        // Check if matrix is square\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Determinant requires a square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return 0.0f;\n        }\n\n        int n = this-&gt;row;\n        Mat A = Mat(*this);  // Working copy\n\n        // Check if copy was successful\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] determinant_gaussian: failed to create working copy\\n\";\n            return 0.0f;\n        }\n\n        int swap_count = 0;  // Track number of row swaps\n\n        // Gaussian elimination to upper triangular form\n        for (int k = 0; k &lt; n - 1; ++k)\n        {\n            // Partial pivoting: find row with largest element in column k\n            int max_row = k;\n            float max_val = fabsf(A(k, k));\n            for (int i = k + 1; i &lt; n; ++i)\n            {\n                if (fabsf(A(i, k)) &gt; max_val)\n                {\n                    max_val = fabsf(A(i, k));\n                    max_row = i;\n                }\n            }\n\n            // Swap rows if necessary\n            if (max_row != k)\n            {\n                A.swap_rows(k, max_row);\n                swap_count++;\n            }\n\n            // Check for singular matrix (near-zero pivot)\n            if (fabsf(A(k, k)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                // Matrix is singular or near-singular\n                return 0.0f;\n            }\n\n            // Eliminate below diagonal\n            for (int i = k + 1; i &lt; n; ++i)\n            {\n                float factor = A(i, k) / A(k, k);\n                for (int j = k; j &lt; n; ++j)\n                {\n                    A(i, j) -= factor * A(k, j);\n                }\n            }\n        }\n\n        // Compute determinant: product of diagonal elements\n        float det = 1.0f;\n        for (int i = 0; i &lt; n; ++i)\n        {\n            det *= A(i, i);\n        }\n\n        // Account for row swaps: each swap multiplies determinant by -1\n        if (swap_count % 2 == 1)\n        {\n            det = -det;\n        }\n\n        return det;\n    }\n\n    /**\n     * @name Mat::adjoint()\n     * @brief Compute the adjoint (adjugate) matrix.\n     * @note The adjoint matrix is the transpose of the cofactor matrix.\n     *       adj(A)_ij = (-1)^(i+j) * det(minor_ji)\n     *       Note: The result is stored at (j,i) to achieve transpose.\n     * @return Mat The adjoint matrix, or empty Mat() on error\n     * @note Time complexity: O(n\u00b2 * O(det)) - expensive for large matrices.\n     *       For n\u00d7n matrix, requires computing n\u00b2 determinants of (n-1)\u00d7(n-1) matrices.\n     */\n    Mat Mat::adjoint()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] adjoint: matrix data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] adjoint: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check if matrix is square\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Adjoint requires a square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        int n = this-&gt;row;\n        Mat result(n, n);\n\n        // Check if result matrix was created successfully\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] adjoint: failed to create result matrix\\n\";\n            return Mat();\n        }\n\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; n; ++j)\n            {\n                Mat cofactor_mat = this-&gt;cofactor(i, j);\n\n                // Check if cofactor matrix was created successfully\n                if (cofactor_mat.data == nullptr)\n                {\n                    std::cerr &lt;&lt; \"[Error] adjoint: failed to create cofactor matrix at (\" \n                              &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j &lt;&lt; \")\\n\";\n                    return Mat();\n                }\n\n                // Compute cofactor value: (-1)^(i+j) * det(minor)\n                float sign = ((i + j) % 2 == 0) ? 1.0f : -1.0f;\n                float cofactor_val = sign * cofactor_mat.determinant();\n\n                // Store at (j,i) to achieve transpose: adj(A) = C^T\n                result(j, i) = cofactor_val;\n            }\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::normalize()\n     * @brief Normalize the matrix by dividing each element by the matrix norm (Frobenius norm).\n     * @note Normalization: M_normalized = M / ||M||_F\n     *       where ||M||_F = sqrt(sum of squares of all elements)\n     * @note If the matrix norm is zero or too small, normalization is skipped\n     *       and a warning is printed. The matrix remains unchanged.\n     * @note This function modifies the matrix in-place.\n     */\n    void Mat::normalize()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] normalize: matrix data pointer is null\\n\";\n            return;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] normalize: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return;\n        }\n\n        // Check for empty matrix\n        if (this-&gt;row == 0 || this-&gt;col == 0)\n        {\n            // Empty matrix, nothing to normalize\n            return;\n        }\n\n        float n = this-&gt;norm();\n\n        // Check for invalid norm (NaN, Inf, or too small)\n        if (!(n &gt; TINY_MATH_MIN_POSITIVE_INPUT_F32))\n        {\n            if (n == 0.0f)\n            {\n                std::cerr &lt;&lt; \"[Warning] normalize: matrix norm is zero (matrix is all zeros), \"\n                          &lt;&lt; \"normalization skipped\\n\";\n            }\n            else if (std::isnan(n) || std::isinf(n))\n            {\n                std::cerr &lt;&lt; \"[Error] normalize: matrix norm is invalid (NaN or Inf), \"\n                          &lt;&lt; \"normalization skipped\\n\";\n            }\n            else\n            {\n                std::cerr &lt;&lt; \"[Warning] normalize: matrix norm is too small (\" &lt;&lt; n \n                          &lt;&lt; \"), normalization skipped\\n\";\n            }\n            return;\n        }\n\n        // Normalize each element\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                (*this)(i, j) /= n;\n            }\n        }\n    }\n\n    /**\n     * @name Mat::norm()\n     * @brief Compute the Frobenius norm (Euclidean norm) of the matrix.\n     * @note Frobenius norm: ||M||_F = sqrt(\u03a3 M_ij\u00b2)\n     *       This is the square root of the sum of squares of all matrix elements.\n     * @note For empty matrices, returns 0.0f.\n     * @note For zero matrices, returns 0.0f.\n     * \n     * @return float The Frobenius norm of the matrix, or 0.0f on error\n     */\n    float Mat::norm() const\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] norm: matrix data pointer is null\\n\";\n            return 0.0f;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] norm: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return 0.0f;\n        }\n\n        // Handle empty matrix\n        if (this-&gt;row == 0 || this-&gt;col == 0)\n        {\n            return 0.0f;\n        }\n\n        float sum_sq = 0.0f;\n        for (int i = 0; i &lt; this-&gt;row; ++i)\n        {\n            for (int j = 0; j &lt; this-&gt;col; ++j)\n            {\n                float val = (*this)(i, j);\n                sum_sq += val * val;\n            }\n        }\n\n        // Compute square root\n        // Note: sum_sq should always be non-negative (sum of squares)\n        float result = sqrtf(sum_sq);\n\n        // Safety check: if result is invalid, return 0.0f\n        if (std::isnan(result) || std::isinf(result))\n        {\n            std::cerr &lt;&lt; \"[Warning] norm: computed norm is invalid (NaN or Inf), returning 0.0f\\n\";\n            return 0.0f;\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::inverse_adjoint()\n     * @brief Compute the inverse matrix using the adjoint method.\n     * @note Formula: A^(-1) = (1 / det(A)) * adj(A)\n     *       where adj(A) is the adjoint (transpose of cofactor matrix).\n     * @note WARNING: This method is SLOW for large matrices!\n     *       - Time complexity: O(n\u00b2 \u00d7 n!) - exponential growth with matrix size\n     *       - For n\u00d7n matrix, requires computing n\u00b2 determinants of (n-1)\u00d7(n-1) matrices\n     *       - Each determinant calculation uses Laplace expansion (O(n!) complexity)\n     *       - Example: 4\u00d74 matrix needs 16 determinants of 3\u00d73 matrices\n     *       - Example: 5\u00d75 matrix needs 25 determinants of 4\u00d74 matrices (very slow!)\n     * @note Performance comparison:\n     *       - 2\u00d72 matrix: Fast (direct formula)\n     *       - 3\u00d73 matrix: Acceptable\n     *       - 4\u00d74 matrix: Slow but usable\n     *       - 5\u00d75+ matrix: VERY SLOW - use other methods instead\n     * @note For larger matrices (n &gt;= 4), strongly recommend using:\n     *       - inverse_gje() (Gauss-Jordan elimination, O(n\u00b3))\n     *       - LU decomposition methods (O(n\u00b3), more stable)\n     * @note This method is mainly useful for:\n     *       - Small matrices (n &lt;= 3) where simplicity is preferred\n     *       - Educational purposes to understand the adjoint formula\n     *       - Cases where you need the adjoint matrix anyway\n     * \n     * @return Mat The inverse matrix, or empty Mat() on error\n     */\n    Mat Mat::inverse_adjoint()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_adjoint: matrix data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_adjoint: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check if matrix is square\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_adjoint: requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Compute determinant\n        float det = this-&gt;determinant();\n\n        // Check if determinant is valid\n        if (std::isnan(det) || std::isinf(det))\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_adjoint: determinant is invalid (NaN or Inf)\\n\";\n            return Mat();\n        }\n\n        // Check if matrix is singular (determinant is zero or too small)\n        if (fabsf(det) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_adjoint: matrix is singular (det=\" &lt;&lt; det \n                      &lt;&lt; \"), cannot compute inverse\\n\";\n            return Mat();\n        }\n\n        // Compute adjoint matrix\n        Mat adj = this-&gt;adjoint();\n\n        // Check if adjoint computation was successful\n        if (adj.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_adjoint: failed to compute adjoint matrix\\n\";\n            return Mat();\n        }\n\n        // Check if adjoint matrix has correct dimensions\n        if (adj.row != this-&gt;row || adj.col != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_adjoint: adjoint matrix has incorrect dimensions: \" \n                      &lt;&lt; adj.row &lt;&lt; \"x\" &lt;&lt; adj.col &lt;&lt; \" (expected \" &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Compute inverse: A^(-1) = (1 / det(A)) * adj(A)\n        float inv_det = 1.0f / det;\n        Mat result = adj * inv_det;\n\n        // Check if matrix multiplication was successful\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_adjoint: failed to compute inverse matrix (multiplication failed)\\n\";\n            return Mat();\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::dotprod(const Mat &amp;A, const Mat &amp;B)\n     * @brief Compute the dot product (Frobenius inner product) of two matrices.\n     * @note Mathematical definition: A \u00b7 B = \u03a3 A_ij * B_ij (sum over all elements)\n     *       This is the element-wise multiplication followed by summation.\n     * @note Also known as:\n     *       - Frobenius inner product\n     *       - Hadamard product sum\n     *       - Element-wise dot product\n     * @note For vectors, this is equivalent to the standard dot product.\n     * @note For empty matrices, returns 0.0f.\n     *\n     * @param A First matrix\n     * @param B Second matrix\n     * @return float Dot product value, or 0.0f on error\n     */\n    float Mat::dotprod(const Mat &amp;A, const Mat &amp;B)\n    {\n        // Check for null pointers\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] dotprod: matrix A data pointer is null\\n\";\n            return 0.0f;\n        }\n\n        if (B.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] dotprod: matrix B data pointer is null\\n\";\n            return 0.0f;\n        }\n\n        // Validate matrix dimensions\n        if (A.row &lt;= 0 || A.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] dotprod: invalid matrix A dimensions: rows=\" \n                      &lt;&lt; A.row &lt;&lt; \", cols=\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return 0.0f;\n        }\n\n        if (B.row &lt;= 0 || B.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] dotprod: invalid matrix B dimensions: rows=\" \n                      &lt;&lt; B.row &lt;&lt; \", cols=\" &lt;&lt; B.col &lt;&lt; \"\\n\";\n            return 0.0f;\n        }\n\n        // Check if matrices have the same size\n        if (A.row != B.row || A.col != B.col)\n        {\n            std::cerr &lt;&lt; \"[Error] dotprod: matrices must have the same size (A: \" \n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \", B: \" &lt;&lt; B.row &lt;&lt; \"x\" &lt;&lt; B.col &lt;&lt; \")\\n\";\n            return 0.0f;\n        }\n\n        // Handle empty matrices\n        if (A.row == 0 || A.col == 0)\n        {\n            return 0.0f;\n        }\n\n        // Compute dot product: sum of element-wise products\n        float result = 0.0f;\n        for (int i = 0; i &lt; A.row; ++i)\n        {\n            for (int j = 0; j &lt; A.col; ++j)\n            {\n                result += A(i, j) * B(i, j);\n            }\n        }\n\n        return result;\n    }\n\n    // ============================================================================\n    // Linear Algebra - Matrix Utilities\n    // ============================================================================\n    /**\n     * @name Mat::eye(int size)\n     * @brief Create an identity matrix (unit matrix) of specified size.\n     * @note Identity matrix I has:\n     *       - I_ij = 1 if i == j (diagonal elements)\n     *       - I_ij = 0 if i != j (off-diagonal elements)\n     * @note Properties:\n     *       - I * A = A (left identity)\n     *       - A * I = A (right identity)\n     *       - I^(-1) = I (self-inverse)\n     * @note For size = 0, returns empty matrix.\n     *\n     * @param size Size of the square identity matrix (must be &gt;= 0)\n     * @return Mat Identity matrix, or empty Mat() on error\n     */\n    Mat Mat::eye(int size)\n    {\n        // Validate parameter\n        if (size &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] eye: size must be non-negative (got \" &lt;&lt; size &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Handle size = 0 (empty matrix)\n        if (size == 0)\n        {\n            return Mat(0, 0);\n        }\n\n        Mat identity(size, size);\n\n        // Check if matrix was created successfully\n        if (identity.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] eye: failed to create identity matrix of size \" &lt;&lt; size &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Initialize identity matrix: diagonal = 1, others = 0\n        // Note: Mat constructor already initializes to 0, so we only need to set diagonal\n        for (int i = 0; i &lt; size; ++i)\n        {\n            identity(i, i) = 1.0f;  // Set diagonal elements to 1\n            // Off-diagonal elements are already 0 from constructor\n        }\n\n        return identity;\n    }\n\n    /**\n     * @name Mat::ones(int rows, int cols)\n     * @brief Create a matrix filled with ones (all elements = 1.0f).\n     * @note Creates a matrix where every element is 1.0f.\n     * @note For rows = 0 or cols = 0, returns empty matrix.\n     *\n     * @param rows Number of rows (must be &gt;= 0)\n     * @param cols Number of columns (must be &gt;= 0)\n     * @return Mat Matrix filled with ones, or empty Mat() on error\n     */\n    Mat Mat::ones(int rows, int cols)\n    {\n        // Validate parameters\n        if (rows &lt; 0 || cols &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] ones: dimensions must be non-negative (got rows=\" \n                      &lt;&lt; rows &lt;&lt; \", cols=\" &lt;&lt; cols &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Handle empty matrix\n        if (rows == 0 || cols == 0)\n        {\n            return Mat(rows, cols);\n        }\n\n        Mat result(rows, cols);\n\n        // Check if matrix was created successfully\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] ones: failed to create matrix of size \" \n                      &lt;&lt; rows &lt;&lt; \"x\" &lt;&lt; cols &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Fill all elements with 1.0f\n        for (int i = 0; i &lt; rows; ++i)\n        {\n            for (int j = 0; j &lt; cols; ++j)\n            {\n                result(i, j) = 1.0f;\n            }\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::ones(int size)\n     * @brief Create a square matrix filled with ones (all elements = 1.0f).\n     * @note Convenience function that creates a size\u00d7size matrix filled with ones.\n     *       Equivalent to ones(size, size).\n     * @note For size = 0, returns empty matrix.\n     *\n     * @param size Size of the square matrix (rows = cols, must be &gt;= 0)\n     * @return Mat Square matrix [size x size] with all elements = 1, or empty Mat() on error\n     */\n    Mat Mat::ones(int size)\n    {\n        // All validation is handled by ones(size, size)\n        return Mat::ones(size, size);\n    }\n\n    /**\n     * @name Mat::augment(const Mat &amp;A, const Mat &amp;B)\n     * @brief Augment two matrices horizontally [A | B] (concatenate columns).\n     * @note Creates a new matrix by placing B to the right of A.\n     *       Result: [A | B] with dimensions (rows, A.cols + B.cols)\n     *       where rows must be the same for both matrices.\n     * @note Common use case: Creating augmented matrix [A | b] for solving Ax = b\n     *       using Gaussian elimination.\n     * @note For empty matrices, returns empty matrix if dimensions are valid.\n     *\n     * @param A Left matrix\n     * @param B Right matrix\n     * @return Mat Augmented matrix [A B], or empty Mat() on error\n     */\n    Mat Mat::augment(const Mat &amp;A, const Mat &amp;B)\n    {\n        // Check for null pointers\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] augment: matrix A data pointer is null\\n\";\n            return Mat();\n        }\n\n        if (B.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] augment: matrix B data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (A.row &lt; 0 || A.col &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] augment: invalid matrix A dimensions: rows=\" \n                      &lt;&lt; A.row &lt;&lt; \", cols=\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        if (B.row &lt; 0 || B.col &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] augment: invalid matrix B dimensions: rows=\" \n                      &lt;&lt; B.row &lt;&lt; \", cols=\" &lt;&lt; B.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check if row counts match\n        if (A.row != B.row)\n        {\n            std::cerr &lt;&lt; \"[Error] augment: row counts must match (A: \" \n                      &lt;&lt; A.row &lt;&lt; \", B: \" &lt;&lt; B.row &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check for integer overflow in column sum\n        if (A.col &gt; INT_MAX - B.col)\n        {\n            std::cerr &lt;&lt; \"[Error] augment: combined column count too large, integer overflow \"\n                      &lt;&lt; \"(A.col=\" &lt;&lt; A.col &lt;&lt; \", B.col=\" &lt;&lt; B.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Create new matrix with combined columns\n        Mat AB(A.row, A.col + B.col);\n\n        // Check if matrix was created successfully\n        if (AB.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] augment: failed to create augmented matrix of size \" \n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; (A.col + B.col) &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Handle empty matrices\n        if (A.row == 0)\n        {\n            // Empty result matrix already created, return it\n            return AB;\n        }\n\n        // Copy data from A and B\n        for (int i = 0; i &lt; A.row; ++i)\n        {\n            // Copy A (left part)\n            for (int j = 0; j &lt; A.col; ++j)\n            {\n                AB(i, j) = A(i, j);\n            }\n            // Copy B (right part)\n            for (int j = 0; j &lt; B.col; ++j)\n            {\n                AB(i, A.col + j) = B(i, j);\n            }\n        }\n\n        return AB;\n    }\n\n    /**\n     * @name Mat::vstack(const Mat &amp;A, const Mat &amp;B)\n     * @brief Vertically stack two matrices [A; B] (concatenate rows).\n     * @note Creates a new matrix by placing B below A.\n     *       Result: [A; B] with dimensions (A.rows + B.rows, cols)\n     *       where cols must be the same for both matrices.\n     * @note Common use case: Combining data from multiple sources vertically,\n     *       or building block matrices in linear algebra operations.\n     * @note For empty matrices, returns empty matrix if dimensions are valid.\n     *\n     * @param A Top matrix\n     * @param B Bottom matrix\n     * @return Mat Vertically stacked matrix [A; B], or empty Mat() on error\n     */\n    Mat Mat::vstack(const Mat &amp;A, const Mat &amp;B)\n    {\n        // Check for null pointers\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] vstack: matrix A data pointer is null\\n\";\n            return Mat();\n        }\n\n        if (B.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] vstack: matrix B data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (A.row &lt; 0 || A.col &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] vstack: invalid matrix A dimensions: rows=\" \n                      &lt;&lt; A.row &lt;&lt; \", cols=\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        if (B.row &lt; 0 || B.col &lt; 0)\n        {\n            std::cerr &lt;&lt; \"[Error] vstack: invalid matrix B dimensions: rows=\" \n                      &lt;&lt; B.row &lt;&lt; \", cols=\" &lt;&lt; B.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check if column counts match\n        if (A.col != B.col)\n        {\n            std::cerr &lt;&lt; \"[Error] vstack: column counts must match (A: \" \n                      &lt;&lt; A.col &lt;&lt; \", B: \" &lt;&lt; B.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check for integer overflow in row sum\n        if (A.row &gt; INT_MAX - B.row)\n        {\n            std::cerr &lt;&lt; \"[Error] vstack: combined row count too large, integer overflow \"\n                      &lt;&lt; \"(A.row=\" &lt;&lt; A.row &lt;&lt; \", B.row=\" &lt;&lt; B.row &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Create new matrix with combined rows\n        Mat AB(A.row + B.row, A.col);\n\n        // Check if matrix was created successfully\n        if (AB.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] vstack: failed to create stacked matrix of size \" \n                      &lt;&lt; (A.row + B.row) &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Handle empty matrices\n        if (A.col == 0)\n        {\n            // Empty result matrix already created, return it\n            return AB;\n        }\n\n        // Copy data from A and B\n        // Copy A (top rows)\n        for (int i = 0; i &lt; A.row; ++i)\n        {\n            for (int j = 0; j &lt; A.col; ++j)\n            {\n                AB(i, j) = A(i, j);\n            }\n        }\n        // Copy B (bottom rows)\n        for (int i = 0; i &lt; B.row; ++i)\n        {\n            for (int j = 0; j &lt; B.col; ++j)\n            {\n                AB(A.row + i, j) = B(i, j);\n            }\n        }\n\n        return AB;\n    }\n\n    /**\n     * @name Mat::gram_schmidt_orthogonalize()\n     * @brief Orthogonalize a set of vectors using the Gram-Schmidt process\n     * @note This is a general-purpose orthogonalization function that can be reused\n     *       for QR decomposition and other applications requiring orthogonal bases\n     * \n     * @param vectors Input matrix where each column is a vector to be orthogonalized\n     * @param orthogonal_vectors Output matrix for orthogonalized vectors (each column is orthogonal)\n     * @param coefficients Output matrix for projection coefficients (upper triangular, like R in QR)\n     * @param tolerance Minimum norm threshold for linear independence check\n     * @return true if successful, false if input is invalid\n     */\n    bool Mat::gram_schmidt_orthogonalize(const Mat &amp;vectors, Mat &amp;orthogonal_vectors, \n                                         Mat &amp;coefficients, float tolerance)\n    {\n        // Validation: check for null pointer\n        if (vectors.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] gram_schmidt_orthogonalize: Input matrix is null.\\n\";\n            return false;\n        }\n\n        int m = vectors.row;  // Dimension of vectors\n        int n = vectors.col;  // Number of vectors\n\n        // Validate dimensions\n        if (m &lt;= 0 || n &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] gram_schmidt_orthogonalize: Invalid dimensions (m=\" \n                      &lt;&lt; m &lt;&lt; \", n=\" &lt;&lt; n &lt;&lt; \")\\n\";\n            return false;\n        }\n\n        // Validate tolerance\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] gram_schmidt_orthogonalize: tolerance must be non-negative (got \" \n                      &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            return false;\n        }\n\n        // Initialize output matrices\n        orthogonal_vectors = Mat(m, n);\n        coefficients = Mat(n, n);  // Upper triangular matrix for coefficients\n\n        // Check if output matrices were created successfully\n        if (orthogonal_vectors.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] gram_schmidt_orthogonalize: failed to create orthogonal_vectors matrix\\n\";\n            return false;\n        }\n\n        if (coefficients.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] gram_schmidt_orthogonalize: failed to create coefficients matrix\\n\";\n            return false;\n        }\n\n        coefficients.clear();  // Initialize to zero\n\n        // Modified Gram-Schmidt process (more numerically stable than classical GS)\n        // Also includes re-orthogonalization for better numerical stability\n        for (int j = 0; j &lt; n; ++j)\n        {\n            // Copy j-th column of input vectors to working vector\n            for (int i = 0; i &lt; m; ++i)\n            {\n                orthogonal_vectors(i, j) = vectors(i, j);\n            }\n\n            // Modified Gram-Schmidt: orthogonalize against previous columns\n            // Use a more stable approach: subtract projection immediately\n            for (int k = 0; k &lt; j; ++k)\n            {\n                // Compute dot product: coefficient(k,j) = Q(:,k)^T * Q(:,j)\n                float dot = 0.0f;\n                for (int i = 0; i &lt; m; ++i)\n                {\n                    dot += orthogonal_vectors(i, k) * orthogonal_vectors(i, j);\n                }\n                coefficients(k, j) = dot;  // Store projection coefficient\n\n                // Subtract projection immediately: Q(:,j) = Q(:,j) - dot * Q(:,k)\n                for (int i = 0; i &lt; m; ++i)\n                {\n                    orthogonal_vectors(i, j) -= dot * orthogonal_vectors(i, k);\n                }\n            }\n\n            // Re-orthogonalization: improve numerical stability by doing one more pass\n            // This helps reduce accumulated rounding errors (especially important for\n            // near-linearly-dependent vectors)\n            for (int k = 0; k &lt; j; ++k)\n            {\n                float dot = 0.0f;\n                for (int i = 0; i &lt; m; ++i)\n                {\n                    dot += orthogonal_vectors(i, k) * orthogonal_vectors(i, j);\n                }\n                // Update coefficient with correction (small correction for numerical stability)\n                coefficients(k, j) += dot;\n                // Subtract residual projection to improve orthogonality\n                for (int i = 0; i &lt; m; ++i)\n                {\n                    orthogonal_vectors(i, j) -= dot * orthogonal_vectors(i, k);\n                }\n            }\n\n            // Normalize: compute norm of orthogonalized vector\n            float norm = 0.0f;\n            for (int i = 0; i &lt; m; ++i)\n            {\n                norm += orthogonal_vectors(i, j) * orthogonal_vectors(i, j);\n            }\n            norm = sqrtf(norm);\n\n            // Use stricter tolerance for near-linear-dependent vectors\n            // If norm is very small, generate an orthogonal vector to complete the basis\n            if (norm &lt; tolerance || norm &lt; 1e-5f)  // Stricter check for numerical stability\n            {\n                // Vector is linearly dependent (or near-zero)\n                // Instead of setting to zero, generate an orthogonal vector to maintain Q's orthogonality\n                // Strategy: Start with a standard basis vector and orthogonalize it\n                coefficients(j, j) = 0.0f;  // Original vector has zero norm (linearly dependent)\n\n                // Try to find an orthogonal vector by starting with standard basis vectors\n                // and orthogonalizing them against previous columns\n                bool found_orthogonal = false;\n                for (int basis_idx = 0; basis_idx &lt; m &amp;&amp; !found_orthogonal; ++basis_idx)\n                {\n                    // Start with standard basis vector e_basis_idx\n                    for (int i = 0; i &lt; m; ++i)\n                    {\n                        orthogonal_vectors(i, j) = (i == basis_idx) ? 1.0f : 0.0f;\n                    }\n\n                    // Orthogonalize against previous columns\n                    for (int k = 0; k &lt; j; ++k)\n                    {\n                        float dot = 0.0f;\n                        for (int i = 0; i &lt; m; ++i)\n                        {\n                            dot += orthogonal_vectors(i, k) * orthogonal_vectors(i, j);\n                        }\n                        for (int i = 0; i &lt; m; ++i)\n                        {\n                            orthogonal_vectors(i, j) -= dot * orthogonal_vectors(i, k);\n                        }\n                    }\n\n                    // Check if we got a non-zero vector\n                    float new_norm = 0.0f;\n                    for (int i = 0; i &lt; m; ++i)\n                    {\n                        new_norm += orthogonal_vectors(i, j) * orthogonal_vectors(i, j);\n                    }\n                    new_norm = sqrtf(new_norm);\n\n                    if (new_norm &gt; 1e-5f)\n                    {\n                        // Found a valid orthogonal vector, normalize it\n                        // Note: coefficients(j, j) remains 0 (original vector was linearly dependent)\n                        // but Q(:, j) is now a normalized orthogonal vector\n                        for (int i = 0; i &lt; m; ++i)\n                        {\n                            orthogonal_vectors(i, j) /= new_norm;\n                        }\n                        found_orthogonal = true;\n                    }\n                }\n\n                // If still no orthogonal vector found, set to zero (shouldn't happen for full-rank cases)\n                if (!found_orthogonal)\n                {\n                    coefficients(j, j) = 0.0f;\n                    for (int i = 0; i &lt; m; ++i)\n                    {\n                        orthogonal_vectors(i, j) = 0.0f;\n                    }\n                }\n            }\n            else\n            {\n                coefficients(j, j) = norm;\n                // Normalize the orthogonalized vector\n                for (int i = 0; i &lt; m; ++i)\n                {\n                    orthogonal_vectors(i, j) /= norm;\n                }\n            }\n        }\n\n        return true;\n    }\n\n    // ============================================================================\n    // Linear Algebra - Matrix Operations\n    // ============================================================================\n    /**\n     * @name Mat::minor(int target_row, int target_col)\n     * @brief Calculate the minor matrix by removing specified row and column.\n     * \n     * @note This function returns a MATRIX (the minor matrix), NOT a scalar value.\n     *       The minor matrix is (n-1)\u00d7(n-1) for an n\u00d7n input matrix.\n     * \n     * @note Difference from cofactor():\n     *       - minor() and cofactor() return the SAME matrix (submatrix)\n     *       - minor() is the general term for the submatrix\n     *       - cofactor() is semantically used when computing cofactor values (with sign)\n     *       - Both functions can be used interchangeably for getting the submatrix\n     * \n     * @note To compute minor value: minor_value = det(minor_matrix)\n     * @note To compute cofactor value: cofactor_value = (-1)^(i+j) * det(minor_matrix)\n     *\n     * @param target_row Row index to remove (0-based)\n     * @param target_col Column index to remove (0-based)\n     * @return Mat The (n-1)\u00d7(n-1) minor matrix, or empty Mat() on error\n     */\n    Mat Mat::minor(int target_row, int target_col)\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] minor: matrix data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] minor: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check if matrix is square\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] Minor requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        int n = this-&gt;row;\n\n        // Validate indices\n        if (target_row &lt; 0 || target_row &gt;= n)\n        {\n            std::cerr &lt;&lt; \"[Error] minor: target_row=\" &lt;&lt; target_row \n                      &lt;&lt; \" is out of range [0, \" &lt;&lt; (n-1) &lt;&lt; \"]\\n\";\n            return Mat();\n        }\n\n        if (target_col &lt; 0 || target_col &gt;= n)\n        {\n            std::cerr &lt;&lt; \"[Error] minor: target_col=\" &lt;&lt; target_col \n                      &lt;&lt; \" is out of range [0, \" &lt;&lt; (n-1) &lt;&lt; \"]\\n\";\n            return Mat();\n        }\n\n        // For 1\u00d71 matrix, removing one row and one column results in 0\u00d70 matrix\n        // This is a valid but empty result\n        if (n == 1)\n        {\n            return Mat(0, 0);\n        }\n\n        Mat result(n - 1, n - 1);\n\n        // Check if result matrix was created successfully\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] minor: failed to create result matrix\\n\";\n            return Mat();\n        }\n\n        // Copy elements, skipping the specified row and column\n        for (int i = 0, res_i = 0; i &lt; n; ++i)\n        {\n            if (i == target_row)\n                continue;\n\n            for (int j = 0, res_j = 0; j &lt; n; ++j)\n            {\n                if (j == target_col)\n                    continue;\n\n                result.data[res_i * result.stride + res_j] = this-&gt;data[i * this-&gt;stride + j];\n                res_j++;\n            }\n            res_i++;\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::cofactor(int target_row, int target_col)\n     * @brief Calculate the cofactor matrix (same as minor matrix).\n     * \n     * @note IMPORTANT DISTINCTION:\n     *       - This function returns a MATRIX (the cofactor matrix), NOT a scalar value.\n     *       - The cofactor matrix is mathematically identical to the minor matrix.\n     *       - To get the COFACTOR VALUE (scalar), you must:\n     *         cofactor_value = (-1)^(i+j) * det(cofactor_matrix)\n     * \n     * @note Mathematical definitions:\n     *       - Minor matrix M_ij = submatrix after removing row i and column j\n     *       - Cofactor matrix C_ij = M_ij (same as minor matrix)\n     *       - Cofactor VALUE = (-1)^(i+j) * det(M_ij)\n     * \n     * @note Difference from minor():\n     *       - minor() and cofactor() return the SAME matrix (submatrix)\n     *       - The difference is semantic: cofactor() is used when computing\n     *         cofactor values (with sign), while minor() is more general.\n     *       - Both functions can be used interchangeably for getting the submatrix.\n     * \n     * @note Usage example:\n     *       Mat cofactor_mat = A.cofactor(i, j);  // Returns matrix\n     *       float cofactor_val = ((i+j) % 2 == 0 ? 1.0f : -1.0f) * cofactor_mat.determinant();  // Value\n     *\n     * @param target_row Row index to remove (0-based)\n     * @param target_col Column index to remove (0-based)\n     * @return Mat The (n-1)\u00d7(n-1) cofactor matrix (same as minor matrix), or empty Mat() on error\n     */\n    Mat Mat::cofactor(int target_row, int target_col)\n    {\n        // Cofactor matrix is the same as minor matrix\n        // The sign is applied when computing cofactor values, not to matrix elements\n        // All validation is handled by minor()\n        return this-&gt;minor(target_row, target_col);\n    }\n\n    /**\n     * @name Mat::gaussian_eliminate\n     * @brief Perform Gaussian Elimination to convert matrix to Row Echelon Form (REF).\n     * @note Gaussian elimination transforms a matrix to upper triangular form (REF) using\n     *       elementary row operations: row swapping, row scaling, and row addition.\n     * @note Algorithm:\n     *       1. For each row r, find a pivot (non-zero element) in column lead\n     *       2. Swap rows if necessary to bring pivot to current row\n     *       3. Eliminate elements below pivot by subtracting multiples of pivot row\n     *       4. Move to next column and repeat\n     * @note Uses partial pivoting (finds first non-zero element) for numerical stability.\n     * @note Near-zero values are set to zero for numerical precision.\n     *\n     * @return Mat The upper triangular matrix (REF form), or empty Mat() on error\n     */\n    Mat Mat::gaussian_eliminate() const\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] gaussian_eliminate: matrix data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] gaussian_eliminate: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Handle empty matrix\n        if (this-&gt;row == 0 || this-&gt;col == 0)\n        {\n            return Mat(*this);  // Return copy of empty matrix\n        }\n\n        Mat result(*this); // Create a copy of the original matrix\n\n        // Check if copy was successful\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] gaussian_eliminate: failed to create working copy\\n\";\n            return Mat();\n        }\n\n        int rows = result.row;\n        int cols = result.col;\n\n        int lead = 0; // Leading column tracker\n\n        for (int r = 0; r &lt; rows; ++r)\n        {\n            if (lead &gt;= cols)\n                break;\n\n            int i = r;\n\n            // Find pivot row (partial pivoting)\n            // Look for first non-zero (or near-zero) element in column lead\n            while (fabsf(result(i, lead)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                i++;\n                if (i == rows)\n                {\n                    i = r;\n                    lead++;\n                    if (lead == cols)\n                        return result; // Return the result matrix (upper triangular)\n                }\n            }\n\n            // Swap rows if pivot is not in current row\n            if (i != r)\n            {\n                result.swap_rows(i, r);\n            }\n\n            // Check if pivot is still valid after swap\n            if (fabsf(result(r, lead)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                // Pivot is still too small, move to next column\n                lead++;\n                continue;\n            }\n\n            // Eliminate rows below\n            for (int j = r + 1; j &lt; rows; ++j)\n            {\n                if (fabsf(result(j, lead)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    continue;\n\n                float factor = result(j, lead) / result(r, lead);\n                for (int k = lead; k &lt; cols; ++k)\n                {\n                    result(j, k) -= factor * result(r, k);\n\n                    // Numerical precision handling (set near-zero values to zero)\n                    if (fabsf(result(j, k)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                        result(j, k) = 0.0f;\n                }\n            }\n\n            lead++;\n        }\n\n        return result; // Return the upper triangular matrix\n    }\n\n    /**\n     * @name Mat::row_reduce_from_gaussian()\n     * @brief Convert a matrix (assumed in row echelon form) to Reduced Row Echelon Form (RREF).\n     * @note This function assumes the input matrix is already in Row Echelon Form (REF).\n     *       It performs back-substitution to convert REF to RREF.\n     * @note RREF properties:\n     *       - Leading entry (pivot) in each row is 1\n     *       - Pivot is the only non-zero entry in its column\n     *       - Rows with all zeros are at the bottom\n     * @note Algorithm:\n     *       1. Start from bottom row and work upwards\n     *       2. For each row with a pivot:\n     *          a. Normalize pivot to 1 (divide row by pivot value)\n     *          b. Eliminate entries above pivot (make them zero)\n     *       3. Continue until all rows are processed\n     *\n     * @return Mat The matrix in RREF form, or empty Mat() on error\n     */\n    Mat Mat::row_reduce_from_gaussian()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] row_reduce_from_gaussian: matrix data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] row_reduce_from_gaussian: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Handle empty matrix\n        if (this-&gt;row == 0 || this-&gt;col == 0)\n        {\n            return Mat(*this);  // Return copy of empty matrix\n        }\n\n        Mat R(*this); // Make a copy to preserve original matrix\n\n        // Check if copy was successful\n        if (R.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] row_reduce_from_gaussian: failed to create working copy\\n\";\n            return Mat();\n        }\n\n        int rows = R.row;\n        int cols = R.col;\n\n        int pivot_row = rows - 1;\n\n        while (pivot_row &gt;= 0)\n        {\n            // Locate pivot in current row (first non-zero element)\n            int current_pivot_col = -1;\n            for (int k = 0; k &lt; cols; ++k)\n            {\n                if (fabsf(R(pivot_row, k)) &gt;= TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                {\n                    current_pivot_col = k;\n                    break;\n                }\n            }\n\n            if (current_pivot_col != -1)\n            {\n                // Normalize pivot row (make pivot = 1)\n                float pivot_val = R(pivot_row, current_pivot_col);\n\n                // Check if pivot value is valid (not zero or too small)\n                if (fabsf(pivot_val) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                {\n                    // Pivot is too small, skip this row\n                    pivot_row--;\n                    continue;\n                }\n\n                for (int s = current_pivot_col; s &lt; cols; ++s)\n                {\n                    R(pivot_row, s) /= pivot_val;\n                    // Numerical precision handling\n                    if (fabsf(R(pivot_row, s)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    {\n                        R(pivot_row, s) = 0.0f;\n                    }\n                }\n\n                // Eliminate above pivot (make entries above pivot zero)\n                for (int t = pivot_row - 1; t &gt;= 0; --t)\n                {\n                    float factor = R(t, current_pivot_col);\n                    // Skip if factor is already zero (optimization)\n                    if (fabsf(factor) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                        continue;\n\n                    for (int s = current_pivot_col; s &lt; cols; ++s)\n                    {\n                        R(t, s) -= factor * R(pivot_row, s);\n                        // Numerical precision handling\n                        if (fabsf(R(t, s)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                        {\n                            R(t, s) = 0.0f;\n                        }\n                    }\n                }\n            }\n\n            pivot_row--;\n        }\n\n        return R;\n    }\n\n    /**\n     * @name Mat::inverse_gje()\n     * @brief Compute the inverse of a square matrix using Gauss-Jordan elimination.\n     * @note Algorithm:\n     *       1. Create augmented matrix [A | I] where I is identity matrix\n     *       2. Apply Gauss-Jordan elimination to get [I | A^(-1)]\n     *       3. Extract the right half as the inverse matrix\n     * @note Time complexity: O(n\u00b3) - efficient for large matrices.\n     *       More efficient than adjoint method for n &gt;= 4.\n     * @note If matrix is singular (not invertible), returns empty matrix.\n     *\n     * @return Mat The inverse matrix if invertible, or empty Mat() on error\n     */\n    Mat Mat::inverse_gje()\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: matrix data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check if matrix is square\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        int n = this-&gt;row;\n\n        // Step 1: Create augmented matrix [A | I]\n        Mat I = Mat::eye(n);            // Identity matrix\n\n        // Check if identity matrix was created successfully\n        if (I.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: failed to create identity matrix\\n\";\n            return Mat();\n        }\n\n        Mat augmented = Mat::augment(*this, I); // Augment matrix A with I\n\n        // Check if augmented matrix was created successfully\n        if (augmented.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: failed to create augmented matrix\\n\";\n            return Mat();\n        }\n\n        // Check augmented matrix dimensions\n        if (augmented.col != 2 * n)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: augmented matrix has incorrect dimensions: \" \n                      &lt;&lt; augmented.row &lt;&lt; \"x\" &lt;&lt; augmented.col &lt;&lt; \" (expected \" &lt;&lt; n &lt;&lt; \"x\" &lt;&lt; (2*n) &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Step 2: Apply Gauss-Jordan elimination to get [I | A_inv]\n        Mat rref = augmented.gaussian_eliminate();\n\n        // Check if gaussian_eliminate was successful\n        if (rref.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: gaussian_eliminate failed\\n\";\n            return Mat();\n        }\n\n        rref = rref.row_reduce_from_gaussian();\n\n        // Check if row_reduce_from_gaussian was successful\n        if (rref.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: row_reduce_from_gaussian failed\\n\";\n            return Mat();\n        }\n\n        // Check if the left half is the identity matrix\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; n; ++j)\n            {\n                float expected = (i == j) ? 1.0f : 0.0f;\n                float actual = rref(i, j);\n                if (fabsf(actual - expected) &gt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                {\n                    std::cerr &lt;&lt; \"[Error] inverse_gje: matrix is singular (not invertible), \"\n                              &lt;&lt; \"left half is not identity matrix at (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j \n                              &lt;&lt; \"): expected=\" &lt;&lt; expected &lt;&lt; \", actual=\" &lt;&lt; actual &lt;&lt; \"\\n\";\n                    return Mat();\n                }\n            }\n        }\n\n        // Step 3: Extract the right half as the inverse matrix\n        Mat result(n, n);\n\n        // Check if result matrix was created successfully\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_gje: failed to create result matrix\\n\";\n            return Mat();\n        }\n\n        // Extract the right half (columns n to 2n-1)\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; n; ++j)\n            {\n                int col_idx = j + n;  // Right half starts at column n\n                // Boundary check (should not be needed, but safe)\n                if (col_idx &gt;= rref.col)\n                {\n                    std::cerr &lt;&lt; \"[Error] inverse_gje: column index out of bounds: \" \n                              &lt;&lt; col_idx &lt;&lt; \" &gt;= \" &lt;&lt; rref.col &lt;&lt; \"\\n\";\n                    return Mat();\n                }\n                result(i, j) = rref(i, col_idx); // Extract the right part\n            }\n        }\n\n        return result;\n    }\n\n    /**\n     * @name Mat::solve\n     * @brief Solve the linear system Ax = b using Gaussian elimination with back-substitution.\n     * @note Solves the system of linear equations: A \u00d7 x = b\n     *       where A is an n\u00d7n coefficient matrix and b is an n\u00d71 vector.\n     * @note Algorithm:\n     *       1. Create augmented matrix [A | b]\n     *       2. Apply Gaussian elimination to convert to upper triangular form\n     *       3. Use back-substitution to solve for x\n     * @note Time complexity: O(n\u00b3) - efficient for solving linear systems.\n     * @note If matrix A is singular (not invertible), returns empty matrix.\n     *\n     * @param A Coefficient matrix (N\u00d7N, must be square)\n     * @param b Result vector (N\u00d71)\n     * @return Mat Solution vector (N\u00d71) containing x such that Ax = b, or empty Mat() on error\n     */\n    Mat Mat::solve(const Mat &amp;A, const Mat &amp;b) const\n    {\n        // Check for null pointers\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: matrix A data pointer is null\\n\";\n            return Mat();\n        }\n\n        if (b.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: vector b data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (A.row &lt;= 0 || A.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: invalid matrix A dimensions: rows=\" \n                      &lt;&lt; A.row &lt;&lt; \", cols=\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        if (b.row &lt;= 0 || b.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: invalid vector b dimensions: rows=\" \n                      &lt;&lt; b.row &lt;&lt; \", cols=\" &lt;&lt; b.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check if the matrix A is square\n        if (A.row != A.col)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: matrix A must be square (got \" \n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check if A and b dimensions are compatible for solving\n        if (A.row != b.row || b.col != 1)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: dimensions do not match (A: \" \n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \", b: \" &lt;&lt; b.row &lt;&lt; \"x\" &lt;&lt; b.col \n                      &lt;&lt; \", expected b: \" &lt;&lt; A.row &lt;&lt; \"x1)\\n\";\n            return Mat();\n        }\n\n        int n = A.row;\n\n        // Check for integer overflow in augmented matrix column count\n        if (A.col &gt; INT_MAX - 1)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: matrix size too large, integer overflow\\n\";\n            return Mat();\n        }\n\n        // Create augmented matrix [A | b]\n        Mat augmentedMatrix(n, A.col + 1);\n\n        // Check if augmented matrix was created successfully\n        if (augmentedMatrix.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: failed to create augmented matrix\\n\";\n            return Mat();\n        }\n\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; A.col; ++j)\n            {\n                augmentedMatrix(i, j) = A(i, j); // Copy matrix A into augmented matrix\n            }\n            augmentedMatrix(i, A.col) = b(i, 0); // Copy vector b into augmented matrix\n        }\n\n        // Perform Gaussian elimination\n        for (int i = 0; i &lt; n; ++i)\n        {\n            // Find pivot and make sure it's non-zero (or not too small)\n            // Note: This is a simplified version without partial pivoting\n            // For better numerical stability, consider using partial pivoting\n            if (fabsf(augmentedMatrix(i, i)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] solve: pivot at (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; i \n                          &lt;&lt; \") is zero or too small (\" &lt;&lt; augmentedMatrix(i, i) \n                          &lt;&lt; \"), matrix is singular or near-singular\\n\";\n                return Mat();\n            }\n\n            // Normalize the pivot row\n            float pivot = augmentedMatrix(i, i);\n            for (int j = i; j &lt; augmentedMatrix.col; ++j)\n            {\n                augmentedMatrix(i, j) /= pivot; // Normalize the pivot row\n            }\n\n            // Eliminate the entries below the pivot\n            for (int j = i + 1; j &lt; n; ++j)\n            {\n                float factor = augmentedMatrix(j, i);\n                // Skip if factor is already zero (optimization)\n                if (fabsf(factor) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    continue;\n\n                for (int k = i; k &lt; augmentedMatrix.col; ++k)\n                {\n                    augmentedMatrix(j, k) -= factor * augmentedMatrix(i, k);\n\n                    // Numerical precision handling\n                    if (fabsf(augmentedMatrix(j, k)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    {\n                        augmentedMatrix(j, k) = 0.0f;\n                    }\n                }\n            }\n        }\n\n        // Back-substitution to find the solution\n        Mat solution(n, 1);\n\n        // Check if solution matrix was created successfully\n        if (solution.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve: failed to create solution vector\\n\";\n            return Mat();\n        }\n\n        for (int i = n - 1; i &gt;= 0; --i)\n        {\n            float sum = augmentedMatrix(i, A.col); // Right-hand side value\n            for (int j = i + 1; j &lt; n; ++j)\n            {\n                sum -= augmentedMatrix(i, j) * solution(j, 0);\n            }\n            solution(i, 0) = sum;\n        }\n\n        return solution;\n    }\n\n    /**\n     * @name Mat::band_solve\n     * @brief Solve the system of equations Ax = b using optimized Gaussian elimination for banded matrices.\n     * @note Banded matrices have non-zero elements only in a narrow band around the diagonal.\n     *       This function optimizes Gaussian elimination by only processing elements within the band.\n     * @note Algorithm:\n     *       1. Forward elimination: only eliminate elements within the band\n     *       2. Back-substitution: solve for x\n     * @note Time complexity: O(n \u00d7 k\u00b2) where n is matrix size and k is bandwidth.\n     *       More efficient than general solve() for banded matrices (k &lt;&lt; n).\n     * @note Bandwidth k: total width of non-zero band (including diagonal).\n     *       For tridiagonal matrix, k = 3.\n     *\n     * @param A Coefficient matrix (N\u00d7N) - banded matrix (passed by value, will be modified)\n     * @param b Result vector (N\u00d71) (passed by value, will be modified)\n     * @param k Bandwidth of the matrix (must be &gt;= 1 and odd, typically 3, 5, 7, ...)\n     * @return Mat Solution vector (N\u00d71) containing x such that Ax = b, or empty Mat() on error\n     */\n    Mat Mat::band_solve(Mat A, Mat b, int k)\n    {\n        // Check for null pointers\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: matrix A data pointer is null\\n\";\n            return Mat();\n        }\n\n        if (b.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: vector b data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (A.row &lt;= 0 || A.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: invalid matrix A dimensions: rows=\" \n                      &lt;&lt; A.row &lt;&lt; \", cols=\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        if (b.row &lt;= 0 || b.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: invalid vector b dimensions: rows=\" \n                      &lt;&lt; b.row &lt;&lt; \", cols=\" &lt;&lt; b.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Dimension compatibility check\n        if (A.row != A.col) // Check if A is a square matrix\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: matrix A must be square (got \" \n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        if (A.row != b.row || b.col != 1) // Check if dimensions of A and b are compatible\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: dimensions do not match (A: \" \n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \", b: \" &lt;&lt; b.row &lt;&lt; \"x\" &lt;&lt; b.col \n                      &lt;&lt; \", expected b: \" &lt;&lt; A.row &lt;&lt; \"x1)\\n\";\n            return Mat();\n        }\n\n        // Validate bandwidth parameter\n        if (k &lt; 1)\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: bandwidth k must be &gt;= 1 (got \" &lt;&lt; k &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        if (k &gt; A.row)\n        {\n            std::cerr &lt;&lt; \"[Warning] band_solve: bandwidth k=\" &lt;&lt; k \n                      &lt;&lt; \" is larger than matrix size \" &lt;&lt; A.row \n                      &lt;&lt; \", using general solve may be more efficient\\n\";\n        }\n\n        int n = A.row;\n        int bandsBelow = (k - 1) / 2; // Number of bands below the main diagonal\n\n        // Perform forward elimination to reduce the matrix\n        for (int i = 0; i &lt; n; ++i)\n        {\n            // Check if pivot is valid (not zero or too small)\n            if (fabsf(A(i, i)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] band_solve: zero or near-zero pivot detected at (\" \n                          &lt;&lt; i &lt;&lt; \", \" &lt;&lt; i &lt;&lt; \") = \" &lt;&lt; A(i, i) \n                          &lt;&lt; \", matrix is singular or near-singular\\n\";\n                return Mat();\n            }\n\n            float a_ii = 1.0f / A(i, i); // Inverse of the pivot element\n\n            // Eliminate elements below the pivot in the current column\n            // Only process elements within the band (j &lt;= i + bandsBelow)\n            for (int j = i + 1; j &lt; n &amp;&amp; j &lt;= i + bandsBelow; ++j)\n            {\n                if (fabsf(A(j, i)) &gt;= TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                {\n                    float factor = A(j, i) * a_ii;\n                    for (int col_idx = i; col_idx &lt; A.col; ++col_idx)\n                    {\n                        A(j, col_idx) -= A(i, col_idx) * factor; // Eliminate the element\n\n                        // Numerical precision handling\n                        if (fabsf(A(j, col_idx)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                        {\n                            A(j, col_idx) = 0.0f;\n                        }\n                    }\n                    b(j, 0) -= b(i, 0) * factor; // Update the result vector\n\n                    // Numerical precision handling\n                    if (fabsf(b(j, 0)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    {\n                        b(j, 0) = 0.0f;\n                    }\n\n                    A(j, i) = 0.0f; // Set the element to zero as it has been eliminated\n                }\n            }\n        }\n\n        // Back substitution to solve for x\n        Mat x(n, 1);\n\n        // Check if solution matrix was created successfully\n        if (x.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: failed to create solution vector\\n\";\n            return Mat();\n        }\n\n        // Solve the last variable\n        int last_idx = n - 1;\n        if (fabsf(A(last_idx, last_idx)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            std::cerr &lt;&lt; \"[Error] band_solve: zero pivot at (\" &lt;&lt; last_idx &lt;&lt; \", \" \n                      &lt;&lt; last_idx &lt;&lt; \") during back-substitution\\n\";\n            return Mat();\n        }\n        x(last_idx, 0) = b(last_idx, 0) / A(last_idx, last_idx);\n\n        // Solve remaining variables\n        for (int i = n - 2; i &gt;= 0; --i)\n        {\n            float sum = 0.0f;\n            // Only sum elements within the band\n            int max_j = std::min(i + bandsBelow + 1, n);\n            for (int j = i + 1; j &lt; max_j; ++j)\n            {\n                sum += A(i, j) * x(j, 0); // Sum of the known terms\n            }\n\n            if (fabsf(A(i, i)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] band_solve: zero pivot at (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; i \n                          &lt;&lt; \") during back-substitution\\n\";\n                return Mat();\n            }\n\n            x(i, 0) = (b(i, 0) - sum) / A(i, i); // Solve for the current variable\n        }\n\n        return x; // Return the solution vector\n    }\n\n    /**\n     * @name Mat::roots(Mat A, Mat y)\n     * @brief Solve the linear system A * x = y using Gaussian elimination.\n     * @note This is an alternative implementation of solve() function.\n     *       It uses a slightly different Gaussian elimination approach:\n     *       - Normalizes pivot row first (makes pivot = 1)\n     *       - Then eliminates below pivot\n     * @note Algorithm:\n     *       1. Create augmented matrix [A | y]\n     *       2. For each row: normalize pivot to 1, then eliminate below\n     *       3. Back-substitution to solve for x\n     * @note Time complexity: O(n\u00b3) - same as solve().\n     * @note If matrix A is singular (not invertible), returns empty matrix.\n     *\n     * @param A Coefficient matrix (N\u00d7N, must be square, passed by value, will be modified)\n     * @param y Result vector (N\u00d71, passed by value, will be modified)\n     * @return Mat Solution vector (N\u00d71) containing x such that Ax = y, or empty Mat() on error\n     */\n    Mat Mat::roots(Mat A, Mat y)\n    {\n        // Check for null pointers\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: matrix A data pointer is null\\n\";\n            return Mat();\n        }\n\n        if (y.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: vector y data pointer is null\\n\";\n            return Mat();\n        }\n\n        // Validate matrix dimensions\n        if (A.row &lt;= 0 || A.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: invalid matrix A dimensions: rows=\" \n                      &lt;&lt; A.row &lt;&lt; \", cols=\" &lt;&lt; A.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        if (y.row &lt;= 0 || y.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: invalid vector y dimensions: rows=\" \n                      &lt;&lt; y.row &lt;&lt; \", cols=\" &lt;&lt; y.col &lt;&lt; \"\\n\";\n            return Mat();\n        }\n\n        // Check if A is square\n        if (A.row != A.col)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: matrix A must be square (got \" \n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check if A and y dimensions are compatible\n        if (A.row != y.row || y.col != 1)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: dimensions do not match (A: \" \n                      &lt;&lt; A.row &lt;&lt; \"x\" &lt;&lt; A.col &lt;&lt; \", y: \" &lt;&lt; y.row &lt;&lt; \"x\" &lt;&lt; y.col \n                      &lt;&lt; \", expected y: \" &lt;&lt; A.row &lt;&lt; \"x1)\\n\";\n            return Mat();\n        }\n\n        int n = A.row; // Number of rows and columns in A (A is square)\n\n        // Create augmented matrix [A | y]\n        Mat augmentedMatrix = Mat::augment(A, y);\n\n        // Check if augmented matrix was created successfully\n        if (augmentedMatrix.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: failed to create augmented matrix\\n\";\n            return Mat();\n        }\n\n        // Verify augmented matrix dimensions\n        if (augmentedMatrix.col != n + 1)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: augmented matrix has incorrect dimensions: \" \n                      &lt;&lt; augmentedMatrix.row &lt;&lt; \"x\" &lt;&lt; augmentedMatrix.col \n                      &lt;&lt; \" (expected \" &lt;&lt; n &lt;&lt; \"x\" &lt;&lt; (n+1) &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Perform Gaussian elimination\n        for (int j = 0; j &lt; n; j++)\n        {\n            // Normalize the pivot row (make pivot element equal to 1)\n            float pivot = augmentedMatrix(j, j);\n\n            // Check if pivot is valid (not zero or too small)\n            if (fabsf(pivot) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] roots: pivot is zero or too small at (\" &lt;&lt; j &lt;&lt; \", \" &lt;&lt; j \n                          &lt;&lt; \") = \" &lt;&lt; pivot &lt;&lt; \", system may have no solution\\n\";\n                return Mat();\n            }\n\n            // Normalize the pivot row\n            for (int k = 0; k &lt; augmentedMatrix.col; k++)\n            {\n                augmentedMatrix(j, k) /= pivot;\n\n                // Numerical precision handling\n                if (fabsf(augmentedMatrix(j, k)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                {\n                    augmentedMatrix(j, k) = 0.0f;\n                }\n            }\n\n            // Eliminate the column below the pivot (set other elements in the column to zero)\n            for (int i = j + 1; i &lt; n; i++)\n            {\n                float factor = augmentedMatrix(i, j);\n\n                // Skip if factor is already zero (optimization)\n                if (fabsf(factor) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    continue;\n\n                for (int k = 0; k &lt; augmentedMatrix.col; k++)\n                {\n                    augmentedMatrix(i, k) -= factor * augmentedMatrix(j, k);\n\n                    // Numerical precision handling\n                    if (fabsf(augmentedMatrix(i, k)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    {\n                        augmentedMatrix(i, k) = 0.0f;\n                    }\n                }\n            }\n        }\n\n        // Perform back-substitution\n        Mat result(n, 1);\n\n        // Check if result matrix was created successfully\n        if (result.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] roots: failed to create result vector\\n\";\n            return Mat();\n        }\n\n        for (int i = n - 1; i &gt;= 0; i--)\n        {\n            // Right-hand side of the augmented matrix (last column)\n            int rhs_col = n;  // Last column index\n            if (rhs_col &gt;= augmentedMatrix.col)\n            {\n                std::cerr &lt;&lt; \"[Error] roots: column index out of bounds: \" \n                          &lt;&lt; rhs_col &lt;&lt; \" &gt;= \" &lt;&lt; augmentedMatrix.col &lt;&lt; \"\\n\";\n                return Mat();\n            }\n\n            float sum = augmentedMatrix(i, rhs_col);\n            for (int j = i + 1; j &lt; n; j++)\n            {\n                sum -= augmentedMatrix(i, j) * result(j, 0); // Subtract the known terms\n            }\n            result(i, 0) = sum; // Solve for the current variable\n        }\n\n        return result;\n    }\n\n    // ============================================================================\n    // Matrix Decomposition\n    // ============================================================================\n    /**\n     * @name Mat::LUDecomposition::LUDecomposition()\n     * @brief Default constructor for LUDecomposition structure\n     */\n    Mat::LUDecomposition::LUDecomposition()\n    {\n        pivoted = false;\n        status = TINY_OK;\n    }\n\n    /**\n     * @name Mat::CholeskyDecomposition::CholeskyDecomposition()\n     * @brief Default constructor for CholeskyDecomposition structure\n     */\n    Mat::CholeskyDecomposition::CholeskyDecomposition()\n    {\n        status = TINY_OK;\n    }\n\n    /**\n     * @name Mat::QRDecomposition::QRDecomposition()\n     * @brief Default constructor for QRDecomposition structure\n     */\n    Mat::QRDecomposition::QRDecomposition()\n    {\n        status = TINY_OK;\n    }\n\n    /**\n     * @name Mat::SVDDecomposition::SVDDecomposition()\n     * @brief Default constructor for SVDDecomposition structure\n     */\n    Mat::SVDDecomposition::SVDDecomposition()\n    {\n        rank = 0;\n        iterations = 0;\n        status = TINY_OK;\n    }\n\n    /**\n     * @name Mat::is_positive_definite()\n     * @brief Check if matrix is positive definite (for Cholesky decomposition).\n     * @note A matrix A is positive definite if:\n     *       1. A is symmetric: A^T = A\n     *       2. All eigenvalues are positive: \u03bb_i &gt; 0\n     *       3. For all non-zero vectors x: x^T A x &gt; 0\n     * @note Uses Sylvester's criterion: all leading principal minors must be positive.\n     *       Checks leading principal minors according to max_minors_to_check parameter.\n     * @note Positive definite matrices have:\n     *       - All diagonal elements &gt; 0\n     *       - All leading principal minors &gt; 0\n     *       - Can be decomposed as A = L L^T (Cholesky decomposition)\n     * \n     * @param tolerance Tolerance for numerical checks (must be &gt;= 0)\n     * @param max_minors_to_check Maximum number of leading principal minors to check.\n     *                            - If -1: check all minors (complete Sylvester's criterion)\n     *                            - If &gt; 0: check first max_minors_to_check minors\n     *                            - Default: -1 (check all)\n     * @return true if matrix is positive definite, false otherwise\n     */\n    bool Mat::is_positive_definite(float tolerance, int max_minors_to_check) const\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] is_positive_definite: matrix data pointer is null\\n\";\n            return false;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] is_positive_definite: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return false;\n        }\n\n        // Validate tolerance\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] is_positive_definite: tolerance must be non-negative (got \" \n                      &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            return false;\n        }\n\n        // Must be square\n        if (this-&gt;row != this-&gt;col)\n        {\n            return false;\n        }\n\n        // Must be symmetric\n        if (!this-&gt;is_symmetric(tolerance))\n        {\n            return false;\n        }\n\n        int n = this-&gt;row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            return true;  // Empty matrix is trivially positive definite\n        }\n\n        // Determine how many minors to check\n        int num_minors_to_check;\n        if (max_minors_to_check &lt; 0)\n        {\n            // Check all minors (complete Sylvester's criterion)\n            num_minors_to_check = n;\n        }\n        else if (max_minors_to_check == 0)\n        {\n            std::cerr &lt;&lt; \"[Error] is_positive_definite: max_minors_to_check must be &gt; 0 or -1 (got 0)\\n\";\n            return false;\n        }\n        else\n        {\n            // Check first max_minors_to_check minors (or all if n is smaller)\n            num_minors_to_check = (max_minors_to_check &gt; n) ? n : max_minors_to_check;\n        }\n\n        // Check Sylvester's criterion: all leading principal minors must be positive\n        for (int k = 1; k &lt;= num_minors_to_check; ++k)\n        {\n            Mat submatrix(k, k);\n\n            // Check if submatrix was created successfully\n            if (submatrix.data == nullptr)\n            {\n                std::cerr &lt;&lt; \"[Error] is_positive_definite: failed to create submatrix of size \" \n                          &lt;&lt; k &lt;&lt; \"x\" &lt;&lt; k &lt;&lt; \"\\n\";\n                return false;\n            }\n\n            // Copy leading principal minor\n            for (int i = 0; i &lt; k; ++i)\n            {\n                for (int j = 0; j &lt; k; ++j)\n                {\n                    submatrix(i, j) = (*this)(i, j);\n                }\n            }\n\n            float det = submatrix.determinant();\n\n            // Check if determinant is valid\n            if (std::isnan(det) || std::isinf(det))\n            {\n                std::cerr &lt;&lt; \"[Error] is_positive_definite: determinant is invalid (NaN or Inf) \"\n                          &lt;&lt; \"for leading principal minor of size \" &lt;&lt; k &lt;&lt; \"x\" &lt;&lt; k &lt;&lt; \"\\n\";\n                return false;\n            }\n\n            // Sylvester's criterion: determinant must be &gt; tolerance\n            if (det &lt;= tolerance)\n            {\n                return false;\n            }\n        }\n\n        // Additional check: all diagonal elements should be positive\n        for (int i = 0; i &lt; n; ++i)\n        {\n            if ((*this)(i, i) &lt;= tolerance)\n            {\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    /**\n     * @name Mat::lu_decompose()\n     * @brief Compute LU decomposition: A = L * U (with optional pivoting).\n     * @note LU decomposition factors a matrix A into:\n     *       - L: Lower triangular matrix (with unit diagonal)\n     *       - U: Upper triangular matrix\n     *       - P: Permutation matrix (if pivoting used)\n     * @note With pivoting: P * A = L * U\n     *       Without pivoting: A = L * U\n     * @note Algorithm: Modified Gaussian elimination that stores multipliers in L.\n     *       Uses partial pivoting for numerical stability.\n     * @note Time complexity: O(n\u00b3) - efficient for large matrices.\n     *       More efficient than Gaussian elimination when solving multiple systems\n     *       with the same coefficient matrix.\n     * \n     * @param use_pivoting Whether to use partial pivoting (default: true).\n     *                     Pivoting improves numerical stability but requires P matrix.\n     * @return LUDecomposition containing L, U, P matrices and status\n     */\n    Mat::LUDecomposition Mat::lu_decompose(bool use_pivoting) const\n    {\n        LUDecomposition result;\n\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] lu_decompose: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] lu_decompose: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validation: must be square matrix\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] lu_decompose: requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        int n = this-&gt;row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            // Empty matrix: L, U, P are all empty\n            result.L = Mat(0, 0);\n            result.U = Mat(0, 0);\n            if (use_pivoting)\n            {\n                result.P = Mat(0, 0);\n            }\n            result.pivoted = use_pivoting;\n            result.status = TINY_OK;\n            return result;\n        }\n\n        Mat A = Mat(*this);  // Working copy\n\n        // Check if working copy was created successfully\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] lu_decompose: failed to create working copy\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        result.L = Mat::eye(n);  // Initialize L as identity\n\n        // Check if L matrix was created successfully\n        if (result.L.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] lu_decompose: failed to create L matrix\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        result.U = Mat(n, n);   // Initialize U\n\n        // Check if U matrix was created successfully\n        if (result.U.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] lu_decompose: failed to create U matrix\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        result.pivoted = use_pivoting;\n\n        if (use_pivoting)\n        {\n            result.P = Mat::eye(n);  // Initialize P as identity\n\n            // Check if P matrix was created successfully\n            if (result.P.data == nullptr)\n            {\n                std::cerr &lt;&lt; \"[Error] lu_decompose: failed to create P matrix\\n\";\n                result.status = TINY_ERR_MATH_NULL_POINTER;\n                return result;\n            }\n        }\n\n        // LU decomposition with partial pivoting\n        for (int k = 0; k &lt; n; ++k)\n        {\n            if (use_pivoting)\n            {\n                // Find pivot (largest element in column k, below diagonal)\n                int max_row = k;\n                float max_val = fabsf(A(k, k));\n                for (int i = k + 1; i &lt; n; ++i)\n                {\n                    float abs_val = fabsf(A(i, k));\n                    if (abs_val &gt; max_val)\n                    {\n                        max_val = abs_val;\n                        max_row = i;\n                    }\n                }\n\n                // Swap rows if necessary\n                if (max_row != k)\n                {\n                    A.swap_rows(k, max_row);\n                    result.P.swap_rows(k, max_row);\n                    // Also swap previously computed L rows (but only the multipliers)\n                    for (int j = 0; j &lt; k; ++j)\n                    {\n                        float temp = result.L(k, j);\n                        result.L(k, j) = result.L(max_row, j);\n                        result.L(max_row, j) = temp;\n                    }\n                }\n            }\n\n            // Check for singular matrix\n            if (fabsf(A(k, k)) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] LU decomposition: Matrix is singular or near-singular.\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            // Compute U (upper triangular part)\n            for (int j = k; j &lt; n; ++j)\n            {\n                result.U(k, j) = A(k, j);\n            }\n\n            // Compute L (lower triangular multipliers)\n            for (int i = k + 1; i &lt; n; ++i)\n            {\n                float multiplier = A(i, k) / A(k, k);\n                result.L(i, k) = multiplier;\n\n                // Update A for next iteration\n                for (int j = k + 1; j &lt; n; ++j)\n                {\n                    A(i, j) -= multiplier * A(k, j);\n                }\n            }\n        }\n\n        result.status = TINY_OK;\n        return result;\n    }\n\n    /**\n     * @name Mat::cholesky_decompose()\n     * @brief Compute Cholesky decomposition: A = L * L^T (for symmetric positive definite matrices).\n     * @note Cholesky decomposition factors a symmetric positive definite matrix A into:\n     *       A = L * L^T\n     *       where L is a lower triangular matrix with positive diagonal elements.\n     * @note Algorithm: For each row i and column j (j &lt;= i):\n     *       - Diagonal (j == i): L[i][i] = sqrt(A[i][i] - sum(L[i][k]^2))\n     *       - Off-diagonal (j &lt; i): L[i][j] = (A[i][j] - sum(L[i][k]*L[j][k])) / L[j][j]\n     * @note Requirements:\n     *       - Matrix must be square\n     *       - Matrix must be symmetric: A^T = A\n     *       - Matrix must be positive definite: all eigenvalues &gt; 0\n     * @note Advantages over LU decomposition:\n     *       - Faster: O(n\u00b3/3) vs O(n\u00b3) for LU\n     *       - More stable: no pivoting needed\n     *       - Uses less memory: only stores L (not L and U)\n     * @note Applications: Structural dynamics, optimization, Kalman filtering, Monte Carlo simulation\n     * @note Time complexity: O(n\u00b3/3) - about 2x faster than LU decomposition\n     * \n     * @return CholeskyDecomposition containing L matrix and status\n     */\n    Mat::CholeskyDecomposition Mat::cholesky_decompose() const\n    {\n        CholeskyDecomposition result;\n\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] cholesky_decompose: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] cholesky_decompose: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validation: must be square matrix\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] cholesky_decompose: requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        int n = this-&gt;row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            // Empty matrix: L is also empty\n            result.L = Mat(0, 0);\n            result.status = TINY_OK;\n            return result;\n        }\n\n        // Check if symmetric (use standard tolerance)\n        if (!this-&gt;is_symmetric(TINY_MATH_MIN_POSITIVE_INPUT_F32))\n        {\n            std::cerr &lt;&lt; \"[Error] cholesky_decompose: requires symmetric matrix\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        result.L = Mat(n, n);\n\n        // Check if L matrix was created successfully\n        if (result.L.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] cholesky_decompose: failed to create L matrix\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Cholesky decomposition: A = L * L^T\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt;= i; ++j)\n            {\n                float sum = 0.0f;\n\n                if (j == i)\n                {\n                    // Diagonal elements: L[i][i] = sqrt(A[i][i] - sum(L[i][k]^2))\n                    for (int k = 0; k &lt; j; ++k)\n                    {\n                        sum += result.L(j, k) * result.L(j, k);\n                    }\n                    float diag_val = (*this)(j, j) - sum;\n\n                    // Check if matrix is positive definite\n                    // For positive definite matrices, diag_val must be &gt; tolerance\n                    if (diag_val &lt;= TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    {\n                        std::cerr &lt;&lt; \"[Error] cholesky_decompose: matrix is not positive definite \"\n                                  &lt;&lt; \"(diagonal value \" &lt;&lt; diag_val &lt;&lt; \" at position [\" \n                                  &lt;&lt; j &lt;&lt; \"][\" &lt;&lt; j &lt;&lt; \"] is not positive)\\n\";\n                        result.status = TINY_ERR_MATH_INVALID_PARAM;\n                        return result;\n                    }\n\n                    float sqrt_result = sqrtf(diag_val);\n\n                    // Check if sqrt result is valid\n                    if (std::isnan(sqrt_result) || std::isinf(sqrt_result))\n                    {\n                        std::cerr &lt;&lt; \"[Error] cholesky_decompose: sqrt result is invalid (NaN or Inf) \"\n                                  &lt;&lt; \"at position [\" &lt;&lt; j &lt;&lt; \"][\" &lt;&lt; j &lt;&lt; \"]\\n\";\n                        result.status = TINY_ERR_MATH_INVALID_PARAM;\n                        return result;\n                    }\n\n                    result.L(j, j) = sqrt_result;\n                }\n                else\n                {\n                    // Off-diagonal elements: L[i][j] = (A[i][j] - sum(L[i][k]*L[j][k])) / L[j][j]\n                    for (int k = 0; k &lt; j; ++k)\n                    {\n                        sum += result.L(i, k) * result.L(j, k);\n                    }\n\n                    // Check if divisor is valid (should be &gt; 0 from previous diagonal calculation)\n                    float divisor = result.L(j, j);\n                    if (fabsf(divisor) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32 || \n                        std::isnan(divisor) || std::isinf(divisor))\n                    {\n                        std::cerr &lt;&lt; \"[Error] cholesky_decompose: invalid divisor at position [\" \n                                  &lt;&lt; j &lt;&lt; \"][\" &lt;&lt; j &lt;&lt; \"] (value: \" &lt;&lt; divisor &lt;&lt; \")\\n\";\n                        result.status = TINY_ERR_MATH_INVALID_PARAM;\n                        return result;\n                    }\n\n                    result.L(i, j) = ((*this)(i, j) - sum) / divisor;\n\n                    // Check if result is valid\n                    if (std::isnan(result.L(i, j)) || std::isinf(result.L(i, j)))\n                    {\n                        std::cerr &lt;&lt; \"[Error] cholesky_decompose: computed value is invalid (NaN or Inf) \"\n                                  &lt;&lt; \"at position [\" &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; j &lt;&lt; \"]\\n\";\n                        result.status = TINY_ERR_MATH_INVALID_PARAM;\n                        return result;\n                    }\n                }\n            }\n        }\n\n        result.status = TINY_OK;\n        return result;\n    }\n\n    /**\n     * @name Mat::qr_decompose()\n     * @brief Compute QR decomposition: A = Q * R (Q orthogonal, R upper triangular).\n     * @note QR decomposition factors a matrix A into:\n     *       A = Q * R\n     *       where:\n     *       - Q: Orthogonal matrix (Q^T * Q = I, columns are orthonormal)\n     *       - R: Upper triangular matrix\n     * @note Algorithm: Uses Modified Gram-Schmidt process for orthogonalization.\n     *       The Gram-Schmidt process orthogonalizes the columns of A to form Q,\n     *       and stores the projection coefficients in R.\n     * @note Mathematical relationship:\n     *       - Q is m\u00d7min(m,n) matrix with orthonormal columns\n     *       - R is min(m,n)\u00d7n upper triangular matrix\n     *       - For m &gt;= n: A = Q * R (full QR)\n     *       - For m &lt; n: A = Q * R (reduced QR, Q is m\u00d7m, R is m\u00d7n)\n     * @note Applications:\n     *       - Least squares problems: min ||A*x - b|| \u2192 solve R*x = Q^T*b\n     *       - Solving overdetermined systems\n     *       - Eigenvalue computation (QR algorithm)\n     *       - Matrix rank estimation\n     * @note Time complexity: O(m*n\u00b2) - efficient for tall matrices (m &gt;&gt; n)\n     * @note Numerical stability: Modified Gram-Schmidt is more stable than classical GS\n     * \n     * @return QRDecomposition containing Q and R matrices and status\n     */\n    Mat::QRDecomposition Mat::qr_decompose() const\n    {\n        QRDecomposition result;\n\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] qr_decompose: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] qr_decompose: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        int m = this-&gt;row;\n        int n = this-&gt;col;\n        int min_dim = (m &lt; n) ? m : n;\n\n        // Handle empty matrix\n        if (m == 0 || n == 0)\n        {\n            // Empty matrix: Q and R are also empty\n            result.Q = Mat(0, 0);\n            result.R = Mat(0, 0);\n            result.status = TINY_OK;\n            return result;\n        }\n\n        // QR decomposition using Gram-Schmidt process\n        // Use the reusable gram_schmidt_orthogonalize function\n        Mat Q_ortho, R_coeff;\n        if (!Mat::gram_schmidt_orthogonalize(*this, Q_ortho, R_coeff, TINY_MATH_MIN_POSITIVE_INPUT_F32))\n        {\n            std::cerr &lt;&lt; \"[Error] qr_decompose: gram_schmidt_orthogonalize failed\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Verify that Q_ortho and R_coeff were created successfully\n        if (Q_ortho.data == nullptr || R_coeff.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] qr_decompose: failed to create Q or R coefficient matrices\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Verify dimensions of Q_ortho and R_coeff\n        if (Q_ortho.row != m || Q_ortho.col != n || \n            R_coeff.row != n || R_coeff.col != n)\n        {\n            std::cerr &lt;&lt; \"[Error] qr_decompose: invalid dimensions from gram_schmidt_orthogonalize\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Extract Q and R from the orthogonalization results\n        result.Q = Q_ortho;\n        result.R = Mat(m, n);\n\n        // Check if R matrix was created successfully\n        if (result.R.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] qr_decompose: failed to create R matrix\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Copy coefficients to R (upper triangular part)\n        for (int j = 0; j &lt; min_dim; ++j)\n        {\n            for (int k = 0; k &lt;= j; ++k)\n            {\n                result.R(k, j) = R_coeff(k, j);\n            }\n\n            // Compute remaining R elements: R(j,k) = Q(:,j)^T * A(:,k) for k &gt; j\n            for (int k = j + 1; k &lt; n; ++k)\n            {\n                float dot = 0.0f;\n                for (int i = 0; i &lt; m; ++i)\n                {\n                    dot += result.Q(i, j) * (*this)(i, k);\n                }\n                result.R(j, k) = dot;\n            }\n        }\n\n        // Fill remaining rows of R with zeros (if m &gt; n)\n        for (int i = min_dim; i &lt; m; ++i)\n        {\n            for (int j = 0; j &lt; n; ++j)\n            {\n                result.R(i, j) = 0.0f;\n            }\n        }\n\n        result.status = TINY_OK;\n        return result;\n    }\n\n    /**\n     * @name Mat::svd_decompose()\n     * @brief Compute Singular Value Decomposition: A = U * S * V^T.\n     * @note SVD decomposes a matrix A (m\u00d7n) into:\n     *       A = U * S * V^T\n     *       where:\n     *       - U: m\u00d7min(m,n) matrix with orthonormal columns (left singular vectors)\n     *       - S: min(m,n)\u00d71 vector of singular values (diagonal matrix stored as vector)\n     *       - V: n\u00d7n matrix with orthonormal columns (right singular vectors)\n     * @note Algorithm: Uses eigendecomposition of A^T * A to compute V and singular values.\n     *       Then computes U from A * V = U * S.\n     *       This is a simplified approach; full SVD uses bidiagonalization + QR iteration.\n     * @note Mathematical properties:\n     *       - Singular values are non-negative and sorted in descending order\n     *       - U and V are orthogonal: U^T * U = I, V^T * V = I\n     *       - Rank of A = number of non-zero singular values\n     * @note Applications:\n     *       - Rank estimation and matrix rank computation\n     *       - Pseudo-inverse: A^+ = V * S^+ * U^T\n     *       - Dimension reduction (PCA, data compression)\n     *       - Least squares problems\n     *       - Image processing and signal processing\n     * @note Time complexity: O(m*n\u00b2 + n\u00b3) - dominated by eigendecomposition\n     * @note Note: This is a simplified implementation. For production use, consider\n     *       more robust algorithms like bidiagonalization + divide-and-conquer.\n     * \n     * @param max_iter Maximum number of iterations for eigendecomposition (must be &gt; 0)\n     * @param tolerance Convergence tolerance for eigendecomposition (must be &gt;= 0)\n     * @return SVDDecomposition containing U, S, V matrices, rank, iterations, and status\n     */\n    Mat::SVDDecomposition Mat::svd_decompose(int max_iter, float tolerance) const\n    {\n        SVDDecomposition result;\n\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validate parameters\n        if (max_iter &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: max_iter must be &gt; 0 (got \" &lt;&lt; max_iter &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: tolerance must be &gt;= 0 (got \" &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        int m = this-&gt;row;\n        int n = this-&gt;col;\n        int min_dim = (m &lt; n) ? m : n;\n\n        // Handle empty matrix\n        if (m == 0 || n == 0)\n        {\n            // Empty matrix: U, S, V are also empty\n            result.U = Mat(0, 0);\n            result.S = Mat(0, 0);\n            result.V = Mat(0, 0);\n            result.rank = 0;\n            result.iterations = 0;\n            result.status = TINY_OK;\n            return result;\n        }\n\n        // For simplicity, we use a simplified SVD algorithm\n        // Full SVD implementation is complex, so we use an iterative approach\n        // based on eigendecomposition of A^T * A and A * A^T\n\n        // Compute A^T * A (n x n matrix)\n        Mat AtA(n, n);\n\n        // Check if AtA matrix was created successfully\n        if (AtA.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: failed to create AtA matrix\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; n; ++j)\n            {\n                AtA(i, j) = 0.0f;\n                for (int k = 0; k &lt; m; ++k)\n                {\n                    AtA(i, j) += (*this)(k, i) * (*this)(k, j);\n                }\n            }\n        }\n\n        // Eigendecomposition of A^T * A to get V and singular values squared\n        Mat::EigenDecomposition eig_AtA = AtA.eigendecompose_jacobi(tolerance, max_iter);\n\n        if (eig_AtA.status != TINY_OK)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: eigendecomposition failed with status \" \n                      &lt;&lt; eig_AtA.status &lt;&lt; \"\\n\";\n            result.status = eig_AtA.status;\n            return result;\n        }\n\n        // Verify eigendecomposition results\n        if (eig_AtA.eigenvalues.data == nullptr || eig_AtA.eigenvectors.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: eigendecomposition returned null pointers\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Verify dimensions\n        if (eig_AtA.eigenvalues.row != n || eig_AtA.eigenvalues.col != 1 ||\n            eig_AtA.eigenvectors.row != n || eig_AtA.eigenvectors.col != n)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: invalid dimensions from eigendecomposition\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Extract singular values (square root of eigenvalues of A^T * A)\n        result.S = Mat(min_dim, 1);\n        result.V = Mat(n, n);\n\n        // Check if result matrices were created successfully\n        if (result.S.data == nullptr || result.V.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: failed to create S or V matrices\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Extract singular values from eigenvalues\n        // Note: Eigenvalues should be sorted in descending order by eigendecompose_jacobi\n        // but we verify and extract only positive eigenvalues\n        int sv_count = 0;\n        for (int i = 0; i &lt; n &amp;&amp; sv_count &lt; min_dim; ++i)\n        {\n            float eigenval = eig_AtA.eigenvalues(i, 0);\n\n            // Check if eigenvalue is valid\n            if (std::isnan(eigenval) || std::isinf(eigenval))\n            {\n                std::cerr &lt;&lt; \"[Warning] svd_decompose: invalid eigenvalue at index \" &lt;&lt; i \n                          &lt;&lt; \" (NaN or Inf), skipping\\n\";\n                continue;\n            }\n\n            // Only consider positive eigenvalues (singular values are non-negative)\n            if (eigenval &gt; tolerance)\n            {\n                float sqrt_result = sqrtf(eigenval);\n\n                // Check if sqrt result is valid\n                if (std::isnan(sqrt_result) || std::isinf(sqrt_result))\n                {\n                    std::cerr &lt;&lt; \"[Warning] svd_decompose: invalid sqrt result for eigenvalue \" \n                              &lt;&lt; eigenval &lt;&lt; \" at index \" &lt;&lt; i &lt;&lt; \", skipping\\n\";\n                    continue;\n                }\n\n                result.S(sv_count, 0) = sqrt_result;\n\n                // Copy corresponding eigenvector to V\n                for (int j = 0; j &lt; n; ++j)\n                {\n                    result.V(j, sv_count) = eig_AtA.eigenvectors(j, i);\n                }\n                sv_count++;\n            }\n        }\n\n        result.rank = sv_count;\n\n        // Compute U from A * V = U * S\n        result.U = Mat(m, min_dim);\n\n        // Check if U matrix was created successfully\n        if (result.U.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] svd_decompose: failed to create U matrix\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        for (int i = 0; i &lt; sv_count; ++i)\n        {\n            float sigma = result.S(i, 0);\n\n            // Check if sigma is valid\n            if (std::isnan(sigma) || std::isinf(sigma) || sigma &lt;= tolerance)\n            {\n                // Fill U column with zeros if sigma is invalid or too small\n                for (int j = 0; j &lt; m; ++j)\n                {\n                    result.U(j, i) = 0.0f;\n                }\n                continue;\n            }\n\n            // U(:,i) = (A * V(:,i)) / sigma\n            for (int j = 0; j &lt; m; ++j)\n            {\n                float sum = 0.0f;\n                for (int k = 0; k &lt; n; ++k)\n                {\n                    sum += (*this)(j, k) * result.V(k, i);\n                }\n\n                float u_val = sum / sigma;\n\n                // Check if result is valid\n                if (std::isnan(u_val) || std::isinf(u_val))\n                {\n                    std::cerr &lt;&lt; \"[Warning] svd_decompose: invalid U value at [\" \n                              &lt;&lt; j &lt;&lt; \"][\" &lt;&lt; i &lt;&lt; \"], setting to 0\\n\";\n                    result.U(j, i) = 0.0f;\n                }\n                else\n                {\n                    result.U(j, i) = u_val;\n                }\n            }\n        }\n\n        // Fill remaining columns of U with zeros (if sv_count &lt; min_dim)\n        for (int i = sv_count; i &lt; min_dim; ++i)\n        {\n            for (int j = 0; j &lt; m; ++j)\n            {\n                result.U(j, i) = 0.0f;\n            }\n        }\n\n        result.iterations = eig_AtA.iterations;\n        result.status = TINY_OK;\n        return result;\n    }\n\n    /**\n     * @name Mat::solve_lu()\n     * @brief Solve linear system using LU decomposition (more efficient for multiple RHS).\n     * @note Solves A * x = b using precomputed LU decomposition.\n     *       Algorithm: P * A = L * U, so A * x = b becomes:\n     *       1. Apply permutation: P * A * x = P * b \u2192 (L * U) * x = P * b\n     *       2. Forward substitution: L * y = P * b \u2192 solve for y\n     *       3. Backward substitution: U * x = y \u2192 solve for x\n     * @note Advantages over direct solve():\n     *       - More efficient when solving multiple systems with same A\n     *       - LU decomposition computed once, reused for different b vectors\n     *       - Time complexity: O(n\u00b2) vs O(n\u00b3) for direct solve\n     * @note Requirements:\n     *       - LU decomposition must be valid (status == TINY_OK)\n     *       - Matrix A must be square and non-singular\n     *       - Vector b must have same dimension as A\n     * \n     * @param lu LU decomposition of coefficient matrix A\n     * @param b Right-hand side vector (must be column vector)\n     * @return Solution vector x such that A * x = b, or empty matrix on error\n     */\n    Mat Mat::solve_lu(const LUDecomposition &amp;lu, const Mat &amp;b)\n    {\n        // Check LU decomposition status\n        if (lu.status != TINY_OK)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_lu: invalid LU decomposition (status: \" \n                      &lt;&lt; lu.status &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check for null pointers\n        if (lu.L.data == nullptr || lu.U.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_lu: LU decomposition matrices have null pointers\\n\";\n            return Mat();\n        }\n\n        if (b.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_lu: right-hand side vector has null pointer\\n\";\n            return Mat();\n        }\n\n        // Validate LU decomposition dimensions\n        if (lu.L.row &lt;= 0 || lu.L.col &lt;= 0 || lu.U.row &lt;= 0 || lu.U.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_lu: invalid LU decomposition dimensions\\n\";\n            return Mat();\n        }\n\n        // Check if L and U are square and have same size\n        if (lu.L.row != lu.L.col || lu.U.row != lu.U.col || lu.L.row != lu.U.row)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_lu: L and U must be square matrices of same size\\n\";\n            return Mat();\n        }\n\n        int n = lu.L.row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            return Mat(0, 1);  // Return empty solution vector\n        }\n\n        // Validate right-hand side vector dimensions\n        if (b.row != n || b.col != 1)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_lu: dimension mismatch - b must be \" \n                      &lt;&lt; n &lt;&lt; \"x1 vector (got \" &lt;&lt; b.row &lt;&lt; \"x\" &lt;&lt; b.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check permutation matrix if pivoting was used\n        if (lu.pivoted)\n        {\n            if (lu.P.data == nullptr)\n            {\n                std::cerr &lt;&lt; \"[Error] solve_lu: pivoting enabled but P matrix is null\\n\";\n                return Mat();\n            }\n\n            if (lu.P.row != n || lu.P.col != n)\n            {\n                std::cerr &lt;&lt; \"[Error] solve_lu: P matrix dimensions mismatch (got \" \n                          &lt;&lt; lu.P.row &lt;&lt; \"x\" &lt;&lt; lu.P.col &lt;&lt; \", expected \" &lt;&lt; n &lt;&lt; \"x\" &lt;&lt; n &lt;&lt; \")\\n\";\n                return Mat();\n            }\n        }\n\n        // Apply permutation if pivoting was used\n        Mat b_perm = b;\n        if (lu.pivoted)\n        {\n            // b_perm = P * b\n            b_perm = Mat(n, 1);\n\n            // Check if b_perm was created successfully\n            if (b_perm.data == nullptr)\n            {\n                std::cerr &lt;&lt; \"[Error] solve_lu: failed to create permuted vector\\n\";\n                return Mat();\n            }\n\n            for (int i = 0; i &lt; n; ++i)\n            {\n                bool found = false;\n                for (int j = 0; j &lt; n; ++j)\n                {\n                    // P is permutation matrix: each row/column has exactly one 1.0\n                    // Use tolerance for floating-point comparison\n                    if (fabsf(lu.P(i, j) - 1.0f) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                    {\n                        b_perm(i, 0) = b(j, 0);\n                        found = true;\n                        break;\n                    }\n                }\n                if (!found)\n                {\n                    std::cerr &lt;&lt; \"[Warning] solve_lu: no 1.0 found in row \" &lt;&lt; i \n                              &lt;&lt; \" of permutation matrix, using 0.0\\n\";\n                    b_perm(i, 0) = 0.0f;\n                }\n            }\n        }\n\n        // Solve L * y = b_perm (forward substitution)\n        // L is lower triangular with unit diagonal\n        Mat y(n, 1);\n\n        // Check if y was created successfully\n        if (y.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_lu: failed to create intermediate vector y\\n\";\n            return Mat();\n        }\n\n        for (int i = 0; i &lt; n; ++i)\n        {\n            float sum = b_perm(i, 0);\n            for (int j = 0; j &lt; i; ++j)\n            {\n                sum -= lu.L(i, j) * y(j, 0);\n            }\n            y(i, 0) = sum;  // L has unit diagonal, so no division needed\n\n            // Check if result is valid\n            if (std::isnan(y(i, 0)) || std::isinf(y(i, 0)))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_lu: invalid intermediate value at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                return Mat();\n            }\n        }\n\n        // Solve U * x = y (backward substitution)\n        // U is upper triangular\n        Mat x(n, 1);\n\n        // Check if x was created successfully\n        if (x.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_lu: failed to create solution vector x\\n\";\n            return Mat();\n        }\n\n        for (int i = n - 1; i &gt;= 0; --i)\n        {\n            float sum = y(i, 0);\n            for (int j = i + 1; j &lt; n; ++j)\n            {\n                sum -= lu.U(i, j) * x(j, 0);\n            }\n\n            // Check if diagonal element is valid\n            float u_ii = lu.U(i, i);\n            if (std::isnan(u_ii) || std::isinf(u_ii))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_lu: invalid diagonal element U[\" &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; i &lt;&lt; \"]\\n\";\n                return Mat();\n            }\n\n            if (fabsf(u_ii) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] solve_lu: singular matrix (U[\" &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; i \n                          &lt;&lt; \"] = \" &lt;&lt; u_ii &lt;&lt; \" is too small)\\n\";\n                return Mat();\n            }\n\n            x(i, 0) = sum / u_ii;\n\n            // Check if result is valid\n            if (std::isnan(x(i, 0)) || std::isinf(x(i, 0)))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_lu: invalid solution value at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                return Mat();\n            }\n        }\n\n        return x;\n    }\n\n    /**\n     * @name Mat::solve_cholesky()\n     * @brief Solve linear system using Cholesky decomposition (for SPD matrices).\n     * @note Solves A * x = b using precomputed Cholesky decomposition.\n     *       Algorithm: A = L * L^T, so A * x = b becomes:\n     *       1. Forward substitution: L * y = b \u2192 solve for y\n     *       2. Backward substitution: L^T * x = y \u2192 solve for x\n     * @note Advantages over LU decomposition:\n     *       - Faster: O(n\u00b2) vs O(n\u00b2) but with better numerical stability\n     *       - More stable: no pivoting needed for SPD matrices\n     *       - Uses less memory: only stores L (not L and U)\n     *       - Guaranteed to work for positive definite matrices\n     * @note Requirements:\n     *       - Cholesky decomposition must be valid (status == TINY_OK)\n     *       - Matrix A must be symmetric positive definite (SPD)\n     *       - Vector b must have same dimension as A\n     * @note Time complexity: O(n\u00b2) - efficient for SPD systems\n     * \n     * @param chol Cholesky decomposition of coefficient matrix A (A = L * L^T)\n     * @param b Right-hand side vector (must be column vector)\n     * @return Solution vector x such that A * x = b, or empty matrix on error\n     */\n    Mat Mat::solve_cholesky(const CholeskyDecomposition &amp;chol, const Mat &amp;b)\n    {\n        // Check Cholesky decomposition status\n        if (chol.status != TINY_OK)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_cholesky: invalid Cholesky decomposition (status: \" \n                      &lt;&lt; chol.status &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check for null pointers\n        if (chol.L.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_cholesky: Cholesky L matrix has null pointer\\n\";\n            return Mat();\n        }\n\n        if (b.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_cholesky: right-hand side vector has null pointer\\n\";\n            return Mat();\n        }\n\n        // Validate Cholesky decomposition dimensions\n        if (chol.L.row &lt;= 0 || chol.L.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_cholesky: invalid Cholesky decomposition dimensions\\n\";\n            return Mat();\n        }\n\n        // Check if L is square\n        if (chol.L.row != chol.L.col)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_cholesky: L must be a square matrix (got \" \n                      &lt;&lt; chol.L.row &lt;&lt; \"x\" &lt;&lt; chol.L.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        int n = chol.L.row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            return Mat(0, 1);  // Return empty solution vector\n        }\n\n        // Validate right-hand side vector dimensions\n        if (b.row != n || b.col != 1)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_cholesky: dimension mismatch - b must be \" \n                      &lt;&lt; n &lt;&lt; \"x1 vector (got \" &lt;&lt; b.row &lt;&lt; \"x\" &lt;&lt; b.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Solve L * y = b (forward substitution)\n        // L is lower triangular with positive diagonal elements\n        Mat y(n, 1);\n\n        // Check if y was created successfully\n        if (y.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_cholesky: failed to create intermediate vector y\\n\";\n            return Mat();\n        }\n\n        for (int i = 0; i &lt; n; ++i)\n        {\n            float sum = b(i, 0);\n            for (int j = 0; j &lt; i; ++j)\n            {\n                sum -= chol.L(i, j) * y(j, 0);\n            }\n\n            // Check if diagonal element is valid\n            float l_ii = chol.L(i, i);\n            if (std::isnan(l_ii) || std::isinf(l_ii))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_cholesky: invalid diagonal element L[\" &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; i &lt;&lt; \"]\\n\";\n                return Mat();\n            }\n\n            if (fabsf(l_ii) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] solve_cholesky: singular matrix (L[\" &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; i \n                          &lt;&lt; \"] = \" &lt;&lt; l_ii &lt;&lt; \" is too small)\\n\";\n                return Mat();\n            }\n\n            y(i, 0) = sum / l_ii;\n\n            // Check if result is valid\n            if (std::isnan(y(i, 0)) || std::isinf(y(i, 0)))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_cholesky: invalid intermediate value at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                return Mat();\n            }\n        }\n\n        // Solve L^T * x = y (backward substitution)\n        // L^T is upper triangular (transpose of L)\n        Mat x(n, 1);\n\n        // Check if x was created successfully\n        if (x.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_cholesky: failed to create solution vector x\\n\";\n            return Mat();\n        }\n\n        for (int i = n - 1; i &gt;= 0; --i)\n        {\n            float sum = y(i, 0);\n            for (int j = i + 1; j &lt; n; ++j)\n            {\n                // L^T(j,i) = L(i,j), so we access L(j,i) for L^T(j,i)\n                sum -= chol.L(j, i) * x(j, 0);\n            }\n\n            // Check if diagonal element is valid (same as forward substitution)\n            float l_ii = chol.L(i, i);\n            if (std::isnan(l_ii) || std::isinf(l_ii))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_cholesky: invalid diagonal element L[\" &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; i &lt;&lt; \"]\\n\";\n                return Mat();\n            }\n\n            if (fabsf(l_ii) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] solve_cholesky: singular matrix (L[\" &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; i \n                          &lt;&lt; \"] = \" &lt;&lt; l_ii &lt;&lt; \" is too small)\\n\";\n                return Mat();\n            }\n\n            x(i, 0) = sum / l_ii;\n\n            // Check if result is valid\n            if (std::isnan(x(i, 0)) || std::isinf(x(i, 0)))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_cholesky: invalid solution value at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                return Mat();\n            }\n        }\n\n        return x;\n    }\n\n    /**\n     * @name Mat::solve_qr()\n     * @brief Solve linear system using QR decomposition (least squares solution).\n     * @note Solves A * x = b using precomputed QR decomposition.\n     *       Algorithm: A = Q * R, so A * x = b becomes:\n     *       1. Compute Q^T * b (project b onto column space of Q)\n     *       2. Solve R * x = Q^T * b using backward substitution\n     * @note This method provides least squares solution:\n     *       - For overdetermined systems (m &gt; n): minimizes ||A * x - b||\n     *       - For determined systems (m = n): exact solution\n     *       - For underdetermined systems (m &lt; n): minimum norm solution\n     * @note Advantages:\n     *       - Numerically stable (no pivoting needed)\n     *       - Works for rectangular matrices\n     *       - Handles rank-deficient matrices gracefully\n     * @note Requirements:\n     *       - QR decomposition must be valid (status == TINY_OK)\n     *       - Vector b must have same number of rows as Q\n     * @note Time complexity: O(m*n) - efficient for least squares problems\n     * \n     * @param qr QR decomposition of coefficient matrix A (A = Q * R)\n     * @param b Right-hand side vector (must be column vector)\n     * @return Least squares solution vector x such that ||A * x - b|| is minimized,\n     *         or empty matrix on error\n     */\n    Mat Mat::solve_qr(const QRDecomposition &amp;qr, const Mat &amp;b)\n    {\n        // Check QR decomposition status\n        if (qr.status != TINY_OK)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_qr: invalid QR decomposition (status: \" \n                      &lt;&lt; qr.status &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check for null pointers\n        if (qr.Q.data == nullptr || qr.R.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_qr: QR decomposition matrices have null pointers\\n\";\n            return Mat();\n        }\n\n        if (b.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_qr: right-hand side vector has null pointer\\n\";\n            return Mat();\n        }\n\n        // Validate QR decomposition dimensions\n        if (qr.Q.row &lt;= 0 || qr.Q.col &lt;= 0 || qr.R.row &lt;= 0 || qr.R.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_qr: invalid QR decomposition dimensions\\n\";\n            return Mat();\n        }\n\n        int m = qr.Q.row;\n        int n = qr.R.col;\n        int min_dim = (m &lt; n) ? m : n;\n\n        // Verify Q and R dimensions are consistent\n        // Q should be m\u00d7min(m,n) or m\u00d7n, R should be m\u00d7n or min(m,n)\u00d7n\n        if (qr.Q.col &lt; min_dim || qr.R.row &lt; min_dim)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_qr: inconsistent QR decomposition dimensions\\n\";\n            return Mat();\n        }\n\n        // Handle empty matrix\n        if (m == 0 || n == 0)\n        {\n            return Mat(n, 1);  // Return empty solution vector with correct dimension\n        }\n\n        // Validate right-hand side vector dimensions\n        if (b.row != m || b.col != 1)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_qr: dimension mismatch - b must be \" \n                      &lt;&lt; m &lt;&lt; \"x1 vector (got \" &lt;&lt; b.row &lt;&lt; \"x\" &lt;&lt; b.col &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Compute Q^T * b\n        // Note: Q^T has dimensions min(m,n)\u00d7m, so Q^T * b has dimension min(m,n)\u00d71\n        // But we need n\u00d71 for backward substitution, so we compute first min(m,n) components\n        Mat Qt_b(n, 1);\n\n        // Check if Qt_b was created successfully\n        if (Qt_b.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_qr: failed to create Qt_b vector\\n\";\n            return Mat();\n        }\n\n        // Initialize Qt_b to zero\n        for (int i = 0; i &lt; n; ++i)\n        {\n            Qt_b(i, 0) = 0.0f;\n        }\n\n        // Compute Q^T * b (only first min(m,n) components, rest are zero)\n        for (int i = 0; i &lt; min_dim; ++i)\n        {\n            float sum = 0.0f;\n            for (int j = 0; j &lt; m; ++j)\n            {\n                // Q^T(i,j) = Q(j,i)\n                sum += qr.Q(j, i) * b(j, 0);\n            }\n            Qt_b(i, 0) = sum;\n\n            // Check if result is valid\n            if (std::isnan(Qt_b(i, 0)) || std::isinf(Qt_b(i, 0)))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_qr: invalid Qt_b value at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                return Mat();\n            }\n        }\n\n        // Solve R * x = Q^T * b (backward substitution)\n        // R is upper triangular (or upper trapezoidal if m &lt; n)\n        Mat x(n, 1);\n\n        // Check if x was created successfully\n        if (x.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] solve_qr: failed to create solution vector x\\n\";\n            return Mat();\n        }\n\n        // Initialize x to zero\n        for (int i = 0; i &lt; n; ++i)\n        {\n            x(i, 0) = 0.0f;\n        }\n\n        // Backward substitution (only for first min(m,n) rows of R)\n        for (int i = min_dim - 1; i &gt;= 0; --i)\n        {\n            // Check if diagonal element is valid\n            float r_ii = qr.R(i, i);\n            if (std::isnan(r_ii) || std::isinf(r_ii))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_qr: invalid diagonal element R[\" &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; i &lt;&lt; \"]\\n\";\n                return Mat();\n            }\n\n            if (fabsf(r_ii) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                // Skip zero diagonal (underdetermined system or rank-deficient)\n                // Set x[i] = 0 (minimum norm solution)\n                x(i, 0) = 0.0f;\n                continue;\n            }\n\n            float sum = Qt_b(i, 0);\n\n            // Sum over upper triangular part (only up to n columns)\n            int max_j = (qr.R.col &lt; n) ? qr.R.col : n;\n            for (int j = i + 1; j &lt; max_j; ++j)\n            {\n                sum -= qr.R(i, j) * x(j, 0);\n            }\n\n            x(i, 0) = sum / r_ii;\n\n            // Check if result is valid\n            if (std::isnan(x(i, 0)) || std::isinf(x(i, 0)))\n            {\n                std::cerr &lt;&lt; \"[Error] solve_qr: invalid solution value at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                return Mat();\n            }\n        }\n\n        // Set remaining components to zero if n &gt; m (underdetermined system)\n        // This is already done by initialization, but we keep it explicit\n        for (int i = min_dim; i &lt; n; ++i)\n        {\n            x(i, 0) = 0.0f;\n        }\n\n        return x;\n    }\n\n    /**\n     * @name Mat::pseudo_inverse()\n     * @brief Compute pseudo-inverse using SVD: A^+ = V * S^+ * U^T.\n     * @note Pseudo-inverse (Moore-Penrose inverse) is the generalization of matrix inverse\n     *       for rectangular or singular matrices.\n     * @note Algorithm: A = U * S * V^T, so A^+ = V * S^+ * U^T\n     *       where S^+ is the pseudo-inverse of S (diagonal matrix):\n     *       - If \u03c3_i &gt; tolerance: S^+[i][i] = 1/\u03c3_i\n     *       - If \u03c3_i &lt;= tolerance: S^+[i][i] = 0 (treat as zero)\n     * @note Mathematical properties:\n     *       - A * A^+ * A = A\n     *       - A^+ * A * A^+ = A^+\n     *       - (A * A^+)^T = A * A^+\n     *       - (A^+ * A)^T = A^+ * A\n     * @note Applications:\n     *       - Solving least squares problems: x = A^+ * b\n     *       - Solving underdetermined systems (minimum norm solution)\n     *       - Solving overdetermined systems (least squares solution)\n     *       - Rank-deficient matrix inversion\n     * @note Time complexity: O(m*n*rank) - dominated by matrix multiplications\n     * \n     * @param svd SVD decomposition of matrix A (A = U * S * V^T)\n     * @param tolerance Tolerance for singular values (must be &gt;= 0).\n     *                  Singular values &lt;= tolerance are treated as zero.\n     * @return Pseudo-inverse matrix A^+ (n\u00d7m matrix), or empty matrix on error\n     */\n    Mat Mat::pseudo_inverse(const SVDDecomposition &amp;svd, float tolerance)\n    {\n        // Check SVD decomposition status\n        if (svd.status != TINY_OK)\n        {\n            std::cerr &lt;&lt; \"[Error] pseudo_inverse: invalid SVD decomposition (status: \" \n                      &lt;&lt; svd.status &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Check for null pointers\n        if (svd.U.data == nullptr || svd.V.data == nullptr || svd.S.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] pseudo_inverse: SVD decomposition matrices have null pointers\\n\";\n            return Mat();\n        }\n\n        // Validate parameters\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] pseudo_inverse: tolerance must be &gt;= 0 (got \" &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Validate SVD decomposition dimensions\n        if (svd.U.row &lt;= 0 || svd.U.col &lt;= 0 || \n            svd.V.row &lt;= 0 || svd.V.col &lt;= 0 ||\n            svd.S.row &lt;= 0 || svd.S.col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] pseudo_inverse: invalid SVD decomposition dimensions\\n\";\n            return Mat();\n        }\n\n        int m = svd.U.row;  // Original matrix A has m rows\n        int n = svd.V.row;  // Original matrix A has n columns\n        int min_dim = (m &lt; n) ? m : n;\n        int rank = svd.rank;\n\n        // Validate rank\n        if (rank &lt; 0 || rank &gt; min_dim)\n        {\n            std::cerr &lt;&lt; \"[Error] pseudo_inverse: invalid rank \" &lt;&lt; rank \n                      &lt;&lt; \" (expected 0 to \" &lt;&lt; min_dim &lt;&lt; \")\\n\";\n            return Mat();\n        }\n\n        // Verify SVD dimensions\n        // U should be m\u00d7min(m,n), V should be n\u00d7n, S should be min(m,n)\u00d71\n        if (svd.U.col &lt; min_dim || svd.V.col &lt; n || svd.S.row &lt; min_dim || svd.S.col != 1)\n        {\n            std::cerr &lt;&lt; \"[Error] pseudo_inverse: inconsistent SVD dimensions\\n\";\n            return Mat();\n        }\n\n        // Handle empty matrix\n        if (m == 0 || n == 0)\n        {\n            return Mat(n, m);  // Return empty pseudo-inverse with correct dimensions\n        }\n\n        // Compute S^+ (pseudo-inverse of S)\n        // S^+ is a min(m,n)\u00d7min(m,n) diagonal matrix\n        // For efficiency, we'll compute V * S^+ directly without storing S^+ explicitly\n        // S^+[i][i] = 1/\u03c3_i if \u03c3_i &gt; tolerance, else 0\n\n        // Compute A^+ = V * S^+ * U^T\n        // Dimensions: V is n\u00d7n, S^+ is min(m,n)\u00d7min(m,n), U^T is min(m,n)\u00d7m\n        // Result: A^+ is n\u00d7m\n\n        Mat A_plus(n, m);\n\n        // Check if A_plus was created successfully\n        if (A_plus.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] pseudo_inverse: failed to create result matrix\\n\";\n            return Mat();\n        }\n\n        // Initialize A_plus to zero\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; m; ++j)\n            {\n                A_plus(i, j) = 0.0f;\n            }\n        }\n\n        // Compute A^+ = V * S^+ * U^T\n        // For each element A^+[i][j]:\n        //   A^+[i][j] = sum(V[i][k] * (1/\u03c3_k) * U[j][k], k=0..rank-1)\n        //   where \u03c3_k &gt; tolerance\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = 0; j &lt; m; ++j)\n            {\n                float sum = 0.0f;\n                for (int k = 0; k &lt; rank; ++k)\n                {\n                    // Check if k is within valid range\n                    if (k &gt;= svd.S.row)\n                    {\n                        break;\n                    }\n\n                    float sigma = svd.S(k, 0);\n\n                    // Check if sigma is valid\n                    if (std::isnan(sigma) || std::isinf(sigma))\n                    {\n                        std::cerr &lt;&lt; \"[Warning] pseudo_inverse: invalid singular value at index \" \n                                  &lt;&lt; k &lt;&lt; \", skipping\\n\";\n                        continue;\n                    }\n\n                    // Only use singular values above tolerance\n                    if (sigma &gt; tolerance)\n                    {\n                        float inv_sigma = 1.0f / sigma;\n\n                        // Check if inverse is valid\n                        if (std::isnan(inv_sigma) || std::isinf(inv_sigma))\n                        {\n                            std::cerr &lt;&lt; \"[Warning] pseudo_inverse: invalid inverse of singular value \" \n                                      &lt;&lt; sigma &lt;&lt; \" at index \" &lt;&lt; k &lt;&lt; \", skipping\\n\";\n                            continue;\n                        }\n\n                        // A^+[i][j] += V[i][k] * (1/\u03c3_k) * U[j][k]\n                        // Note: U^T[k][j] = U[j][k]\n                        if (k &lt; svd.V.col &amp;&amp; k &lt; svd.U.col)\n                        {\n                            float term = svd.V(i, k) * inv_sigma * svd.U(j, k);\n\n                            // Check if term is valid\n                            if (std::isnan(term) || std::isinf(term))\n                            {\n                                std::cerr &lt;&lt; \"[Warning] pseudo_inverse: invalid term at [\" \n                                          &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; j &lt;&lt; \"], k=\" &lt;&lt; k &lt;&lt; \", skipping\\n\";\n                                continue;\n                            }\n\n                            sum += term;\n                        }\n                    }\n                }\n\n                A_plus(i, j) = sum;\n\n                // Check if result is valid\n                if (std::isnan(A_plus(i, j)) || std::isinf(A_plus(i, j)))\n                {\n                    std::cerr &lt;&lt; \"[Warning] pseudo_inverse: invalid result at [\" \n                              &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; j &lt;&lt; \"], setting to 0\\n\";\n                    A_plus(i, j) = 0.0f;\n                }\n            }\n        }\n\n        return A_plus;\n    }\n\n    // ============================================================================\n    // Eigenvalue &amp; Eigenvector Decomposition\n    // ============================================================================\n    /**\n     * @name Mat::EigenPair::EigenPair()\n     * @brief Default constructor for EigenPair structure\n     */\n    Mat::EigenPair::EigenPair() : eigenvalue(0.0f), iterations(0), status(TINY_OK)\n    {\n    }\n\n    /**\n     * @name Mat::EigenDecomposition::EigenDecomposition()\n     * @brief Default constructor for EigenDecomposition structure\n     */\n    Mat::EigenDecomposition::EigenDecomposition() : iterations(0), status(TINY_OK)\n    {\n    }\n\n    /**\n     * @name Mat::is_symmetric()\n     * @brief Check if the matrix is symmetric within a given tolerance.\n     * @note A matrix A is symmetric if A^T = A, i.e., A[i][j] = A[j][i] for all i, j.\n     * @note Essential for SHM applications where structural matrices are typically symmetric.\n     * @note Time complexity: O(n\u00b2) - checks upper triangular part only\n     * \n     * @param tolerance Maximum allowed difference between A(i,j) and A(j,i) (must be &gt;= 0).\n     *                  Used to handle floating-point numerical errors.\n     * @return true if matrix is symmetric, false otherwise\n     */\n    bool Mat::is_symmetric(float tolerance) const\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] is_symmetric: matrix data pointer is null\\n\";\n            return false;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] is_symmetric: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            return false;\n        }\n\n        // Validate tolerance\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] is_symmetric: tolerance must be &gt;= 0 (got \" &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            return false;\n        }\n\n        // Only square matrices can be symmetric\n        if (this-&gt;row != this-&gt;col)\n        {\n            return false;\n        }\n\n        int n = this-&gt;row;\n\n        // Handle empty matrix (0x0 is trivially symmetric)\n        if (n == 0)\n        {\n            return true;\n        }\n\n        // Check symmetry: A(i,j) should equal A(j,i) within tolerance\n        // Only check upper triangular part (i &lt; j) to avoid redundant checks\n        for (int i = 0; i &lt; n; ++i)\n        {\n            for (int j = i + 1; j &lt; n; ++j)\n            {\n                float a_ij = (*this)(i, j);\n                float a_ji = (*this)(j, i);\n\n                // Check if values are valid\n                if (std::isnan(a_ij) || std::isnan(a_ji) || \n                    std::isinf(a_ij) || std::isinf(a_ji))\n                {\n                    std::cerr &lt;&lt; \"[Warning] is_symmetric: invalid matrix elements at [\" \n                              &lt;&lt; i &lt;&lt; \"][\" &lt;&lt; j &lt;&lt; \"] or [\" &lt;&lt; j &lt;&lt; \"][\" &lt;&lt; i &lt;&lt; \"]\\n\";\n                    return false;\n                }\n\n                float diff = fabsf(a_ij - a_ji);\n                if (diff &gt; tolerance)\n                {\n                    return false;\n                }\n            }\n        }\n\n        return true;\n    }\n\n    /**\n     * @name Mat::power_iteration()\n     * @brief Compute the dominant (largest magnitude) eigenvalue and eigenvector using power iteration.\n     * @note Power iteration finds the eigenvalue with the largest absolute value and its corresponding eigenvector.\n     *       Algorithm: v_{k+1} = A * v_k / ||A * v_k||, converges to dominant eigenvector.\n     * @note Fast method suitable for real-time SHM applications to quickly identify primary frequency.\n     * @note Time complexity: O(n\u00b2 * iterations) - efficient for sparse or large matrices\n     * @note Convergence: Requires that the dominant eigenvalue is unique and has larger magnitude than others.\n     * \n     * @param max_iter Maximum number of iterations (must be &gt; 0)\n     * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when |\u03bb_k - \u03bb_{k-1}| &lt; tolerance * |\u03bb_k|\n     * @return EigenPair containing the dominant eigenvalue, eigenvector, and status\n     */\n    Mat::EigenPair Mat::power_iteration(int max_iter, float tolerance) const\n    {\n        EigenPair result;\n\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] power_iteration: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] power_iteration: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validation: must be square matrix\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] power_iteration: requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validate parameters\n        if (max_iter &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] power_iteration: max_iter must be &gt; 0 (got \" &lt;&lt; max_iter &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] power_iteration: tolerance must be &gt;= 0 (got \" &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        int n = this-&gt;row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            result.eigenvalue = 0.0f;\n            result.eigenvector = Mat(0, 1);\n            result.iterations = 0;\n            result.status = TINY_OK;\n            return result;\n        }\n\n        // Initialize eigenvector with better strategy to avoid convergence to smaller eigenvalues\n        // Strategy: Use sum of columns (or rows) to get a vector with components in all directions\n        result.eigenvector = Mat(n, 1);\n\n        // Check if eigenvector was created successfully\n        if (result.eigenvector.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] power_iteration: failed to create eigenvector\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        float norm_sq = 0.0f;\n\n        // Method 1: Use sum of absolute values of columns (more robust)\n        for (int i = 0; i &lt; n; ++i)\n        {\n            float col_sum = 0.0f;\n            for (int j = 0; j &lt; n; ++j)\n            {\n                col_sum += fabsf((*this)(j, i));\n            }\n            result.eigenvector(i, 0) = col_sum + 1.0f; // Add 1 to avoid zero\n            norm_sq += result.eigenvector(i, 0) * result.eigenvector(i, 0);\n        }\n\n        // If all components are too similar, use a different initialization\n        if (norm_sq &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            // Fallback: use values based on index with some variation\n            norm_sq = 0.0f;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                result.eigenvector(i, 0) = 1.0f + 0.1f * static_cast&lt;float&gt;(i);\n                norm_sq += result.eigenvector(i, 0) * result.eigenvector(i, 0);\n            }\n        }\n\n        // Normalize initial eigenvector\n        float sqrt_norm = sqrtf(norm_sq);\n        if (std::isnan(sqrt_norm) || std::isinf(sqrt_norm) || sqrt_norm &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            std::cerr &lt;&lt; \"[Error] power_iteration: invalid initial eigenvector norm\\n\";\n            result.status = TINY_ERR_MATH_INVALID_PARAM;\n            return result;\n        }\n\n        float inv_norm = 1.0f / sqrt_norm;\n        for (int i = 0; i &lt; n; ++i)\n        {\n            result.eigenvector(i, 0) *= inv_norm;\n        }\n\n        // Power iteration loop\n        Mat temp_vec(n, 1);\n\n        // Check if temp_vec was created successfully\n        if (temp_vec.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] power_iteration: failed to create temporary vector\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        float prev_eigenvalue = 0.0f;\n\n        for (int iter = 0; iter &lt; max_iter; ++iter)\n        {\n            // Compute A * v\n            for (int i = 0; i &lt; n; ++i)\n            {\n                temp_vec(i, 0) = 0.0f;\n                for (int j = 0; j &lt; n; ++j)\n                {\n                    temp_vec(i, 0) += (*this)(i, j) * result.eigenvector(j, 0);\n                }\n\n                // Check if result is valid\n                if (std::isnan(temp_vec(i, 0)) || std::isinf(temp_vec(i, 0)))\n                {\n                    std::cerr &lt;&lt; \"[Error] power_iteration: invalid matrix-vector product at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                    result.status = TINY_ERR_MATH_INVALID_PARAM;\n                    return result;\n                }\n            }\n\n            // Compute Rayleigh quotient: lambda = v^T * A * v / (v^T * v)\n            float numerator = 0.0f;\n            float denominator = 0.0f;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                numerator += result.eigenvector(i, 0) * temp_vec(i, 0);\n                denominator += result.eigenvector(i, 0) * result.eigenvector(i, 0);\n            }\n\n            if (fabsf(denominator) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] power_iteration: eigenvector norm too small\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            result.eigenvalue = numerator / denominator;\n\n            // Check if eigenvalue is valid\n            if (std::isnan(result.eigenvalue) || std::isinf(result.eigenvalue))\n            {\n                std::cerr &lt;&lt; \"[Error] power_iteration: invalid eigenvalue computed\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            // Normalize the new vector\n            float new_norm_sq = 0.0f;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                new_norm_sq += temp_vec(i, 0) * temp_vec(i, 0);\n            }\n\n            if (new_norm_sq &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] power_iteration: computed vector norm too small\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            float new_sqrt_norm = sqrtf(new_norm_sq);\n            if (std::isnan(new_sqrt_norm) || std::isinf(new_sqrt_norm))\n            {\n                std::cerr &lt;&lt; \"[Error] power_iteration: invalid sqrt of vector norm\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            float new_inv_norm = 1.0f / new_sqrt_norm;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                result.eigenvector(i, 0) = temp_vec(i, 0) * new_inv_norm;\n\n                // Check if eigenvector component is valid\n                if (std::isnan(result.eigenvector(i, 0)) || std::isinf(result.eigenvector(i, 0)))\n                {\n                    std::cerr &lt;&lt; \"[Error] power_iteration: invalid eigenvector component at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                    result.status = TINY_ERR_MATH_INVALID_PARAM;\n                    return result;\n                }\n            }\n\n            // Check convergence\n            if (iter &gt; 0)\n            {\n                float eigenvalue_change = fabsf(result.eigenvalue - prev_eigenvalue);\n                float abs_eigenvalue = fabsf(result.eigenvalue);\n\n                // Avoid division by zero\n                if (abs_eigenvalue &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                {\n                    // If eigenvalue is near zero, check absolute change\n                    if (eigenvalue_change &lt; tolerance)\n                    {\n                        result.iterations = iter + 1;\n                        result.status = TINY_OK;\n                        return result;\n                    }\n                }\n                else\n                {\n                    // Relative change check\n                    if (eigenvalue_change &lt; tolerance * abs_eigenvalue)\n                    {\n                        result.iterations = iter + 1;\n                        result.status = TINY_OK;\n                        return result;\n                    }\n                }\n            }\n\n            prev_eigenvalue = result.eigenvalue;\n        }\n\n        // Max iterations reached\n        result.iterations = max_iter;\n        result.status = TINY_ERR_NOT_FINISHED;\n        std::cerr &lt;&lt; \"[Warning] power_iteration: did not converge within \" &lt;&lt; max_iter &lt;&lt; \" iterations\\n\";\n        return result;\n    }\n\n    /**\n     * @name Mat::inverse_power_iteration()\n     * @brief Compute the smallest (minimum magnitude) eigenvalue and eigenvector using inverse power iteration.\n     * @note Inverse power iteration finds the eigenvalue with the smallest absolute value and its eigenvector.\n     *       Algorithm: v_{k+1} = A^(-1) * v_k / ||A^(-1) * v_k||, converges to smallest eigenvector.\n     * @note Critical for system identification - finds fundamental frequency/lowest mode in structural dynamics.\n     *       This method is essential for SHM applications where the smallest eigenvalue corresponds to the\n     *       fundamental frequency of the system.\n     * @note Time complexity: O(n\u00b3 * iterations) - each iteration requires solving a linear system\n     * @note The matrix must be invertible (non-singular) for this method to work.\n     *       If the matrix is singular or near-singular, the method will fail gracefully.\n     * \n     * @param max_iter Maximum number of iterations (must be &gt; 0)\n     * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when |\u03bb_k - \u03bb_{k-1}| &lt; tolerance * max(|\u03bb_k|, 1)\n     * @return EigenPair containing the smallest eigenvalue, eigenvector, and status\n     */\n    Mat::EigenPair Mat::inverse_power_iteration(int max_iter, float tolerance) const\n    {\n        EigenPair result;\n\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_power_iteration: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_power_iteration: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validation: must be square matrix\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_power_iteration: requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validate parameters\n        if (max_iter &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_power_iteration: max_iter must be &gt; 0 (got \" &lt;&lt; max_iter &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_power_iteration: tolerance must be &gt;= 0 (got \" &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        int n = this-&gt;row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            result.eigenvalue = 0.0f;\n            result.eigenvector = Mat(0, 1);\n            result.iterations = 0;\n            result.status = TINY_OK;\n            return result;\n        }\n\n        // Check if matrix is singular by computing determinant (quick check)\n        // For efficiency, we'll check during the first solve operation instead\n\n        // Initialize eigenvector for inverse power iteration\n        // Strategy: Use a vector that is orthogonal to the dominant eigenvector direction\n        // For inverse power iteration, we want to converge to the smallest eigenvalue\n        // Use a simple initialization: [1, 1, ..., 1]^T normalized, which typically\n        // has components in all eigenvector directions\n        result.eigenvector = Mat(n, 1);\n\n        // Check if eigenvector was created successfully\n        if (result.eigenvector.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_power_iteration: failed to create eigenvector\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        float norm_sq = 0.0f;\n\n        // Initialize with alternating signs to avoid alignment with dominant eigenvector\n        // This helps ensure we converge to the smallest eigenvalue\n        for (int i = 0; i &lt; n; ++i)\n        {\n            // Use alternating pattern: 1, -1, 1, -1, ... with small variations\n            result.eigenvector(i, 0) = (i % 2 == 0) ? 1.0f : -1.0f;\n            result.eigenvector(i, 0) += 0.1f * static_cast&lt;float&gt;(i) / static_cast&lt;float&gt;(n);\n            norm_sq += result.eigenvector(i, 0) * result.eigenvector(i, 0);\n        }\n\n        // Normalize\n        if (norm_sq &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            // Fallback: use uniform vector\n            norm_sq = 0.0f;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                result.eigenvector(i, 0) = 1.0f;\n                norm_sq += 1.0f;\n            }\n        }\n\n        float sqrt_norm = sqrtf(norm_sq);\n        if (std::isnan(sqrt_norm) || std::isinf(sqrt_norm) || sqrt_norm &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_power_iteration: invalid initial eigenvector norm\\n\";\n            result.status = TINY_ERR_MATH_INVALID_PARAM;\n            return result;\n        }\n\n        float inv_norm = 1.0f / sqrt_norm;\n        for (int i = 0; i &lt; n; ++i)\n        {\n            result.eigenvector(i, 0) *= inv_norm;\n        }\n\n        // Inverse power iteration loop\n        Mat temp_vec(n, 1);\n\n        // Check if temp_vec was created successfully\n        if (temp_vec.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] inverse_power_iteration: failed to create temporary vector\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        float prev_eigenvalue = 0.0f;\n\n        for (int iter = 0; iter &lt; max_iter; ++iter)\n        {\n            // Solve A * y = v (equivalent to computing A^(-1) * v)\n            // This is the key difference from power iteration\n            temp_vec = solve(*this, result.eigenvector);\n\n            // Check if solve failed (matrix is singular or near-singular)\n            if (temp_vec.row == 0 || temp_vec.data == nullptr)\n            {\n                std::cerr &lt;&lt; \"[Error] Inverse power iteration: Matrix is singular or near-singular. \"\n                          &lt;&lt; \"Cannot solve linear system A * y = v.\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            // Check if solution vector is valid (not all zeros or NaN)\n            bool valid_solution = false;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                if (std::isnan(temp_vec(i, 0)) || std::isinf(temp_vec(i, 0)))\n                {\n                    std::cerr &lt;&lt; \"[Error] Inverse power iteration: Solution contains NaN or Inf.\\n\";\n                    result.status = TINY_ERR_MATH_INVALID_PARAM;\n                    return result;\n                }\n                if (fabsf(temp_vec(i, 0)) &gt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n                {\n                    valid_solution = true;\n                }\n            }\n\n            if (!valid_solution)\n            {\n                std::cerr &lt;&lt; \"[Error] Inverse power iteration: Solution vector is zero or too small.\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            // Compute Rayleigh quotient for A directly: lambda = (v^T * A * v) / (v^T * v)\n            // This gives us the eigenvalue of A corresponding to eigenvector v\n            // Note: In inverse power iteration, we iterate on A^(-1), but we want the eigenvalue of A\n            // Since y = A^(-1) * v, we have A * y = v, so we can compute v^T * A * v = v^T * A * y\n            // But more directly, we compute A * v to get the eigenvalue\n\n            // Compute A * v\n            Mat Av(n, 1);\n            for (int i = 0; i &lt; n; ++i)\n            {\n                Av(i, 0) = 0.0f;\n                for (int j = 0; j &lt; n; ++j)\n                {\n                    Av(i, 0) += (*this)(i, j) * result.eigenvector(j, 0);\n                }\n            }\n\n            // Compute Rayleigh quotient: lambda = (v^T * A * v) / (v^T * v)\n            float numerator = 0.0f;\n            float denominator = 0.0f;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                numerator += result.eigenvector(i, 0) * Av(i, 0);\n                denominator += result.eigenvector(i, 0) * result.eigenvector(i, 0);\n            }\n\n            if (fabsf(denominator) &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] Inverse power iteration: eigenvector norm too small.\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            // Compute eigenvalue of A using Rayleigh quotient\n            result.eigenvalue = numerator / denominator;\n\n            // Check if eigenvalue is valid\n            if (std::isnan(result.eigenvalue) || std::isinf(result.eigenvalue))\n            {\n                std::cerr &lt;&lt; \"[Error] inverse_power_iteration: invalid eigenvalue computed\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            // Normalize the new vector\n            float new_norm_sq = 0.0f;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                new_norm_sq += temp_vec(i, 0) * temp_vec(i, 0);\n            }\n\n            if (new_norm_sq &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n            {\n                std::cerr &lt;&lt; \"[Error] inverse_power_iteration: computed vector norm too small\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            float new_sqrt_norm = sqrtf(new_norm_sq);\n            if (std::isnan(new_sqrt_norm) || std::isinf(new_sqrt_norm))\n            {\n                std::cerr &lt;&lt; \"[Error] inverse_power_iteration: invalid sqrt of vector norm\\n\";\n                result.status = TINY_ERR_MATH_INVALID_PARAM;\n                return result;\n            }\n\n            float new_inv_norm = 1.0f / new_sqrt_norm;\n            for (int i = 0; i &lt; n; ++i)\n            {\n                result.eigenvector(i, 0) = temp_vec(i, 0) * new_inv_norm;\n\n                // Check if eigenvector component is valid\n                if (std::isnan(result.eigenvector(i, 0)) || std::isinf(result.eigenvector(i, 0)))\n                {\n                    std::cerr &lt;&lt; \"[Error] inverse_power_iteration: invalid eigenvector component at index \" &lt;&lt; i &lt;&lt; \"\\n\";\n                    result.status = TINY_ERR_MATH_INVALID_PARAM;\n                    return result;\n                }\n            }\n\n            // Check convergence\n            if (iter &gt; 0)\n            {\n                float eigenvalue_change = fabsf(result.eigenvalue - prev_eigenvalue);\n                // Use relative tolerance for convergence check\n                float abs_eigenvalue = fabsf(result.eigenvalue);\n                float rel_tolerance = tolerance * fmaxf(abs_eigenvalue, 1.0f);\n\n                if (eigenvalue_change &lt; rel_tolerance)\n                {\n                    result.iterations = iter + 1;\n                    result.status = TINY_OK;\n                    return result;\n                }\n            }\n\n            prev_eigenvalue = result.eigenvalue;\n        }\n\n        // Max iterations reached\n        result.iterations = max_iter;\n        result.status = TINY_ERR_NOT_FINISHED;\n        std::cerr &lt;&lt; \"[Warning] inverse_power_iteration: did not converge within \" &lt;&lt; max_iter &lt;&lt; \" iterations\\n\";\n        return result;\n    }\n\n    /**\n     * @name Mat::eigendecompose_jacobi()\n     * @brief Compute complete eigenvalue decomposition using Jacobi method for symmetric matrices.\n     * @note Jacobi method iteratively applies Givens rotations to diagonalize a symmetric matrix.\n     *       Algorithm: Repeatedly find largest off-diagonal element and eliminate it with a rotation.\n     * @note Robust and accurate method ideal for structural dynamics matrices in SHM.\n     * @note Time complexity: O(n\u00b3 * iterations) - typically converges in O(n\u00b2) iterations\n     * @note Best for: Symmetric matrices (required), small to medium sized matrices (n &lt; 100)\n     * \n     * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when max off-diagonal &lt; tolerance\n     * @param max_iter Maximum number of iterations (must be &gt; 0)\n     * @return EigenDecomposition containing all eigenvalues, eigenvectors, and status\n     */\n    Mat::EigenDecomposition Mat::eigendecompose_jacobi(float tolerance, int max_iter) const\n    {\n        EigenDecomposition result;\n\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validation: must be square matrix\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validate parameters\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: tolerance must be &gt;= 0 (got \" &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        if (max_iter &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: max_iter must be &gt; 0 (got \" &lt;&lt; max_iter &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Check if matrix is symmetric\n        if (!this-&gt;is_symmetric(tolerance * 10.0f))\n        {\n            std::cerr &lt;&lt; \"[Warning] eigendecompose_jacobi: matrix is not symmetric. \"\n                      &lt;&lt; \"Jacobi method may not converge correctly.\\n\";\n        }\n\n        int n = this-&gt;row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            result.eigenvalues = Mat(0, 1);\n            result.eigenvectors = Mat(0, 0);\n            result.iterations = 0;\n            result.status = TINY_OK;\n            return result;\n        }\n\n        // Initialize: working copy of matrix, eigenvectors as identity\n        Mat A = Mat(*this); // Working copy (will become diagonal)\n\n        // Check if working copy was created successfully\n        if (A.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: failed to create working copy\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        result.eigenvectors = Mat::eye(n);\n\n        // Check if eigenvectors matrix was created successfully\n        if (result.eigenvectors.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: failed to create eigenvectors matrix\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Jacobi iteration\n        for (int iter = 0; iter &lt; max_iter; ++iter)\n        {\n            // Find largest off-diagonal element\n            float max_off_diag = 0.0f;\n            int p = 0, q = 0;\n\n            for (int i = 0; i &lt; n; ++i)\n            {\n                for (int j = i + 1; j &lt; n; ++j)\n                {\n                    float abs_val = fabsf(A(i, j));\n                    if (abs_val &gt; max_off_diag)\n                    {\n                        max_off_diag = abs_val;\n                        p = i;\n                        q = j;\n                    }\n                }\n            }\n\n            // Check convergence\n            if (max_off_diag &lt; tolerance)\n            {\n                // Extract eigenvalues from diagonal\n                result.eigenvalues = Mat(n, 1);\n\n                // Check if eigenvalues matrix was created successfully\n                if (result.eigenvalues.data == nullptr)\n                {\n                    std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: failed to create eigenvalues matrix\\n\";\n                    result.status = TINY_ERR_MATH_NULL_POINTER;\n                    return result;\n                }\n\n                for (int i = 0; i &lt; n; ++i)\n                {\n                    result.eigenvalues(i, 0) = A(i, i);\n                }\n                result.iterations = iter + 1;\n                result.status = TINY_OK;\n                return result;\n            }\n\n            // Compute rotation angle\n            float app = A(p, p);\n            float aqq = A(q, q);\n            float apq = A(p, q);\n\n            float tau = (aqq - app) / (2.0f * apq);\n            float t;\n            if (tau &gt;= 0.0f)\n            {\n                t = 1.0f / (tau + sqrtf(1.0f + tau * tau));\n            }\n            else\n            {\n                t = -1.0f / (-tau + sqrtf(1.0f + tau * tau));\n            }\n\n            float c = 1.0f / sqrtf(1.0f + t * t); // cosine\n            float s = t * c;                       // sine\n\n            // Apply Jacobi rotation to A\n            // Update rows p and q\n            for (int j = 0; j &lt; n; ++j)\n            {\n                if (j != p &amp;&amp; j != q)\n                {\n                    float apj = A(p, j);\n                    float aqj = A(q, j);\n                    A(p, j) = c * apj - s * aqj;\n                    A(q, j) = s * apj + c * aqj;\n                    A(j, p) = A(p, j); // Maintain symmetry\n                    A(j, q) = A(q, j);\n                }\n            }\n\n            // Update diagonal elements\n            float app_new = c * c * app - 2.0f * c * s * apq + s * s * aqq;\n            float aqq_new = s * s * app + 2.0f * c * s * apq + c * c * aqq;\n            A(p, p) = app_new;\n            A(q, q) = aqq_new;\n            A(p, q) = 0.0f;\n            A(q, p) = 0.0f;\n\n            // Update eigenvectors\n            for (int i = 0; i &lt; n; ++i)\n            {\n                float vip = result.eigenvectors(i, p);\n                float viq = result.eigenvectors(i, q);\n                result.eigenvectors(i, p) = c * vip - s * viq;\n                result.eigenvectors(i, q) = s * vip + c * viq;\n            }\n        }\n\n        // Extract eigenvalues from diagonal\n        result.eigenvalues = Mat(n, 1);\n\n        // Check if eigenvalues matrix was created successfully\n        if (result.eigenvalues.data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_jacobi: failed to create eigenvalues matrix\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        for (int i = 0; i &lt; n; ++i)\n        {\n            result.eigenvalues(i, 0) = A(i, i);\n        }\n\n        result.iterations = max_iter;\n        result.status = TINY_ERR_NOT_FINISHED;\n        std::cerr &lt;&lt; \"[Warning] eigendecompose_jacobi: did not converge within \" &lt;&lt; max_iter &lt;&lt; \" iterations\\n\";\n        return result;\n    }\n\n    /**\n     * @name Mat::eigendecompose_qr()\n     * @brief Compute complete eigenvalue decomposition using QR algorithm for general matrices.\n     * @note QR algorithm iteratively applies QR decomposition: A_k = Q_k * R_k, A_{k+1} = R_k * Q_k.\n     *       Converges to Schur form (upper triangular) for real eigenvalues.\n     * @note Supports non-symmetric matrices, but may have complex eigenvalues (only real part returned).\n     * @note Time complexity: O(n\u00b3 * iterations) - typically requires O(n) iterations\n     * @note Best for: General matrices, when all eigenvalues are real\n     * \n     * @param max_iter Maximum number of QR iterations (must be &gt; 0)\n     * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when subdiagonal &lt; tolerance\n     * @return EigenDecomposition containing eigenvalues, eigenvectors, and status\n     */\n    Mat::EigenDecomposition Mat::eigendecompose_qr(int max_iter, float tolerance) const\n    {\n        EigenDecomposition result;\n\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_qr: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate matrix dimensions\n        if (this-&gt;row &lt;= 0 || this-&gt;col &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_qr: invalid matrix dimensions: rows=\" \n                      &lt;&lt; this-&gt;row &lt;&lt; \", cols=\" &lt;&lt; this-&gt;col &lt;&lt; \"\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validation: must be square matrix\n        if (this-&gt;row != this-&gt;col)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_qr: requires square matrix (got \" \n                      &lt;&lt; this-&gt;row &lt;&lt; \"x\" &lt;&lt; this-&gt;col &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Validate parameters\n        if (max_iter &lt;= 0)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_qr: max_iter must be &gt; 0 (got \" &lt;&lt; max_iter &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        if (tolerance &lt; 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] eigendecompose_qr: tolerance must be &gt;= 0 (got \" &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        int n = this-&gt;row;\n\n        // Handle empty matrix\n        if (n == 0)\n        {\n            result.eigenvalues = Mat(0, 1);\n            result.eigenvectors = Mat(0, 0);\n            result.iterations = 0;\n            result.status = TINY_OK;\n            return result;\n        }\n\n        // Initialize: start with original matrix, eigenvectors as identity\n        Mat A = Mat(*this); // Working copy (will become upper triangular)\n        result.eigenvectors = Mat::eye(n);\n\n        // QR iteration with improved convergence checking\n        for (int iter = 0; iter &lt; max_iter; ++iter)\n        {\n            // Check convergence: check if matrix is upper triangular\n            // Use a more lenient tolerance for sub-diagonal elements\n            bool converged = true;\n            float max_off_diag = 0.0f;\n            for (int i = 1; i &lt; n; ++i)\n            {\n                for (int j = 0; j &lt; i; ++j)\n                {\n                    float abs_val = fabsf(A(i, j));\n                    if (abs_val &gt; max_off_diag)\n                        max_off_diag = abs_val;\n                    // Use relative tolerance: compare with diagonal elements\n                    float diag_scale = fmaxf(fabsf(A(i, i)), fabsf(A(j, j)));\n                    float rel_tolerance = tolerance * fmaxf(1.0f, diag_scale);\n                    if (abs_val &gt; rel_tolerance)\n                    {\n                        converged = false;\n                    }\n                }\n            }\n\n            if (converged)\n            {\n                // Extract eigenvalues from diagonal\n                result.eigenvalues = Mat(n, 1);\n                for (int i = 0; i &lt; n; ++i)\n                {\n                    result.eigenvalues(i, 0) = A(i, i);\n                }\n                result.iterations = iter + 1;\n                result.status = TINY_OK;\n                return result;\n            }\n\n            // Optional: Use shift to accelerate convergence (Wilkinson shift for last 2x2 block)\n            // For simplicity, we skip shift for now but can add it later if needed\n\n            // QR decomposition using Gram-Schmidt process\n            // Use the reusable gram_schmidt_orthogonalize function\n            Mat Q_ortho, R_coeff;\n            if (!Mat::gram_schmidt_orthogonalize(A, Q_ortho, R_coeff, TINY_MATH_MIN_POSITIVE_INPUT_F32))\n            {\n                result.status = TINY_ERR_MATH_NULL_POINTER;\n                return result;\n            }\n\n            Mat Q = Q_ortho;\n            Mat R(n, n);\n\n            // Copy coefficients to R (upper triangular part)\n            for (int j = 0; j &lt; n; ++j)\n            {\n                for (int k = 0; k &lt;= j; ++k)\n                {\n                    R(k, j) = R_coeff(k, j);\n                }\n\n                // Compute remaining R elements: R(j,k) = Q(:,j)^T * A(:,k) for k &gt; j\n                for (int k = j + 1; k &lt; n; ++k)\n                {\n                    float dot = 0.0f;\n                    for (int i = 0; i &lt; n; ++i)\n                    {\n                        dot += Q(i, j) * A(i, k);\n                    }\n                    R(j, k) = dot;\n                }\n            }\n\n            // Update A = R * Q\n            Mat A_new(n, n);\n            for (int i = 0; i &lt; n; ++i)\n            {\n                for (int j = 0; j &lt; n; ++j)\n                {\n                    A_new(i, j) = 0.0f;\n                    for (int k = 0; k &lt; n; ++k)\n                    {\n                        A_new(i, j) += R(i, k) * Q(k, j);\n                    }\n                }\n            }\n            A = A_new;\n\n            // Update eigenvectors: V = V * Q\n            Mat V_new(n, n);\n            for (int i = 0; i &lt; n; ++i)\n            {\n                for (int j = 0; j &lt; n; ++j)\n                {\n                    V_new(i, j) = 0.0f;\n                    for (int k = 0; k &lt; n; ++k)\n                    {\n                        V_new(i, j) += result.eigenvectors(i, k) * Q(k, j);\n                    }\n                }\n            }\n            result.eigenvectors = V_new;\n        }\n\n        // Extract eigenvalues from diagonal\n        result.eigenvalues = Mat(n, 1);\n        for (int i = 0; i &lt; n; ++i)\n        {\n            result.eigenvalues(i, 0) = A(i, i);\n        }\n\n        result.iterations = max_iter;\n        result.status = TINY_ERR_NOT_FINISHED;\n        std::cerr &lt;&lt; \"[Warning] QR algorithm did not converge within \" &lt;&lt; max_iter &lt;&lt; \" iterations.\\n\";\n        return result;\n    }\n\n    /**\n     * @name Mat::eigendecompose()\n     * @brief Automatic eigenvalue decomposition with method selection.\n     * @note Convenient interface for edge computing: automatically selects the best method.\n     *       - Symmetric matrices: Uses Jacobi method (more efficient and stable)\n     *       - General matrices: Uses QR algorithm\n     * @note Time complexity: Depends on selected method\n     *       - Jacobi: O(n\u00b3 * iterations) for symmetric matrices\n     *       - QR: O(n\u00b3 * iterations) for general matrices\n     * \n     * @param tolerance Convergence tolerance (must be &gt;= 0)\n     * @return EigenDecomposition containing eigenvalues, eigenvectors, and status\n     */\n    Mat::EigenDecomposition Mat::eigendecompose(float tolerance) const\n    {\n        // Check for null pointer\n        if (this-&gt;data == nullptr)\n        {\n            EigenDecomposition result;\n            std::cerr &lt;&lt; \"[Error] eigendecompose: matrix data pointer is null\\n\";\n            result.status = TINY_ERR_MATH_NULL_POINTER;\n            return result;\n        }\n\n        // Validate tolerance\n        if (tolerance &lt; 0.0f)\n        {\n            EigenDecomposition result;\n            std::cerr &lt;&lt; \"[Error] eigendecompose: tolerance must be &gt;= 0 (got \" &lt;&lt; tolerance &lt;&lt; \")\\n\";\n            result.status = TINY_ERR_INVALID_ARG;\n            return result;\n        }\n\n        // Check if matrix is symmetric\n        if (this-&gt;is_symmetric(tolerance * 10.0f))\n        {\n            // Use Jacobi method for symmetric matrices (more efficient and stable)\n            return this-&gt;eigendecompose_jacobi(tolerance, 100);\n        }\n        else\n        {\n            // Use QR algorithm for general matrices\n            return this-&gt;eigendecompose_qr(100, tolerance);\n        }\n    }\n\n    // ============================================================================\n    // Stream Operators\n    // ============================================================================\n    /**\n     * @name operator&lt;&lt;\n     * @brief Stream insertion operator for printing matrix to the output stream (e.g., std::cout).\n     *\n     * This function allows printing the contents of a matrix to an output stream.\n     * It prints each row of the matrix on a new line, with elements separated by spaces.\n     *\n     * @param os Output stream where the matrix will be printed (e.g., std::cout)\n     * @param m Matrix to be printed\n     *\n     * @return os The output stream after printing the matrix\n     */\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m)\n    {\n        if (m.data == nullptr)\n        {\n            os &lt;&lt; \"[Error] Cannot print matrix: data pointer is null.\\n\";\n            return os;\n        }\n\n        for (int i = 0; i &lt; m.row; ++i)\n        {\n            os &lt;&lt; m(i, 0);\n            for (int j = 1; j &lt; m.col; ++j)\n            {\n                os &lt;&lt; \" \" &lt;&lt; m(i, j);\n            }\n            os &lt;&lt; std::endl;\n        }\n        return os;\n    }\n\n    /**\n     * @name operator&lt;&lt;\n     * @brief Stream insertion operator for printing the Rectangular ROI structure to the output stream.\n     *\n     * This function prints the details of the ROI (Region of Interest) including the start row and column,\n     * and the width and height of the rectangular region.\n     *\n     * @param os Output stream where the ROI will be printed (e.g., std::cout)\n     * @param roi The ROI structure to be printed\n     *\n     * @return os The output stream after printing the ROI details\n     */\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi)\n    {\n        os &lt;&lt; \"row start \" &lt;&lt; roi.pos_y &lt;&lt; std::endl;\n        os &lt;&lt; \"col start \" &lt;&lt; roi.pos_x &lt;&lt; std::endl;\n        os &lt;&lt; \"row count \" &lt;&lt; roi.height &lt;&lt; std::endl;\n        os &lt;&lt; \"col count \" &lt;&lt; roi.width &lt;&lt; std::endl;\n\n        return os;\n    }\n\n    /**\n     * @name operator&gt;&gt;\n     * @brief Stream extraction operator for reading matrix from the input stream (e.g., std::cin).\n     *\n     * This function reads the contents of a matrix from an input stream.\n     * The matrix elements are read row by row, with elements separated by spaces or newlines.\n     *\n     * @param is Input stream from which the matrix will be read (e.g., std::cin)\n     * @param m Matrix to store the read data\n     *\n     * @return is The input stream after reading the matrix\n     */\n    std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m)\n    {\n        for (int i = 0; i &lt; m.row; ++i)\n        {\n            for (int j = 0; j &lt; m.col; ++j)\n            {\n                is &gt;&gt; m(i, j);\n            }\n        }\n        return is;\n    }\n\n    // ============================================================================\n    // Global Arithmetic Operators\n    // ============================================================================\n    /**\n     * + operator, sum of two matrices\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *     - result matrix A+B\n     */\n    Mat operator+(const Mat &amp;m1, const Mat &amp;m2)\n    {\n        if ((m1.row != m2.row) || (m1.col != m2.col))\n        {\n            std::cerr &lt;&lt; \"operator + Error: matrices do not have equal dimensions\" &lt;&lt; std::endl;\n            Mat err_ret;\n            return err_ret;\n        }\n\n        if (m1.sub_matrix || m2.sub_matrix)\n        {\n            Mat temp(m1.row, m1.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_add_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m1.pad, m2.pad, temp.pad, 1, 1, 1);\n#else\n            tiny_mat_add_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m1.pad, m2.pad, temp.pad, 1, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m1);\n            return (temp += m2);\n        }\n    }\n\n    /**\n     * + operator, sum of matrix with constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] C: Input constant\n     *\n     * @return\n     *     - result matrix A+C\n     */\n    Mat operator+(const Mat &amp;m, float C)\n    {\n        if (m.sub_matrix)\n        {\n            Mat temp(m.row, m.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_addc_f32(m.data, temp.data, C, m.row, m.col, m.pad, temp.pad, 1, 1);\n#else\n            tiny_mat_addc_f32(m.data, temp.data, C, m.row, m.col, m.pad, temp.pad, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m);\n            return (temp += C);\n        }\n    }\n\n    /**\n     * - operator, subtraction of two matrices\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *     - result matrix A-B\n     */\n    Mat operator-(const Mat &amp;m1, const Mat &amp;m2)\n    {\n        if ((m1.row != m2.row) || (m1.col != m2.col))\n        {\n            std::cerr &lt;&lt; \"operator - Error: matrices do not have equal dimensions\" &lt;&lt; std::endl;\n            Mat err_ret;\n            return err_ret;\n        }\n\n        if (m1.sub_matrix || m2.sub_matrix)\n        {\n            Mat temp(m1.row, m1.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_sub_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m1.pad, m2.pad, temp.pad, 1, 1, 1);\n#else\n            tiny_mat_sub_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m1.pad, m2.pad, temp.pad, 1, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m1);\n            return (temp -= m2);\n        }\n    }\n\n\n    /**\n     * - operator, subtraction of matrix with constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] C: Input constant\n     *\n     * @return\n     *     - result matrix A-C\n     */\n    Mat operator-(const Mat &amp;m, float C)\n    {\n        if (m.sub_matrix)\n        {\n            Mat temp(m.row, m.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_addc_f32(m.data, temp.data, -C, m.row, m.col, m.pad, temp.pad, 1, 1);\n#else\n            tiny_mat_addc_f32(m.data, temp.data, -C, m.row, m.col, m.pad, temp.pad, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m);\n            return (temp -= C);\n        }\n    }\n\n\n    /**\n     * * operator, multiplication of two matrices.\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *     - result matrix A*B\n     */\n    Mat operator*(const Mat &amp;m1, const Mat &amp;m2)\n    {\n        if (m1.col != m2.row)\n        {\n            std::cerr &lt;&lt; \"operator * Error: matrices do not have correct dimensions\" &lt;&lt; std::endl;\n            Mat err_ret;\n            return err_ret;\n        }\n        Mat temp(m1.row, m2.col);\n\n        if (m1.sub_matrix || m2.sub_matrix)\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mult_ex_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m2.col, m1.pad, m2.pad, temp.pad);\n#else\n            tiny_mat_mult_ex_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m2.col, m1.pad, m2.pad, temp.pad);\n#endif\n        }\n        else\n        {\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mult_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m2.col);\n#else\n            tiny_mat_mult_f32(m1.data, m2.data, temp.data, m1.row, m1.col, m2.col);\n#endif\n        }\n\n        return temp;\n    }\n\n    /**\n     * * operator, multiplication of matrix with constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] C: floating point value\n     *\n     * @return\n     *     - result matrix A*B\n     */\n    Mat operator*(const Mat &amp;m, float num)\n    {\n        if (m.sub_matrix)\n        {\n            Mat temp(m.row, m.col);\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mulc_f32(m.data, temp.data, num, m.row, m.col, m.pad, temp.pad, 1, 1);\n#else\n            tiny_mat_multc_f32(m.data, temp.data, num, m.row, m.col, m.pad, temp.pad, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m);\n            return (temp *= num);\n        }\n    }\n\n    /**\n     * * operator, multiplication of matrix with constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] C: floating point value\n     * @param[in] A: Input matrix A\n     *\n     * @return\n     *     - result matrix C*A\n     */\n    Mat operator*(float num, const Mat &amp;m)\n    {\n        return (m * num);\n    }\n\n    /**\n     * / operator, divide of matrix by constant\n     * The operator use DSP optimized implementation of multiplication.\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] C: floating point value\n     *\n     * @return\n     *     - result matrix A/C\n     */\n    Mat operator/(const Mat &amp;m, float num)\n    {\n        // Check division by zero\n        if (num == 0.0f)\n        {\n            std::cerr &lt;&lt; \"[Error] Division by zero in operator/.\\n\";\n            Mat err_ret;\n            return err_ret;\n        }\n\n        if (m.sub_matrix)\n        {\n            Mat temp(m.row, m.col);\n            float inv_num = 1.0f / num;\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n            dspm_mulc_f32(m.data, temp.data, inv_num, m.row, m.col, m.pad, temp.pad, 1, 1);\n#else\n            tiny_mat_multc_f32(m.data, temp.data, inv_num, m.row, m.col, m.pad, temp.pad, 1, 1);\n#endif\n            return temp;\n        }\n        else\n        {\n            Mat temp(m);\n            return (temp /= num);\n        }\n    }\n\n\n    /**\n     * / operator, divide matrix A by matrix B (element-wise)\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *     - result matrix C, where C[i,j] = A[i,j]/B[i,j]\n     */\n    Mat operator/(const Mat &amp;A, const Mat &amp;B)\n    {\n        if ((A.row != B.row) || (A.col != B.col))\n        {\n            std::cerr &lt;&lt; \"operator / Error: matrices do not have equal dimensions\" &lt;&lt; std::endl;\n            Mat err_ret;\n            return err_ret;\n        }\n\n        Mat temp(A.row, A.col);\n        for (int row = 0; row &lt; A.row; row++)\n        {\n            for (int col = 0; col &lt; A.col; col++)\n            {\n                temp(row, col) = A(row, col) / B(row, col);\n            }\n        }\n        return temp;\n    }\n\n\n    /**\n     * == operator, compare two matrices\n     *\n     * @param[in] A: Input matrix A\n     * @param[in] B: Input matrix B\n     *\n     * @return\n     *      - true if matrices are the same\n     *      - false if matrices are different\n     */\n    bool operator==(const Mat &amp;m1, const Mat &amp;m2)\n    {\n        if ((m1.col != m2.col) || (m1.row != m2.row))\n        {\n            return false;\n        }\n\n        const float epsilon = 1e-5f;\n        for (int row = 0; row &lt; m1.row; row++)\n        {\n            for (int col = 0; col &lt; m1.col; col++)\n            {\n                float diff = fabs(m1(row, col) - m2(row, col));\n                if (diff &gt; epsilon)\n                {\n                    std::cout &lt;&lt; \"operator == Error: \" &lt;&lt; row &lt;&lt; \" \" &lt;&lt; col &lt;&lt; \", m1.data=\" &lt;&lt; m1(row, col) &lt;&lt; \", m2.data=\" &lt;&lt; m2(row, col) &lt;&lt; \", diff=\" &lt;&lt; diff &lt;&lt; std::endl;\n                    return false;\n                }\n            }\n        }\n\n        return true;\n    }\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/","title":"Tests","text":"<p>Tip</p> <p>The following test code and cases also serve as usage teaching examples.</p>"},{"location":"MATH/MATRIX/tiny-matrix-test/#tiny_matrix_testhpp","title":"tiny_matrix_test.hpp","text":"<pre><code>/**\n * @file tiny_matrix_test.hpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the test of the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_matrix.hpp\" // TinyMatrix Header\n\n/* STATEMENTS */\nvoid tiny_matrix_test();  // C-compatible test entry\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#tiny_matrix_testcpp","title":"tiny_matrix_test.cpp","text":"<pre><code>/**\n * @file tiny_matrix_test.cpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the source file for the test of the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @copyright Copyright (c) 2025\n *\n */\n\n/* DEPENDENCIES */\n#include \"tiny_matrix_test.hpp\" // TinyMatrix Test Header\n#include \"tiny_time.h\"           // For performance testing\n\n#include &lt;iostream&gt;\n#include &lt;iomanip&gt;\n#include &lt;cmath&gt;\n#include &lt;sstream&gt;  // For std::istringstream (used in stream operator tests)\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n#include \"esp_task_wdt.h\"       // For FreeRTOS task watchdog\n#endif\n\n/* PERFORMANCE TESTING MACROS */\n// Reduced matrix sizes and iterations to prevent watchdog timeout and memory issues\n#define PERFORMANCE_TEST_ITERATIONS 100        // Reduced from 1000 to prevent timeout\n#define PERFORMANCE_TEST_ITERATIONS_HEAVY 10   // Reduced from 100 for compute-intensive operations\n#define PERFORMANCE_TEST_WARMUP 3              // Reduced from 10\n\n// Macro for timing a single operation\n#define TIME_OPERATION(operation, description) \\\n    do { \\\n        TinyTimeMark_t t0 = tiny_get_running_time(); \\\n        operation; \\\n        TinyTimeMark_t t1 = tiny_get_running_time(); \\\n        double dt_us = (double)(t1 - t0); \\\n        std::cout &lt;&lt; \"[Performance] \" &lt;&lt; description &lt;&lt; \": \" &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; dt_us &lt;&lt; \" us\\n\"; \\\n    } while(0)\n\n// Helper function to feed watchdog (inline to avoid function call overhead in tight loops)\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n// Static flag to track if task has been added to watchdog\nstatic bool task_wdt_added = false;\n\ninline void ensure_task_wdt_added()\n{\n    if (!task_wdt_added)\n    {\n        esp_task_wdt_add(NULL);  // Add current task to watchdog (NULL = current task)\n        task_wdt_added = true;\n    }\n}\n\ninline void feed_watchdog()\n{\n    ensure_task_wdt_added();\n    esp_task_wdt_reset();\n}\n\ninline void feed_watchdog_if_needed(int iteration, int interval)\n{\n    if ((iteration + 1) % interval == 0)\n    {\n        feed_watchdog();\n    }\n}\n#else\ninline void feed_watchdog()\n{\n    // No-op for non-ESP32 platforms\n}\n\ninline void feed_watchdog_if_needed(int iteration, int interval)\n{\n    // No-op for non-ESP32 platforms\n    (void)iteration;\n    (void)interval;\n}\n#endif\n\n// Macro for timing repeated operations\n#define TIME_REPEATED_OPERATION(operation, iterations, description) \\\n    do { \\\n        /* Feed watchdog before starting */ \\\n        feed_watchdog(); \\\n        /* Warmup */ \\\n        for (int w = 0; w &lt; PERFORMANCE_TEST_WARMUP; ++w) { \\\n            feed_watchdog();  /* Feed watchdog before each operation */ \\\n            operation; \\\n            feed_watchdog();  /* Feed watchdog after each operation */ \\\n        } \\\n        /* Actual test */ \\\n        TinyTimeMark_t perf_t0 = tiny_get_running_time(); \\\n        for (int i = 0; i &lt; iterations; ++i) { \\\n            /* Feed watchdog every 10 iterations (increased interval to reduce overhead) */ \\\n            if (i % 10 == 0) feed_watchdog(); \\\n            operation; \\\n        } \\\n        feed_watchdog();  /* Final feed after loop */ \\\n        TinyTimeMark_t perf_t1 = tiny_get_running_time(); \\\n        double perf_dt_total_us = (double)(perf_t1 - perf_t0); \\\n        double perf_dt_avg_us = perf_dt_total_us / iterations; \\\n        std::cout &lt;&lt; \"[Performance] \" &lt;&lt; description &lt;&lt; \" (\" &lt;&lt; iterations &lt;&lt; \" iterations): \" \\\n                  &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; perf_dt_total_us &lt;&lt; \" us total, \" \\\n                  &lt;&lt; perf_dt_avg_us &lt;&lt; \" us avg\\n\"; \\\n    } while(0)\n\n// Helper function to check if two matrices are approximately equal\nbool matrices_approximately_equal(const tiny::Mat &amp;m1, const tiny::Mat &amp;m2, float epsilon = 1e-5f)\n{\n    if (m1.row != m2.row || m1.col != m2.col)\n        return false;\n\n    for (int i = 0; i &lt; m1.row; ++i)\n    {\n        for (int j = 0; j &lt; m1.col; ++j)\n        {\n            if (std::fabs(m1(i, j) - m2(i, j)) &gt; epsilon)\n                return false;\n        }\n    }\n    return true;\n}\n\n// ============================================================================\n// A1: Constructor &amp; Destructor\n// ============================================================================\nvoid test_constructor_destructor()\n{\n    std::cout &lt;&lt; \"\\n[A1: Constructor &amp; Destructor Tests]\\n\";\n\n    // A1.1: default constructor\n    std::cout &lt;&lt; \"[A1.1] Default Constructor\\n\";\n    tiny::Mat mat1;\n    mat1.print_info();\n    mat1.print_matrix(true);\n\n    // A1.2: constructor with rows and cols, using internal allocation\n    std::cout &lt;&lt; \"[A1.2] Constructor with Rows and Cols\\n\";\n    tiny::Mat mat2(3, 4);\n    mat2.print_info();\n    mat2.print_matrix(true);\n\n    // A1.3: constructor with rows and cols, specifying stride, using internal allocation\n    std::cout &lt;&lt; \"[A1.3] Constructor with Rows, Cols and Stride\\n\";\n    tiny::Mat mat3(3, 4, 5);\n    mat3.print_info();\n    mat3.print_matrix(true);\n\n    // A1.4: constructor with external data\n    std::cout &lt;&lt; \"[A1.4] Constructor with External Data\\n\";\n    float data[12] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11};\n    tiny::Mat mat4(data, 3, 4);\n    mat4.print_info();\n    mat4.print_matrix(true);\n\n    // A1.5: constructor with external data and stride\n    std::cout &lt;&lt; \"[A1.5] Constructor with External Data and Stride\\n\";\n    float data_stride[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n    tiny::Mat mat5(data_stride, 3, 4, 5);\n    mat5.print_info();\n    mat5.print_matrix(true);\n\n    // A1.6: copy constructor\n    std::cout &lt;&lt; \"[A1.6] Copy Constructor\\n\";\n    tiny::Mat mat6(mat5);\n    mat6.print_info();\n    mat6.print_matrix(true);\n}\n\n// ============================================================================\n// A2: Element Access\n// ============================================================================\nvoid test_element_access()\n{\n    std::cout &lt;&lt; \"\\n[A2: Element Access Tests]\\n\";\n    tiny::Mat mat(2, 3);\n\n    // A2.1: non-const access\n    std::cout &lt;&lt; \"[A2.1] Non-const Access\\n\";\n    mat(0, 0) = 1.1f;\n    mat(0, 1) = 2.2f;\n    mat(0, 2) = 3.3f;\n    mat(1, 0) = 4.4f;\n    mat(1, 1) = 5.5f;\n    mat(1, 2) = 6.6f;\n    mat.print_info();\n    mat.print_matrix(true);\n\n    // A2.2: const access\n    std::cout &lt;&lt; \"[A2.2] Const Access\\n\";\n    const tiny::Mat const_mat = mat;\n    std::cout &lt;&lt; \"const_mat(0, 0): \" &lt;&lt; const_mat(0, 0) &lt;&lt; \"\\n\";\n}\n\n// ============================================================================\n// A3: ROI Operations\n// ============================================================================\nvoid test_roi_operations()\n{\n    std::cout &lt;&lt; \"\\n[A3: ROI Operations Tests]\\n\";\n\n    // Material Matrices\n    tiny::Mat matA(2, 3);\n    for (int i = 0; i &lt; 2; ++i)\n    {\n        for (int j = 0; j &lt; 3; ++j)\n        {\n            matA(i, j) = i * 3 + j + 1;\n            matA(i, j) = matA(i, j) / 10;\n        }\n    }\n\n    float data[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n    tiny::Mat matB(data, 3, 4, 5);\n\n    tiny::Mat matC;\n\n    std::cout &lt;&lt; \"[Material Matrices]\\n\";\n    std::cout &lt;&lt; \"matA:\\n\";\n    matA.print_info();\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"matB:\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"matC:\\n\";\n    matC.print_info();\n    matC.print_matrix(true);\n\n    // A3.1: Copy ROI\n    std::cout &lt;&lt; \"[A3.1] Copy ROI - Over Range Case\\n\";\n    matB.copy_paste(matA, 1, 2);\n    std::cout &lt;&lt; \"matB after copy_paste matA at (1, 2):\\n\";\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"nothing changed.\\n\";\n\n    std::cout &lt;&lt; \"[A3.2] Copy ROI - Suitable Range Case\\n\";\n    matB.copy_paste(matA, 1, 1);\n    std::cout &lt;&lt; \"matB after copy_paste matA at (1, 1):\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"successfully copied.\\n\";\n\n    // A3.3: Copy Head\n    std::cout &lt;&lt; \"[A3.3] Copy Head\\n\";\n    matC.copy_head(matB);\n    std::cout &lt;&lt; \"matC after copy_head matB:\\n\";\n    matC.print_info();\n    matC.print_matrix(true);\n\n    std::cout &lt;&lt; \"[A3.4] Copy Head - Memory Sharing Check\\n\"; // matB and matC share the same data pointer\n    matB(0, 0) = 99.99f;\n    std::cout &lt;&lt; \"matB(0, 0) = 99.99f\\n\";\n\n    // A3.5: copy_paste() - Error handling - negative position\n    std::cout &lt;&lt; \"\\n[A3.5] copy_paste() - Error Handling - Negative Position\\n\";\n    tiny::Mat dest1(3, 3);\n    tiny::Mat src1(2, 2);\n    src1(0, 0) = 1.0f; src1(0, 1) = 2.0f;\n    src1(1, 0) = 3.0f; src1(1, 1) = 4.0f;\n    tiny_error_t err1 = dest1.copy_paste(src1, -1, 0);\n    std::cout &lt;&lt; \"copy_paste with row_pos=-1: error = \" &lt;&lt; err1 \n              &lt;&lt; \" (Expected: TINY_ERR_INVALID_ARG) \" \n              &lt;&lt; (err1 == TINY_ERR_INVALID_ARG ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    err1 = dest1.copy_paste(src1, 0, -1);\n    std::cout &lt;&lt; \"copy_paste with col_pos=-1: error = \" &lt;&lt; err1 \n              &lt;&lt; \" (Expected: TINY_ERR_INVALID_ARG) \" \n              &lt;&lt; (err1 == TINY_ERR_INVALID_ARG ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // A3.6: copy_paste() - Error handling - out of bounds\n    std::cout &lt;&lt; \"\\n[A3.6] copy_paste() - Error Handling - Out of Bounds\\n\";\n    tiny::Mat dest2(2, 2);\n    tiny::Mat src2(3, 3);  // Larger than destination\n    err1 = dest2.copy_paste(src2, 0, 0);\n    std::cout &lt;&lt; \"copy_paste 3x3 into 2x2 at (0,0): error = \" &lt;&lt; err1 \n              &lt;&lt; \" (Expected: TINY_ERR_INVALID_ARG) \" \n              &lt;&lt; (err1 == TINY_ERR_INVALID_ARG ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    err1 = dest2.copy_paste(src1, 1, 1);  // src1 is 2x2, dest2 is 2x2, position (1,1) would exceed\n    std::cout &lt;&lt; \"copy_paste 2x2 into 2x2 at (1,1): error = \" &lt;&lt; err1 \n              &lt;&lt; \" (Expected: TINY_ERR_INVALID_ARG) \" \n              &lt;&lt; (err1 == TINY_ERR_INVALID_ARG ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // A3.7: copy_paste() - Boundary case - empty source\n    std::cout &lt;&lt; \"\\n[A3.7] copy_paste() - Boundary Case - Empty Source Matrix\\n\";\n    tiny::Mat dest3(3, 3);\n    tiny::Mat empty_src(0, 0);\n    err1 = dest3.copy_paste(empty_src, 0, 0);\n    std::cout &lt;&lt; \"copy_paste empty matrix: error = \" &lt;&lt; err1 \n              &lt;&lt; \" (Expected: TINY_ERR_INVALID_ARG) \" \n              &lt;&lt; (err1 == TINY_ERR_INVALID_ARG ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // A3.8: copy_head() - Error handling - source owns its memory\n    std::cout &lt;&lt; \"\\n[A3.8] copy_head() - Error Handling - Source Owns Its Memory\\n\";\n    tiny::Mat dest4;\n    tiny::Mat owned_src(2, 2);  // Creates matrix with its own memory (ext_buff=false)\n    owned_src(0, 0) = 1.0f; owned_src(0, 1) = 2.0f;\n    owned_src(1, 0) = 3.0f; owned_src(1, 1) = 4.0f;\n    // Note: copy_head should only work with external buffers or submatrix views\n    // If source owns its memory, copy_head should return error to prevent double-free\n    tiny_error_t err2 = dest4.copy_head(owned_src);\n    std::cout &lt;&lt; \"copy_head from matrix with owned memory: error = \" &lt;&lt; err2 \n              &lt;&lt; \" (Expected: TINY_ERR_INVALID_ARG) \" \n              &lt;&lt; (err2 == TINY_ERR_INVALID_ARG ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"matC (should be unchanged):\\n\";\n    matC.print_info();\n    matC.print_matrix(true);\n\n    // A3.9: Get a View of ROI - low level function\n    std::cout &lt;&lt; \"[A3.9] Get a View of ROI - Low Level Function\\n\";\n    std::cout &lt;&lt; \"get a view of ROI with overrange dimensions - rows:\\n\";\n    tiny::Mat roi1 = matB.view_roi(1, 1, 3, 2); // note here, C++ will use the copy constructor, which will copy according to the case (submatrix - shallow copy | normal - deep copy)\n    std::cout &lt;&lt; \"get a view of ROI with overrange dimensions - cols:\\n\";\n    tiny::Mat roi2 = matB.view_roi(1, 1, 2, 4); // note here, C++ will use the copy constructor, which will copy according to the case (submatrix - shallow copy | normal - deep copy)\n    std::cout &lt;&lt; \"get a view of ROI with suitable dimensions:\\n\";\n    tiny::Mat roi3 = matB.view_roi(1, 1, 2, 2); // note here, C++ will use the copy constructor, which will copy according to the case (submatrix - shallow copy | normal - deep copy)\n    std::cout &lt;&lt; \"roi3:\\n\";\n    roi3.print_info();\n    roi3.print_matrix(true);\n\n    // A3.10: Get a View of ROI - using ROI structure\n    std::cout &lt;&lt; \"[A3.10] Get a View of ROI - Using ROI Structure\\n\";\n    tiny::Mat::ROI roi_struct(1, 1, 2, 2);\n    tiny::Mat roi4 = matB.view_roi(roi_struct);\n    roi4.print_info();\n    roi4.print_matrix(true);\n\n    // A3.11: Copy ROI - low level function\n    std::cout &lt;&lt; \"[A3.11] Copy ROI - Low Level Function\\n\";\n    tiny::Mat mat_deep_copy = matB.copy_roi(1, 1, 2, 2);\n    mat_deep_copy.print_info();\n    mat_deep_copy.print_matrix(true);\n\n    // A3.12: Copy ROI - using ROI structure\n    std::cout &lt;&lt; \"[A3.12] Copy ROI - Using ROI Structure\\n\";\n    TinyTimeMark_t tic1 = tiny_get_running_time();\n    tiny::Mat::ROI roi_struct2(1, 1, 2, 2);\n    tiny::Mat mat_deep_copy2 = matB.copy_roi(roi_struct2);\n    TinyTimeMark_t toc1 = tiny_get_running_time();\n    TinyTimeMark_t copy_roi_time = toc1 - tic1;\n    std::cout &lt;&lt; \"time for copy_roi using ROI structure: \" &lt;&lt; copy_roi_time &lt;&lt; \" ms\\n\";\n    mat_deep_copy2.print_info();\n    mat_deep_copy2.print_matrix(true);\n\n    // A3.13: ROI resize_roi() function\n    std::cout &lt;&lt; \"\\n[A3.13] ROI resize_roi() Function\\n\";\n    tiny::Mat::ROI test_roi(0, 0, 2, 2);\n    std::cout &lt;&lt; \"Initial ROI: pos_x=\" &lt;&lt; test_roi.pos_x &lt;&lt; \", pos_y=\" &lt;&lt; test_roi.pos_y \n              &lt;&lt; \", width=\" &lt;&lt; test_roi.width &lt;&lt; \", height=\" &lt;&lt; test_roi.height &lt;&lt; \"\\n\";\n    test_roi.resize_roi(1, 1, 3, 3);\n    std::cout &lt;&lt; \"After resize_roi(1, 1, 3, 3): pos_x=\" &lt;&lt; test_roi.pos_x &lt;&lt; \", pos_y=\" &lt;&lt; test_roi.pos_y \n              &lt;&lt; \", width=\" &lt;&lt; test_roi.width &lt;&lt; \", height=\" &lt;&lt; test_roi.height &lt;&lt; \"\\n\";\n    bool roi_resize_correct = (test_roi.pos_x == 1 &amp;&amp; test_roi.pos_y == 1 &amp;&amp; \n                                test_roi.width == 3 &amp;&amp; test_roi.height == 3);\n    std::cout &lt;&lt; \"ROI resize test: \" &lt;&lt; (roi_resize_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // A3.14: ROI area_roi() function\n    std::cout &lt;&lt; \"\\n[A3.14] ROI area_roi() Function\\n\";\n    tiny::Mat::ROI area_roi1(0, 0, 3, 4);\n    int area1 = area_roi1.area_roi();\n    std::cout &lt;&lt; \"ROI(0, 0, 3, 4) area: \" &lt;&lt; area1 &lt;&lt; \" (Expected: 12) \";\n    std::cout &lt;&lt; (area1 == 12 ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    tiny::Mat::ROI area_roi2(1, 2, 5, 6);\n    int area2 = area_roi2.area_roi();\n    std::cout &lt;&lt; \"ROI(1, 2, 5, 6) area: \" &lt;&lt; area2 &lt;&lt; \" (Expected: 30) \";\n    std::cout &lt;&lt; (area2 == 30 ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // A3.15: Block\n    std::cout &lt;&lt; \"[A3.15] Block\\n\";\n    TinyTimeMark_t tic2 = tiny_get_running_time();\n    tiny::Mat mat_block = matB.block(1, 1, 2, 2);\n    TinyTimeMark_t toc2 = tiny_get_running_time();\n    TinyTimeMark_t block_roi_time = toc2 - tic2;\n    std::cout &lt;&lt; \"time for block: \" &lt;&lt; block_roi_time &lt;&lt; \" ms\\n\";\n    mat_block.print_info();\n    mat_block.print_matrix(true);\n\n    // A3.16: Swap Rows\n    std::cout &lt;&lt; \"[A3.16] Swap Rows\\n\";\n    std::cout &lt;&lt; \"matB before swap rows:\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"matB after swap_rows(0, 2):\\n\";\n    matB.swap_rows(0, 2);\n    matB.print_info();\n    matB.print_matrix(true);\n\n    // A3.17: Swap Columns\n    std::cout &lt;&lt; \"[A3.17] Swap Columns\\n\";\n    std::cout &lt;&lt; \"matB before swap columns:\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"matB after swap_cols(0, 2):\\n\";\n    matB.swap_cols(0, 2);\n    matB.print_info();\n    matB.print_matrix(true);\n\n    // A3.18: Clear\n    std::cout &lt;&lt; \"[A3.18] Clear\\n\";\n    std::cout &lt;&lt; \"matB before clear:\\n\";\n    matB.print_info();\n    matB.print_matrix(true);\n    std::cout &lt;&lt; \"matB after clear:\\n\";\n    matB.clear();\n    matB.print_info();\n    matB.print_matrix(true);\n}\n\n// ============================================================================\n// B1: Assignment Operator\n// ============================================================================\nvoid test_assignment_operator()\n{\n    std::cout &lt;&lt; \"\\n[B1: Assignment Operator Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[B1.1] Assignment (Same Dimensions)\\n\";\n    tiny::Mat dst(2, 3), src(2, 3);\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            src(i, j) = static_cast&lt;float&gt;(i * 3 + j + 1);\n    dst = src;\n    dst.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B1.2] Assignment (Different Dimensions)\\n\";\n    tiny::Mat dst2(4, 2);\n    dst2 = src;\n    dst2.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B1.3] Assignment to Sub-Matrix (Expect Error)\\n\";\n    float data[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n    tiny::Mat base(data, 3, 4, 5);\n    tiny::Mat subView = base.view_roi(1, 1, 2, 2);\n    subView = src;\n    subView.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B1.4] Self-Assignment\\n\";\n    src = src;\n    src.print_matrix(true);\n}\n\n// ============================================================================\n// B2: Matrix Addition\n// ============================================================================\nvoid test_matrix_addition()\n{\n    std::cout &lt;&lt; \"\\n[B2: Matrix Addition Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[B2.1] Matrix Addition (Same Dimensions)\\n\";\n    tiny::Mat A(2, 3), B(2, 3);\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n        {\n            A(i, j) = static_cast&lt;float&gt;(i * 3 + j + 1);\n            B(i, j) = 1.0f;\n        }\n    A += B;\n    A.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B2.2] Sub-Matrix Addition\\n\";\n    float data[20] = {0,1,2,3,0,4,5,6,7,0,8,9,10,11,0,12,13,14,15,0};\n    tiny::Mat base(data, 4, 4, 5);\n    tiny::Mat subA = base.view_roi(1,1,2,2);\n    tiny::Mat subB = base.view_roi(1,1,2,2);\n    subA += subB;\n    subA.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B2.3] Full Matrix + Sub-Matrix Addition\\n\";\n    tiny::Mat full(2,2);\n    for(int i=0;i&lt;2;++i) for(int j=0;j&lt;2;++j) full(i,j)=2.0f;\n    full += subB;\n    full.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B2.4] Addition Dimension Mismatch (Expect Error)\\n\";\n    tiny::Mat wrongDim(3,3);\n    full += wrongDim;\n}\n\n// ============================================================================\n// B3: Constant Addition\n// ============================================================================\nvoid test_constant_addition()\n{\n    std::cout &lt;&lt; \"\\n[B3: Constant Addition Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[B3.1] Full Matrix + Constant\\n\";\n    tiny::Mat mat1(2,3);\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat1(i,j) = static_cast&lt;float&gt;(i*3 + j);\n    mat1 += 5.0f;\n    mat1.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B3.2] Sub-Matrix + Constant\\n\";\n    float data[20] = {0,1,2,3,0,4,5,6,7,0,8,9,10,11,0,12,13,14,15,0};\n    tiny::Mat base(data,4,4,5);\n    tiny::Mat sub = base.view_roi(1,1,2,2);\n    sub += 3.0f;\n    sub.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B3.3] Add Zero\\n\";\n    tiny::Mat mat2(2,2);\n    mat2(0,0)=1; mat2(0,1)=2; mat2(1,0)=3; mat2(1,1)=4;\n    mat2 += 0.0f;\n    mat2.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B3.4] Add Negative Constant\\n\";\n    tiny::Mat mat3(2,2);\n    mat3(0,0)=10; mat3(0,1)=20; mat3(1,0)=30; mat3(1,1)=40;\n    mat3 += -15.0f;\n    mat3.print_matrix(true);\n}\n\n// ============================================================================\n// B4: Matrix Subtraction\n// ============================================================================\nvoid test_matrix_subtraction()\n{\n    std::cout &lt;&lt; \"\\n[B4: Matrix Subtraction Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[B4.1] Matrix Subtraction\\n\";\n    tiny::Mat A(2,2), B(2,2);\n    A(0,0)=5; A(0,1)=7; A(1,0)=9; A(1,1)=11;\n    B(0,0)=1; B(0,1)=2; B(1,0)=3; B(1,1)=4;\n    A -= B;\n    A.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B4.2] Subtraction Dimension Mismatch (Expect Error)\\n\";\n    tiny::Mat wrong(3,3);\n    A -= wrong;\n}\n\n// ============================================================================\n// B5: Constant Subtraction\n// ============================================================================\nvoid test_constant_subtraction()\n{\n    std::cout &lt;&lt; \"\\n[B5: Constant Subtraction Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[B5.1] Full Matrix - Constant\\n\";\n    tiny::Mat mat(2,3);\n    for (int i=0;i&lt;2;++i) for(int j=0;j&lt;3;++j) mat(i,j) = i*3+j+1;\n    mat -= 2.0f;\n    mat.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B5.2] Sub-Matrix - Constant\\n\";\n    float data[15] = {0,1,2,3,0,4,5,6,7,0,8,9,10,11,0};\n    tiny::Mat base(data,3,4,5);\n    tiny::Mat sub = base.view_roi(1,1,2,2);\n    sub -= 1.5f;\n    sub.print_matrix(true);\n}\n\n// ============================================================================\n// B6: Matrix Division\n// ============================================================================\nvoid test_matrix_division()\n{\n    std::cout &lt;&lt; \"\\n[B6: Matrix Element-wise Division Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[B6.1] Element-wise Division (Same Dimensions, No Zero)\\n\";\n    tiny::Mat A(2, 2), B(2, 2);\n    A(0,0) = 10; A(0,1) = 20; A(1,0) = 30; A(1,1) = 40;\n    B(0,0) = 2;  B(0,1) = 4;  B(1,0) = 5;  B(1,1) = 8;\n    A /= B;\n    A.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B6.2] Dimension Mismatch (Expect Error)\\n\";\n    tiny::Mat wrongDim(3, 3);\n    A /= wrongDim;\n\n    std::cout &lt;&lt; \"\\n[B6.3] Division by Matrix Containing Zero (Expect Error)\\n\";\n    tiny::Mat C(2, 2), D(2, 2);\n    C(0,0)=5; C(0,1)=10; C(1,0)=15; C(1,1)=20;\n    D(0,0)=1; D(0,1)=0;  D(1,0)=3;  D(1,1)=4;  // Contains zero\n    C /= D;\n    C.print_matrix(true);  // Should remain unchanged\n}\n\n// ============================================================================\n// B7: Constant Division\n// ============================================================================\nvoid test_constant_division()\n{\n    std::cout &lt;&lt; \"\\n[B7: Matrix Division by Constant Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[B7.1] Divide Full Matrix by Positive Constant\\n\";\n    tiny::Mat mat1(2, 3);\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat1(i, j) = static_cast&lt;float&gt;(i * 3 + j + 2);  // Avoid zero\n    mat1 /= 2.0f;\n    mat1.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B7.2] Divide Matrix by Negative Constant\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0,0)=6; mat2(0,1)=12; mat2(1,0)=18; mat2(1,1)=24;\n    mat2 /= -3.0f;\n    mat2.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B7.3] Division by Zero Constant (Expect Error)\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0,0)=1; mat3(0,1)=2; mat3(1,0)=3; mat3(1,1)=4;\n    mat3 /= 0.0f;\n    mat3.print_matrix(true);  // Should remain unchanged\n}\n\n// ============================================================================\n// B8: Matrix Exponentiation\n// ============================================================================\nvoid test_matrix_exponentiation()\n{\n    std::cout &lt;&lt; \"\\n[B8: Matrix Exponentiation Tests]\\n\";\n\n    std::cout &lt;&lt; \"\\n[B8.1] Raise Each Element to Power of 2\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0,0)=2; mat1(0,1)=3; mat1(1,0)=4; mat1(1,1)=5;\n    tiny::Mat result1 = mat1 ^ 2;\n    result1.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B8.2] Raise Each Element to Power of 0\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0,0)=7; mat2(0,1)=-3; mat2(1,0)=0.5f; mat2(1,1)=10;\n    tiny::Mat result2 = mat2 ^ 0;\n    result2.print_matrix(true);  // Expect all 1\n\n    std::cout &lt;&lt; \"\\n[B8.3] Raise Each Element to Power of 1\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0,0)=9; mat3(0,1)=8; mat3(1,0)=7; mat3(1,1)=6;\n    tiny::Mat result3 = mat3 ^ 1;\n    result3.print_matrix(true);  // Expect same as original\n\n    std::cout &lt;&lt; \"\\n[B8.4] Raise Each Element to Power of -1 (Expect Error or Warning)\\n\";\n    tiny::Mat mat4(2, 2);\n    mat4(0,0)=1; mat4(0,1)=2; mat4(1,0)=4; mat4(1,1)=5;\n    tiny::Mat result4 = mat4 ^ -1;\n    result4.print_matrix(true);\n\n    std::cout &lt;&lt; \"\\n[B8.5] Raise Matrix Containing Zero to Power of 3\\n\";\n    tiny::Mat mat5(2, 2);\n    mat5(0,0)=0; mat5(0,1)=2; mat5(1,0)=-1; mat5(1,1)=3;\n    tiny::Mat result5 = mat5 ^ 3;\n    result5.print_matrix(true);\n}\n\n// ============================================================================\n// C1: Matrix Transpose\n// ============================================================================\nvoid test_matrix_transpose()\n{\n    std::cout &lt;&lt; \"\\n[C1: Matrix Transpose Tests]\\n\";\n\n    // C1.1: Basic 2x3 matrix transpose\n    std::cout &lt;&lt; \"\\n[C1.1] Transpose of 2x3 Matrix\\n\";\n    tiny::Mat mat1(2, 3);\n    int val = 1;\n    for (int i = 0; i &lt; 2; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat1(i, j) = val++;\n\n    std::cout &lt;&lt; \"Original 2x3 Matrix:\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat transposed1 = mat1.transpose();\n    std::cout &lt;&lt; \"Transposed 3x2 Matrix:\\n\";\n    transposed1.print_matrix(true);\n\n    // C1.2: Square matrix transpose (3x3)\n    std::cout &lt;&lt; \"\\n[C1.2] Transpose of 3x3 Square Matrix\\n\";\n    tiny::Mat mat2(3, 3);\n    val = 1;\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat2(i, j) = val++;\n\n    std::cout &lt;&lt; \"Original 3x3 Matrix:\\n\";\n    mat2.print_matrix(true);\n\n    tiny::Mat transposed2 = mat2.transpose();\n    std::cout &lt;&lt; \"Transposed 3x3 Matrix:\\n\";\n    transposed2.print_matrix(true);\n\n    // C1.3: Matrix with padding (4x2, stride=3)\n    std::cout &lt;&lt; \"\\n[C1.3] Transpose of Matrix with Padding\\n\";\n    float data[12] = {1, 2, 0, 3, 4, 0, 5, 6, 0, 7, 8, 0};  // stride=3, 4 rows\n    tiny::Mat mat3(data, 4, 2, 3);\n    std::cout &lt;&lt; \"Original 4x2 Matrix (with padding):\\n\";\n    mat3.print_matrix(true);\n\n    tiny::Mat transposed3 = mat3.transpose();\n    std::cout &lt;&lt; \"Transposed 2x4 Matrix:\\n\";\n    transposed3.print_matrix(true);\n\n    // C1.4: Transpose of empty matrix\n    std::cout &lt;&lt; \"\\n[C1.4] Transpose of Empty Matrix\\n\";\n    tiny::Mat mat4;\n    mat4.print_matrix(true);\n\n    tiny::Mat transposed4 = mat4.transpose();\n    transposed4.print_matrix(true);\n}\n\n// ============================================================================\n// C2: Matrix Minor and Cofactor\n// ============================================================================\nvoid test_matrix_cofactor()\n{\n    std::cout &lt;&lt; \"\\n[C2: Matrix Minor and Cofactor Tests]\\n\";\n\n    // C2.1: Minor of 3x3 Matrix - Standard Case\n    std::cout &lt;&lt; \"\\n[C2.1] Minor of 3x3 Matrix (Remove Row 1, Col 1)\\n\";\n    tiny::Mat mat1(3, 3);\n    int val = 1;\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat1(i, j) = val++;\n\n    std::cout &lt;&lt; \"Original 3x3 Matrix:\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat minor1 = mat1.minor(1, 1);\n    std::cout &lt;&lt; \"Minor Matrix (remove row 1, col 1, no sign):\\n\";\n    minor1.print_matrix(true);  // Expected: [[1,3],[7,9]]\n\n    // C2.2: Cofactor of 3x3 Matrix - Same position\n    std::cout &lt;&lt; \"\\n[C2.2] Cofactor of 3x3 Matrix (Remove Row 1, Col 1)\\n\";\n    std::cout &lt;&lt; \"Note: Cofactor matrix is the same as minor matrix.\\n\";\n    std::cout &lt;&lt; \"      The sign (-1)^(i+j) is applied when computing cofactor value, not to matrix elements.\\n\";\n    tiny::Mat cof1 = mat1.cofactor(1, 1);\n    std::cout &lt;&lt; \"Cofactor Matrix (same as minor):\\n\";\n    cof1.print_matrix(true);  // Expected: [[1,3],[7,9]] (same as minor)\n\n    // C2.3: Minor - Remove first row and first column\n    std::cout &lt;&lt; \"\\n[C2.3] Minor (Remove Row 0, Col 0)\\n\";\n    tiny::Mat minor2 = mat1.minor(0, 0);\n    minor2.print_matrix(true);  // Expected: [[5,6],[8,9]]\n\n    // C2.4: Cofactor - Remove first row and first column\n    std::cout &lt;&lt; \"\\n[C2.4] Cofactor (Remove Row 0, Col 0)\\n\";\n    std::cout &lt;&lt; \"Note: Cofactor matrix is the same as minor matrix.\\n\";\n    tiny::Mat cof2 = mat1.cofactor(0, 0);\n    cof2.print_matrix(true);  // Expected: [[5,6],[8,9]] (same as minor)\n\n    // C2.5: Cofactor - Remove row 0, col 1\n    std::cout &lt;&lt; \"\\n[C2.5] Cofactor (Remove Row 0, Col 1)\\n\";\n    std::cout &lt;&lt; \"Note: Cofactor matrix is the same as minor matrix.\\n\";\n    std::cout &lt;&lt; \"      When computing cofactor value, sign (-1)^(0+1) = -1 would be applied.\\n\";\n    tiny::Mat cof2_neg = mat1.cofactor(0, 1);\n    std::cout &lt;&lt; \"Cofactor Matrix (same as minor):\\n\";\n    cof2_neg.print_matrix(true);  // Expected: [[4,6],[7,9]] (same as minor, no sign in matrix)\n\n    // C2.6: Minor - Remove last row and last column\n    std::cout &lt;&lt; \"\\n[C2.6] Minor (Remove Row 2, Col 2)\\n\";\n    tiny::Mat minor3 = mat1.minor(2, 2);\n    minor3.print_matrix(true);  // Expected: [[1,2],[4,5]]\n\n    // C2.7: Cofactor - Remove last row and last column\n    std::cout &lt;&lt; \"\\n[C2.7] Cofactor (Remove Row 2, Col 2)\\n\";\n    std::cout &lt;&lt; \"Note: Cofactor matrix is the same as minor matrix.\\n\";\n    tiny::Mat cof3 = mat1.cofactor(2, 2);\n    cof3.print_matrix(true);  // Expected: [[1,2],[4,5]] (same as minor)\n\n    // C2.8: 4x4 Matrix Example - Minor\n    std::cout &lt;&lt; \"\\n[C2.8] Minor of 4x4 Matrix (Remove Row 2, Col 1)\\n\";\n    tiny::Mat mat4(4, 4);\n    val = 1;\n    for (int i = 0; i &lt; 4; ++i)\n        for (int j = 0; j &lt; 4; ++j)\n            mat4(i, j) = val++;\n\n    mat4.print_matrix(true);\n    tiny::Mat minor4 = mat4.minor(2, 1);\n    std::cout &lt;&lt; \"Minor Matrix:\\n\";\n    minor4.print_matrix(true);\n\n    // C2.9: 4x4 Matrix Example - Cofactor\n    std::cout &lt;&lt; \"\\n[C2.9] Cofactor of 4x4 Matrix (Remove Row 2, Col 1)\\n\";\n    std::cout &lt;&lt; \"Note: Cofactor matrix is the same as minor matrix.\\n\";\n    std::cout &lt;&lt; \"      When computing cofactor value, sign (-1)^(2+1) = -1 would be applied.\\n\";\n    tiny::Mat cof4 = mat4.cofactor(2, 1);\n    std::cout &lt;&lt; \"Cofactor Matrix (same as minor):\\n\";\n    cof4.print_matrix(true);\n\n    // C2.10: Non-square Matrix (Expect Error)\n    std::cout &lt;&lt; \"\\n[C2.10] Non-square Matrix (Expect Error)\\n\";\n    tiny::Mat rectMat(3, 4);\n    std::cout &lt;&lt; \"Testing minor():\\n\";\n    tiny::Mat minor_rect = rectMat.minor(1, 1);\n    bool minor_rect_empty = (minor_rect.row == 0 &amp;&amp; minor_rect.col == 0);\n    std::cout &lt;&lt; \"minor() result: \" &lt;&lt; (minor_rect_empty ? \"Empty matrix (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (minor_rect_empty ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Testing cofactor():\\n\";\n    tiny::Mat cof_rect = rectMat.cofactor(1, 1);\n    bool cof_rect_empty = (cof_rect.row == 0 &amp;&amp; cof_rect.col == 0);\n    std::cout &lt;&lt; \"cofactor() result: \" &lt;&lt; (cof_rect_empty ? \"Empty matrix (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (cof_rect_empty ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // C2.11: minor() - Boundary case - out of bounds indices\n    std::cout &lt;&lt; \"\\n[C2.11] minor() - Boundary Case - Out of Bounds Indices\\n\";\n    tiny::Mat test_mat(3, 3);\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            test_mat(i, j) = i * 3 + j + 1;\n\n    tiny::Mat minor_out1 = test_mat.minor(-1, 0);\n    bool minor_out1_empty = (minor_out1.row == 0 &amp;&amp; minor_out1.col == 0);\n    std::cout &lt;&lt; \"minor(-1, 0): \" &lt;&lt; (minor_out1_empty ? \"Empty matrix (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (minor_out1_empty ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    tiny::Mat minor_out2 = test_mat.minor(0, -1);\n    bool minor_out2_empty = (minor_out2.row == 0 &amp;&amp; minor_out2.col == 0);\n    std::cout &lt;&lt; \"minor(0, -1): \" &lt;&lt; (minor_out2_empty ? \"Empty matrix (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (minor_out2_empty ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    tiny::Mat minor_out3 = test_mat.minor(3, 0);\n    bool minor_out3_empty = (minor_out3.row == 0 &amp;&amp; minor_out3.col == 0);\n    std::cout &lt;&lt; \"minor(3, 0) (out of bounds): \" &lt;&lt; (minor_out3_empty ? \"Empty matrix (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (minor_out3_empty ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // C2.12: minor() - Boundary case - 1x1 matrix\n    std::cout &lt;&lt; \"\\n[C2.12] minor() - Boundary Case - 1x1 Matrix\\n\";\n    tiny::Mat mat1x1(1, 1);\n    mat1x1(0, 0) = 5.0f;\n    tiny::Mat minor_1x1 = mat1x1.minor(0, 0);\n    bool minor_1x1_empty = (minor_1x1.row == 0 &amp;&amp; minor_1x1.col == 0);\n    std::cout &lt;&lt; \"1x1 matrix minor(0,0): \" &lt;&lt; (minor_1x1_empty ? \"Empty matrix (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (minor_1x1_empty ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n}\n\n// ============================================================================\n// C3: Matrix Determinant\n// ============================================================================\nvoid test_matrix_determinant()\n{\n    std::cout &lt;&lt; \"\\n[C3: Matrix Determinant Tests]\\n\";\n\n    // C3.1: 1x1 Matrix\n    std::cout &lt;&lt; \"\\n[C3.1] 1x1 Matrix Determinant\\n\";\n    tiny::Mat mat1(1, 1);\n    mat1(0, 0) = 7;\n    std::cout &lt;&lt; \"Matrix:\\n\";\n    mat1.print_matrix(true);\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; mat1.determinant() &lt;&lt; \"  (Expected: 7)\\n\";\n\n    // C3.2: 2x2 Matrix\n    std::cout &lt;&lt; \"\\n[C3.2] 2x2 Matrix Determinant\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0, 0) = 3; mat2(0, 1) = 8;\n    mat2(1, 0) = 4; mat2(1, 1) = 6;\n    std::cout &lt;&lt; \"Matrix:\\n\";\n    mat2.print_matrix(true);\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; mat2.determinant() &lt;&lt; \"  (Expected: -14)\\n\";\n\n    // C3.3: 3x3 Matrix\n    std::cout &lt;&lt; \"\\n[C3.3] 3x3 Matrix Determinant\\n\";\n    tiny::Mat mat3(3, 3);\n    mat3(0,0) = 1; mat3(0,1) = 2; mat3(0,2) = 3;\n    mat3(1,0) = 0; mat3(1,1) = 4; mat3(1,2) = 5;\n    mat3(2,0) = 1; mat3(2,1) = 0; mat3(2,2) = 6;\n    std::cout &lt;&lt; \"Matrix:\\n\";\n    mat3.print_matrix(true);\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; mat3.determinant() &lt;&lt; \"  (Expected: 22)\\n\";\n\n    // C3.4: 4x4 Matrix\n    std::cout &lt;&lt; \"\\n[C3.4] 4x4 Matrix Determinant\\n\";\n    tiny::Mat mat4(4, 4);\n    int val = 1;\n    for (int i = 0; i &lt; 4; ++i)\n        for (int j = 0; j &lt; 4; ++j)\n            mat4(i, j) = val++;\n    std::cout &lt;&lt; \"Matrix:\\n\";\n    mat4.print_matrix(true);\n    std::cout &lt;&lt; \"Note: This matrix has linearly dependent rows (each row differs by constant 4),\\n\";\n    std::cout &lt;&lt; \"      so the determinant should be 0.\\n\";\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; mat4.determinant() &lt;&lt; \"  (Expected: 0)\\n\";  \n\n    // C3.5: 5x5 Matrix (Tests Auto-select Mechanism)\n    std::cout &lt;&lt; \"\\n[C3.5] 5x5 Matrix Determinant (Tests Auto-select to LU Method)\\n\";\n    tiny::Mat mat5_basic(5, 5);\n    // Create a well-conditioned 5x5 matrix\n    mat5_basic(0,0) = 2; mat5_basic(0,1) = 1; mat5_basic(0,2) = 0; mat5_basic(0,3) = 0; mat5_basic(0,4) = 0;\n    mat5_basic(1,0) = 1; mat5_basic(1,1) = 2; mat5_basic(1,2) = 1; mat5_basic(1,3) = 0; mat5_basic(1,4) = 0;\n    mat5_basic(2,0) = 0; mat5_basic(2,1) = 1; mat5_basic(2,2) = 2; mat5_basic(2,3) = 1; mat5_basic(2,4) = 0;\n    mat5_basic(3,0) = 0; mat5_basic(3,1) = 0; mat5_basic(3,2) = 1; mat5_basic(3,3) = 2; mat5_basic(3,4) = 1;\n    mat5_basic(4,0) = 0; mat5_basic(4,1) = 0; mat5_basic(4,2) = 0; mat5_basic(4,3) = 1; mat5_basic(4,4) = 2;\n    std::cout &lt;&lt; \"Matrix (5x5, tridiagonal):\\n\";\n    mat5_basic.print_matrix(true);\n    float det5_basic = mat5_basic.determinant();\n    std::cout &lt;&lt; \"Determinant (auto-select, should use LU for n &gt; 4): \" &lt;&lt; det5_basic &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Note: For n = 5 &gt; 4, auto-select should use LU decomposition (O(n\u00b3)).\\n\";\n\n    // C3.6: Non-square Matrix (Expect Error)\n    std::cout &lt;&lt; \"\\n[C3.6] Non-square Matrix (Expect Error)\\n\";\n    tiny::Mat rectMat(3, 4);\n    std::cout &lt;&lt; \"Matrix (3x4, non-square):\\n\";\n    rectMat.print_matrix(true);\n    float det_rect = rectMat.determinant();  // should trigger error\n    std::cout &lt;&lt; \"Determinant: \" &lt;&lt; det_rect &lt;&lt; \"  (Expected: 0 with error message)\\n\";\n\n    // C3.7: Comparison of Different Methods (5x5 Matrix)\n    std::cout &lt;&lt; \"\\n[C3.7] Comparison of Different Methods (5x5 Matrix)\\n\";\n    tiny::Mat mat_test(5, 5);\n    // Create a test matrix\n    for (int i = 0; i &lt; 5; ++i)\n    {\n        for (int j = 0; j &lt; 5; ++j)\n        {\n            mat_test(i, j) = static_cast&lt;float&gt;((i + 1) * (j + 1) + (i == j ? 1.0f : 0.0f));\n        }\n    }\n    std::cout &lt;&lt; \"Matrix (5x5):\\n\";\n    mat_test.print_matrix(true);\n    float det_auto = mat_test.determinant();\n    float det_laplace = mat_test.determinant_laplace();\n    float det_lu = mat_test.determinant_lu();\n    float det_gaussian = mat_test.determinant_gaussian();\n    std::cout &lt;&lt; \"Determinant (auto-select): \" &lt;&lt; det_auto &lt;&lt; \"  (should use LU for n &gt; 4)\\n\";\n    std::cout &lt;&lt; \"Determinant (Laplace):     \" &lt;&lt; det_laplace &lt;&lt; \"  (O(n!), slow for n=5)\\n\";\n    std::cout &lt;&lt; \"Determinant (LU):          \" &lt;&lt; det_lu &lt;&lt; \"  (O(n\u00b3), efficient)\\n\";\n    std::cout &lt;&lt; \"Determinant (Gaussian):    \" &lt;&lt; det_gaussian &lt;&lt; \"  (O(n\u00b3), efficient)\\n\";\n    std::cout &lt;&lt; \"Note: All methods should give the same result (within numerical precision).\\n\";\n    std::cout &lt;&lt; \"      Auto-select should use LU for n &gt; 4, avoiding slow Laplace expansion.\\n\";\n\n    // C3.8: Large Matrix (6x6) - Tests Efficient Methods\n    std::cout &lt;&lt; \"\\n[C3.8] Large Matrix (6x6) - Tests Efficient Methods\\n\";\n    tiny::Mat mat6(6, 6);\n    for (int i = 0; i &lt; 6; ++i)\n    {\n        for (int j = 0; j &lt; 6; ++j)\n        {\n            mat6(i, j) = static_cast&lt;float&gt;((i + 1) * (j + 1) + (i == j ? 0.5f : 0.0f));\n        }\n    }\n    std::cout &lt;&lt; \"Matrix (6x6, showing first 4x4 block):\\n\";\n    for (int i = 0; i &lt; 4; ++i)\n    {\n        for (int j = 0; j &lt; 4; ++j)\n        {\n            std::cout &lt;&lt; std::setw(10) &lt;&lt; mat6(i, j) &lt;&lt; \" \";\n        }\n        std::cout &lt;&lt; \"...\\n\";\n    }\n    std::cout &lt;&lt; \"...\\n\";\n    float det6_auto = mat6.determinant();\n    float det6_lu = mat6.determinant_lu();\n    float det6_gaussian = mat6.determinant_gaussian();\n    std::cout &lt;&lt; \"Determinant (auto-select, uses LU): \" &lt;&lt; det6_auto &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Determinant (LU):                   \" &lt;&lt; det6_lu &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Determinant (Gaussian):             \" &lt;&lt; det6_gaussian &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Note: For n &gt; 4, auto-select uses LU decomposition (O(n\u00b3) instead of O(n!)).\\n\";\n\n    // C3.9: Large Matrix (8x8) - Performance Test\n    std::cout &lt;&lt; \"\\n[C3.9] Large Matrix (8x8) - Performance Comparison\\n\";\n    tiny::Mat mat8(8, 8);\n    for (int i = 0; i &lt; 8; ++i)\n    {\n        for (int j = 0; j &lt; 8; ++j)\n        {\n            mat8(i, j) = static_cast&lt;float&gt;((i + 1) * (j + 1));\n        }\n    }\n    std::cout &lt;&lt; \"Matrix (8x8, showing first 4x4 block):\\n\";\n    // Print partial matrix for display\n    for (int i = 0; i &lt; 4; ++i)\n    {\n        for (int j = 0; j &lt; 4; ++j)\n        {\n            std::cout &lt;&lt; std::setw(10) &lt;&lt; mat8(i, j) &lt;&lt; \" \";\n        }\n        std::cout &lt;&lt; \"...\\n\";\n    }\n    std::cout &lt;&lt; \"...\\n\";\n    float det8_lu = mat8.determinant_lu();\n    float det8_gaussian = mat8.determinant_gaussian();\n    std::cout &lt;&lt; \"Determinant (LU):       \" &lt;&lt; det8_lu &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Determinant (Gaussian): \" &lt;&lt; det8_gaussian &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Note: Both methods are O(n\u00b3) and should be much faster than Laplace expansion.\\n\";\n\n    // C3.10: determinant_laplace() - Boundary case - empty matrix\n    std::cout &lt;&lt; \"\\n[C3.10] determinant_laplace() - Boundary Case - Empty Matrix\\n\";\n    tiny::Mat empty_det(0, 0);\n    float det_empty_laplace = empty_det.determinant_laplace();\n    std::cout &lt;&lt; \"Empty matrix determinant (Laplace): \" &lt;&lt; det_empty_laplace \n              &lt;&lt; \" (Expected: 1.0) \" &lt;&lt; (fabsf(det_empty_laplace - 1.0f) &lt; 1e-6f ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // C3.11: determinant_lu() - Boundary case - empty matrix\n    std::cout &lt;&lt; \"\\n[C3.11] determinant_lu() - Boundary Case - Empty Matrix\\n\";\n    float det_empty_lu = empty_det.determinant_lu();\n    std::cout &lt;&lt; \"Empty matrix determinant (LU): \" &lt;&lt; det_empty_lu \n              &lt;&lt; \" (Expected: 1.0) \" &lt;&lt; (fabsf(det_empty_lu - 1.0f) &lt; 1e-6f ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // C3.12: determinant_gaussian() - Boundary case - empty matrix\n    std::cout &lt;&lt; \"\\n[C3.12] determinant_gaussian() - Boundary Case - Empty Matrix\\n\";\n    float det_empty_gaussian = empty_det.determinant_gaussian();\n    std::cout &lt;&lt; \"Empty matrix determinant (Gaussian): \" &lt;&lt; det_empty_gaussian \n              &lt;&lt; \" (Expected: 1.0) \" &lt;&lt; (fabsf(det_empty_gaussian - 1.0f) &lt; 1e-6f ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // C3.13: determinant methods - Non-square matrix (should return 0)\n    std::cout &lt;&lt; \"\\n[C3.13] Determinant Methods - Non-Square Matrix\\n\";\n    tiny::Mat rect_det(2, 3);\n    float det_rect_laplace = rect_det.determinant_laplace();\n    float det_rect_lu = rect_det.determinant_lu();\n    float det_rect_gaussian = rect_det.determinant_gaussian();\n    std::cout &lt;&lt; \"Non-square matrix (2x3) determinant (Laplace): \" &lt;&lt; det_rect_laplace \n              &lt;&lt; \" (Expected: 0.0) \" &lt;&lt; (fabsf(det_rect_laplace) &lt; 1e-6f ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Non-square matrix (2x3) determinant (LU): \" &lt;&lt; det_rect_lu \n              &lt;&lt; \" (Expected: 0.0) \" &lt;&lt; (fabsf(det_rect_lu) &lt; 1e-6f ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Non-square matrix (2x3) determinant (Gaussian): \" &lt;&lt; det_rect_gaussian \n              &lt;&lt; \" (Expected: 0.0) \" &lt;&lt; (fabsf(det_rect_gaussian) &lt; 1e-6f ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n}\n\n// ============================================================================\n// C4: Matrix Adjoint\n// ============================================================================\nvoid test_matrix_adjoint()\n{\n    std::cout &lt;&lt; \"\\n[C4: Matrix Adjoint Tests]\\n\";\n\n    // C4.1: 1x1 Matrix\n    std::cout &lt;&lt; \"\\n[C4.1] Adjoint of 1x1 Matrix\\n\";\n    tiny::Mat mat1(1, 1);\n    mat1(0, 0) = 5;\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat1.print_matrix(true);\n    tiny::Mat adj1 = mat1.adjoint();\n    std::cout &lt;&lt; \"Adjoint Matrix:\\n\";\n    adj1.print_matrix(true);  // Expected: [1]\n\n    // C4.2: 2x2 Matrix\n    std::cout &lt;&lt; \"\\n[C4.2] Adjoint of 2x2 Matrix\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0, 0) = 1; mat2(0, 1) = 2;\n    mat2(1, 0) = 3; mat2(1, 1) = 4;\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat2.print_matrix(true);\n    tiny::Mat adj2 = mat2.adjoint();\n    std::cout &lt;&lt; \"Adjoint Matrix:\\n\";\n    adj2.print_matrix(true);  // Expected: [4, -2; -3, 1]\n\n    // C4.3: 3x3 Matrix\n    std::cout &lt;&lt; \"\\n[C4.3] Adjoint of 3x3 Matrix\\n\";\n    tiny::Mat mat3(3, 3);\n    mat3(0,0) = 1; mat3(0,1) = 2; mat3(0,2) = 3;\n    mat3(1,0) = 0; mat3(1,1) = 4; mat3(1,2) = 5;\n    mat3(2,0) = 1; mat3(2,1) = 0; mat3(2,2) = 6;\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat3.print_matrix(true);\n    tiny::Mat adj3 = mat3.adjoint();\n    std::cout &lt;&lt; \"Adjoint Matrix:\\n\";\n    adj3.print_matrix(true);\n    // No simple expected value, but should compute correctly\n\n    // C4.4: Non-Square Matrix (Expect Error)\n    std::cout &lt;&lt; \"\\n[C4.4] Adjoint of Non-Square Matrix (Expect Error)\\n\";\n    tiny::Mat rectMat(2, 3);\n    std::cout &lt;&lt; \"Original Matrix (2x3, non-square):\\n\";\n    rectMat.print_matrix(true);\n    tiny::Mat adjRect = rectMat.adjoint();\n    std::cout &lt;&lt; \"Adjoint Matrix (should be empty due to error):\\n\";\n    adjRect.print_matrix(true);  // Should be empty or default matrix\n\n}\n\n// ============================================================================\n// C5: Matrix Normalization\n// ============================================================================\nvoid test_matrix_normalize()\n{\n    std::cout &lt;&lt; \"\\n[C5: Matrix Normalization Tests]\\n\";\n\n    // C5.1: Standard normalization\n    std::cout &lt;&lt; \"\\n[C5.1] Normalize a Standard 2x2 Matrix\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0, 0) = 3.0f; mat1(0, 1) = 4.0f;\n    mat1(1, 0) = 3.0f; mat1(1, 1) = 4.0f;\n\n    std::cout &lt;&lt; \"Before normalization:\\n\";\n    mat1.print_matrix(true);\n\n    mat1.normalize();\n\n    std::cout &lt;&lt; \"After normalization (Expected L2 norm = 1):\\n\";\n    mat1.print_matrix(true);\n\n    // C5.2: Matrix with padding\n    std::cout &lt;&lt; \"\\n[C5.2] Normalize a 2x2 Matrix with Stride=4 (Padding Test)\\n\";\n    float data_with_padding[8] = {3.0f, 4.0f, 0.0f, 0.0f, 3.0f, 4.0f, 0.0f, 0.0f};\n    tiny::Mat mat2(data_with_padding, 2, 2, 4);  // 2x2 matrix, stride 4\n\n    std::cout &lt;&lt; \"Before normalization:\\n\";\n    mat2.print_matrix(true);\n\n    mat2.normalize();\n\n    std::cout &lt;&lt; \"After normalization:\\n\";\n    mat2.print_matrix(true);\n\n    // C5.3: Zero matrix normalization\n    std::cout &lt;&lt; \"\\n[C5.3] Normalize a Zero Matrix (Expect Warning)\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3.clear();  // Assuming clear() sets all elements to zero\n\n    mat3.print_matrix(true);\n    mat3.normalize();  // Should trigger warning\n}\n\n// ============================================================================\n// C6: Matrix Norm Calculation\n// ============================================================================\nvoid test_matrix_norm()\n{\n    std::cout &lt;&lt; \"\\n[C6: Matrix Norm Calculation Tests]\\n\";\n\n    // C6.1: Simple 2x2 Matrix\n    std::cout &lt;&lt; \"\\n[C6.1] 2x2 Matrix Norm (Expect 5.0)\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0, 0) = 3.0f; mat1(0, 1) = 4.0f;\n    mat1(1, 0) = 0.0f; mat1(1, 1) = 0.0f;\n    std::cout &lt;&lt; \"Matrix:\\n\";\n    mat1.print_matrix(true);\n    float norm1 = mat1.norm();\n    std::cout &lt;&lt; \"Calculated Norm: \" &lt;&lt; norm1 &lt;&lt; \"\\n\";\n\n    // C6.2: Zero Matrix\n    std::cout &lt;&lt; \"\\n[C6.2] Zero Matrix Norm (Expect 0.0)\\n\";\n    tiny::Mat mat2(3, 3);\n    mat2.clear();  // Assuming clear() sets all elements to zero\n    std::cout &lt;&lt; \"Matrix:\\n\";\n    mat2.print_matrix(true);\n    float norm2 = mat2.norm();\n    std::cout &lt;&lt; \"Calculated Norm: \" &lt;&lt; norm2 &lt;&lt; \"\\n\";\n\n    // C6.3: Matrix with Negative Values\n    std::cout &lt;&lt; \"\\n[C6.3] Matrix with Negative Values\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0, 0) = -1.0f; mat3(0, 1) = -2.0f;\n    mat3(1, 0) = -3.0f; mat3(1, 1) = -4.0f;\n    std::cout &lt;&lt; \"Matrix:\\n\";\n    mat3.print_matrix(true);\n    float norm3 = mat3.norm();\n    std::cout &lt;&lt; \"Calculated Norm: \" &lt;&lt; norm3 &lt;&lt; \"  (Expect sqrt(30) \u2248 5.477)\\n\";\n\n    // C6.4: Matrix with Padding\n    std::cout &lt;&lt; \"\\n[C6.4] 2x2 Matrix with Stride=4 (Padding Test)\\n\";\n    float data4[8] = {1.0f, 2.0f, 0.0f, 0.0f, 3.0f, 4.0f, 0.0f, 0.0f};\n    tiny::Mat mat4(data4, 2, 2, 4);  // 2x2 matrix, stride 4\n    std::cout &lt;&lt; \"Matrix:\\n\";\n    mat4.print_matrix(true);\n    float norm4 = mat4.norm();\n    std::cout &lt;&lt; \"Calculated Norm: \" &lt;&lt; norm4 &lt;&lt; \"  (Expect sqrt(30) \u2248 5.477)\\n\";\n}\n\n// ============================================================================\n// C7: Matrix Inversion\n// ============================================================================\nvoid test_inverse_adjoint_adjoint()\n{\n    std::cout &lt;&lt; \"\\n[C7: Matrix Inversion Tests]\\n\";\n\n    // C7.1: 2x2 Regular Matrix\n    std::cout &lt;&lt; \"\\n[C7.1] Inverse of 2x2 Matrix\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0, 0) = 4;  mat1(0, 1) = 7;\n    mat1(1, 0) = 2;  mat1(1, 1) = 6;\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat1.print_matrix(true);\n    tiny::Mat inv1 = mat1.inverse_adjoint();\n    std::cout &lt;&lt; \"Inverse Matrix:\\n\";\n    inv1.print_matrix(true);\n    std::cout &lt;&lt; \"Expected Approx:\\n[ 0.6  -0.7 ]\\n[ -0.2  0.4 ]\\n\";\n\n    // C7.2: Singular Matrix (Determinant = 0)\n    std::cout &lt;&lt; \"\\n[C7.2] Singular Matrix (Expect Error)\\n\";\n    tiny::Mat mat2(2, 2);\n    mat2(0, 0) = 1;  mat2(0, 1) = 2;\n    mat2(1, 0) = 2;  mat2(1, 1) = 4;   // Rank-deficient, det = 0\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat2.print_matrix(true);\n    std::cout &lt;&lt; \"Note: This matrix is singular (determinant = 0), so inverse should fail.\\n\";\n    tiny::Mat inv2 = mat2.inverse_adjoint();\n    std::cout &lt;&lt; \"Inverse Matrix (Should be zero matrix):\\n\";\n    inv2.print_matrix(true);\n\n    // C7.3: 3x3 Regular Matrix\n    std::cout &lt;&lt; \"\\n[C7.3] Inverse of 3x3 Matrix\\n\";\n    tiny::Mat mat3(3, 3);\n    mat3(0,0) = 3; mat3(0,1) = 0; mat3(0,2) = 2;\n    mat3(1,0) = 2; mat3(1,1) = 0; mat3(1,2) = -2;\n    mat3(2,0) = 0; mat3(2,1) = 1; mat3(2,2) = 1;\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat3.print_matrix(true);\n    tiny::Mat inv3 = mat3.inverse_adjoint();\n    std::cout &lt;&lt; \"Inverse Matrix:\\n\";\n    inv3.print_matrix(true);\n\n    // C7.4: Non-Square Matrix (Expect Error)\n    std::cout &lt;&lt; \"\\n[C7.4] Non-Square Matrix (Expect Error)\\n\";\n    tiny::Mat mat4(2, 3);\n    std::cout &lt;&lt; \"Original Matrix (2x3, non-square):\\n\";\n    mat4.print_matrix(true);\n    tiny::Mat inv4 = mat4.inverse_adjoint();\n    std::cout &lt;&lt; \"Inverse Matrix (should be empty due to error):\\n\";\n    inv4.print_matrix(true);\n}\n\n// ============================================================================\n// C8: Matrix Utilities\n// ============================================================================\nvoid test_matrix_utilities()\n{\n    std::cout &lt;&lt; \"\\n[C8: Matrix Utilities Tests]\\n\";\n\n    // C8.1: Identity Matrix (eye)\n    std::cout &lt;&lt; \"\\n[C8.1] Generate Identity Matrix (eye)\\n\";\n    tiny::Mat I3 = tiny::Mat::eye(3);\n    std::cout &lt;&lt; \"3x3 Identity Matrix:\\n\";\n    I3.print_matrix(true);\n\n    tiny::Mat I5 = tiny::Mat::eye(5);\n    std::cout &lt;&lt; \"5x5 Identity Matrix:\\n\";\n    I5.print_matrix(true);\n\n    // C8.2: Ones Matrix\n    std::cout &lt;&lt; \"\\n[C8.2] Generate Ones Matrix\\n\";\n    tiny::Mat ones_3x4 = tiny::Mat::ones(3, 4);\n    std::cout &lt;&lt; \"3x4 Ones Matrix:\\n\";\n    ones_3x4.print_matrix(true);\n\n    tiny::Mat ones_4x4 = tiny::Mat::ones(4);\n    std::cout &lt;&lt; \"4x4 Ones Matrix (Square):\\n\";\n    ones_4x4.print_matrix(true);\n\n    // C8.3: Matrix Augmentation\n    std::cout &lt;&lt; \"\\n[C8.3] Augment Two Matrices Horizontally [A | B]\\n\";\n\n    // Prepare matrices A (2x2) and B (2x3)\n    tiny::Mat A(2, 2);\n    A(0,0) = 1;  A(0,1) = 2;\n    A(1,0) = 3;  A(1,1) = 4;\n\n    tiny::Mat B(2, 3);\n    B(0,0) = 5;  B(0,1) = 6;  B(0,2) = 7;\n    B(1,0) = 8;  B(1,1) = 9;  B(1,2) = 10;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix B:\\n\";\n    B.print_matrix(true);\n\n    tiny::Mat AB = tiny::Mat::augment(A, B);\n    std::cout &lt;&lt; \"Augmented Matrix [A | B]:\\n\";\n    AB.print_matrix(true);\n\n    // C8.4: Row mismatch case\n    std::cout &lt;&lt; \"\\n[C8.4] Augment with Row Mismatch (Expect Error)\\n\";\n    tiny::Mat C(3, 2);  // 3x2 matrix\n    tiny::Mat invalidAug = tiny::Mat::augment(A, C);\n    invalidAug.print_info();  // Should show empty matrix due to error\n\n    // C8.5: Vertical Stack (vstack)\n    std::cout &lt;&lt; \"\\n[C8.5] Vertically Stack Two Matrices [A; B]\\n\";\n\n    // Prepare matrices A (2x3) and B (2x3)\n    tiny::Mat A_vstack(2, 3);\n    A_vstack(0,0) = 1;  A_vstack(0,1) = 2;  A_vstack(0,2) = 3;\n    A_vstack(1,0) = 4;  A_vstack(1,1) = 5;  A_vstack(1,2) = 6;\n\n    tiny::Mat B_vstack(2, 3);\n    B_vstack(0,0) = 7;  B_vstack(0,1) = 8;  B_vstack(0,2) = 9;\n    B_vstack(1,0) = 10; B_vstack(1,1) = 11; B_vstack(1,2) = 12;\n\n    std::cout &lt;&lt; \"Matrix A (top):\\n\";\n    A_vstack.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix B (bottom):\\n\";\n    B_vstack.print_matrix(true);\n\n    tiny::Mat AB_vstack = tiny::Mat::vstack(A_vstack, B_vstack);\n    std::cout &lt;&lt; \"Vertically Stacked Matrix [A; B]:\\n\";\n    AB_vstack.print_matrix(true);\n    std::cout &lt;&lt; \"Expected: 4x3 matrix with A on top, B on bottom\\n\";\n\n    // C8.6: Vertical Stack with different row counts\n    std::cout &lt;&lt; \"\\n[C8.6] Vertical Stack with Different Row Counts (Same Columns)\\n\";\n    tiny::Mat A_small(1, 3);\n    A_small(0,0) = 1; A_small(0,1) = 2; A_small(0,2) = 3;\n\n    tiny::Mat B_large(3, 3);\n    B_large(0,0) = 4;  B_large(0,1) = 5;  B_large(0,2) = 6;\n    B_large(1,0) = 7;  B_large(1,1) = 8;  B_large(1,2) = 9;\n    B_large(2,0) = 10; B_large(2,1) = 11; B_large(2,2) = 12;\n\n    std::cout &lt;&lt; \"Matrix A (1x3):\\n\";\n    A_small.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix B (3x3):\\n\";\n    B_large.print_matrix(true);\n\n    tiny::Mat AB_mixed = tiny::Mat::vstack(A_small, B_large);\n    std::cout &lt;&lt; \"Vertically Stacked Matrix [A; B] (1x3 + 3x3 = 4x3):\\n\";\n    AB_mixed.print_matrix(true);\n\n    // C8.7: Column mismatch case (Expect Error)\n    std::cout &lt;&lt; \"\\n[C8.7] VStack with Column Mismatch (Expect Error)\\n\";\n    tiny::Mat A_col(2, 2);\n    A_col(0,0) = 1; A_col(0,1) = 2;\n    A_col(1,0) = 3; A_col(1,1) = 4;\n\n    tiny::Mat B_col(2, 3);  // Different column count\n    B_col(0,0) = 5; B_col(0,1) = 6; B_col(0,2) = 7;\n    B_col(1,0) = 8; B_col(1,1) = 9; B_col(1,2) = 10;\n\n    std::cout &lt;&lt; \"Matrix A (2x2):\\n\";\n    A_col.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix B (2x3, different columns):\\n\";\n    B_col.print_matrix(true);\n\n    tiny::Mat invalidVStack = tiny::Mat::vstack(A_col, B_col);\n    std::cout &lt;&lt; \"Result (should be empty due to error):\\n\";\n    invalidVStack.print_info();  // Should show empty matrix due to error\n\n}\n\n// ============================================================================\n// D1: Gaussian Elimination\n// ============================================================================\nvoid test_gaussian_eliminate()\n{\n    std::cout &lt;&lt; \"\\n[D1: Gaussian Elimination Tests]\\n\";\n\n    // D1.1: Simple 3x3 System\n    std::cout &lt;&lt; \"\\n[D1.1] 3x3 Matrix (Simple Upper Triangular)\\n\";\n    tiny::Mat mat1(3, 3);\n    mat1(0,0) = 2; mat1(0,1) = 1; mat1(0,2) = -1;\n    mat1(1,0) = -3; mat1(1,1) = -1; mat1(1,2) = 2;\n    mat1(2,0) = -2; mat1(2,1) = 1; mat1(2,2) = 2;\n\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat result1 = mat1.gaussian_eliminate();\n\n    std::cout &lt;&lt; \"After Gaussian Elimination (Should be upper triangular):\\n\";\n    result1.print_matrix(true);\n\n    // D1.2: 3x4 Augmented Matrix\n    std::cout &lt;&lt; \"\\n[D1.2] 3x4 Augmented Matrix (Linear System Ax = b)\\n\";\n    tiny::Mat mat2(3, 4);\n    mat2(0,0) = 1; mat2(0,1) = 2; mat2(0,2) = -1; mat2(0,3) =  8;\n    mat2(1,0) = -3; mat2(1,1) = -1; mat2(1,2) = 2; mat2(1,3) = -11;\n    mat2(2,0) = -2; mat2(2,1) = 1; mat2(2,2) = 2; mat2(2,3) = -3;\n\n    std::cout &lt;&lt; \"Original Augmented Matrix [A | b]:\\n\";\n    mat2.print_matrix(true);\n\n    tiny::Mat result2 = mat2.gaussian_eliminate();\n\n    std::cout &lt;&lt; \"After Gaussian Elimination (Row Echelon Form):\\n\";\n    result2.print_matrix(true);\n\n    // D1.3: Singular Matrix\n    std::cout &lt;&lt; \"\\n[D1.3] Singular Matrix (No Unique Solution)\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0,0) = 1; mat3(0,1) = 2;\n    mat3(1,0) = 2; mat3(1,1) = 4;  // Linearly dependent rows\n\n    std::cout &lt;&lt; \"Original Singular Matrix:\\n\";\n    mat3.print_matrix(true);\n\n    tiny::Mat result3 = mat3.gaussian_eliminate();\n    std::cout &lt;&lt; \"After Gaussian Elimination (Should show rows of zeros):\\n\";\n    result3.print_matrix(true);\n\n    // D1.4: Zero Matrix\n    std::cout &lt;&lt; \"\\n[D1.4] Zero Matrix\\n\";\n    tiny::Mat mat4(3, 3);\n    mat4.clear();  // Assuming clear() sets all elements to zero\n    mat4.print_matrix(true);\n\n    tiny::Mat result4 = mat4.gaussian_eliminate();\n    std::cout &lt;&lt; \"After Gaussian Elimination (Should be a zero matrix):\\n\";\n    result4.print_matrix(true);\n\n    // D1.5: gaussian_eliminate() - Boundary case - empty matrix\n    std::cout &lt;&lt; \"\\n[D1.5] gaussian_eliminate() - Boundary Case - Empty Matrix\\n\";\n    tiny::Mat empty_ge(0, 0);\n    tiny::Mat result_empty_ge = empty_ge.gaussian_eliminate();\n    // Empty matrix should return empty matrix (0x0) or error state (data == nullptr or 1x1 error matrix)\n    bool empty_ge_correct = (result_empty_ge.row == 0 &amp;&amp; result_empty_ge.col == 0) || \n                           (result_empty_ge.data == nullptr) ||\n                           (result_empty_ge.row == 1 &amp;&amp; result_empty_ge.col == 1 &amp;&amp; result_empty_ge.data != nullptr);\n    std::cout &lt;&lt; \"Empty matrix gaussian_eliminate: \" &lt;&lt; (empty_ge_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (empty_ge_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // D1.6: gaussian_eliminate() - Boundary case - 1x1 matrix\n    std::cout &lt;&lt; \"\\n[D1.6] gaussian_eliminate() - Boundary Case - 1x1 Matrix\\n\";\n    tiny::Mat mat1x1_ge(1, 1);\n    mat1x1_ge(0, 0) = 5.0f;\n    tiny::Mat result1x1_ge = mat1x1_ge.gaussian_eliminate();\n    std::cout &lt;&lt; \"1x1 matrix after gaussian_eliminate:\\n\";\n    result1x1_ge.print_matrix(true);\n    bool ge1x1_correct = (result1x1_ge.row == 1 &amp;&amp; result1x1_ge.col == 1 &amp;&amp; \n                          fabsf(result1x1_ge(0, 0) - 5.0f) &lt; 1e-6f);\n    std::cout &lt;&lt; \"1x1 matrix gaussian_eliminate: \" &lt;&lt; (ge1x1_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n}\n\n\n// ============================================================================\n// D2: Row Reduce from Gaussian (RREF Calculation)\n// ============================================================================\nvoid test_row_reduce_from_gaussian()\n{\n    std::cout &lt;&lt; \"\\n[D2: Row Reduce from Gaussian (RREF) Tests]\\n\";\n\n    // D2.1: Simple 3x4 augmented matrix (representing a system of equations)\n    std::cout &lt;&lt; \"\\n[D2.1] 3x4 Augmented Matrix\\n\";\n    tiny::Mat mat1(3, 4);\n\n    // Matrix:\n    // [ 1  2 -1  -4 ]\n    // [ 2  3 -1 -11 ]\n    // [-2  0 -3  22 ]\n    mat1(0,0) = 1;  mat1(0,1) = 2;  mat1(0,2) = -1; mat1(0,3) = -4;\n    mat1(1,0) = 2;  mat1(1,1) = 3;  mat1(1,2) = -1; mat1(1,3) = -11;\n    mat1(2,0) = -2; mat1(2,1) = 0;  mat1(2,2) = -3; mat1(2,3) = 22;\n\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat rref1 = mat1.gaussian_eliminate().row_reduce_from_gaussian();\n    std::cout &lt;&lt; \"RREF Result:\\n\";\n    rref1.print_matrix(true);\n\n    // D2.2: 2x3 Matrix\n    std::cout &lt;&lt; \"\\n[D2.2] 2x3 Matrix\\n\";\n    tiny::Mat mat2(2, 3);\n    mat2(0,0) = 1; mat2(0,1) = 2;  mat2(0,2) = 3;\n    mat2(1,0) = 4; mat2(1,1) = 5;  mat2(1,2) = 6;\n\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat2.print_matrix(true);\n\n    tiny::Mat rref2 = mat2.gaussian_eliminate().row_reduce_from_gaussian();\n    std::cout &lt;&lt; \"RREF Result:\\n\";\n    rref2.print_matrix(true);\n\n    // D2.3: Already reduced matrix (should remain the same)\n    std::cout &lt;&lt; \"\\n[D2.3] Already Reduced Matrix\\n\";\n    tiny::Mat mat3(2, 3);\n    mat3(0,0) = 1; mat3(0,1) = 0; mat3(0,2) = 2;\n    mat3(1,0) = 0; mat3(1,1) = 1; mat3(1,2) = 3;\n\n    std::cout &lt;&lt; \"Original Matrix:\\n\";\n    mat3.print_matrix(true);\n\n    tiny::Mat rref3 = mat3.row_reduce_from_gaussian();\n    std::cout &lt;&lt; \"RREF Result:\\n\";\n    rref3.print_matrix(true);\n\n    // D2.4: row_reduce_from_gaussian() - Boundary case - empty matrix\n    std::cout &lt;&lt; \"\\n[D2.4] row_reduce_from_gaussian() - Boundary Case - Empty Matrix\\n\";\n    tiny::Mat empty_rref(0, 0);\n    tiny::Mat result_empty_rref = empty_rref.row_reduce_from_gaussian();\n    // Empty matrix should return empty matrix (0x0) or error state (data == nullptr or 1x1 error matrix)\n    bool empty_rref_correct = (result_empty_rref.row == 0 &amp;&amp; result_empty_rref.col == 0) || \n                              (result_empty_rref.data == nullptr) ||\n                              (result_empty_rref.row == 1 &amp;&amp; result_empty_rref.col == 1 &amp;&amp; result_empty_rref.data != nullptr);\n    std::cout &lt;&lt; \"Empty matrix row_reduce_from_gaussian: \" &lt;&lt; (empty_rref_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (empty_rref_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n}\n\n// ============================================================================\n// D3: Gaussian Inverse\n// ============================================================================\nvoid test_inverse_gje()\n{\n    std::cout &lt;&lt; \"\\n[D3: Gaussian Inverse Tests]\\n\";\n\n    // D3.1: Regular 2x2 Matrix\n    std::cout &lt;&lt; \"\\n[D3.1] 2x2 Matrix Inverse\\n\";\n    tiny::Mat mat1(2, 2);\n    mat1(0, 0) = 4; mat1(0, 1) = 7;\n    mat1(1, 0) = 2; mat1(1, 1) = 6;\n    std::cout &lt;&lt; \"Original matrix (mat1):\\n\";\n    mat1.print_matrix(true);\n\n    tiny::Mat invMat1 = mat1.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (mat1):\\n\";\n    invMat1.print_matrix(true);\n\n    // D3.2: Identity Matrix (should return identity matrix)\n    std::cout &lt;&lt; \"\\n[D3.2] Identity Matrix Inverse\\n\";\n    tiny::Mat mat2 = tiny::Mat::eye(3);\n    std::cout &lt;&lt; \"Original matrix (Identity):\\n\";\n    mat2.print_matrix(true);\n\n    tiny::Mat invMat2 = mat2.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (Identity):\\n\";\n    invMat2.print_matrix(true); // Expected: Identity matrix\n\n    // D3.3: Singular Matrix (should return empty matrix or indicate error)\n    std::cout &lt;&lt; \"\\n[D3.3] Singular Matrix (Expected: No Inverse)\\n\";\n    tiny::Mat mat3(3, 3);\n    mat3(0, 0) = 1; mat3(0, 1) = 2; mat3(0, 2) = 3;\n    mat3(1, 0) = 4; mat3(1, 1) = 5; mat3(1, 2) = 6;\n    mat3(2, 0) = 7; mat3(2, 1) = 8; mat3(2, 2) = 9;  // Determinant is 0\n    std::cout &lt;&lt; \"Original matrix (singular):\\n\";\n    mat3.print_matrix(true);\n\n    tiny::Mat invMat3 = mat3.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (singular):\\n\";\n    invMat3.print_matrix(true); // Expected: empty matrix or error message\n\n    // D3.4: 3x3 Matrix with a valid inverse\n    std::cout &lt;&lt; \"\\n[D3.4] 3x3 Matrix Inverse\\n\";\n    tiny::Mat mat4(3, 3);\n    mat4(0, 0) = 4; mat4(0, 1) = 7; mat4(0, 2) = 2;\n    mat4(1, 0) = 3; mat4(1, 1) = 5; mat4(1, 2) = 1;\n    mat4(2, 0) = 8; mat4(2, 1) = 6; mat4(2, 2) = 9;\n    std::cout &lt;&lt; \"Original matrix (mat4):\\n\";\n    mat4.print_matrix(true);\n\n    tiny::Mat invMat4 = mat4.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (mat4):\\n\";\n    invMat4.print_matrix(true); // Check that the inverse is calculated correctly\n\n    // D3.5: Non-square Matrix (should return error or empty matrix)\n    std::cout &lt;&lt; \"\\n[D3.5] Non-square Matrix Inverse (Expected Error)\\n\";\n    tiny::Mat mat5(2, 3);\n    mat5(0, 0) = 1; mat5(0, 1) = 2; mat5(0, 2) = 3;\n    mat5(1, 0) = 4; mat5(1, 1) = 5; mat5(1, 2) = 6;\n    std::cout &lt;&lt; \"Original matrix (non-square):\\n\";\n    mat5.print_matrix(true);\n\n    tiny::Mat invMat5 = mat5.inverse_gje();\n    std::cout &lt;&lt; \"Inverse matrix (non-square):\\n\";\n    invMat5.print_matrix(true); // Expected: Error message or empty matrix\n}\n\n// ============================================================================\n// D4: Dot Product\n// ============================================================================\nvoid test_dotprod()\n{\n    std::cout &lt;&lt; \"\\n[D4: Dot Product Tests]\\n\";\n\n    // D4.1: Valid Dot Product Calculation (Same Length Vectors)\n    std::cout &lt;&lt; \"\\n[D4.1] Valid Dot Product (Same Length Vectors)\\n\";\n    tiny::Mat vectorA(3, 1);  // Create a 3x1 vector\n    tiny::Mat vectorB(3, 1);  // Create a 3x1 vector\n\n    // Initialize vectors\n    vectorA(0, 0) = 1.0f;\n    vectorA(1, 0) = 2.0f;\n    vectorA(2, 0) = 3.0f;\n\n    vectorB(0, 0) = 4.0f;\n    vectorB(1, 0) = 5.0f;\n    vectorB(2, 0) = 6.0f;\n\n    std::cout &lt;&lt; \"Vector A:\\n\";\n    vectorA.print_matrix(true);\n    std::cout &lt;&lt; \"Vector B:\\n\";\n    vectorB.print_matrix(true);\n\n    // Compute the dot product\n    float result = vectorA.dotprod(vectorA, vectorB);\n    std::cout &lt;&lt; \"Dot product of vectorA and vectorB: \" &lt;&lt; result &lt;&lt; std::endl;  // Expected result: 1*4 + 2*5 + 3*6 = 32\n\n    // D4.2: Dot Product with Dimension Mismatch (Different Length Vectors)\n    std::cout &lt;&lt; \"\\n[D4.2] Invalid Dot Product (Dimension Mismatch)\\n\";\n    tiny::Mat vectorC(2, 1);  // Create a 2x1 vector (different size)\n    vectorC(0, 0) = 1.0f;\n    vectorC(1, 0) = 2.0f;\n\n    std::cout &lt;&lt; \"Vector A (3x1):\\n\";\n    vectorA.print_matrix(true);\n    std::cout &lt;&lt; \"Vector C (2x1, different size):\\n\";\n    vectorC.print_matrix(true);\n\n    float invalidResult = vectorA.dotprod(vectorA, vectorC);  // Should print an error and return 0\n    std::cout &lt;&lt; \"Dot product (dimension mismatch): \" &lt;&lt; invalidResult &lt;&lt; std::endl;  // Expected: 0 and error message\n\n    // D4.3: Dot Product of Zero Vectors\n    std::cout &lt;&lt; \"\\n[D4.3] Dot Product of Zero Vectors\\n\";\n    tiny::Mat zeroVectorA(3, 1);  // Create a 3x1 zero vector\n    tiny::Mat zeroVectorB(3, 1);  // Create a 3x1 zero vector\n\n    // Initialize vectors\n    zeroVectorA(0, 0) = 0.0f;\n    zeroVectorA(1, 0) = 0.0f;\n    zeroVectorA(2, 0) = 0.0f;\n\n    zeroVectorB(0, 0) = 0.0f;\n    zeroVectorB(1, 0) = 0.0f;\n    zeroVectorB(2, 0) = 0.0f;\n\n    std::cout &lt;&lt; \"Zero Vector A:\\n\";\n    zeroVectorA.print_matrix(true);\n    std::cout &lt;&lt; \"Zero Vector B:\\n\";\n    zeroVectorB.print_matrix(true);\n\n    float zeroResult = zeroVectorA.dotprod(zeroVectorA, zeroVectorB);\n    std::cout &lt;&lt; \"Dot product of zero vectors: \" &lt;&lt; zeroResult &lt;&lt; std::endl;  // Expected: 0\n\n}\n\n// ============================================================================\n// D5: Solve Linear System\n// ============================================================================\nvoid test_solve()\n{\n    std::cout &lt;&lt; \"\\n[D5: Solve Linear System Tests]\\n\";\n\n    // D5.1: Solving a simple 2x2 system\n    std::cout &lt;&lt; \"\\n[D5.1] Solving a Simple 2x2 System Ax = b\\n\";\n    tiny::Mat A(2, 2);\n    tiny::Mat b(2, 1);\n\n    A(0, 0) = 2; A(0, 1) = 1;\n    A(1, 0) = 1; A(1, 1) = 3;\n\n    b(0, 0) = 5;\n    b(1, 0) = 6;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b.print_matrix(true);\n\n    tiny::Mat solution = A.solve(A, b);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution.print_matrix(true);\n\n    // D5.2: Solving a 3x3 system\n    std::cout &lt;&lt; \"\\n[D5.2] Solving a 3x3 System Ax = b\\n\";\n    tiny::Mat A2(3, 3);\n    tiny::Mat b2(3, 1);\n\n    A2(0, 0) = 1; A2(0, 1) = 2; A2(0, 2) = 1;\n    A2(1, 0) = 2; A2(1, 1) = 0; A2(1, 2) = 3;\n    A2(2, 0) = 3; A2(2, 1) = 2; A2(2, 2) = 1;\n\n    b2(0, 0) = 9;\n    b2(1, 0) = 8;\n    b2(2, 0) = 7;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A2.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b2.print_matrix(true);\n\n    tiny::Mat solution2 = A2.solve(A2, b2);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution2.print_matrix(true);\n\n    // D5.3: Solving a system where one row is all zeros\n    std::cout &lt;&lt; \"\\n[D5.3] Solving a System Where One Row is All Zeros (Expect Failure or Infinite Solutions)\\n\";\n    tiny::Mat A3(3, 3);\n    tiny::Mat b3(3, 1);\n\n    A3(0, 0) = 1; A3(0, 1) = 2; A3(0, 2) = 3;\n    A3(1, 0) = 0; A3(1, 1) = 0; A3(1, 2) = 0; // Zero row\n    A3(2, 0) = 4; A3(2, 1) = 5; A3(2, 2) = 6;\n\n    b3(0, 0) = 9;\n    b3(1, 0) = 0; // Inconsistent, no solution should be possible\n    b3(2, 0) = 15;\n\n    std::cout &lt;&lt; \"Matrix A (has zero row):\\n\";\n    A3.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b3.print_matrix(true);\n\n    tiny::Mat solution3 = A3.solve(A3, b3);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution3.print_matrix(true);\n\n    // D5.4: Solving a system with zero determinant (singular matrix)\n    std::cout &lt;&lt; \"\\n[D5.4] Solving a System with Zero Determinant (Singular Matrix)\\n\";\n    tiny::Mat A4(3, 3);\n    tiny::Mat b4(3, 1);\n\n    A4(0, 0) = 2; A4(0, 1) = 4; A4(0, 2) = 1;\n    A4(1, 0) = 1; A4(1, 1) = 2; A4(1, 2) = 3;\n    A4(2, 0) = 3; A4(2, 1) = 6; A4(2, 2) = 2; // The matrix is singular (row 2 = 2 * row 1)\n\n    b4(0, 0) = 5;\n    b4(1, 0) = 6;\n    b4(2, 0) = 7;\n\n    std::cout &lt;&lt; \"Matrix A (singular, determinant = 0):\\n\";\n    A4.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b4.print_matrix(true);\n\n    tiny::Mat solution4 = A4.solve(A4, b4);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution4.print_matrix(true); // Expect no solution or an error message\n\n    // D5.5: Solving a system with linearly dependent rows\n    std::cout &lt;&lt; \"\\n[D5.5] Solving a System with Linearly Dependent Rows (Expect Failure or Infinite Solutions)\\n\";\n    tiny::Mat A5(3, 3);\n    tiny::Mat b5(3, 1);\n\n    A5(0, 0) = 1; A5(0, 1) = 1; A5(0, 2) = 1;\n    A5(1, 0) = 2; A5(1, 1) = 2; A5(1, 2) = 2;\n    A5(2, 0) = 3; A5(2, 1) = 3; A5(2, 2) = 3; // All rows are linearly dependent\n\n    b5(0, 0) = 6;\n    b5(1, 0) = 12;\n    b5(2, 0) = 18;\n\n    std::cout &lt;&lt; \"Matrix A (all rows linearly dependent):\\n\";\n    A5.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b5.print_matrix(true);\n\n    tiny::Mat solution5 = A5.solve(A5, b5);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution5.print_matrix(true); // Expect an error message or infinite solutions\n\n    // D5.6: Solving a larger 4x4 system\n    std::cout &lt;&lt; \"\\n[D5.6] Solving a Larger 4x4 System Ax = b\\n\";\n    tiny::Mat A6(4, 4);\n    tiny::Mat b6(4, 1);\n\n    A6(0, 0) = 4; A6(0, 1) = 2; A6(0, 2) = 3; A6(0, 3) = 1;\n    A6(1, 0) = 2; A6(1, 1) = 5; A6(1, 2) = 1; A6(1, 3) = 2;\n    A6(2, 0) = 3; A6(2, 1) = 1; A6(2, 2) = 6; A6(2, 3) = 3;\n    A6(3, 0) = 1; A6(3, 1) = 2; A6(3, 2) = 3; A6(3, 3) = 4;\n\n    b6(0, 0) = 10;\n    b6(1, 0) = 12;\n    b6(2, 0) = 14;\n    b6(3, 0) = 16;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A6.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b6.print_matrix(true);\n\n    tiny::Mat solution6 = A6.solve(A6, b6);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution6.print_matrix(true); // Should print the solution vector\n\n    // D5.7: solve() - Boundary case - empty matrix\n    std::cout &lt;&lt; \"\\n[D5.7] solve() - Boundary Case - Empty Matrix\\n\";\n    tiny::Mat empty_A(0, 0);\n    tiny::Mat empty_b(0, 1);\n    tiny::Mat solution_empty = empty_A.solve(empty_A, empty_b);\n    // Error case should return empty matrix (0x0) or error state (data == nullptr or 1x1 error matrix)\n    bool solve_empty_correct = (solution_empty.row == 0 &amp;&amp; solution_empty.col == 0) || \n                               (solution_empty.data == nullptr) ||\n                               (solution_empty.row == 1 &amp;&amp; solution_empty.col == 1 &amp;&amp; solution_empty.data != nullptr);\n    std::cout &lt;&lt; \"Empty system solve: \" &lt;&lt; (solve_empty_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (solve_empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // D5.8: solve() - Error handling - dimension mismatch\n    std::cout &lt;&lt; \"\\n[D5.8] solve() - Error Handling - Dimension Mismatch\\n\";\n    tiny::Mat A_mismatch(2, 2);\n    tiny::Mat b_mismatch(3, 1);  // Different dimension\n    tiny::Mat solution_mismatch = A_mismatch.solve(A_mismatch, b_mismatch);\n    // Error case should return empty matrix (0x0) or error state (data == nullptr or 1x1 error matrix)\n    // For dimension mismatch, expected solution size is 2x1, so 1x1 indicates error\n    bool solve_mismatch_correct = (solution_mismatch.row == 0 &amp;&amp; solution_mismatch.col == 0) || \n                                  (solution_mismatch.data == nullptr) ||\n                                  (solution_mismatch.row == 1 &amp;&amp; solution_mismatch.col == 1 &amp;&amp; solution_mismatch.data != nullptr);\n    std::cout &lt;&lt; \"Dimension mismatch solve: \" &lt;&lt; (solve_mismatch_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (solve_mismatch_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n}\n\n// ============================================================================\n// D6: Band Solve\n// ============================================================================\nvoid test_band_solve()\n{\n    std::cout &lt;&lt; \"\\n[D6: Band Solve Tests]\\n\";\n\n    // D6.1: Simple 3x3 Band Matrix\n    std::cout &lt;&lt; \"\\n[D6.1] Simple 3x3 Band Matrix\\n\";\n    tiny::Mat A1(3, 3);\n    tiny::Mat b1(3, 1);\n\n    // Define the matrix A and vector b for the system Ax = b\n    A1(0, 0) = 2; A1(0, 1) = 1; A1(0, 2) = 0;\n    A1(1, 0) = 1; A1(1, 1) = 3; A1(1, 2) = 2;\n    A1(2, 0) = 0; A1(2, 1) = 1; A1(2, 2) = 4;\n\n    b1(0, 0) = 5;\n    b1(1, 0) = 6;\n    b1(2, 0) = 7;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A1.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b1.print_matrix(true);\n\n    // Solve Ax = b using band_solve\n    tiny::Mat solution1 = A1.band_solve(A1, b1, 3);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution1.print_matrix(true);\n\n    // D6.2: 4x4 Band Matrix with different right-hand side vector\n    std::cout &lt;&lt; \"\\n[D6.2] 4x4 Band Matrix\\n\";\n    tiny::Mat A2(4, 4);\n    tiny::Mat b2(4, 1);\n\n    // Define the matrix A and vector b\n    A2(0, 0) = 2; A2(0, 1) = 1; A2(0, 2) = 0; A2(0, 3) = 0;\n    A2(1, 0) = 1; A2(1, 1) = 3; A2(1, 2) = 2; A2(1, 3) = 0;\n    A2(2, 0) = 0; A2(2, 1) = 1; A2(2, 2) = 4; A2(2, 3) = 2;\n    A2(3, 0) = 0; A2(3, 1) = 0; A2(3, 2) = 1; A2(3, 3) = 5;\n\n    b2(0, 0) = 8;\n    b2(1, 0) = 9;\n    b2(2, 0) = 10;\n    b2(3, 0) = 11;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A2.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b2.print_matrix(true);\n\n    // Solve Ax = b using band_solve\n    tiny::Mat solution2 = A2.band_solve(A2, b2, 3);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution2.print_matrix(true);\n\n    // D6.3: Incompatible dimensions (expect error)\n    std::cout &lt;&lt; \"\\n[D6.3] Incompatible Dimensions (Expect Error)\\n\";\n    tiny::Mat A3(3, 3);\n    tiny::Mat b3(2, 1);  // Incompatible dimension\n\n    A3(0, 0) = 1; A3(0, 1) = 2; A3(0, 2) = 3;\n    A3(1, 0) = 4; A3(1, 1) = 5; A3(1, 2) = 6;\n    A3(2, 0) = 7; A3(2, 1) = 8; A3(2, 2) = 9;\n\n    b3(0, 0) = 10;\n    b3(1, 0) = 11;\n\n    std::cout &lt;&lt; \"Matrix A (3x3):\\n\";\n    A3.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b (2x1, incompatible):\\n\";\n    b3.print_matrix(true);\n\n    // This should print an error because of incompatible dimensions\n    tiny::Mat solution3 = A3.band_solve(A3, b3, 3);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution3.print_matrix(true);\n\n    // D6.4: Singular Matrix (Should fail)\n    std::cout &lt;&lt; \"\\n[D6.4] Singular Matrix (No Unique Solution)\\n\";\n    tiny::Mat A4(3, 3);\n    tiny::Mat b4(3, 1);\n\n    // Define a singular matrix (linearly dependent rows)\n    A4(0, 0) = 1; A4(0, 1) = 2; A4(0, 2) = 3;\n    A4(1, 0) = 2; A4(1, 1) = 4; A4(1, 2) = 6;\n    A4(2, 0) = 3; A4(2, 1) = 6; A4(2, 2) = 9;\n\n    b4(0, 0) = 10;\n    b4(1, 0) = 20;\n    b4(2, 0) = 30;\n\n    std::cout &lt;&lt; \"Matrix A (singular, linearly dependent rows):\\n\";\n    A4.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b4.print_matrix(true);\n\n    // This should print an error as the matrix is singular and does not have a unique solution\n    tiny::Mat solution4 = A4.band_solve(A4, b4, 3);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution4.print_matrix(true);\n\n    // D6.5: band_solve() - Boundary case - empty matrix\n    std::cout &lt;&lt; \"\\n[D6.5] band_solve() - Boundary Case - Empty Matrix\\n\";\n    tiny::Mat empty_A_band(0, 0);\n    tiny::Mat empty_b_band(0, 1);\n    tiny::Mat solution_empty_band = empty_A_band.band_solve(empty_A_band, empty_b_band, 0);\n    // Error case should return empty matrix (0x0) or error state (data == nullptr or 1x1 error matrix)\n    bool band_solve_empty_correct = (solution_empty_band.row == 0 &amp;&amp; solution_empty_band.col == 0) || \n                                    (solution_empty_band.data == nullptr) ||\n                                    (solution_empty_band.row == 1 &amp;&amp; solution_empty_band.col == 1 &amp;&amp; solution_empty_band.data != nullptr);\n    std::cout &lt;&lt; \"Empty system band_solve: \" &lt;&lt; (band_solve_empty_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (band_solve_empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // D6.6: band_solve() - Error handling - invalid bandwidth\n    std::cout &lt;&lt; \"\\n[D6.6] band_solve() - Error Handling - Invalid Bandwidth\\n\";\n    tiny::Mat A_band(3, 3);\n    tiny::Mat b_band(3, 1);\n    tiny::Mat solution_neg_k = A_band.band_solve(A_band, b_band, -1);\n    // Error case should return empty matrix (0x0) or error state (data == nullptr or 1x1 error matrix)\n    // For invalid bandwidth, expected solution size is 3x1, so 1x1 indicates error\n    bool band_solve_neg_k_correct = (solution_neg_k.row == 0 &amp;&amp; solution_neg_k.col == 0) || \n                                     (solution_neg_k.data == nullptr) ||\n                                     (solution_neg_k.row == 1 &amp;&amp; solution_neg_k.col == 1 &amp;&amp; solution_neg_k.data != nullptr);\n    std::cout &lt;&lt; \"band_solve with k=-1: \" &lt;&lt; (band_solve_neg_k_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (band_solve_neg_k_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n}\n\n// ============================================================================\n// D7: Roots\n// ============================================================================\nvoid test_roots()\n{\n    std::cout &lt;&lt; \"\\n[D7: Roots Tests]\\n\";\n\n    // D7.1: Simple 2x2 System\n    std::cout &lt;&lt; \"\\n[D7.1] Solving a Simple 2x2 System Ax = b\\n\";\n    tiny::Mat A1(2, 2);\n    tiny::Mat b1(2, 1);\n\n    // Define the matrix A and vector b for the system Ax = b\n    A1(0, 0) = 2; A1(0, 1) = 1;\n    A1(1, 0) = 1; A1(1, 1) = 3;\n\n    b1(0, 0) = 5;\n    b1(1, 0) = 6;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A1.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b1.print_matrix(true);\n\n    // Solve Ax = b using roots\n    tiny::Mat solution1 = A1.roots(A1, b1);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution1.print_matrix(true);\n\n    // D7.2: 3x3 System\n    std::cout &lt;&lt; \"\\n[D7.2] Solving a 3x3 System Ax = b\\n\";\n    tiny::Mat A2(3, 3);\n    tiny::Mat b2(3, 1);\n\n    A2(0, 0) = 1; A2(0, 1) = 2; A2(0, 2) = 1;\n    A2(1, 0) = 2; A2(1, 1) = 0; A2(1, 2) = 3;\n    A2(2, 0) = 3; A2(2, 1) = 2; A2(2, 2) = 1;\n\n    b2(0, 0) = 9;\n    b2(1, 0) = 8;\n    b2(2, 0) = 7;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    A2.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b2.print_matrix(true);\n\n    // Solve Ax = b using roots\n    tiny::Mat solution2 = A2.roots(A2, b2);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution2.print_matrix(true);\n\n    // D7.3: Singular Matrix\n    std::cout &lt;&lt; \"\\n[D7.3] Singular Matrix (No Unique Solution)\\n\";\n    tiny::Mat A3(2, 2);\n    tiny::Mat b3(2, 1);\n\n    // Define a singular matrix (linearly dependent rows)\n    A3(0, 0) = 1; A3(0, 1) = 2;\n    A3(1, 0) = 2; A3(1, 1) = 4;\n\n    b3(0, 0) = 5;\n    b3(1, 0) = 6;\n\n    std::cout &lt;&lt; \"Matrix A (singular, linearly dependent rows):\\n\";\n    A3.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b:\\n\";\n    b3.print_matrix(true);\n\n    // This should print an error as the matrix is singular and does not have a unique solution\n    tiny::Mat solution3 = A3.roots(A3, b3);\n    std::cout &lt;&lt; \"Solution x:\\n\";\n    solution3.print_matrix(true);\n\n    // D7.4: Incompatible Dimensions (Expect Error)\n    std::cout &lt;&lt; \"\\n[D7.4] Incompatible Dimensions (Expect Error)\\n\";\n    tiny::Mat A4(3, 3);\n    tiny::Mat b4(2, 1);  // Incompatible dimension\n\n    A4(0, 0) = 1; A4(0, 1) = 2; A4(0, 2) = 3;\n    A4(1, 0) = 4; A4(1, 1) = 5; A4(1, 2) = 6;\n    A4(2, 0) = 7; A4(2, 1) = 8; A4(2, 2) = 9;\n\n    b4(0, 0) = 10;\n    b4(1, 0) = 11;\n\n    std::cout &lt;&lt; \"Matrix A (3x3):\\n\";\n    A4.print_matrix(true);\n    std::cout &lt;&lt; \"Vector b (2x1, incompatible):\\n\";\n    b4.print_matrix(true);\n\n    // This should print an error because of incompatible dimensions\n    tiny::Mat solution4 = A4.roots(A4, b4);\n    // Error case should return empty matrix (0x0) or error state (data == nullptr or 1x1 error matrix)\n    // For dimension mismatch, expected solution size is 3x1, so 1x1 indicates error\n    bool roots_mismatch_correct = (solution4.row == 0 &amp;&amp; solution4.col == 0) || \n                                  (solution4.data == nullptr) ||\n                                  (solution4.row == 1 &amp;&amp; solution4.col == 1 &amp;&amp; solution4.data != nullptr);\n    std::cout &lt;&lt; \"Dimension mismatch roots: \" &lt;&lt; (roots_mismatch_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (roots_mismatch_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n    // D7.5: roots() - Boundary case - empty matrix\n    std::cout &lt;&lt; \"\\n[D7.5] roots() - Boundary Case - Empty Matrix\\n\";\n    tiny::Mat empty_A_roots(0, 0);\n    tiny::Mat empty_y_roots(0, 1);\n    tiny::Mat solution_empty_roots = empty_A_roots.roots(empty_A_roots, empty_y_roots);\n    // Error case should return empty matrix (0x0) or error state (data == nullptr or 1x1 error matrix)\n    bool roots_empty_correct = (solution_empty_roots.row == 0 &amp;&amp; solution_empty_roots.col == 0) || \n                                (solution_empty_roots.data == nullptr) ||\n                                (solution_empty_roots.row == 1 &amp;&amp; solution_empty_roots.col == 1 &amp;&amp; solution_empty_roots.data != nullptr);\n    std::cout &lt;&lt; \"Empty system roots: \" &lt;&lt; (roots_empty_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (roots_empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n}\n\n// ============================================================================\n// E: Advanced Linear Algebra\n// ============================================================================\n// Purpose: Advanced linear algebra operations for stable and efficient solving\n// E1: Matrix Decomposition\n// E2: Gram-Schmidt Orthogonalization\n\n// ============================================================================\n// E3: Eigenvalue Decomposition\n// ============================================================================\n// Purpose: Eigenvalue decomposition for SHM and modal analysis\n// E3: Eigenvalue &amp; Eigenvector\n\n// ============================================================================\n// F: Auxiliary Functions\n// ============================================================================\n// Purpose: Convenience functions and I/O operations\n// F1: Stream Operators\n// F2: Global Arithmetic Operators\n\n// ============================================================================\n// G: Quality Assurance\n// ============================================================================\n// Purpose: Ensure robustness, performance, and correctness\n// G1: Boundary Conditions and Error Handling\n// G2: Performance Benchmarks\n// G3: Memory Layout\n\n// ============================================================================\n// F1: Stream Operators\n// ============================================================================\nvoid test_stream_operators()\n{\n    std::cout &lt;&lt; \"\\n[F1: Stream Operators Tests]\\n\";\n\n    // F1.1: Test stream insertion operator (&lt;&lt;) for Mat\n    std::cout &lt;&lt; \"\\n[F1.1] Stream Insertion Operator (&lt;&lt;) for Mat\\n\";\n    tiny::Mat mat1(3, 3);\n    mat1(0, 0) = 1; mat1(0, 1) = 2; mat1(0, 2) = 3;\n    mat1(1, 0) = 4; mat1(1, 1) = 5; mat1(1, 2) = 6;\n    mat1(2, 0) = 7; mat1(2, 1) = 8; mat1(2, 2) = 9;\n\n    std::cout &lt;&lt; \"Matrix mat1:\\n\";\n    std::cout &lt;&lt; mat1 &lt;&lt; std::endl; // Use the &lt;&lt; operator to print mat1\n\n    // F1.2: Test stream insertion operator (&lt;&lt;) for Mat::ROI\n    std::cout &lt;&lt; \"\\n[F1.2] Stream Insertion Operator (&lt;&lt;) for Mat::ROI\\n\";\n    tiny::Mat::ROI roi(1, 2, 3, 4);\n    // ROI constructor: ROI(pos_x, pos_y, width, height)\n    // roi(1, 2, 3, 4) means: start at column 1, row 2, with width 3, height 4\n    std::cout &lt;&lt; \"ROI created: ROI(pos_x=1, pos_y=2, width=3, height=4)\\n\";\n    std::cout &lt;&lt; \"Expected output:\\n\";\n    std::cout &lt;&lt; \"  row start: 2 (pos_y)\\n\";\n    std::cout &lt;&lt; \"  col start: 1 (pos_x)\\n\";\n    std::cout &lt;&lt; \"  row count: 4 (height)\\n\";\n    std::cout &lt;&lt; \"  col count: 3 (width)\\n\";\n    std::cout &lt;&lt; \"\\nActual output:\\n\";\n    std::cout &lt;&lt; roi &lt;&lt; std::endl; // Use the &lt;&lt; operator to print roi\n\n    // F1.3: Test stream extraction operator (&gt;&gt;) for Mat\n    std::cout &lt;&lt; \"\\n[F1.3] Stream Extraction Operator (&gt;&gt;) for Mat\\n\";\n    tiny::Mat mat2(2, 2);\n    // Use istringstream to simulate input (for automated testing)\n    std::istringstream input1(\"10 20 30 40\");\n    std::cout &lt;&lt; \"Simulated input: \\\"10 20 30 40\\\"\\n\";\n    input1 &gt;&gt; mat2; // Use the &gt;&gt; operator to read from string stream\n    std::cout &lt;&lt; \"Matrix mat2 after input:\\n\";\n    std::cout &lt;&lt; mat2 &lt;&lt; std::endl; // Use the &lt;&lt; operator to print mat2\n    std::cout &lt;&lt; \"Expected: [10, 20; 30, 40]\\n\";\n\n    // F1.4: Test stream extraction operator (&gt;&gt;) for Mat (with different values)\n    std::cout &lt;&lt; \"\\n[F1.4] Stream Extraction Operator (&gt;&gt;) for Mat (2x3 matrix)\\n\";\n    tiny::Mat mat3(2, 3);\n    // Use istringstream to simulate input (for automated testing)\n    std::istringstream input2(\"1.5 2.5 3.5 4.5 5.5 6.5\");\n    std::cout &lt;&lt; \"Simulated input: \\\"1.5 2.5 3.5 4.5 5.5 6.5\\\"\\n\";\n    input2 &gt;&gt; mat3; // Use the &gt;&gt; operator to read from string stream\n    std::cout &lt;&lt; \"Matrix mat3 after input:\\n\";\n    std::cout &lt;&lt; mat3 &lt;&lt; std::endl; // Use the &lt;&lt; operator to print mat3\n    std::cout &lt;&lt; \"Expected: [1.5, 2.5, 3.5; 4.5, 5.5, 6.5]\\n\";\n}\n\n// ============================================================================\n// F2: Global Arithmetic Operators\n// ============================================================================\nvoid test_matrix_operations()\n{\n    std::cout &lt;&lt; \"\\n[F2: Global Arithmetic Operators Tests]\\n\";\n\n    // F2.1: Matrix Addition (operator+)\n    std::cout &lt;&lt; \"\\n[F2.1] Matrix Addition (operator+)\\n\";\n    tiny::Mat matA(2, 2);\n    tiny::Mat matB(2, 2);\n\n    matA(0, 0) = 1; matA(0, 1) = 2;\n    matA(1, 0) = 3; matA(1, 1) = 4;\n\n    matB(0, 0) = 5; matB(0, 1) = 6;\n    matB(1, 0) = 7; matB(1, 1) = 8;\n\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix B:\\n\";\n    matB.print_matrix(true);\n\n    tiny::Mat resultAdd = matA + matB;\n    std::cout &lt;&lt; \"matA + matB:\\n\";\n    std::cout &lt;&lt; resultAdd &lt;&lt; std::endl;  // Expected: [6, 8], [10, 12]\n\n    // F2.2: Matrix Addition with Constant (operator+)\n    std::cout &lt;&lt; \"\\n[F2.2] Matrix Addition with Constant (operator+)\\n\";\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"Constant: 5.0\\n\";\n    tiny::Mat resultAddConst = matA + 5.0f;\n    std::cout &lt;&lt; \"matA + 5.0f:\\n\";\n    std::cout &lt;&lt; resultAddConst &lt;&lt; std::endl;  // Expected: [6, 7], [8, 9]\n\n    // F2.3: Matrix Subtraction (operator-)\n    std::cout &lt;&lt; \"\\n[F2.3] Matrix Subtraction (operator-)\\n\";\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix B:\\n\";\n    matB.print_matrix(true);\n    tiny::Mat resultSub = matA - matB;\n    std::cout &lt;&lt; \"matA - matB:\\n\";\n    std::cout &lt;&lt; resultSub &lt;&lt; std::endl;  // Expected: [-4, -4], [-4, -4]\n\n    // F2.4: Matrix Subtraction with Constant (operator-)\n    std::cout &lt;&lt; \"\\n[F2.4] Matrix Subtraction with Constant (operator-)\\n\";\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"Constant: 2.0\\n\";\n    tiny::Mat resultSubConst = matA - 2.0f;\n    std::cout &lt;&lt; \"matA - 2.0f:\\n\";\n    std::cout &lt;&lt; resultSubConst &lt;&lt; std::endl;  // Expected: [-1, 0], [1, 2]\n\n    // F2.5: Matrix Multiplication (operator*)\n    std::cout &lt;&lt; \"\\n[F2.5] Matrix Multiplication (operator*)\\n\";\n    tiny::Mat matC(2, 3);\n    tiny::Mat matD(3, 2);\n\n    matC(0, 0) = 1; matC(0, 1) = 2; matC(0, 2) = 3;\n    matC(1, 0) = 4; matC(1, 1) = 5; matC(1, 2) = 6;\n\n    matD(0, 0) = 7; matD(0, 1) = 8;\n    matD(1, 0) = 9; matD(1, 1) = 10;\n    matD(2, 0) = 11; matD(2, 1) = 12;\n\n    std::cout &lt;&lt; \"Matrix C (2x3):\\n\";\n    matC.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix D (3x2):\\n\";\n    matD.print_matrix(true);\n\n    tiny::Mat resultMul = matC * matD;\n    std::cout &lt;&lt; \"matC * matD:\\n\";\n    std::cout &lt;&lt; resultMul &lt;&lt; std::endl;  // Expected: [58, 64], [139, 154]\n\n    // F2.6: Matrix Multiplication with Constant (operator*)\n    std::cout &lt;&lt; \"\\n[F2.6] Matrix Multiplication with Constant (operator*)\\n\";\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"Constant: 2.0\\n\";\n    tiny::Mat resultMulConst = matA * 2.0f;\n    std::cout &lt;&lt; \"matA * 2.0f:\\n\";\n    std::cout &lt;&lt; resultMulConst &lt;&lt; std::endl;  // Expected: [2, 4], [6, 8]\n\n    // F2.7: Matrix Division (operator/)\n    std::cout &lt;&lt; \"\\n[F2.7] Matrix Division (operator/)\\n\";\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"Constant: 2.0\\n\";\n    tiny::Mat resultDiv = matA / 2.0f;\n    std::cout &lt;&lt; \"matA / 2.0f:\\n\";\n    std::cout &lt;&lt; resultDiv &lt;&lt; std::endl;  // Expected: [0.5, 1], [1.5, 2]\n\n    // F2.8: Matrix Division Element-wise (operator/)\n    std::cout &lt;&lt; \"\\n[F2.8] Matrix Division Element-wise (operator/)\\n\";\n    std::cout &lt;&lt; \"Matrix A:\\n\";\n    matA.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix B:\\n\";\n    matB.print_matrix(true);\n    tiny::Mat resultDivElem = matA / matB;\n    std::cout &lt;&lt; \"matA / matB:\\n\";\n    std::cout &lt;&lt; resultDivElem &lt;&lt; std::endl;  // Expected: [0.2, 0.333], [0.428, 0.5]\n\n    // F2.9: Matrix Comparison (operator==)\n    std::cout &lt;&lt; \"\\n[F2.9] Matrix Comparison (operator==)\\n\";\n    tiny::Mat matE(2, 2);\n    matE(0, 0) = 1; matE(0, 1) = 2;\n    matE(1, 0) = 3; matE(1, 1) = 4;\n\n    tiny::Mat matF(2, 2);\n    matF(0, 0) = 1; matF(0, 1) = 2;\n    matF(1, 0) = 3; matF(1, 1) = 4;\n\n    std::cout &lt;&lt; \"Matrix E:\\n\";\n    matE.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix F:\\n\";\n    matF.print_matrix(true);\n\n    bool isEqual = (matE == matF);\n    std::cout &lt;&lt; \"matE == matF: \" &lt;&lt; (isEqual ? \"True\" : \"False\") &lt;&lt; std::endl;  // Expected: True\n\n    matF(0, 0) = 5;  // Modify matF\n    std::cout &lt;&lt; \"\\nAfter modifying matF(0,0) = 5:\\n\";\n    std::cout &lt;&lt; \"Matrix E:\\n\";\n    matE.print_matrix(true);\n    std::cout &lt;&lt; \"Matrix F:\\n\";\n    matF.print_matrix(true);\n    isEqual = (matE == matF);\n    std::cout &lt;&lt; \"matE == matF after modification: \" &lt;&lt; (isEqual ? \"True\" : \"False\") &lt;&lt; std::endl;  // Expected: False\n}\n\n// ============================================================================\n// G1: Quality Assurance - Boundary Conditions and Error Handling Tests\n// ============================================================================\n// Purpose: Test error handling and edge cases - ensure robustness\nvoid test_boundary_conditions()\n{\n    std::cout &lt;&lt; \"\\n[G1: Quality Assurance - Boundary Conditions and Error Handling Tests]\\n\";\n\n    // G1.1: Null pointer handling in print functions\n    std::cout &lt;&lt; \"\\n[G1.1] Null Pointer Handling in print_matrix\\n\";\n    tiny::Mat null_mat;\n    null_mat.data = nullptr;  // Simulate null pointer\n    null_mat.print_matrix(true);  // Should handle gracefully\n\n    // G1.2: Null pointer handling in operator&lt;&lt;\n    std::cout &lt;&lt; \"\\n[G1.2] Null Pointer Handling in operator&lt;&lt;\\n\";\n    tiny::Mat null_mat2;\n    null_mat2.data = nullptr;\n    std::cout &lt;&lt; null_mat2 &lt;&lt; std::endl;  // Should handle gracefully\n\n    // G1.3: Invalid block parameters\n    std::cout &lt;&lt; \"\\n[G1.3] Invalid Block Parameters\\n\";\n    tiny::Mat mat(3, 3);\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat(i, j) = i * 3 + j + 1;\n\n    // Negative start position\n    tiny::Mat block1 = mat.block(-1, 0, 2, 2);\n    std::cout &lt;&lt; \"block(-1, 0, 2, 2): \" &lt;&lt; (block1.data == nullptr ? \"Empty (correct)\" : \"Error\") &lt;&lt; \"\\n\";\n\n    // Block exceeds boundaries\n    tiny::Mat block2 = mat.block(2, 2, 2, 2);\n    std::cout &lt;&lt; \"block(2, 2, 2, 2) on 3x3 matrix: \" &lt;&lt; (block2.data == nullptr ? \"Empty (correct)\" : \"Error\") &lt;&lt; \"\\n\";\n\n    // Zero or negative block size\n    tiny::Mat block3 = mat.block(0, 0, 0, 2);\n    std::cout &lt;&lt; \"block(0, 0, 0, 2): \" &lt;&lt; (block3.data == nullptr ? \"Empty (correct)\" : \"Error\") &lt;&lt; \"\\n\";\n\n    // G1.4: Invalid swap_rows parameters\n    std::cout &lt;&lt; \"\\n[G1.4] Invalid swap_rows Parameters\\n\";\n    tiny::Mat mat2(3, 3);\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat2(i, j) = i * 3 + j + 1;\n\n    std::cout &lt;&lt; \"Before invalid swap_rows:\\n\";\n    mat2.print_matrix(true);\n\n    // Negative index\n    mat2.swap_rows(-1, 1);\n    std::cout &lt;&lt; \"After swap_rows(-1, 1):\\n\";\n    mat2.print_matrix(true);\n\n    // Index out of range\n    mat2.swap_rows(0, 5);\n    std::cout &lt;&lt; \"After swap_rows(0, 5):\\n\";\n    mat2.print_matrix(true);\n\n    // G1.5: Invalid swap_cols parameters\n    std::cout &lt;&lt; \"\\n[G1.5] Invalid swap_cols Parameters\\n\";\n    tiny::Mat mat2_cols(3, 3);\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 3; ++j)\n            mat2_cols(i, j) = i * 3 + j + 1;\n\n    std::cout &lt;&lt; \"Before invalid swap_cols:\\n\";\n    mat2_cols.print_matrix(true);\n\n    // Negative index\n    mat2_cols.swap_cols(-1, 1);\n    std::cout &lt;&lt; \"After swap_cols(-1, 1):\\n\";\n    mat2_cols.print_matrix(true);\n\n    // Index out of range\n    mat2_cols.swap_cols(0, 5);\n    std::cout &lt;&lt; \"After swap_cols(0, 5):\\n\";\n    mat2_cols.print_matrix(true);\n\n    // G1.6: Division by zero\n    std::cout &lt;&lt; \"\\n[G1.6] Division by Zero\\n\";\n    tiny::Mat mat3(2, 2);\n    mat3(0, 0) = 1; mat3(0, 1) = 2;\n    mat3(1, 0) = 3; mat3(1, 1) = 4;\n\n    tiny::Mat result = mat3 / 0.0f;\n    std::cout &lt;&lt; \"mat3 / 0.0f: \" &lt;&lt; (result.data == nullptr ? \"Empty (correct)\" : \"Error\") &lt;&lt; \"\\n\";\n\n    // G1.7: Matrix division with zero elements\n    std::cout &lt;&lt; \"\\n[G1.7] Matrix Division with Zero Elements\\n\";\n    tiny::Mat mat4(2, 2);\n    mat4(0, 0) = 1; mat4(0, 1) = 2;\n    mat4(1, 0) = 3; mat4(1, 1) = 4;\n\n    tiny::Mat divisor(2, 2);\n    divisor(0, 0) = 1; divisor(0, 1) = 0;  // Contains zero\n    divisor(1, 0) = 3; divisor(1, 1) = 4;\n\n    mat4 /= divisor;\n    std::cout &lt;&lt; \"mat4 /= divisor (with zero):\\n\";\n    mat4.print_matrix(true);\n\n    // G1.8: Empty matrix operations\n    std::cout &lt;&lt; \"\\n[G1.8] Empty Matrix Operations\\n\";\n    tiny::Mat empty1(0, 0), empty2(0, 0);  // True empty matrices (0x0)\n    tiny::Mat empty_sum = empty1 + empty2;\n    // Empty matrix addition should return empty matrix (0x0) or error state\n    bool empty_sum_correct = (empty_sum.row == 0 &amp;&amp; empty_sum.col == 0) || \n                             (empty_sum.data == nullptr) ||\n                             (empty_sum.row == 1 &amp;&amp; empty_sum.col == 1 &amp;&amp; empty_sum.data != nullptr);\n    std::cout &lt;&lt; \"Empty matrix addition: \" &lt;&lt; (empty_sum_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n              &lt;&lt; \" \" &lt;&lt; (empty_sum_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n}\n\n// ============================================================================\n// G2: Quality Assurance - Performance Benchmarks Tests\n// ============================================================================\n// Purpose: Test performance characteristics - critical for real-time applications\nvoid test_performance_benchmarks()\n{\n    std::cout &lt;&lt; \"\\n[G2: Quality Assurance - Performance Benchmarks Tests]\\n\";\n\n    // Ensure current task is added to watchdog before starting performance tests\n    #if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    ensure_task_wdt_added();\n    #endif\n\n    // G2.1: Matrix Addition Performance (reduced size to prevent timeout)\n    std::cout &lt;&lt; \"\\n[G2.1] Matrix Addition Performance\\n\";\n    tiny::Mat A(50, 50);  // Reduced from 100x100 to 50x50\n    tiny::Mat B(50, 50);\n    for (int i = 0; i &lt; 50; ++i)\n    {\n        for (int j = 0; j &lt; 50; ++j)\n        {\n            A(i, j) = static_cast&lt;float&gt;(i * 50 + j);\n            B(i, j) = static_cast&lt;float&gt;(i * 50 + j + 1);\n        }\n    }\n    TIME_REPEATED_OPERATION(tiny::Mat C = A + B;, PERFORMANCE_TEST_ITERATIONS, \"50x50 Matrix Addition\");\n\n    // G2.2: Matrix Multiplication Performance (reduced size)\n    std::cout &lt;&lt; \"\\n[G2.2] Matrix Multiplication Performance\\n\";\n    tiny::Mat D(30, 30);  // Reduced from 50x50 to 30x30\n    tiny::Mat E(30, 30);\n    for (int i = 0; i &lt; 30; ++i)\n    {\n        for (int j = 0; j &lt; 30; ++j)\n        {\n            D(i, j) = static_cast&lt;float&gt;(i * 30 + j);\n            E(i, j) = static_cast&lt;float&gt;(i * 30 + j + 1);\n        }\n    }\n    TIME_REPEATED_OPERATION(tiny::Mat F = D * E;, PERFORMANCE_TEST_ITERATIONS, \"30x30 Matrix Multiplication\");\n\n    // G2.3: Matrix Transpose Performance (reduced size)\n    std::cout &lt;&lt; \"\\n[G2.3] Matrix Transpose Performance\\n\";\n    tiny::Mat G(50, 30);  // Reduced from 100x50 to 50x30\n    for (int i = 0; i &lt; 50; ++i)\n        for (int j = 0; j &lt; 30; ++j)\n            G(i, j) = static_cast&lt;float&gt;(i * 30 + j);\n    TIME_REPEATED_OPERATION(tiny::Mat H = G.transpose();, PERFORMANCE_TEST_ITERATIONS, \"50x30 Matrix Transpose\");\n\n    // G2.4: Determinant Performance Comparison\n    // Note: Determinant calculation now has multiple methods:\n    //   - Laplace expansion: O(n!) - for small matrices (n &lt;= 4)\n    //   - LU decomposition: O(n\u00b3) - for large matrices (n &gt; 4, auto-selected)\n    //   - Gaussian elimination: O(n\u00b3) - alternative for large matrices\n    std::cout &lt;&lt; \"\\n[G2.4] Determinant Calculation Performance Comparison\\n\";\n\n    // G2.4.1: Small Matrix (4x4) - Laplace Expansion\n        std::cout &lt;&lt; \"\\n[G2.4.1] Small Matrix (4x4) - Laplace Expansion\\n\";\n    tiny::Mat I4(4, 4);\n    for (int i = 0; i &lt; 4; ++i)\n        for (int j = 0; j &lt; 4; ++j)\n            I4(i, j) = static_cast&lt;float&gt;(i * 4 + j + 1);\n\n    feed_watchdog();\n    TinyTimeMark_t det4_t0 = tiny_get_running_time();\n    for (int i = 0; i &lt; PERFORMANCE_TEST_ITERATIONS_HEAVY; ++i)\n    {\n        feed_watchdog();\n        float det = I4.determinant_laplace();\n        (void)det;\n        feed_watchdog();\n    }\n    TinyTimeMark_t det4_t1 = tiny_get_running_time();\n    double det4_dt_total_us = (double)(det4_t1 - det4_t0);\n    double det4_dt_avg_us = det4_dt_total_us / PERFORMANCE_TEST_ITERATIONS_HEAVY;\n    std::cout &lt;&lt; \"[Performance] 4x4 Determinant (Laplace, \" &lt;&lt; PERFORMANCE_TEST_ITERATIONS_HEAVY &lt;&lt; \" iterations): \"\n              &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; det4_dt_total_us &lt;&lt; \" us total, \"\n              &lt;&lt; det4_dt_avg_us &lt;&lt; \" us avg\\n\";\n\n    // G2.4.2: Large Matrix (8x8) - LU Decomposition\n        std::cout &lt;&lt; \"\\n[G2.4.2] Large Matrix (8x8) - LU Decomposition\\n\";\n    tiny::Mat I8(8, 8);\n    // Create a non-singular matrix (diagonally dominant matrix) for performance testing\n    for (int i = 0; i &lt; 8; ++i)\n    {\n        for (int j = 0; j &lt; 8; ++j)\n        {\n            if (i == j)\n                I8(i, j) = static_cast&lt;float&gt;(10 + i + 1);  // Diagonal dominance\n            else\n                I8(i, j) = static_cast&lt;float&gt;((i + 1) * (j + 1) * 0.1f);  // Off-diagonal elements\n        }\n    }\n\n    feed_watchdog();\n    TinyTimeMark_t det8_lu_t0 = tiny_get_running_time();\n    for (int i = 0; i &lt; PERFORMANCE_TEST_ITERATIONS_HEAVY; ++i)\n    {\n        feed_watchdog();\n        float det = I8.determinant_lu();\n        (void)det;\n        feed_watchdog();\n    }\n    TinyTimeMark_t det8_lu_t1 = tiny_get_running_time();\n    double det8_lu_dt_total_us = (double)(det8_lu_t1 - det8_lu_t0);\n    double det8_lu_dt_avg_us = det8_lu_dt_total_us / PERFORMANCE_TEST_ITERATIONS_HEAVY;\n    std::cout &lt;&lt; \"[Performance] 8x8 Determinant (LU, \" &lt;&lt; PERFORMANCE_TEST_ITERATIONS_HEAVY &lt;&lt; \" iterations): \"\n              &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; det8_lu_dt_total_us &lt;&lt; \" us total, \"\n              &lt;&lt; det8_lu_dt_avg_us &lt;&lt; \" us avg\\n\";\n\n    // G2.4.3: Large Matrix (8x8) - Gaussian Elimination\n        std::cout &lt;&lt; \"\\n[G2.4.3] Large Matrix (8x8) - Gaussian Elimination\\n\";\n    feed_watchdog();\n    TinyTimeMark_t det8_gauss_t0 = tiny_get_running_time();\n    for (int i = 0; i &lt; PERFORMANCE_TEST_ITERATIONS_HEAVY; ++i)\n    {\n        feed_watchdog();\n        float det = I8.determinant_gaussian();\n        (void)det;\n        feed_watchdog();\n    }\n    TinyTimeMark_t det8_gauss_t1 = tiny_get_running_time();\n    double det8_gauss_dt_total_us = (double)(det8_gauss_t1 - det8_gauss_t0);\n    double det8_gauss_dt_avg_us = det8_gauss_dt_total_us / PERFORMANCE_TEST_ITERATIONS_HEAVY;\n    std::cout &lt;&lt; \"[Performance] 8x8 Determinant (Gaussian, \" &lt;&lt; PERFORMANCE_TEST_ITERATIONS_HEAVY &lt;&lt; \" iterations): \"\n              &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; det8_gauss_dt_total_us &lt;&lt; \" us total, \"\n              &lt;&lt; det8_gauss_dt_avg_us &lt;&lt; \" us avg\\n\";\n\n    // G2.4.4: Auto-select Method (8x8) - Should use LU\n        std::cout &lt;&lt; \"\\n[G2.4.4] Large Matrix (8x8) - Auto-select Method\\n\";\n    feed_watchdog();\n    TinyTimeMark_t det8_auto_t0 = tiny_get_running_time();\n    for (int i = 0; i &lt; PERFORMANCE_TEST_ITERATIONS_HEAVY; ++i)\n    {\n        feed_watchdog();\n        float det = I8.determinant();  // Auto-selects LU for n &gt; 4\n        (void)det;\n        feed_watchdog();\n    }\n    TinyTimeMark_t det8_auto_t1 = tiny_get_running_time();\n    double det8_auto_dt_total_us = (double)(det8_auto_t1 - det8_auto_t0);\n    double det8_auto_dt_avg_us = det8_auto_dt_total_us / PERFORMANCE_TEST_ITERATIONS_HEAVY;\n    std::cout &lt;&lt; \"[Performance] 8x8 Determinant (auto-select, \" &lt;&lt; PERFORMANCE_TEST_ITERATIONS_HEAVY &lt;&lt; \" iterations): \"\n              &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; det8_auto_dt_total_us &lt;&lt; \" us total, \"\n              &lt;&lt; det8_auto_dt_avg_us &lt;&lt; \" us avg\\n\";\n\n    std::cout &lt;&lt; \"\\n[Note] Performance Summary:\\n\";\n    std::cout &lt;&lt; \"  - Laplace expansion (O(n!)): Suitable only for small matrices (n &lt;= 4)\\n\";\n    std::cout &lt;&lt; \"  - LU decomposition (O(n\u00b3)): Efficient for large matrices, auto-selected for n &gt; 4\\n\";\n    std::cout &lt;&lt; \"  - Gaussian elimination (O(n\u00b3)): Alternative efficient method for large matrices\\n\";\n    std::cout &lt;&lt; \"  - Auto-select: Automatically chooses the best method based on matrix size\\n\";\n\n    // G2.5: Matrix Copy Performance (with padding, reduced size)\n    std::cout &lt;&lt; \"\\n[G2.5] Matrix Copy with Padding Performance\\n\";\n    float data[80] = {0};  // Reduced from 150 to 80\n    for (int i = 0; i &lt; 80; ++i) data[i] = static_cast&lt;float&gt;(i);\n    tiny::Mat J(data, 8, 8, 10);  // Reduced from 10x10 stride 15 to 8x8 stride 10\n    TIME_REPEATED_OPERATION(tiny::Mat K = J.copy_roi(0, 0, 8, 8);, PERFORMANCE_TEST_ITERATIONS, \"8x8 Copy ROI (with padding)\");\n\n    // G2.6: Element Access Performance (reduced size)\n    std::cout &lt;&lt; \"\\n[G2.6] Element Access Performance\\n\";\n    tiny::Mat L(50, 50);  // Reduced from 100x100 to 50x50\n    for (int i = 0; i &lt; 50; ++i)\n        for (int j = 0; j &lt; 50; ++j)\n            L(i, j) = static_cast&lt;float&gt;(i * 50 + j);\n\n    // G2.6 continued: Element Access Performance (custom implementation for multi-line operation)\n    float sum = 0.0f;\n    std::cout &lt;&lt; \"[Performance] Computing element access (warmup)...\\n\";\n    feed_watchdog();  // Feed watchdog before starting\n    for (int w = 0; w &lt; PERFORMANCE_TEST_WARMUP; ++w)\n    {\n        feed_watchdog();  // Feed watchdog before each warmup\n        sum = 0.0f;\n        for (int i = 0; i &lt; 50; ++i)\n            for (int j = 0; j &lt; 50; ++j)\n                sum += L(i, j);\n        feed_watchdog();  // Feed watchdog after each warmup\n    }\n\n    TinyTimeMark_t elem_t0 = tiny_get_running_time();\n    for (int i = 0; i &lt; PERFORMANCE_TEST_ITERATIONS; ++i)\n    {\n        if (i % 20 == 0) feed_watchdog();  // Feed watchdog every 20 iterations (element access is fast)\n        sum = 0.0f;\n        for (int row = 0; row &lt; 50; ++row)\n            for (int col = 0; col &lt; 50; ++col)\n                sum += L(row, col);\n    }\n    feed_watchdog();  // Final feed after loop\n    TinyTimeMark_t elem_t1 = tiny_get_running_time();\n    double elem_dt_total_us = (double)(elem_t1 - elem_t0);\n    double dt_avg_us = elem_dt_total_us / PERFORMANCE_TEST_ITERATIONS;\n    std::cout &lt;&lt; \"[Performance] 50x50 Element Access (all elements) (\" &lt;&lt; PERFORMANCE_TEST_ITERATIONS &lt;&lt; \" iterations): \"\n              &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; elem_dt_total_us &lt;&lt; \" us total, \"\n              &lt;&lt; dt_avg_us &lt;&lt; \" us avg\\n\";\n}\n\n// ============================================================================\n// G3: Quality Assurance - Memory Layout Tests (Padding and Stride)\n// ============================================================================\n// Purpose: Test memory layout handling - important for performance and compatibility\nvoid test_memory_layout()\n{\n    std::cout &lt;&lt; \"\\n[G3: Quality Assurance - Memory Layout Tests (Padding and Stride)]\\n\";\n\n    // G3.1: Contiguous memory (pad=0, step=1)\n    std::cout &lt;&lt; \"\\n[G3.1] Contiguous Memory (no padding)\\n\";\n    tiny::Mat mat1(3, 4);\n    for (int i = 0; i &lt; 3; ++i)\n        for (int j = 0; j &lt; 4; ++j)\n            mat1(i, j) = static_cast&lt;float&gt;(i * 4 + j);\n    std::cout &lt;&lt; \"Matrix 3x4 (stride=4, pad=0):\\n\";\n    mat1.print_info();\n    mat1.print_matrix(true);\n\n    // G3.2: Padded memory (stride &gt; col)\n    std::cout &lt;&lt; \"\\n[G3.2] Padded Memory (stride &gt; col)\\n\";\n    float data[15] = {0, 1, 2, 3, 0, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0};\n    tiny::Mat mat2(data, 3, 4, 5);\n    std::cout &lt;&lt; \"Matrix 3x4 (stride=5, pad=1):\\n\";\n    mat2.print_info();\n    mat2.print_matrix(true);\n\n    // G3.3: Operations with padded matrices\n    std::cout &lt;&lt; \"\\n[G3.3] Addition with Padded Matrices\\n\";\n    float data1[15] = {1, 2, 3, 4, 0, 5, 6, 7, 8, 0, 9, 10, 11, 12, 0};\n    float data2[15] = {10, 20, 30, 40, 0, 50, 60, 70, 80, 0, 90, 100, 110, 120, 0};\n    tiny::Mat mat3(data1, 3, 4, 5);\n    tiny::Mat mat4(data2, 3, 4, 5);\n    tiny::Mat mat5 = mat3 + mat4;\n    std::cout &lt;&lt; \"Result of padded matrix addition:\\n\";\n    mat5.print_info();\n    mat5.print_matrix(true);\n\n    // G3.4: ROI operations with padded matrices\n    std::cout &lt;&lt; \"\\n[G3.4] ROI Operations with Padded Matrices\\n\";\n    tiny::Mat roi = mat2.view_roi(1, 1, 2, 2);\n    std::cout &lt;&lt; \"ROI (1,1,2,2) from padded matrix:\\n\";\n    roi.print_info();\n    roi.print_matrix(true);\n\n    // G3.5: Copy operations preserve stride\n    std::cout &lt;&lt; \"\\n[G3.5] Copy Operations Preserve Stride\\n\";\n    tiny::Mat copied = mat2.copy_roi(0, 0, 3, 4);\n    std::cout &lt;&lt; \"Copied matrix (should have stride=4, no padding):\\n\";\n    copied.print_info();\n    copied.print_matrix(true);\n}\n\n// ============================================================================\n// E1: Matrix Decomposition\n// ============================================================================\nvoid test_matrix_decomposition()\n{\n    std::cout &lt;&lt; \"\\n[E1: Matrix Decomposition Tests]\\n\";\n\n    // E1.1: is_positive_definite() - Basic functionality\n    std::cout &lt;&lt; \"\\n[E1.1] is_positive_definite() - Basic Functionality\\n\";\n\n    // E1.11: Positive definite matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.11] Positive Definite 3x3 Matrix\\n\";\n        tiny::Mat pd_mat(3, 3);\n        pd_mat(0, 0) = 4.0f; pd_mat(0, 1) = 1.0f; pd_mat(0, 2) = 0.0f;\n        pd_mat(1, 0) = 1.0f; pd_mat(1, 1) = 3.0f; pd_mat(1, 2) = 0.0f;\n        pd_mat(2, 0) = 0.0f; pd_mat(2, 1) = 0.0f; pd_mat(2, 2) = 2.0f;\n        std::cout &lt;&lt; \"Matrix:\\n\";\n        pd_mat.print_matrix(true);\n\n        bool is_pd = pd_mat.is_positive_definite(1e-6f);\n        std::cout &lt;&lt; \"Is positive definite: \" &lt;&lt; (is_pd ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: True) \" &lt;&lt; (is_pd ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.12: Non-positive definite matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.12] Non-Positive Definite Matrix\\n\";\n        tiny::Mat non_pd(2, 2);\n        non_pd(0, 0) = 1.0f; non_pd(0, 1) = 2.0f;\n        non_pd(1, 0) = 2.0f; non_pd(1, 1) = 1.0f;  // Has negative eigenvalue\n        std::cout &lt;&lt; \"Matrix:\\n\";\n        non_pd.print_matrix(true);\n\n        bool is_pd = non_pd.is_positive_definite(1e-6f);\n        std::cout &lt;&lt; \"Is positive definite: \" &lt;&lt; (is_pd ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: False) \" &lt;&lt; (!is_pd ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.13: max_minors_to_check parameter\n    {\n        std::cout &lt;&lt; \"\\n[E1.13] max_minors_to_check Parameter Testing\\n\";\n        tiny::Mat pd_mat(4, 4);\n        // Create a 4x4 positive definite matrix\n        pd_mat(0, 0) = 4.0f; pd_mat(0, 1) = 1.0f; pd_mat(0, 2) = 0.0f; pd_mat(0, 3) = 0.0f;\n        pd_mat(1, 0) = 1.0f; pd_mat(1, 1) = 3.0f; pd_mat(1, 2) = 0.0f; pd_mat(1, 3) = 0.0f;\n        pd_mat(2, 0) = 0.0f; pd_mat(2, 1) = 0.0f; pd_mat(2, 2) = 2.0f; pd_mat(2, 3) = 0.5f;\n        pd_mat(3, 0) = 0.0f; pd_mat(3, 1) = 0.0f; pd_mat(3, 2) = 0.5f; pd_mat(3, 3) = 1.5f;\n\n        // Test with max_minors_to_check = -1 (check all minors)\n        bool is_pd_all = pd_mat.is_positive_definite(1e-6f, -1);\n        std::cout &lt;&lt; \"max_minors_to_check = -1 (check all): \" &lt;&lt; (is_pd_all ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: True) \" &lt;&lt; (is_pd_all ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        // Test with max_minors_to_check = 3 (check first 3 minors)\n        bool is_pd_partial = pd_mat.is_positive_definite(1e-6f, 3);\n        std::cout &lt;&lt; \"max_minors_to_check = 3 (check first 3): \" &lt;&lt; (is_pd_partial ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: True) \" &lt;&lt; (is_pd_partial ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        // Test with max_minors_to_check = 0 (should return false/error)\n        bool is_pd_zero = pd_mat.is_positive_definite(1e-6f, 0);\n        std::cout &lt;&lt; \"max_minors_to_check = 0 (invalid): \" &lt;&lt; (is_pd_zero ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: False) \" &lt;&lt; (!is_pd_zero ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.14: Parameter validation - negative tolerance\n    {\n        std::cout &lt;&lt; \"\\n[E1.14] Parameter Validation - Negative Tolerance\\n\";\n        tiny::Mat pd_mat(2, 2);\n        pd_mat(0, 0) = 2.0f; pd_mat(0, 1) = 0.0f;\n        pd_mat(1, 0) = 0.0f; pd_mat(1, 1) = 2.0f;\n\n        // Test with tolerance &lt; 0 (should return false/error)\n        bool is_pd_neg = pd_mat.is_positive_definite(-1e-6f);\n        std::cout &lt;&lt; \"tolerance = -1e-6 (invalid): \" &lt;&lt; (is_pd_neg ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: False) \" &lt;&lt; (!is_pd_neg ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.15: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.15] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        // Empty matrix cannot be positive definite (data is null or invalid dimensions)\n        bool is_pd_empty = empty_mat.is_positive_definite(1e-6f);\n        std::cout &lt;&lt; \"Empty matrix (0x0): \" &lt;&lt; (is_pd_empty ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: False, empty matrix is invalid) \" &lt;&lt; (!is_pd_empty ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.16: Boundary case - invalid dimensions\n    {\n        std::cout &lt;&lt; \"\\n[E1.16] Boundary Case - Invalid Dimensions\\n\";\n        tiny::Mat invalid_mat(2, 3);  // Non-square matrix\n\n        // Non-square matrix cannot be positive definite\n        bool is_pd_invalid = invalid_mat.is_positive_definite(1e-6f);\n        std::cout &lt;&lt; \"Non-square matrix (2x3): \" &lt;&lt; (is_pd_invalid ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: False) \" &lt;&lt; (!is_pd_invalid ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.2: LU Decomposition\n    std::cout &lt;&lt; \"\\n[E1.2] LU Decomposition\\n\";\n\n    // E1.21: Simple 3x3 matrix with pivoting\n    {\n        std::cout &lt;&lt; \"\\n[E1.21] 3x3 Matrix - LU Decomposition with Pivoting\\n\";\n        tiny::Mat A(3, 3);\n        A(0, 0) = 2.0f; A(0, 1) = 1.0f; A(0, 2) = 1.0f;\n        A(1, 0) = 4.0f; A(1, 1) = 3.0f; A(1, 2) = 3.0f;\n        A(2, 0) = 2.0f; A(2, 1) = 1.0f; A(2, 2) = 2.0f;\n        std::cout &lt;&lt; \"Matrix A:\\n\";\n        A.print_matrix(true);\n\n        tiny::Mat::LUDecomposition lu = A.lu_decompose(true);\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (lu.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        if (lu.status == TINY_OK)\n        {\n            std::cout &lt;&lt; \"L matrix (lower triangular):\\n\";\n            lu.L.print_matrix(true);\n            std::cout &lt;&lt; \"U matrix (upper triangular):\\n\";\n            lu.U.print_matrix(true);\n            if (lu.pivoted)\n            {\n                std::cout &lt;&lt; \"P matrix (permutation):\\n\";\n                lu.P.print_matrix(true);\n            }\n\n            // Verify: P * A = L * U\n            tiny::Mat PA = lu.P * A;\n            tiny::Mat LU = lu.L * lu.U;\n            std::cout &lt;&lt; \"\\n[Verification] P * A should equal L * U\\n\";\n            float diff = 0.0f;\n            for (int i = 0; i &lt; 3; ++i)\n            {\n                for (int j = 0; j &lt; 3; ++j)\n                {\n                    diff += fabsf(PA(i, j) - LU(i, j));\n                }\n            }\n            std::cout &lt;&lt; \"Total difference: \" &lt;&lt; diff &lt;&lt; (diff &lt; 0.01f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E1.22: Solve using LU decomposition\n    {\n        std::cout &lt;&lt; \"\\n[E1.22] Solve Linear System using LU Decomposition\\n\";\n        tiny::Mat A(3, 3);\n        A(0, 0) = 2.0f; A(0, 1) = 1.0f; A(0, 2) = 1.0f;\n        A(1, 0) = 4.0f; A(1, 1) = 3.0f; A(1, 2) = 3.0f;\n        A(2, 0) = 2.0f; A(2, 1) = 1.0f; A(2, 2) = 2.0f;\n        tiny::Mat b(3, 1);\n        b(0, 0) = 1.0f;\n        b(1, 0) = 2.0f;\n        b(2, 0) = 3.0f;\n\n        std::cout &lt;&lt; \"System: A * x = b\\n\";\n        std::cout &lt;&lt; \"A:\\n\";\n        A.print_matrix(true);\n        std::cout &lt;&lt; \"b:\\n\";\n        b.print_matrix(true);\n\n        tiny::Mat::LUDecomposition lu = A.lu_decompose(true);\n        tiny::Mat x = tiny::Mat::solve_lu(lu, b);\n\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Solution x:\\n\";\n        x.print_matrix(true);\n\n        // Verify: A * x = b\n        tiny::Mat Ax = A * x;\n        float error = 0.0f;\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            error += fabsf(Ax(i, 0) - b(i, 0));\n        }\n        std::cout &lt;&lt; \"Verification error: \" &lt;&lt; error &lt;&lt; (error &lt; 0.01f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.26: solve_lu() - Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.26] solve_lu() - Boundary Case - Empty Matrix\\n\";\n        tiny::Mat empty_A(0, 0);\n        tiny::Mat empty_b(0, 1);\n\n        tiny::Mat::LUDecomposition lu_empty = empty_A.lu_decompose(true);\n        tiny::Mat x_empty = tiny::Mat::solve_lu(lu_empty, empty_b);\n        // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n        bool empty_correct = (x_empty.row == 0 &amp;&amp; x_empty.col == 0) || \n                            (x_empty.data == nullptr) ||\n                            (x_empty.row == 1 &amp;&amp; x_empty.col == 1 &amp;&amp; x_empty.data != nullptr);\n        std::cout &lt;&lt; \"Empty system: x rows = \" &lt;&lt; x_empty.row \n                  &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.27: solve_lu() - Invalid LU decomposition\n    {\n        std::cout &lt;&lt; \"\\n[E1.27] solve_lu() - Invalid LU Decomposition\\n\";\n        tiny::Mat::LUDecomposition invalid_lu;\n        invalid_lu.status = TINY_ERR_INVALID_ARG;  // Simulate invalid decomposition\n\n        tiny::Mat b(3, 1);\n        b(0, 0) = 1.0f; b(1, 0) = 2.0f; b(2, 0) = 3.0f;\n\n        tiny::Mat x_invalid = tiny::Mat::solve_lu(invalid_lu, b);\n        // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n        bool invalid_correct = (x_invalid.row == 0 &amp;&amp; x_invalid.col == 0) || \n                               (x_invalid.data == nullptr) ||\n                               (x_invalid.row == 1 &amp;&amp; x_invalid.col == 1 &amp;&amp; x_invalid.data != nullptr);\n        std::cout &lt;&lt; \"Invalid LU decomposition: x rows = \" &lt;&lt; x_invalid.row \n                  &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (invalid_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.23: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.23] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        tiny::Mat::LUDecomposition lu_empty = empty_mat.lu_decompose(true);\n        // Error case: empty matrix should return error status, L may be 0x0 or 1x1 error matrix\n        bool empty_correct = (lu_empty.status != TINY_OK) &amp;&amp; \n                            ((lu_empty.L.row == 0 &amp;&amp; lu_empty.L.col == 0) || \n                             (lu_empty.L.data == nullptr) ||\n                             (lu_empty.L.row == 1 &amp;&amp; lu_empty.L.col == 1 &amp;&amp; lu_empty.L.data != nullptr));\n        std::cout &lt;&lt; \"Empty matrix: Status = \" &lt;&lt; (lu_empty.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \", L rows = \" &lt;&lt; lu_empty.L.row \n                  &lt;&lt; \" (Expected: Error status, L is 0x0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.24: lu_decompose() - without pivoting\n    {\n        std::cout &lt;&lt; \"\\n[E1.24] LU Decomposition without Pivoting\\n\";\n        tiny::Mat A(3, 3);\n        A(0, 0) = 2.0f; A(0, 1) = 1.0f; A(0, 2) = 1.0f;\n        A(1, 0) = 4.0f; A(1, 1) = 3.0f; A(1, 2) = 3.0f;\n        A(2, 0) = 2.0f; A(2, 1) = 1.0f; A(2, 2) = 2.0f;\n\n        tiny::Mat::LUDecomposition lu_no_pivot = A.lu_decompose(false);\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (lu_no_pivot.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Pivoted: \" &lt;&lt; (lu_no_pivot.pivoted ? \"Yes\" : \"No (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (!lu_no_pivot.pivoted ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n        if (lu_no_pivot.status == TINY_OK &amp;&amp; !lu_no_pivot.pivoted)\n        {\n            // Verify: A = L * U (no permutation)\n            tiny::Mat LU = lu_no_pivot.L * lu_no_pivot.U;\n            float diff = 0.0f;\n            for (int i = 0; i &lt; 3; ++i)\n            {\n                for (int j = 0; j &lt; 3; ++j)\n                {\n                    diff += fabsf(LU(i, j) - A(i, j));\n                }\n            }\n            std::cout &lt;&lt; \"Verification (A = L * U): difference = \" &lt;&lt; diff \n                      &lt;&lt; (diff &lt; 0.01f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E1.25: lu_decompose() - Error handling - non-square matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.25] lu_decompose() - Error Handling - Non-Square Matrix\\n\";\n        tiny::Mat non_square(2, 3);\n        tiny::Mat::LUDecomposition lu_non_square = non_square.lu_decompose(true);\n        std::cout &lt;&lt; \"Non-square matrix (2x3): Status = \" &lt;&lt; (lu_non_square.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (lu_non_square.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.3: Cholesky Decomposition\n    std::cout &lt;&lt; \"\\n[E1.3] Cholesky Decomposition\\n\";\n\n    // E1.31: Symmetric positive definite matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.31] SPD Matrix - Cholesky Decomposition\\n\";\n        tiny::Mat spd(3, 3);\n        spd(0, 0) = 4.0f; spd(0, 1) = 2.0f; spd(0, 2) = 0.0f;\n        spd(1, 0) = 2.0f; spd(1, 1) = 5.0f; spd(1, 2) = 1.0f;\n        spd(2, 0) = 0.0f; spd(2, 1) = 1.0f; spd(2, 2) = 3.0f;\n        std::cout &lt;&lt; \"Matrix A (SPD):\\n\";\n        spd.print_matrix(true);\n\n        tiny::Mat::CholeskyDecomposition chol = spd.cholesky_decompose();\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (chol.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        if (chol.status == TINY_OK)\n        {\n            std::cout &lt;&lt; \"L matrix (lower triangular):\\n\";\n            chol.L.print_matrix(true);\n\n            // Verify: A = L * L^T\n            tiny::Mat LLT = chol.L * chol.L.transpose();\n            std::cout &lt;&lt; \"\\n[Verification] L * L^T should equal A\\n\";\n            float diff = 0.0f;\n            for (int i = 0; i &lt; 3; ++i)\n            {\n                for (int j = 0; j &lt; 3; ++j)\n                {\n                    diff += fabsf(LLT(i, j) - spd(i, j));\n                }\n            }\n            std::cout &lt;&lt; \"Total difference: \" &lt;&lt; diff &lt;&lt; (diff &lt; 0.01f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E1.32: Solve using Cholesky decomposition\n    {\n        std::cout &lt;&lt; \"\\n[E1.32] Solve Linear System using Cholesky Decomposition\\n\";\n        tiny::Mat A(3, 3);\n        A(0, 0) = 4.0f; A(0, 1) = 2.0f; A(0, 2) = 0.0f;\n        A(1, 0) = 2.0f; A(1, 1) = 5.0f; A(1, 2) = 1.0f;\n        A(2, 0) = 0.0f; A(2, 1) = 1.0f; A(2, 2) = 3.0f;\n        tiny::Mat b(3, 1);\n        b(0, 0) = 2.0f;\n        b(1, 0) = 3.0f;\n        b(2, 0) = 1.0f;\n\n        tiny::Mat::CholeskyDecomposition chol = A.cholesky_decompose();\n        tiny::Mat x = tiny::Mat::solve_cholesky(chol, b);\n\n        std::cout &lt;&lt; \"Solution x:\\n\";\n        x.print_matrix(true);\n\n        // Verify: A * x = b\n        tiny::Mat Ax = A * x;\n        float error = 0.0f;\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            error += fabsf(Ax(i, 0) - b(i, 0));\n        }\n        std::cout &lt;&lt; \"Verification error: \" &lt;&lt; error &lt;&lt; (error &lt; 0.01f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.35: solve_cholesky() - Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.35] solve_cholesky() - Boundary Case - Empty Matrix\\n\";\n        tiny::Mat empty_A(0, 0);\n        tiny::Mat empty_b(0, 1);\n\n        tiny::Mat::CholeskyDecomposition chol_empty = empty_A.cholesky_decompose();\n        tiny::Mat x_empty = tiny::Mat::solve_cholesky(chol_empty, empty_b);\n        // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n        bool empty_correct = (x_empty.row == 0 &amp;&amp; x_empty.col == 0) || \n                            (x_empty.data == nullptr) ||\n                            (x_empty.row == 1 &amp;&amp; x_empty.col == 1 &amp;&amp; x_empty.data != nullptr);\n        std::cout &lt;&lt; \"Empty system: x rows = \" &lt;&lt; x_empty.row \n                  &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.36: solve_cholesky() - Invalid Cholesky decomposition\n    {\n        std::cout &lt;&lt; \"\\n[E1.36] solve_cholesky() - Invalid Cholesky Decomposition\\n\";\n        tiny::Mat::CholeskyDecomposition invalid_chol;\n        invalid_chol.status = TINY_ERR_INVALID_ARG;  // Simulate invalid decomposition\n\n        tiny::Mat b(3, 1);\n        b(0, 0) = 1.0f; b(1, 0) = 2.0f; b(2, 0) = 3.0f;\n\n        tiny::Mat x_invalid = tiny::Mat::solve_cholesky(invalid_chol, b);\n        // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n        bool invalid_correct = (x_invalid.row == 0 &amp;&amp; x_invalid.col == 0) || \n                               (x_invalid.data == nullptr) ||\n                               (x_invalid.row == 1 &amp;&amp; x_invalid.col == 1 &amp;&amp; x_invalid.data != nullptr);\n        std::cout &lt;&lt; \"Invalid Cholesky decomposition: x rows = \" &lt;&lt; x_invalid.row \n                  &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (invalid_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.33: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.33] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        tiny::Mat::CholeskyDecomposition chol_empty = empty_mat.cholesky_decompose();\n        // Error case: empty matrix should return error status, L may be 0x0 or 1x1 error matrix\n        bool empty_correct = (chol_empty.status != TINY_OK) &amp;&amp; \n                            ((chol_empty.L.row == 0 &amp;&amp; chol_empty.L.col == 0) || \n                             (chol_empty.L.data == nullptr) ||\n                             (chol_empty.L.row == 1 &amp;&amp; chol_empty.L.col == 1 &amp;&amp; chol_empty.L.data != nullptr));\n        std::cout &lt;&lt; \"Empty matrix: Status = \" &lt;&lt; (chol_empty.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \", L rows = \" &lt;&lt; chol_empty.L.row \n                  &lt;&lt; \" (Expected: Error status, L is 0x0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.34: Non-symmetric matrix (should fail)\n    {\n        std::cout &lt;&lt; \"\\n[E1.34] Non-Symmetric Matrix (Should Fail)\\n\";\n        tiny::Mat non_sym(2, 2);\n        non_sym(0, 0) = 1.0f; non_sym(0, 1) = 2.0f;\n        non_sym(1, 0) = 3.0f; non_sym(1, 1) = 4.0f;  // Non-symmetric\n\n        tiny::Mat::CholeskyDecomposition chol_non_sym = non_sym.cholesky_decompose();\n        std::cout &lt;&lt; \"Non-symmetric matrix: Status = \" &lt;&lt; (chol_non_sym.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (chol_non_sym.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.37: solve_cholesky() - Error handling - dimension mismatch\n    {\n        std::cout &lt;&lt; \"\\n[E1.37] solve_cholesky() - Error Handling - Dimension Mismatch\\n\";\n        tiny::Mat A(3, 3);\n        A(0, 0) = 4.0f; A(0, 1) = 2.0f; A(0, 2) = 0.0f;\n        A(1, 0) = 2.0f; A(1, 1) = 5.0f; A(1, 2) = 1.0f;\n        A(2, 0) = 0.0f; A(2, 1) = 1.0f; A(2, 2) = 3.0f;\n        tiny::Mat b(4, 1);  // Wrong dimension\n        tiny::Mat::CholeskyDecomposition chol = A.cholesky_decompose();\n        if (chol.status == TINY_OK)\n        {\n            tiny::Mat x_mismatch = tiny::Mat::solve_cholesky(chol, b);\n            // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n            // For dimension mismatch, expected solution size is 3x1, so 1x1 indicates error\n            bool solve_mismatch_correct = (x_mismatch.row == 0 &amp;&amp; x_mismatch.col == 0) || \n                                         (x_mismatch.data == nullptr) ||\n                                         (x_mismatch.row == 1 &amp;&amp; x_mismatch.col == 1 &amp;&amp; x_mismatch.data != nullptr);\n            std::cout &lt;&lt; \"Dimension mismatch solve_cholesky: \" &lt;&lt; (solve_mismatch_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n                      &lt;&lt; \" \" &lt;&lt; (solve_mismatch_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E1.4: QR Decomposition\n    std::cout &lt;&lt; \"\\n[E1.4] QR Decomposition\\n\";\n\n    // E1.41: General matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.41] General 3x3 Matrix - QR Decomposition\\n\";\n        tiny::Mat A(3, 3);\n        A(0, 0) = 1.0f; A(0, 1) = 2.0f; A(0, 2) = 3.0f;\n        A(1, 0) = 4.0f; A(1, 1) = 5.0f; A(1, 2) = 6.0f;\n        A(2, 0) = 7.0f; A(2, 1) = 8.0f; A(2, 2) = 9.0f;\n        std::cout &lt;&lt; \"Matrix A:\\n\";\n        A.print_matrix(true);\n\n        tiny::Mat::QRDecomposition qr = A.qr_decompose();\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (qr.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        if (qr.status == TINY_OK)\n        {\n            std::cout &lt;&lt; \"Q matrix (orthogonal):\\n\";\n            qr.Q.print_matrix(true);\n            std::cout &lt;&lt; \"R matrix (upper triangular):\\n\";\n            qr.R.print_matrix(true);\n\n            // Verify: A = Q * R\n            tiny::Mat QR = qr.Q * qr.R;\n            std::cout &lt;&lt; \"\\n[Verification] Q * R should equal A\\n\";\n            float diff = 0.0f;\n            for (int i = 0; i &lt; 3; ++i)\n            {\n                for (int j = 0; j &lt; 3; ++j)\n                {\n                    diff += fabsf(QR(i, j) - A(i, j));\n                }\n            }\n            std::cout &lt;&lt; \"Total difference: \" &lt;&lt; diff &lt;&lt; (diff &lt; 0.1f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n\n            // Verify Q is orthogonal: Q^T * Q = I\n            tiny::Mat QtQ = qr.Q.transpose() * qr.Q;\n            tiny::Mat I = tiny::Mat::eye(3);\n            float ortho_diff = 0.0f;\n            for (int i = 0; i &lt; 3; ++i)\n            {\n                for (int j = 0; j &lt; 3; ++j)\n                {\n                    ortho_diff += fabsf(QtQ(i, j) - I(i, j));\n                }\n            }\n            std::cout &lt;&lt; \"Q orthogonality error: \" &lt;&lt; ortho_diff &lt;&lt; (ortho_diff &lt; 0.1f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E1.42: Solve using QR decomposition (least squares)\n    {\n        std::cout &lt;&lt; \"\\n[E1.42] Least Squares Solution using QR Decomposition\\n\";\n        tiny::Mat A(3, 2);  // Overdetermined system\n        A(0, 0) = 1.0f; A(0, 1) = 1.0f;\n        A(1, 0) = 1.0f; A(1, 1) = 2.0f;\n        A(2, 0) = 1.0f; A(2, 1) = 3.0f;\n        tiny::Mat b(3, 1);\n        b(0, 0) = 2.0f;\n        b(1, 0) = 3.0f;\n        b(2, 0) = 4.0f;\n\n        std::cout &lt;&lt; \"Overdetermined system: A * x \u2248 b\\n\";\n        std::cout &lt;&lt; \"A:\\n\";\n        A.print_matrix(true);\n        std::cout &lt;&lt; \"b:\\n\";\n        b.print_matrix(true);\n\n        tiny::Mat::QRDecomposition qr = A.qr_decompose();\n        tiny::Mat x = tiny::Mat::solve_qr(qr, b);\n\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Least squares solution x:\\n\";\n        x.print_matrix(true);\n\n        // Compute residual: ||A * x - b||\n        tiny::Mat Ax = A * x;\n        tiny::Mat residual = Ax - b;\n        float residual_norm = 0.0f;\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            residual_norm += residual(i, 0) * residual(i, 0);\n        }\n        residual_norm = sqrtf(residual_norm);\n        std::cout &lt;&lt; \"Residual norm ||A*x - b||: \" &lt;&lt; residual_norm &lt;&lt; \"\\n\";\n    }\n\n    // E1.46: solve_qr() - Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.46] solve_qr() - Boundary Case - Empty Matrix\\n\";\n        tiny::Mat empty_A(0, 0);\n        tiny::Mat empty_b(0, 1);\n\n        tiny::Mat::QRDecomposition qr_empty = empty_A.qr_decompose();\n        tiny::Mat x_empty = tiny::Mat::solve_qr(qr_empty, empty_b);\n        // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n        bool empty_correct = (x_empty.row == 0 &amp;&amp; x_empty.col == 0) || \n                            (x_empty.data == nullptr) ||\n                            (x_empty.row == 1 &amp;&amp; x_empty.col == 1 &amp;&amp; x_empty.data != nullptr);\n        std::cout &lt;&lt; \"Empty system: x rows = \" &lt;&lt; x_empty.row \n                  &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.47: solve_qr() - Invalid QR decomposition\n    {\n        std::cout &lt;&lt; \"\\n[E1.47] solve_qr() - Invalid QR Decomposition\\n\";\n        tiny::Mat::QRDecomposition invalid_qr;\n        invalid_qr.status = TINY_ERR_INVALID_ARG;  // Simulate invalid decomposition\n\n        tiny::Mat b(3, 1);\n        b(0, 0) = 1.0f; b(1, 0) = 2.0f; b(2, 0) = 3.0f;\n\n        tiny::Mat x_invalid = tiny::Mat::solve_qr(invalid_qr, b);\n        // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n        bool invalid_correct = (x_invalid.row == 0 &amp;&amp; x_invalid.col == 0) || \n                               (x_invalid.data == nullptr) ||\n                               (x_invalid.row == 1 &amp;&amp; x_invalid.col == 1 &amp;&amp; x_invalid.data != nullptr);\n        std::cout &lt;&lt; \"Invalid QR decomposition: x rows = \" &lt;&lt; x_invalid.row \n                  &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (invalid_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.43: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.43] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        tiny::Mat::QRDecomposition qr_empty = empty_mat.qr_decompose();\n        // Error case: empty matrix should return error status, Q may be 0x0 or 1x1 error matrix\n        bool empty_correct = (qr_empty.status != TINY_OK) &amp;&amp; \n                            ((qr_empty.Q.row == 0 &amp;&amp; qr_empty.Q.col == 0) || \n                             (qr_empty.Q.data == nullptr) ||\n                             (qr_empty.Q.row == 1 &amp;&amp; qr_empty.Q.col == 1 &amp;&amp; qr_empty.Q.data != nullptr));\n        std::cout &lt;&lt; \"Empty matrix: Status = \" &lt;&lt; (qr_empty.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \", Q rows = \" &lt;&lt; qr_empty.Q.row \n                  &lt;&lt; \" (Expected: Error status, Q is 0x0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.44: Boundary case - m=0 or n=0\n    {\n        std::cout &lt;&lt; \"\\n[E1.44] Boundary Case - Zero Rows or Columns\\n\";\n        tiny::Mat zero_rows(0, 3);\n        tiny::Mat zero_cols(3, 0);\n\n        tiny::Mat::QRDecomposition qr_zero_rows = zero_rows.qr_decompose();\n        // Zero rows/cols should return error status (invalid matrix)\n        std::cout &lt;&lt; \"Matrix with 0 rows (0x3): Status = \" &lt;&lt; (qr_zero_rows.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \" \" &lt;&lt; (qr_zero_rows.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        tiny::Mat::QRDecomposition qr_zero_cols = zero_cols.qr_decompose();\n        // Zero rows/cols should return error status (invalid matrix)\n        std::cout &lt;&lt; \"Matrix with 0 cols (3x0): Status = \" &lt;&lt; (qr_zero_cols.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \" \" &lt;&lt; (qr_zero_cols.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.45: solve_qr() - Error handling - dimension mismatch\n    {\n        std::cout &lt;&lt; \"\\n[E1.45] solve_qr() - Error Handling - Dimension Mismatch\\n\";\n        tiny::Mat A(3, 2);\n        tiny::Mat b(4, 1);  // Wrong dimension\n        tiny::Mat::QRDecomposition qr = A.qr_decompose();\n        if (qr.status == TINY_OK)\n        {\n            tiny::Mat x_mismatch = tiny::Mat::solve_qr(qr, b);\n            // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n            // For dimension mismatch, expected solution size is 2x1, so 1x1 indicates error\n            bool solve_mismatch_correct = (x_mismatch.row == 0 &amp;&amp; x_mismatch.col == 0) || \n                                         (x_mismatch.data == nullptr) ||\n                                         (x_mismatch.row == 1 &amp;&amp; x_mismatch.col == 1 &amp;&amp; x_mismatch.data != nullptr);\n            std::cout &lt;&lt; \"Dimension mismatch solve_qr: \" &lt;&lt; (solve_mismatch_correct ? \"Empty matrix or error state (Expected)\" : \"Non-empty (Error)\") \n                      &lt;&lt; \" \" &lt;&lt; (solve_mismatch_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E1.5: SVD Decomposition\n    std::cout &lt;&lt; \"\\n[E1.5] Singular Value Decomposition (SVD)\\n\";\n\n    // E1.51: General matrix\n    {\n        std::cout &lt;&lt; \"\\n[E1.51] General 3x3 Matrix - SVD Decomposition\\n\";\n        tiny::Mat A(3, 3);\n        A(0, 0) = 1.0f; A(0, 1) = 2.0f; A(0, 2) = 3.0f;\n        A(1, 0) = 4.0f; A(1, 1) = 5.0f; A(1, 2) = 6.0f;\n        A(2, 0) = 7.0f; A(2, 1) = 8.0f; A(2, 2) = 9.0f;\n        std::cout &lt;&lt; \"Matrix A:\\n\";\n        A.print_matrix(true);\n\n        tiny::Mat::SVDDecomposition svd = A.svd_decompose(100, 1e-6f);\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (svd.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        if (svd.status == TINY_OK)\n        {\n            std::cout &lt;&lt; \"Singular values:\\n\";\n            svd.S.print_matrix(true);\n            std::cout &lt;&lt; \"Numerical rank: \" &lt;&lt; svd.rank &lt;&lt; \"\\n\";\n            std::cout &lt;&lt; \"Iterations: \" &lt;&lt; svd.iterations &lt;&lt; \"\\n\";\n\n            // Verify: A \u2248 U * S * V^T (for first rank columns)\n            if (svd.rank &gt; 0)\n            {\n                tiny::Mat US(svd.U.row, svd.rank);\n                for (int i = 0; i &lt; svd.U.row; ++i)\n                {\n                    for (int j = 0; j &lt; svd.rank; ++j)\n                    {\n                        US(i, j) = svd.U(i, j) * svd.S(j, 0);\n                    }\n                }\n                tiny::Mat Vt(svd.rank, svd.V.row);\n                for (int i = 0; i &lt; svd.rank; ++i)\n                {\n                    for (int j = 0; j &lt; svd.V.row; ++j)\n                    {\n                        Vt(i, j) = svd.V(j, i);  // V^T\n                    }\n                }\n                tiny::Mat USVt = US * Vt;\n\n                float diff = 0.0f;\n                for (int i = 0; i &lt; 3; ++i)\n                {\n                    for (int j = 0; j &lt; 3; ++j)\n                    {\n                        diff += fabsf(USVt(i, j) - A(i, j));\n                    }\n                }\n                std::cout &lt;&lt; \"Reconstruction error: \" &lt;&lt; diff &lt;&lt; (diff &lt; 0.5f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n            }\n        }\n    }\n\n    // E1.52: Pseudo-inverse using SVD\n    {\n        std::cout &lt;&lt; \"\\n[E1.52] Pseudo-inverse using SVD\\n\";\n        tiny::Mat A(3, 2);  // Non-square matrix\n        A(0, 0) = 1.0f; A(0, 1) = 2.0f;\n        A(1, 0) = 3.0f; A(1, 1) = 4.0f;\n        A(2, 0) = 5.0f; A(2, 1) = 6.0f;\n\n        std::cout &lt;&lt; \"Matrix A (3x2):\\n\";\n        A.print_matrix(true);\n\n        tiny::Mat::SVDDecomposition svd = A.svd_decompose(100, 1e-6f);\n        tiny::Mat A_plus = tiny::Mat::pseudo_inverse(svd, 1e-6f);\n\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Pseudo-inverse A^+ (2x3):\\n\";\n        A_plus.print_matrix(true);\n\n        // Verify: A * A^+ * A \u2248 A\n        tiny::Mat AAplusA = A * A_plus * A;\n        float diff = 0.0f;\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            for (int j = 0; j &lt; 2; ++j)\n            {\n                diff += fabsf(AAplusA(i, j) - A(i, j));\n            }\n        }\n        std::cout &lt;&lt; \"Verification error (A * A^+ * A \u2248 A): \" &lt;&lt; diff &lt;&lt; (diff &lt; 0.1f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.57: pseudo_inverse() - Parameter validation - tolerance &lt; 0\n    {\n        std::cout &lt;&lt; \"\\n[E1.57] pseudo_inverse() - Parameter Validation - tolerance &lt; 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 1.0f; test_mat(0, 1) = 2.0f;\n        test_mat(1, 0) = 3.0f; test_mat(1, 1) = 4.0f;\n\n        tiny::Mat::SVDDecomposition svd = test_mat.svd_decompose(100, 1e-6f);\n        if (svd.status == TINY_OK)\n        {\n            tiny::Mat A_plus_neg = tiny::Mat::pseudo_inverse(svd, -1e-6f);\n            // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n            bool neg_tol_correct = (A_plus_neg.row == 0 &amp;&amp; A_plus_neg.col == 0) || \n                                  (A_plus_neg.data == nullptr) ||\n                                  (A_plus_neg.row == 1 &amp;&amp; A_plus_neg.col == 1 &amp;&amp; A_plus_neg.data != nullptr);\n            std::cout &lt;&lt; \"tolerance = -1e-6: A_plus rows = \" &lt;&lt; A_plus_neg.row \n                      &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (neg_tol_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E1.58: pseudo_inverse() - Invalid SVD decomposition\n    {\n        std::cout &lt;&lt; \"\\n[E1.58] pseudo_inverse() - Invalid SVD Decomposition\\n\";\n        tiny::Mat::SVDDecomposition invalid_svd;\n        invalid_svd.status = TINY_ERR_INVALID_ARG;  // Simulate invalid decomposition\n\n        tiny::Mat A_plus_invalid = tiny::Mat::pseudo_inverse(invalid_svd, 1e-6f);\n        // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n        bool pseudo_inv_invalid_correct = (A_plus_invalid.row == 0 &amp;&amp; A_plus_invalid.col == 0) || \n                                          (A_plus_invalid.data == nullptr) ||\n                                          (A_plus_invalid.row == 1 &amp;&amp; A_plus_invalid.col == 1 &amp;&amp; A_plus_invalid.data != nullptr);\n        std::cout &lt;&lt; \"Invalid SVD decomposition: A_plus rows = \" &lt;&lt; A_plus_invalid.row \n                  &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (pseudo_inv_invalid_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.53: Parameter validation - max_iter &lt;= 0\n    {\n        std::cout &lt;&lt; \"\\n[E1.53] Parameter Validation - max_iter &lt;= 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 1.0f; test_mat(0, 1) = 2.0f;\n        test_mat(1, 0) = 3.0f; test_mat(1, 1) = 4.0f;\n\n        tiny::Mat::SVDDecomposition result_zero = test_mat.svd_decompose(0, 1e-6f);\n        std::cout &lt;&lt; \"max_iter = 0: Status = \" &lt;&lt; (result_zero.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_zero.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        tiny::Mat::SVDDecomposition result_neg = test_mat.svd_decompose(-1, 1e-6f);\n        std::cout &lt;&lt; \"max_iter = -1: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.54: Parameter validation - tolerance &lt; 0\n    {\n        std::cout &lt;&lt; \"\\n[E1.54] Parameter Validation - tolerance &lt; 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 1.0f; test_mat(0, 1) = 2.0f;\n        test_mat(1, 0) = 3.0f; test_mat(1, 1) = 4.0f;\n\n        tiny::Mat::SVDDecomposition result_neg = test_mat.svd_decompose(100, -1e-6f);\n        std::cout &lt;&lt; \"tolerance = -1e-6: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.55: Boundary case - empty matrix (m=0 or n=0)\n    {\n        std::cout &lt;&lt; \"\\n[E1.55] Boundary Case - Empty Matrix (m=0 or n=0)\\n\";\n        tiny::Mat zero_rows(0, 3);\n        tiny::Mat zero_cols(3, 0);\n\n        tiny::Mat::SVDDecomposition svd_zero_rows = zero_rows.svd_decompose(100, 1e-6f);\n        // Zero rows/cols should return error status (invalid matrix)\n        std::cout &lt;&lt; \"Matrix with 0 rows (0x3): Status = \" &lt;&lt; (svd_zero_rows.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \" \" &lt;&lt; (svd_zero_rows.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        tiny::Mat::SVDDecomposition svd_zero_cols = zero_cols.svd_decompose(100, 1e-6f);\n        // Zero rows/cols should return error status (invalid matrix)\n        std::cout &lt;&lt; \"Matrix with 0 cols (3x0): Status = \" &lt;&lt; (svd_zero_cols.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \" \" &lt;&lt; (svd_zero_cols.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.56: pseudo_inverse() - Error handling - invalid SVD decomposition\n    {\n        std::cout &lt;&lt; \"\\n[E1.56] pseudo_inverse() - Error Handling - Invalid SVD Decomposition\\n\";\n        tiny::Mat::SVDDecomposition invalid_svd;\n        invalid_svd.status = TINY_ERR_INVALID_ARG;  // Simulate invalid decomposition\n\n        tiny::Mat A_plus_invalid = tiny::Mat::pseudo_inverse(invalid_svd, 1e-6f);\n        // Error case should return empty matrix (0x0) or error state (1x1 error matrix)\n        bool pseudo_inv_invalid_correct = (A_plus_invalid.row == 0 &amp;&amp; A_plus_invalid.col == 0) || \n                                          (A_plus_invalid.data == nullptr) ||\n                                          (A_plus_invalid.row == 1 &amp;&amp; A_plus_invalid.col == 1 &amp;&amp; A_plus_invalid.data != nullptr);\n        std::cout &lt;&lt; \"Invalid SVD decomposition: A_plus rows = \" &lt;&lt; A_plus_invalid.row \n                  &lt;&lt; \" (Expected: 0 or error state) \" &lt;&lt; (pseudo_inv_invalid_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E1.6: Performance Tests\n    std::cout &lt;&lt; \"\\n[E1.6] Matrix Decomposition Performance Tests\\n\";\n\n    tiny::Mat perf_mat(4, 4);\n    perf_mat(0, 0) = 4.0f; perf_mat(0, 1) = 2.0f; perf_mat(0, 2) = 1.0f; perf_mat(0, 3) = 0.0f;\n    perf_mat(1, 0) = 2.0f; perf_mat(1, 1) = 5.0f; perf_mat(1, 2) = 1.0f; perf_mat(1, 3) = 0.0f;\n    perf_mat(2, 0) = 1.0f; perf_mat(2, 1) = 1.0f; perf_mat(2, 2) = 3.0f; perf_mat(2, 3) = 1.0f;\n    perf_mat(3, 0) = 0.0f; perf_mat(3, 1) = 0.0f; perf_mat(3, 2) = 1.0f; perf_mat(3, 3) = 2.0f;\n\n    // E1.61: LU decomposition performance\n    std::cout &lt;&lt; \"\\n[E1.61] LU Decomposition Performance\\n\";\n    TIME_OPERATION(\n        tiny::Mat::LUDecomposition perf_lu = perf_mat.lu_decompose(true);\n        (void)perf_lu;\n    , \"LU Decomposition (4x4 matrix)\");\n\n    // E1.62: Cholesky decomposition performance\n    std::cout &lt;&lt; \"\\n[E1.62] Cholesky Decomposition Performance\\n\";\n    TIME_OPERATION(\n        tiny::Mat::CholeskyDecomposition perf_chol = perf_mat.cholesky_decompose();\n        (void)perf_chol;\n    , \"Cholesky Decomposition (4x4 SPD matrix)\");\n\n    // E1.63: QR decomposition performance\n    std::cout &lt;&lt; \"\\n[E1.63] QR Decomposition Performance\\n\";\n    TIME_OPERATION(\n        tiny::Mat::QRDecomposition perf_qr = perf_mat.qr_decompose();\n        (void)perf_qr;\n    , \"QR Decomposition (4x4 matrix)\");\n\n    // E1.64: SVD decomposition performance\n    std::cout &lt;&lt; \"\\n[E1.64] SVD Decomposition Performance\\n\";\n    TIME_OPERATION(\n        tiny::Mat::SVDDecomposition perf_svd = perf_mat.svd_decompose(50, 1e-5f);\n        (void)perf_svd;\n    , \"SVD Decomposition (4x4 matrix)\");\n\n    std::cout &lt;&lt; \"\\n[Matrix Decomposition Tests Complete]\\n\";\n}\n\n// ============================================================================\n// ============================================================================\n// E2: Gram-Schmidt Orthogonalization\n// ============================================================================\nvoid test_gram_schmidt_orthogonalize()\n{\n    std::cout &lt;&lt; \"\\n[E2: Gram-Schmidt Orthogonalization Tests]\\n\";\n\n    // E2.1: Basic orthogonalization of linearly independent vectors\n    {\n        std::cout &lt;&lt; \"\\n[E2.1] Basic Orthogonalization - Linearly Independent Vectors\\n\";\n        tiny::Mat vectors(3, 3);\n        // Create three linearly independent vectors\n        vectors(0, 0) = 1.0f; vectors(0, 1) = 1.0f; vectors(0, 2) = 0.0f;\n        vectors(1, 0) = 0.0f; vectors(1, 1) = 1.0f; vectors(1, 2) = 1.0f;\n        vectors(2, 0) = 1.0f; vectors(2, 1) = 0.0f; vectors(2, 2) = 1.0f;\n\n        std::cout &lt;&lt; \"Input vectors (each column is a vector):\\n\";\n        vectors.print_matrix(true);\n\n        tiny::Mat Q, R;\n        bool success = tiny::Mat::gram_schmidt_orthogonalize(vectors, Q, R, 1e-6f);\n\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (success ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        if (success)\n        {\n            std::cout &lt;&lt; \"Orthogonalized vectors Q (each column is orthogonal):\\n\";\n            Q.print_matrix(true);\n            std::cout &lt;&lt; \"Coefficients R (upper triangular):\\n\";\n            R.print_matrix(true);\n\n            // Verify orthogonality: Q^T * Q should be identity (or close to it)\n            tiny::Mat QtQ = Q.transpose() * Q;\n            tiny::Mat I = tiny::Mat::eye(3);\n            float ortho_error = 0.0f;\n            for (int i = 0; i &lt; 3; ++i)\n            {\n                for (int j = 0; j &lt; 3; ++j)\n                {\n                    ortho_error += fabsf(QtQ(i, j) - I(i, j));\n                }\n            }\n            std::cout &lt;&lt; \"\\n[Verification] Q^T * Q should be identity\\n\";\n            std::cout &lt;&lt; \"Orthogonality error: \" &lt;&lt; ortho_error \n                      &lt;&lt; (ortho_error &lt; 0.1f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n\n            // Verify normalization: each column of Q should be unit vector\n            std::cout &lt;&lt; \"\\n[Verification] Each column of Q should be normalized\\n\";\n            bool all_normalized = true;\n            for (int j = 0; j &lt; 3; ++j)\n            {\n                float norm = 0.0f;\n                for (int i = 0; i &lt; 3; ++i)\n                {\n                    norm += Q(i, j) * Q(i, j);\n                }\n                norm = sqrtf(norm);\n                float norm_error = fabsf(norm - 1.0f);\n                std::cout &lt;&lt; \"  Column \" &lt;&lt; j &lt;&lt; \" norm: \" &lt;&lt; norm \n                          &lt;&lt; \" (error: \" &lt;&lt; norm_error &lt;&lt; \")\";\n                if (norm_error &gt; 0.01f)\n                {\n                    all_normalized = false;\n                    std::cout &lt;&lt; \" [FAIL]\";\n                }\n                else\n                {\n                    std::cout &lt;&lt; \" [PASS]\";\n                }\n                std::cout &lt;&lt; \"\\n\";\n            }\n\n            // Verify reconstruction: vectors should equal Q * R (approximately)\n            tiny::Mat QR = Q * R;\n            float recon_error = 0.0f;\n            for (int i = 0; i &lt; 3; ++i)\n            {\n                for (int j = 0; j &lt; 3; ++j)\n                {\n                    recon_error += fabsf(QR(i, j) - vectors(i, j));\n                }\n            }\n            std::cout &lt;&lt; \"\\n[Verification] Q * R should reconstruct original vectors\\n\";\n            std::cout &lt;&lt; \"Reconstruction error: \" &lt;&lt; recon_error \n                      &lt;&lt; (recon_error &lt; 0.1f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E2.2: Orthogonalization with near-linear-dependent vectors\n    {\n        std::cout &lt;&lt; \"\\n[E2.2] Orthogonalization - Near-Linear-Dependent Vectors\\n\";\n        tiny::Mat vectors(3, 3);\n        // Create vectors where third is almost a linear combination of first two\n        vectors(0, 0) = 1.0f; vectors(0, 1) = 0.0f; vectors(0, 2) = 1.0f;\n        vectors(1, 0) = 0.0f; vectors(1, 1) = 1.0f; vectors(1, 2) = 1.0f;\n        vectors(2, 0) = 0.0f; vectors(2, 1) = 0.0f; vectors(2, 2) = 0.001f;  // Very small third component\n\n        std::cout &lt;&lt; \"Input vectors (third vector is nearly linear dependent):\\n\";\n        vectors.print_matrix(true);\n\n        tiny::Mat Q, R;\n        bool success = tiny::Mat::gram_schmidt_orthogonalize(vectors, Q, R, 1e-6f);\n\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (success ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        if (success)\n        {\n            std::cout &lt;&lt; \"Orthogonalized vectors Q:\\n\";\n            Q.print_matrix(true);\n            std::cout &lt;&lt; \"Coefficients R:\\n\";\n            R.print_matrix(true);\n\n            // Check if third column was handled correctly (should be zero or orthogonal)\n            float third_col_norm = 0.0f;\n            for (int i = 0; i &lt; 3; ++i)\n            {\n                third_col_norm += Q(i, 2) * Q(i, 2);\n            }\n            third_col_norm = sqrtf(third_col_norm);\n            std::cout &lt;&lt; \"\\n[Note] Third column norm: \" &lt;&lt; third_col_norm \n                      &lt;&lt; \" (should be 0 if linearly dependent, or 1 if orthogonalized)\\n\";\n        }\n    }\n\n    // E2.3: Orthogonalization of 2D vectors\n    {\n        std::cout &lt;&lt; \"\\n[E2.3] Orthogonalization - 2D Vectors (2x2)\\n\";\n        tiny::Mat vectors(2, 2);\n        vectors(0, 0) = 3.0f; vectors(0, 1) = 1.0f;\n        vectors(1, 0) = 1.0f; vectors(1, 1) = 2.0f;\n\n        std::cout &lt;&lt; \"Input vectors:\\n\";\n        vectors.print_matrix(true);\n\n        tiny::Mat Q, R;\n        bool success = tiny::Mat::gram_schmidt_orthogonalize(vectors, Q, R, 1e-6f);\n\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (success ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        if (success)\n        {\n            std::cout &lt;&lt; \"Orthogonalized vectors Q:\\n\";\n            Q.print_matrix(true);\n            std::cout &lt;&lt; \"Coefficients R:\\n\";\n            R.print_matrix(true);\n\n            // Verify orthogonality\n            float dot_product = 0.0f;\n            for (int i = 0; i &lt; 2; ++i)\n            {\n                dot_product += Q(i, 0) * Q(i, 1);\n            }\n            std::cout &lt;&lt; \"\\n[Verification] Dot product of Q columns: \" &lt;&lt; dot_product \n                      &lt;&lt; \" (should be ~0 for orthogonal) \" \n                      &lt;&lt; (fabsf(dot_product) &lt; 0.01f ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n        }\n    }\n\n    // E2.4: Error handling - invalid input\n    {\n        std::cout &lt;&lt; \"\\n[E2.4] Error Handling - Invalid Input\\n\";\n        tiny::Mat empty_mat(0, 0);  // True empty matrix (0x0)\n        tiny::Mat Q, R;\n        bool success = tiny::Mat::gram_schmidt_orthogonalize(empty_mat, Q, R, 1e-6f);\n        std::cout &lt;&lt; \"Empty matrix test: \" &lt;&lt; (success ? \"FAIL (should return false)\" : \"PASS (correctly rejected)\") &lt;&lt; \"\\n\";\n    }\n\n    // E2.5: gram_schmidt_orthogonalize() - Parameter validation - negative tolerance\n    {\n        std::cout &lt;&lt; \"\\n[E2.5] gram_schmidt_orthogonalize() - Parameter Validation - Negative Tolerance\\n\";\n        tiny::Mat vectors(2, 2);\n        vectors(0, 0) = 1.0f; vectors(0, 1) = 0.0f;\n        vectors(1, 0) = 0.0f; vectors(1, 1) = 1.0f;\n        tiny::Mat Q, R;\n        bool success_neg = tiny::Mat::gram_schmidt_orthogonalize(vectors, Q, R, -1e-6f);\n        std::cout &lt;&lt; \"tolerance = -1e-6: \" &lt;&lt; (success_neg ? \"FAIL (should return false)\" : \"PASS (correctly rejected)\") &lt;&lt; \"\\n\";\n    }\n\n    // E2.6: gram_schmidt_orthogonalize() - Boundary case - zero rows\n    {\n        std::cout &lt;&lt; \"\\n[E2.6] gram_schmidt_orthogonalize() - Boundary Case - Zero Rows\\n\";\n        tiny::Mat zero_rows(0, 2);\n        tiny::Mat Q, R;\n        bool success_zero_rows = tiny::Mat::gram_schmidt_orthogonalize(zero_rows, Q, R, 1e-6f);\n        std::cout &lt;&lt; \"Zero rows (0x2): \" &lt;&lt; (success_zero_rows ? \"FAIL (should return false)\" : \"PASS (correctly rejected)\") &lt;&lt; \"\\n\";\n    }\n\n    // E2.7: gram_schmidt_orthogonalize() - Boundary case - zero columns\n    {\n        std::cout &lt;&lt; \"\\n[E2.7] gram_schmidt_orthogonalize() - Boundary Case - Zero Columns\\n\";\n        tiny::Mat zero_cols(2, 0);\n        tiny::Mat Q, R;\n        bool success_zero_cols = tiny::Mat::gram_schmidt_orthogonalize(zero_cols, Q, R, 1e-6f);\n        std::cout &lt;&lt; \"Zero columns (2x0): \" &lt;&lt; (success_zero_cols ? \"FAIL (should return false)\" : \"PASS (correctly rejected)\") &lt;&lt; \"\\n\";\n    }\n}\n\n// ============================================================================\n// ============================================================================\n// E3: Eigenvalue Decomposition\n// ============================================================================\nvoid test_eigenvalue_decomposition()\n{\n    std::cout &lt;&lt; \"\\n[E3: Eigenvalue Decomposition Tests]\\n\";\n\n    // E3.1: is_symmetric() - Basic functionality\n    std::cout &lt;&lt; \"\\n[E3.1] is_symmetric() - Basic Functionality\\n\";\n\n    // E3.11: Symmetric matrix\n    {\n        std::cout &lt;&lt; \"[E3.11] Symmetric 3x3 Matrix\\n\";\n        tiny::Mat sym_mat1(3, 3);\n        sym_mat1(0, 0) = 4.0f; sym_mat1(0, 1) = 1.0f; sym_mat1(0, 2) = 2.0f;\n        sym_mat1(1, 0) = 1.0f; sym_mat1(1, 1) = 3.0f; sym_mat1(1, 2) = 0.0f;\n        sym_mat1(2, 0) = 2.0f; sym_mat1(2, 1) = 0.0f; sym_mat1(2, 2) = 5.0f;\n        bool is_sym1 = sym_mat1.is_symmetric(1e-5f);\n        std::cout &lt;&lt; \"Matrix:\\n\";\n        sym_mat1.print_matrix(true);\n        std::cout &lt;&lt; \"Is symmetric: \" &lt;&lt; (is_sym1 ? \"True\" : \"False\") &lt;&lt; \" (Expected: True)\\n\";\n    }\n\n    // E3.12: Non-symmetric matrix (keep for later tests)\n    tiny::Mat non_sym_mat(3, 3);\n    {\n        std::cout &lt;&lt; \"\\n[E3.12] Non-Symmetric 3x3 Matrix\\n\";\n        non_sym_mat(0, 0) = 1.0f; non_sym_mat(0, 1) = 2.0f; non_sym_mat(0, 2) = 3.0f;\n        non_sym_mat(1, 0) = 4.0f; non_sym_mat(1, 1) = 5.0f; non_sym_mat(1, 2) = 6.0f;\n        non_sym_mat(2, 0) = 7.0f; non_sym_mat(2, 1) = 8.0f; non_sym_mat(2, 2) = 9.0f;\n        bool is_sym2 = non_sym_mat.is_symmetric(1e-5f);\n        std::cout &lt;&lt; \"Matrix:\\n\";\n        non_sym_mat.print_matrix(true);\n        std::cout &lt;&lt; \"Is symmetric: \" &lt;&lt; (is_sym2 ? \"True\" : \"False\") &lt;&lt; \" (Expected: False)\\n\";\n    }\n\n    // E3.13: Non-square matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.13] Non-Square Matrix (2x3)\\n\";\n        tiny::Mat rect_mat(2, 3);\n        bool is_sym3 = rect_mat.is_symmetric(1e-5f);\n        std::cout &lt;&lt; \"Is symmetric: \" &lt;&lt; (is_sym3 ? \"True\" : \"False\") &lt;&lt; \" (Expected: False)\\n\";\n    }\n\n    // E3.14: Symmetric matrix with small numerical errors\n    {\n        std::cout &lt;&lt; \"\\n[E3.14] Symmetric Matrix with Small Numerical Errors\\n\";\n        tiny::Mat sym_mat2(2, 2);\n        // Use 1e-5 error which is within float precision (float has ~7 significant digits)\n        // For 2.0, we can represent 2.00001 accurately\n        float error_value = 1e-5f;\n        sym_mat2(0, 0) = 1.0f; \n        sym_mat2(0, 1) = 2.0f + error_value;\n        sym_mat2(1, 0) = 2.0f; \n        sym_mat2(1, 1) = 3.0f;\n        std::cout &lt;&lt; \"Matrix with error \" &lt;&lt; error_value &lt;&lt; \":\\n\";\n        sym_mat2.print_matrix(true);\n        float diff = fabsf(sym_mat2(0, 1) - sym_mat2(1, 0));\n        std::cout &lt;&lt; \"Difference: |A(0,1) - A(1,0)| = \";\n        // Use scientific notation for small values\n        if (diff &lt; 1e-3f)\n        {\n            std::cout &lt;&lt; std::scientific &lt;&lt; std::setprecision(6) &lt;&lt; diff &lt;&lt; std::fixed;\n        }\n        else\n        {\n            std::cout &lt;&lt; std::setprecision(6) &lt;&lt; diff;\n        }\n        std::cout &lt;&lt; \" (Expected: \" &lt;&lt; error_value &lt;&lt; \")\\n\";\n\n        // Verify the difference is actually stored\n        float stored_value = sym_mat2(0, 1);\n        float expected_stored = 2.0f + error_value;\n        std::cout &lt;&lt; \"A(0,1) stored value: \" &lt;&lt; std::setprecision(8) &lt;&lt; stored_value \n                  &lt;&lt; \" (Expected: \" &lt;&lt; expected_stored &lt;&lt; \")\\n\";\n\n        bool is_sym4 = sym_mat2.is_symmetric(1e-4f); // tolerance &gt; error, should pass\n        std::cout &lt;&lt; \"Is symmetric (tolerance=1e-4): \" &lt;&lt; (is_sym4 ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: True, tolerance &gt; error) \";\n        std::cout &lt;&lt; (is_sym4 ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        bool is_sym5 = sym_mat2.is_symmetric(1e-6f); // tolerance &lt; error, should fail\n        std::cout &lt;&lt; \"Is symmetric (tolerance=1e-6): \" &lt;&lt; (is_sym5 ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: False, tolerance &lt; error) \";\n        bool correct_result = !is_sym5; // Should be False (not symmetric)\n        std::cout &lt;&lt; (correct_result ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        // Additional check: verify the difference is close to expected\n        float diff_error = fabsf(diff - error_value);\n        std::cout &lt;&lt; \"Difference accuracy: |actual_diff - expected_diff| = \" \n                  &lt;&lt; std::scientific &lt;&lt; std::setprecision(2) &lt;&lt; diff_error &lt;&lt; std::fixed;\n        bool diff_accurate = (diff_error &lt; error_value * 0.1f); // Within 10% of error value\n        std::cout &lt;&lt; \" \" &lt;&lt; (diff_accurate ? \"[PASS - difference stored correctly]\" : \"[FAIL - float precision issue]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.15: Parameter validation - negative tolerance\n    {\n        std::cout &lt;&lt; \"\\n[E3.15] Parameter Validation - Negative Tolerance\\n\";\n        tiny::Mat sym_mat(2, 2);\n        sym_mat(0, 0) = 1.0f; sym_mat(0, 1) = 2.0f;\n        sym_mat(1, 0) = 2.0f; sym_mat(1, 1) = 3.0f;\n\n        // Test with tolerance &lt; 0 (should return false/error)\n        bool is_sym_neg = sym_mat.is_symmetric(-1e-6f);\n        std::cout &lt;&lt; \"tolerance = -1e-6 (invalid): \" &lt;&lt; (is_sym_neg ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: False) \" &lt;&lt; (!is_sym_neg ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.16: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.16] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        // Empty matrix cannot be checked for symmetry (data is null or invalid)\n        bool is_sym_empty = empty_mat.is_symmetric(1e-6f);\n        std::cout &lt;&lt; \"Empty matrix (0x0): \" &lt;&lt; (is_sym_empty ? \"True\" : \"False\") \n                  &lt;&lt; \" (Expected: False, empty matrix is invalid) \" &lt;&lt; (!is_sym_empty ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.2: power_iteration() - Dominant eigenvalue\n    std::cout &lt;&lt; \"\\n[E3.2] power_iteration() - Dominant Eigenvalue\\n\";\n\n    // E3.21: Simple 2x2 symmetric matrix (known eigenvalues)\n    tiny::Mat mat2x2(2, 2);\n    {\n        std::cout &lt;&lt; \"\\n[E3.21] Simple 2x2 Matrix\\n\";\n        mat2x2(0, 0) = 2.0f; mat2x2(0, 1) = 1.0f;\n        mat2x2(1, 0) = 1.0f; mat2x2(1, 1) = 2.0f;\n        std::cout &lt;&lt; \"Matrix:\\n\";\n        mat2x2.print_matrix(true);\n\n        // Expected values: eigenvalues are 3 and 1 (for matrix [2,1; 1,2])\n        // Characteristic equation: det([2-\u03bb, 1; 1, 2-\u03bb]) = (2-\u03bb)\u00b2 - 1 = \u03bb\u00b2 - 4\u03bb + 3 = 0\n        // Solutions: \u03bb = (4 \u00b1 \u221a(16-12))/2 = (4 \u00b1 2)/2 = 3 or 1\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues: 3.0 (largest), 1.0 (smallest)\\n\";\n        std::cout &lt;&lt; \"  Expected dominant eigenvector (for \u03bb=3): approximately [0.707, 0.707] or [-0.707, -0.707] (normalized)\\n\";\n        std::cout &lt;&lt; \"  Expected dominant eigenvector (for \u03bb=1): approximately [0.707, -0.707] or [-0.707, 0.707] (normalized)\\n\";\n\n        tiny::Mat::EigenPair result_power = mat2x2.power_iteration(1000, 1e-6f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"  Dominant eigenvalue: \" &lt;&lt; result_power.eigenvalue \n                  &lt;&lt; \" (Expected: 3.0, largest eigenvalue)\\n\";\n        std::cout &lt;&lt; \"  Iterations: \" &lt;&lt; result_power.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Status: \" &lt;&lt; (result_power.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Dominant eigenvector:\\n\";\n        result_power.eigenvector.print_matrix(true);\n\n        // Check if result matches expected\n        float error = fabsf(result_power.eigenvalue - 3.0f);\n        std::cout &lt;&lt; \"  Error from expected (3.0): \" &lt;&lt; error &lt;&lt; (error &lt; 0.01f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.22: 3x3 matrix (SHM-like stiffness matrix) - keep for later tests\n    tiny::Mat stiffness(3, 3);\n    {\n        std::cout &lt;&lt; \"\\n[E3.22] 3x3 Stiffness Matrix (SHM Application)\\n\";\n        stiffness(0, 0) = 2.0f; stiffness(0, 1) = -1.0f; stiffness(0, 2) = 0.0f;\n        stiffness(1, 0) = -1.0f; stiffness(1, 1) = 2.0f; stiffness(1, 2) = -1.0f;\n        stiffness(2, 0) = 0.0f; stiffness(2, 1) = -1.0f; stiffness(2, 2) = 2.0f;\n        std::cout &lt;&lt; \"Stiffness Matrix:\\n\";\n        stiffness.print_matrix(true);\n\n        // Expected values for 3x3 tridiagonal symmetric matrix [2,-1,0; -1,2,-1; 0,-1,2]\n        // This is a standard tridiagonal matrix with known eigenvalues\n        // Approximate eigenvalues: \u03bb\u2081 \u2248 3.414, \u03bb\u2082 \u2248 2.000, \u03bb\u2083 \u2248 0.586\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues (approximate): 3.414 (largest), 2.000, 0.586 (smallest)\\n\";\n        std::cout &lt;&lt; \"  Expected primary frequency: sqrt(3.414) \u2248 1.848 rad/s\\n\";\n\n        tiny::Mat::EigenPair result_stiff = stiffness.power_iteration(500, 1e-6f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"  Dominant eigenvalue (primary frequency squared): \" &lt;&lt; result_stiff.eigenvalue &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Primary frequency: \" &lt;&lt; sqrtf(result_stiff.eigenvalue) &lt;&lt; \" rad/s (Expected: ~1.848 rad/s)\\n\";\n        std::cout &lt;&lt; \"  Iterations: \" &lt;&lt; result_stiff.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Status: \" &lt;&lt; (result_stiff.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n\n        float expected_eigen = 3.414f;\n        float error = fabsf(result_stiff.eigenvalue - expected_eigen);\n        std::cout &lt;&lt; \"  Error from expected (\" &lt;&lt; expected_eigen &lt;&lt; \"): \" &lt;&lt; error &lt;&lt; (error &lt; 0.1f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.23: Non-square matrix (should fail)\n    {\n        std::cout &lt;&lt; \"\\n[E3.23] Non-Square Matrix (Expect Error)\\n\";\n        tiny::Mat non_square(2, 3);\n        tiny::Mat::EigenPair result_error = non_square.power_iteration(100, 1e-6f);\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_error.status == TINY_OK ? \"OK\" : \"Error (Expected)\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.25: Parameter validation - max_iter &lt;= 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.25] Parameter Validation - max_iter &lt;= 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 2.0f; test_mat(0, 1) = 1.0f;\n        test_mat(1, 0) = 1.0f; test_mat(1, 1) = 2.0f;\n\n        tiny::Mat::EigenPair result_zero = test_mat.power_iteration(0, 1e-6f);\n        std::cout &lt;&lt; \"max_iter = 0: Status = \" &lt;&lt; (result_zero.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_zero.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        tiny::Mat::EigenPair result_neg = test_mat.power_iteration(-1, 1e-6f);\n        std::cout &lt;&lt; \"max_iter = -1: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.26: Parameter validation - tolerance &lt; 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.26] Parameter Validation - tolerance &lt; 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 2.0f; test_mat(0, 1) = 1.0f;\n        test_mat(1, 0) = 1.0f; test_mat(1, 1) = 2.0f;\n\n        tiny::Mat::EigenPair result_neg = test_mat.power_iteration(100, -1e-6f);\n        std::cout &lt;&lt; \"tolerance = -1e-6: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.27: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.27] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        tiny::Mat::EigenPair result_empty = empty_mat.power_iteration(100, 1e-6f);\n        // Empty matrix should return error status\n        bool empty_correct = (result_empty.status != TINY_OK);\n        std::cout &lt;&lt; \"Empty matrix: Status = \" &lt;&lt; (result_empty.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \", eigenvalue = \" &lt;&lt; result_empty.eigenvalue \n                  &lt;&lt; \" (Expected: Error status) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.24: inverse_power_iteration() - Smallest eigenvalue (Critical for System Identification)\n    std::cout &lt;&lt; \"\\n[E3.24] inverse_power_iteration() - Smallest Eigenvalue (System Identification)\\n\";\n\n    // E3.28: Simple 2x2 symmetric matrix (known eigenvalues)\n    {\n        std::cout &lt;&lt; \"\\n[E3.28] Simple 2x2 Matrix - Smallest Eigenvalue\\n\";\n        std::cout &lt;&lt; \"Matrix (same as E3.21):\\n\";\n        mat2x2.print_matrix(true);\n\n        // Expected values: eigenvalues are 3 and 1 (for matrix [2,1; 1,2])\n        // Power iteration finds \u03bb_max = 3, inverse power iteration should find \u03bb_min = 1\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues: 3.0 (largest), 1.0 (smallest)\\n\";\n        std::cout &lt;&lt; \"  Expected smallest eigenvalue: 1.0\\n\";\n        std::cout &lt;&lt; \"  Expected smallest eigenvector (for \u03bb=1): approximately [0.707, -0.707] or [-0.707, 0.707] (normalized)\\n\";\n        std::cout &lt;&lt; \"  Note: This is critical for system identification - smallest eigenvalue = fundamental frequency\\n\";\n\n        tiny::Mat::EigenPair result_inv_power = mat2x2.inverse_power_iteration(1000, 1e-6f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"  Smallest eigenvalue: \" &lt;&lt; result_inv_power.eigenvalue \n                  &lt;&lt; \" (Expected: 1.0, smallest eigenvalue)\\n\";\n        std::cout &lt;&lt; \"  Iterations: \" &lt;&lt; result_inv_power.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Status: \" &lt;&lt; (result_inv_power.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Smallest eigenvector:\\n\";\n        result_inv_power.eigenvector.print_matrix(true);\n\n        // Check if result matches expected\n        float error = fabsf(result_inv_power.eigenvalue - 1.0f);\n        std::cout &lt;&lt; \"  Error from expected (1.0): \" &lt;&lt; error &lt;&lt; (error &lt; 0.01f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n\n        // Compare with power iteration results (recompute for comparison)\n        tiny::Mat::EigenPair result_power_compare = mat2x2.power_iteration(1000, 1e-6f);\n        std::cout &lt;&lt; \"\\n[Comparison] Power vs Inverse Power Iteration:\\n\";\n        std::cout &lt;&lt; \"  Power iteration (\u03bb_max): \" &lt;&lt; result_power_compare.eigenvalue &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Inverse power iteration (\u03bb_min): \" &lt;&lt; result_inv_power.eigenvalue &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Ratio (\u03bb_max/\u03bb_min): \" &lt;&lt; (result_power_compare.eigenvalue / result_inv_power.eigenvalue) \n                  &lt;&lt; \" (Expected: ~3.0) \" &lt;&lt; (fabsf(result_power_compare.eigenvalue / result_inv_power.eigenvalue - 3.0f) &lt; 0.1f ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.29: 3x3 stiffness matrix - Smallest eigenvalue (SHM Application)\n    {\n        std::cout &lt;&lt; \"\\n[E3.29] 3x3 Stiffness Matrix - Smallest Eigenvalue (SHM Application)\\n\";\n        std::cout &lt;&lt; \"Stiffness Matrix (same as E3.22):\\n\";\n        stiffness.print_matrix(true);\n\n        // Expected values for 3x3 tridiagonal symmetric matrix [2,-1,0; -1,2,-1; 0,-1,2]\n        // Approximate eigenvalues: \u03bb\u2081 \u2248 3.414 (largest), \u03bb\u2082 \u2248 2.000, \u03bb\u2083 \u2248 0.586 (smallest)\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues (approximate): 3.414 (largest), 2.000, 0.586 (smallest)\\n\";\n        std::cout &lt;&lt; \"  Expected smallest eigenvalue: ~0.586 (fundamental frequency squared)\\n\";\n        std::cout &lt;&lt; \"  Expected fundamental frequency: sqrt(0.586) \u2248 0.765 rad/s\\n\";\n        std::cout &lt;&lt; \"  Note: Smallest eigenvalue is critical for system identification - represents fundamental mode\\n\";\n\n        tiny::Mat::EigenPair result_inv_stiff = stiffness.inverse_power_iteration(500, 1e-6f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"  Smallest eigenvalue (fundamental frequency squared): \" &lt;&lt; result_inv_stiff.eigenvalue &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Fundamental frequency: \" &lt;&lt; sqrtf(result_inv_stiff.eigenvalue) &lt;&lt; \" rad/s (Expected: ~0.765 rad/s)\\n\";\n        std::cout &lt;&lt; \"  Iterations: \" &lt;&lt; result_inv_stiff.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Status: \" &lt;&lt; (result_inv_stiff.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"  Smallest eigenvector (fundamental mode shape):\\n\";\n        result_inv_stiff.eigenvector.print_matrix(true);\n\n        float expected_eigen = 0.586f;\n        float error = fabsf(result_inv_stiff.eigenvalue - expected_eigen);\n        std::cout &lt;&lt; \"  Error from expected (\" &lt;&lt; expected_eigen &lt;&lt; \"): \" &lt;&lt; error &lt;&lt; (error &lt; 0.1f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n\n        // Compare with power iteration (recompute for comparison)\n        tiny::Mat::EigenPair result_stiff_compare = stiffness.power_iteration(500, 1e-6f);\n        std::cout &lt;&lt; \"\\n[Comparison] Power vs Inverse Power Iteration for SHM:\\n\";\n        std::cout &lt;&lt; \"  Power iteration (primary frequency\u00b2): \" &lt;&lt; result_stiff_compare.eigenvalue \n                  &lt;&lt; \" \u2192 frequency: \" &lt;&lt; sqrtf(result_stiff_compare.eigenvalue) &lt;&lt; \" rad/s\\n\";\n        std::cout &lt;&lt; \"  Inverse power iteration (fundamental frequency\u00b2): \" &lt;&lt; result_inv_stiff.eigenvalue \n                  &lt;&lt; \" \u2192 frequency: \" &lt;&lt; sqrtf(result_inv_stiff.eigenvalue) &lt;&lt; \" rad/s\\n\";\n        std::cout &lt;&lt; \"  Frequency ratio: \" &lt;&lt; (sqrtf(result_stiff_compare.eigenvalue) / sqrtf(result_inv_stiff.eigenvalue))\n                  &lt;&lt; \" (Expected: ~2.4, ratio of highest to lowest mode)\\n\";\n    }\n\n    // E3.210: Non-square matrix (should fail)\n    {\n        std::cout &lt;&lt; \"\\n[E3.210] Non-Square Matrix (Expect Error)\\n\";\n        tiny::Mat non_square(2, 3);\n        tiny::Mat::EigenPair result_error = non_square.inverse_power_iteration(100, 1e-6f);\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_error.status == TINY_OK ? \"OK\" : \"Error (Expected)\") &lt;&lt; \"\\n\";\n        bool correct = (result_error.status != TINY_OK);\n        std::cout &lt;&lt; \"Error handling: \" &lt;&lt; (correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.211: Near-singular matrix (should handle gracefully)\n    {\n        std::cout &lt;&lt; \"\\n[E3.211] Near-Singular Matrix (Edge Case)\\n\";\n        tiny::Mat near_singular(3, 3);\n        // Create a matrix that is close to singular but still invertible\n        near_singular(0, 0) = 1.0f; near_singular(0, 1) = 0.0f; near_singular(0, 2) = 0.0f;\n        near_singular(1, 0) = 0.0f; near_singular(1, 1) = 1.0f; near_singular(1, 2) = 0.001f;\n        near_singular(2, 0) = 0.0f; near_singular(2, 1) = 0.001f; near_singular(2, 2) = 1.0f;\n        std::cout &lt;&lt; \"Matrix (near-singular but invertible):\\n\";\n        near_singular.print_matrix(true);\n\n        tiny::Mat::EigenPair result_near_sing = near_singular.inverse_power_iteration(500, 1e-5f);\n        std::cout &lt;&lt; \"\\n[Results]\\n\";\n        std::cout &lt;&lt; \"  Status: \" &lt;&lt; (result_near_sing.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        if (result_near_sing.status == TINY_OK)\n        {\n            std::cout &lt;&lt; \"  Smallest eigenvalue: \" &lt;&lt; result_near_sing.eigenvalue &lt;&lt; \"\\n\";\n            std::cout &lt;&lt; \"  Iterations: \" &lt;&lt; result_near_sing.iterations &lt;&lt; \"\\n\";\n            std::cout &lt;&lt; \"  Note: Successfully handled near-singular matrix [PASS]\\n\";\n        }\n        else\n        {\n            std::cout &lt;&lt; \"  Note: Correctly detected problematic matrix [PASS]\\n\";\n        }\n    }\n\n    // E3.212: Parameter validation - max_iter &lt;= 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.212] Parameter Validation - max_iter &lt;= 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 2.0f; test_mat(0, 1) = 1.0f;\n        test_mat(1, 0) = 1.0f; test_mat(1, 1) = 2.0f;\n\n        tiny::Mat::EigenPair result_zero = test_mat.inverse_power_iteration(0, 1e-6f);\n        std::cout &lt;&lt; \"max_iter = 0: Status = \" &lt;&lt; (result_zero.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_zero.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        tiny::Mat::EigenPair result_neg = test_mat.inverse_power_iteration(-1, 1e-6f);\n        std::cout &lt;&lt; \"max_iter = -1: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.213: Parameter validation - tolerance &lt; 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.213] Parameter Validation - tolerance &lt; 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 2.0f; test_mat(0, 1) = 1.0f;\n        test_mat(1, 0) = 1.0f; test_mat(1, 1) = 2.0f;\n\n        tiny::Mat::EigenPair result_neg = test_mat.inverse_power_iteration(100, -1e-6f);\n        std::cout &lt;&lt; \"tolerance = -1e-6: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.214: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.214] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        tiny::Mat::EigenPair result_empty = empty_mat.inverse_power_iteration(100, 1e-6f);\n        // Empty matrix should return error status\n        bool empty_correct = (result_empty.status != TINY_OK);\n        std::cout &lt;&lt; \"Empty matrix: Status = \" &lt;&lt; (result_empty.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \", eigenvalue = \" &lt;&lt; result_empty.eigenvalue \n                  &lt;&lt; \" (Expected: Error status) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.215: Singular matrix (should fail)\n    {\n        std::cout &lt;&lt; \"\\n[E3.215] Singular Matrix (Should Fail)\\n\";\n        tiny::Mat singular(2, 2);\n        singular(0, 0) = 1.0f; singular(0, 1) = 2.0f;\n        singular(1, 0) = 2.0f; singular(1, 1) = 4.0f;  // Second row is 2x first row (singular)\n\n        tiny::Mat::EigenPair result_sing = singular.inverse_power_iteration(100, 1e-6f);\n        // Note: Some implementations may handle singular matrices differently\n        // Check if status is Error OR if eigenvalue is valid (implementation-dependent)\n        // For now, accept either Error status or valid result (some algorithms can handle singular matrices)\n        bool singular_correct = (result_sing.status != TINY_OK) || \n                               (result_sing.status == TINY_OK &amp;&amp; (result_sing.eigenvalue == 0.0f || fabsf(result_sing.eigenvalue) &lt; 1e-5f));\n        std::cout &lt;&lt; \"Singular matrix: Status = \" &lt;&lt; (result_sing.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \" (Expected: Error or OK with eigenvalue \u2248 0) \" &lt;&lt; (singular_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.3: eigendecompose_jacobi() - Symmetric matrix decomposition\n    std::cout &lt;&lt; \"\\n[E3.3] eigendecompose_jacobi() - Symmetric Matrix Decomposition\\n\";\n\n    // E3.31: Simple 2x2 symmetric matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.31] 2x2 Symmetric Matrix - Complete Decomposition\\n\";\n        std::cout &lt;&lt; \"[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues: 3.0, 1.0 (in any order)\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvectors (for \u03bb=3): [0.707, 0.707] or [-0.707, -0.707] (normalized)\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvectors (for \u03bb=1): [0.707, -0.707] or [-0.707, 0.707] (normalized)\\n\";\n\n        tiny::Mat::EigenDecomposition result_jacobi1 = mat2x2.eigendecompose_jacobi(1e-6f, 100);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalues:\\n\";\n        result_jacobi1.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Eigenvectors (each column is an eigenvector):\\n\";\n        result_jacobi1.eigenvectors.print_matrix(true);\n        std::cout &lt;&lt; \"Iterations: \" &lt;&lt; result_jacobi1.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_jacobi1.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n\n        // Check eigenvalues\n        float ev1 = result_jacobi1.eigenvalues(0, 0);\n        float ev2 = result_jacobi1.eigenvalues(1, 0);\n        bool ev_check = ((fabsf(ev1 - 3.0f) &lt; 0.01f &amp;&amp; fabsf(ev2 - 1.0f) &lt; 0.01f) ||\n                         (fabsf(ev1 - 1.0f) &lt; 0.01f &amp;&amp; fabsf(ev2 - 3.0f) &lt; 0.01f));\n        std::cout &lt;&lt; \"Eigenvalue check (should be 3.0 and 1.0): \" &lt;&lt; (ev_check ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        // Verify: A * v = lambda * v\n        std::cout &lt;&lt; \"\\n[Verification] Check A * v = lambda * v for first eigenvector:\\n\";\n        tiny::Mat Av = mat2x2 * result_jacobi1.eigenvectors.block(0, 0, 2, 1);\n        tiny::Mat lambda_v = result_jacobi1.eigenvalues(0, 0) * result_jacobi1.eigenvectors.block(0, 0, 2, 1);\n        std::cout &lt;&lt; \"A * v:\\n\";\n        Av.print_matrix(true);\n        std::cout &lt;&lt; \"lambda * v:\\n\";\n        lambda_v.print_matrix(true);\n        bool verify1 = matrices_approximately_equal(Av, lambda_v, 1e-4f);\n        std::cout &lt;&lt; \"Verification (A*v = \u03bb*v): \" &lt;&lt; (verify1 ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.32: 3x3 symmetric matrix (SHM stiffness matrix)\n    {\n        std::cout &lt;&lt; \"\\n[E3.32] 3x3 Stiffness Matrix (SHM Application)\\n\";\n        std::cout &lt;&lt; \"[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues (approximate): 3.414, 2.000, 0.586\\n\";\n        std::cout &lt;&lt; \"  Expected natural frequencies: 1.848, 1.414, 0.765 rad/s\\n\";\n        std::cout &lt;&lt; \"  Note: Eigenvalues may appear in any order\\n\";\n\n        tiny::Mat::EigenDecomposition result_jacobi2 = stiffness.eigendecompose_jacobi(1e-5f, 100);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalues (natural frequencies squared):\\n\";\n        result_jacobi2.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Natural frequencies (rad/s):\\n\";\n        float expected_freqs[3] = {1.848f, 1.414f, 0.765f};\n        for (int i = 0; i &lt; result_jacobi2.eigenvalues.row; ++i)\n        {\n            float freq = sqrtf(result_jacobi2.eigenvalues(i, 0));\n            std::cout &lt;&lt; \"  Mode \" &lt;&lt; i &lt;&lt; \": \" &lt;&lt; freq &lt;&lt; \" rad/s\";\n            // Check if frequency matches any expected value\n            bool matched = false;\n            for (int j = 0; j &lt; 3; ++j)\n            {\n                if (fabsf(freq - expected_freqs[j]) &lt; 0.1f)\n                {\n                    std::cout &lt;&lt; \" (Expected: ~\" &lt;&lt; expected_freqs[j] &lt;&lt; \" rad/s) [PASS]\";\n                    matched = true;\n                    break;\n                }\n            }\n            if (!matched) std::cout &lt;&lt; \" [CHECK]\";\n            std::cout &lt;&lt; \"\\n\";\n        }\n        std::cout &lt;&lt; \"Eigenvectors (mode shapes):\\n\";\n        result_jacobi2.eigenvectors.print_matrix(true);\n        std::cout &lt;&lt; \"Iterations: \" &lt;&lt; result_jacobi2.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_jacobi2.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.33: Diagonal matrix (trivial case)\n    {\n        std::cout &lt;&lt; \"\\n[E3.33] Diagonal Matrix (Eigenvalues on diagonal)\\n\";\n        tiny::Mat diag_mat(3, 3);\n        diag_mat(0, 0) = 5.0f; diag_mat(0, 1) = 0.0f; diag_mat(0, 2) = 0.0f;\n        diag_mat(1, 0) = 0.0f; diag_mat(1, 1) = 3.0f; diag_mat(1, 2) = 0.0f;\n        diag_mat(2, 0) = 0.0f; diag_mat(2, 1) = 0.0f; diag_mat(2, 2) = 1.0f;\n        std::cout &lt;&lt; \"Matrix:\\n\";\n        diag_mat.print_matrix(true);\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues: 5.0, 3.0, 1.0 (diagonal elements, may be in any order)\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvectors: standard basis vectors [1,0,0], [0,1,0], [0,0,1] (or their negatives)\\n\";\n        std::cout &lt;&lt; \"  Expected iterations: 1 (diagonal matrix should converge immediately)\\n\";\n\n        tiny::Mat::EigenDecomposition result_diag = diag_mat.eigendecompose_jacobi(1e-6f, 10);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalues:\\n\";\n        result_diag.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Eigenvectors:\\n\";\n        result_diag.eigenvectors.print_matrix(true);\n        std::cout &lt;&lt; \"Iterations: \" &lt;&lt; result_diag.iterations &lt;&lt; \" (Expected: 1)\\n\";\n\n        // Check eigenvalues\n        float ev1 = result_diag.eigenvalues(0, 0);\n        float ev2 = result_diag.eigenvalues(1, 0);\n        float ev3 = result_diag.eigenvalues(2, 0);\n        bool ev_check = ((fabsf(ev1 - 5.0f) &lt; 0.01f || fabsf(ev1 - 3.0f) &lt; 0.01f || fabsf(ev1 - 1.0f) &lt; 0.01f) &amp;&amp;\n                         (fabsf(ev2 - 5.0f) &lt; 0.01f || fabsf(ev2 - 3.0f) &lt; 0.01f || fabsf(ev2 - 1.0f) &lt; 0.01f) &amp;&amp;\n                         (fabsf(ev3 - 5.0f) &lt; 0.01f || fabsf(ev3 - 3.0f) &lt; 0.01f || fabsf(ev3 - 1.0f) &lt; 0.01f));\n        std::cout &lt;&lt; \"Eigenvalue check (should be 5.0, 3.0, 1.0): \" &lt;&lt; (ev_check ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.34: Parameter validation - tolerance &lt; 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.34] Parameter Validation - tolerance &lt; 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 2.0f; test_mat(0, 1) = 1.0f;\n        test_mat(1, 0) = 1.0f; test_mat(1, 1) = 2.0f;\n\n        tiny::Mat::EigenDecomposition result_neg = test_mat.eigendecompose_jacobi(-1e-6f, 100);\n        std::cout &lt;&lt; \"tolerance = -1e-6: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.35: Parameter validation - max_iter &lt;= 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.35] Parameter Validation - max_iter &lt;= 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 2.0f; test_mat(0, 1) = 1.0f;\n        test_mat(1, 0) = 1.0f; test_mat(1, 1) = 2.0f;\n\n        tiny::Mat::EigenDecomposition result_zero = test_mat.eigendecompose_jacobi(1e-6f, 0);\n        std::cout &lt;&lt; \"max_iter = 0: Status = \" &lt;&lt; (result_zero.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_zero.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        tiny::Mat::EigenDecomposition result_neg = test_mat.eigendecompose_jacobi(1e-6f, -1);\n        std::cout &lt;&lt; \"max_iter = -1: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.36: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.36] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        tiny::Mat::EigenDecomposition result_empty = empty_mat.eigendecompose_jacobi(1e-6f, 100);\n        // Error case: empty matrix should return error status, eigenvalues may be 0x0 or 1x1 error matrix\n        bool empty_correct = (result_empty.status != TINY_OK) &amp;&amp; \n                            ((result_empty.eigenvalues.row == 0 &amp;&amp; result_empty.eigenvalues.col == 0) || \n                             (result_empty.eigenvalues.data == nullptr) ||\n                             (result_empty.eigenvalues.row == 1 &amp;&amp; result_empty.eigenvalues.col == 1 &amp;&amp; result_empty.eigenvalues.data != nullptr));\n        std::cout &lt;&lt; \"Empty matrix: Status = \" &lt;&lt; (result_empty.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \", eigenvalues rows = \" &lt;&lt; result_empty.eigenvalues.row \n                  &lt;&lt; \" (Expected: Error status, eigenvalues is 0x0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.4: eigendecompose_qr() - General matrix decomposition\n    std::cout &lt;&lt; \"\\n[E3.4] eigendecompose_qr() - General Matrix Decomposition\\n\";\n\n    // E3.41: General 2x2 matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.41] General 2x2 Matrix\\n\";\n        tiny::Mat gen_mat(2, 2);\n        gen_mat(0, 0) = 1.0f; gen_mat(0, 1) = 2.0f;\n        gen_mat(1, 0) = 3.0f; gen_mat(1, 1) = 4.0f;\n        std::cout &lt;&lt; \"Matrix:\\n\";\n        gen_mat.print_matrix(true);\n\n        // Expected values for matrix [1,2; 3,4]\n        // Characteristic equation: det([1-\u03bb, 2; 3, 4-\u03bb]) = (1-\u03bb)(4-\u03bb) - 6 = \u03bb\u00b2 - 5\u03bb - 2 = 0\n        // Solutions: \u03bb = (5 \u00b1 \u221a(25+8))/2 = (5 \u00b1 \u221a33)/2 \u2248 5.372, -0.372\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues: (5+\u221a33)/2 \u2248 5.372, (5-\u221a33)/2 \u2248 -0.372\\n\";\n        std::cout &lt;&lt; \"  Note: This is a non-symmetric matrix, eigenvalues are real but may have complex eigenvectors\\n\";\n\n        tiny::Mat::EigenDecomposition result_qr1 = gen_mat.eigendecompose_qr(100, 1e-5f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalues:\\n\";\n        result_qr1.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Eigenvectors:\\n\";\n        result_qr1.eigenvectors.print_matrix(true);\n        std::cout &lt;&lt; \"Iterations: \" &lt;&lt; result_qr1.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_qr1.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n\n        // Check eigenvalues with detailed error reporting\n        float ev1 = result_qr1.eigenvalues(0, 0);\n        float ev2 = result_qr1.eigenvalues(1, 0);\n        float expected_ev1 = 5.372f;\n        float expected_ev2 = -0.372f;\n\n        // Match eigenvalues to expected values\n        float error1a = fabsf(ev1 - expected_ev1);\n        float error1b = fabsf(ev1 - expected_ev2);\n        float error2a = fabsf(ev2 - expected_ev1);\n        float error2b = fabsf(ev2 - expected_ev2);\n\n        bool match1 = (error1a &lt; error1b); // ev1 matches expected_ev1 better\n        float matched_ev1 = match1 ? expected_ev1 : expected_ev2;\n        float matched_ev2 = match1 ? expected_ev2 : expected_ev1;\n        float actual_error1 = match1 ? error1a : error1b;\n        float actual_error2 = match1 ? error2b : error2a;\n        float rel_error1 = actual_error1 / fabsf(matched_ev1);\n        float rel_error2 = actual_error2 / fabsf(matched_ev2);\n\n        std::cout &lt;&lt; \"Eigenvalue 1: \" &lt;&lt; ev1 &lt;&lt; \" (Expected: \" &lt;&lt; matched_ev1 &lt;&lt; \", Error: \" &lt;&lt; actual_error1 \n                  &lt;&lt; \", Rel Error: \" &lt;&lt; (rel_error1 * 100.0f) &lt;&lt; \"%) \";\n        bool pass1 = (rel_error1 &lt; 0.05f); // 5% relative error tolerance\n        std::cout &lt;&lt; (pass1 ? \"[PASS]\" : \"[FAIL - error too large]\") &lt;&lt; \"\\n\";\n\n        std::cout &lt;&lt; \"Eigenvalue 2: \" &lt;&lt; ev2 &lt;&lt; \" (Expected: \" &lt;&lt; matched_ev2 &lt;&lt; \", Error: \" &lt;&lt; actual_error2 \n                  &lt;&lt; \", Rel Error: \" &lt;&lt; (rel_error2 * 100.0f) &lt;&lt; \"%) \";\n        bool pass2 = (rel_error2 &lt; 0.05f); // 5% relative error tolerance\n        std::cout &lt;&lt; (pass2 ? \"[PASS]\" : \"[FAIL - error too large]\") &lt;&lt; \"\\n\";\n\n        bool ev_check = pass1 &amp;&amp; pass2;\n        std::cout &lt;&lt; \"Overall eigenvalue check: \" &lt;&lt; (ev_check ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.42: Non-symmetric 3x3 matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.42] Non-Symmetric 3x3 Matrix\\n\";\n        std::cout &lt;&lt; \"Matrix [1,2,3; 4,5,6; 7,8,9]:\\n\";\n        non_sym_mat.print_matrix(true);\n\n        // Expected values for matrix [1,2,3; 4,5,6; 7,8,9]\n        // Characteristic equation: \u03bb\u00b3 - 15\u03bb\u00b2 - 18\u03bb = 0\n        // Solutions: \u03bb(\u03bb\u00b2 - 15\u03bb - 18) = 0\n        // \u03bb\u2081 = 0, \u03bb\u2082,\u2083 = (15 \u00b1 \u221a(225+72))/2 = (15 \u00b1 \u221a297)/2 \u2248 16.12, -1.12\n        // However, QR algorithm may have numerical errors, especially for non-symmetric matrices\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues (theoretical): 16.12, -1.12, 0.00\\n\";\n        std::cout &lt;&lt; \"  Note: This matrix is rank-deficient (determinant = 0), so one eigenvalue is 0\\n\";\n        std::cout &lt;&lt; \"  Note: QR algorithm may have numerical errors, especially for non-symmetric matrices\\n\";\n        std::cout &lt;&lt; \"  Acceptable range: largest eigenvalue ~15-18, smallest eigenvalue near 0\\n\";\n\n        tiny::Mat::EigenDecomposition result_qr2 = non_sym_mat.eigendecompose_qr(100, 1e-5f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalues:\\n\";\n        result_qr2.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Eigenvectors:\\n\";\n        result_qr2.eigenvectors.print_matrix(true);\n        std::cout &lt;&lt; \"Iterations: \" &lt;&lt; result_qr2.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_qr2.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n\n        // Check results with detailed error reporting\n        float expected_evs[3] = {16.12f, -1.12f, 0.0f};\n        bool matched[3] = {false, false, false};\n        float errors[3] = {0.0f, 0.0f, 0.0f};\n        float rel_errors[3] = {0.0f, 0.0f, 0.0f};\n\n        // Match each computed eigenvalue to the closest expected value\n        for (int i = 0; i &lt; result_qr2.eigenvalues.row; ++i)\n        {\n            float ev = result_qr2.eigenvalues(i, 0);\n            float min_error = 1e10f;\n            int best_match = -1;\n\n            // Find closest expected eigenvalue\n            for (int j = 0; j &lt; 3; ++j)\n            {\n                if (!matched[j])\n                {\n                    float error = fabsf(ev - expected_evs[j]);\n                    if (error &lt; min_error)\n                    {\n                        min_error = error;\n                        best_match = j;\n                    }\n                }\n            }\n\n            if (best_match &gt;= 0)\n            {\n                matched[best_match] = true;\n                errors[best_match] = min_error;\n                float expected = expected_evs[best_match];\n                rel_errors[best_match] = (fabsf(expected) &gt; 1e-6f) ? (min_error / fabsf(expected)) : min_error;\n\n                std::cout &lt;&lt; \"Eigenvalue \" &lt;&lt; i &lt;&lt; \": \" &lt;&lt; ev &lt;&lt; \" (Expected: \" &lt;&lt; expected \n                          &lt;&lt; \", Error: \" &lt;&lt; min_error &lt;&lt; \", Rel Error: \" &lt;&lt; (rel_errors[best_match] * 100.0f) &lt;&lt; \"%) \";\n\n                // For zero eigenvalue, use absolute tolerance; for others, use relative tolerance\n                bool pass = (fabsf(expected) &lt; 0.1f) ? (min_error &lt; 0.1f) : (rel_errors[best_match] &lt; 0.15f); // 15% tolerance for QR\n                std::cout &lt;&lt; (pass ? \"[PASS]\" : \"[FAIL - error too large]\") &lt;&lt; \"\\n\";\n            }\n        }\n\n        // Overall check\n        bool overall_pass = true;\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            bool pass = (fabsf(expected_evs[i]) &lt; 0.1f) ? (errors[i] &lt; 0.1f) : (rel_errors[i] &lt; 0.15f);\n            if (!pass) overall_pass = false;\n        }\n        std::cout &lt;&lt; \"Overall eigenvalue check: \" &lt;&lt; (overall_pass ? \"[PASS]\" : \"[FAIL - some eigenvalues have large errors]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.43: Parameter validation - max_iter &lt;= 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.43] Parameter Validation - max_iter &lt;= 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 1.0f; test_mat(0, 1) = 2.0f;\n        test_mat(1, 0) = 3.0f; test_mat(1, 1) = 4.0f;\n\n        tiny::Mat::EigenDecomposition result_zero = test_mat.eigendecompose_qr(0, 1e-6f);\n        std::cout &lt;&lt; \"max_iter = 0: Status = \" &lt;&lt; (result_zero.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_zero.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n\n        tiny::Mat::EigenDecomposition result_neg = test_mat.eigendecompose_qr(-1, 1e-6f);\n        std::cout &lt;&lt; \"max_iter = -1: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.44: Parameter validation - tolerance &lt; 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.44] Parameter Validation - tolerance &lt; 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 1.0f; test_mat(0, 1) = 2.0f;\n        test_mat(1, 0) = 3.0f; test_mat(1, 1) = 4.0f;\n\n        tiny::Mat::EigenDecomposition result_neg = test_mat.eigendecompose_qr(100, -1e-6f);\n        std::cout &lt;&lt; \"tolerance = -1e-6: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.45: Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.45] Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        tiny::Mat::EigenDecomposition result_empty = empty_mat.eigendecompose_qr(100, 1e-6f);\n        // Error case: empty matrix should return error status, eigenvalues may be 0x0 or 1x1 error matrix\n        bool empty_correct = (result_empty.status != TINY_OK) &amp;&amp; \n                            ((result_empty.eigenvalues.row == 0 &amp;&amp; result_empty.eigenvalues.col == 0) || \n                             (result_empty.eigenvalues.data == nullptr) ||\n                             (result_empty.eigenvalues.row == 1 &amp;&amp; result_empty.eigenvalues.col == 1 &amp;&amp; result_empty.eigenvalues.data != nullptr));\n        std::cout &lt;&lt; \"Empty matrix: Status = \" &lt;&lt; (result_empty.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \", eigenvalues rows = \" &lt;&lt; result_empty.eigenvalues.row \n                  &lt;&lt; \" (Expected: Error status, eigenvalues is 0x0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.5: eigendecompose() - Automatic method selection\n    std::cout &lt;&lt; \"\\n[E3.5] eigendecompose() - Automatic Method Selection\\n\";\n\n    // E3.51: Symmetric matrix (should use Jacobi)\n    {\n        std::cout &lt;&lt; \"\\n[E3.51] Symmetric Matrix (Auto-select: Jacobi)\\n\";\n        tiny::Mat sym_mat1(3, 3);\n        sym_mat1(0, 0) = 4.0f; sym_mat1(0, 1) = 1.0f; sym_mat1(0, 2) = 2.0f;\n        sym_mat1(1, 0) = 1.0f; sym_mat1(1, 1) = 3.0f; sym_mat1(1, 2) = 0.0f;\n        sym_mat1(2, 0) = 2.0f; sym_mat1(2, 1) = 0.0f; sym_mat1(2, 2) = 5.0f;\n        std::cout &lt;&lt; \"Matrix:\\n\";\n        sym_mat1.print_matrix(true);\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Method: Should automatically use Jacobi (symmetric matrix detected)\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues (approximate): 6.67, 3.48, 1.85\\n\";\n        std::cout &lt;&lt; \"  Note: Eigenvalues may appear in any order\\n\";\n\n        tiny::Mat::EigenDecomposition result_auto1 = sym_mat1.eigendecompose(1e-5f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalues:\\n\";\n        result_auto1.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Iterations: \" &lt;&lt; result_auto1.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_auto1.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Method used: Jacobi (auto-selected for symmetric matrix)\\n\";\n    }\n\n    // E3.52: Non-symmetric matrix (should use QR)\n    {\n        std::cout &lt;&lt; \"\\n[E3.52] Non-Symmetric Matrix (Auto-select: QR)\\n\";\n        std::cout &lt;&lt; \"[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Method: Should automatically use QR (non-symmetric matrix detected)\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues (theoretical): 16.12, -1.12, 0.00\\n\";\n        std::cout &lt;&lt; \"  Note: One eigenvalue should be near 0 (rank-deficient matrix)\\n\";\n        std::cout &lt;&lt; \"  Note: QR algorithm may have numerical errors for non-symmetric matrices\\n\";\n        std::cout &lt;&lt; \"  Acceptable: largest ~15-18, smallest near 0, one near -1 to -3\\n\";\n\n        tiny::Mat::EigenDecomposition result_auto2 = non_sym_mat.eigendecompose(1e-5f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalues:\\n\";\n        result_auto2.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Iterations: \" &lt;&lt; result_auto2.iterations &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_auto2.status == TINY_OK ? \"OK\" : \"Error\") &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"Method used: QR (auto-selected for non-symmetric matrix)\\n\";\n\n        // Check results with detailed error reporting\n        float expected_evs[3] = {16.12f, -1.12f, 0.0f};\n        bool matched[3] = {false, false, false};\n        float errors[3] = {0.0f, 0.0f, 0.0f};\n        float rel_errors[3] = {0.0f, 0.0f, 0.0f};\n\n        for (int i = 0; i &lt; result_auto2.eigenvalues.row; ++i)\n        {\n            float ev = result_auto2.eigenvalues(i, 0);\n            float min_error = 1e10f;\n            int best_match = -1;\n\n            for (int j = 0; j &lt; 3; ++j)\n            {\n                if (!matched[j])\n                {\n                    float error = fabsf(ev - expected_evs[j]);\n                    if (error &lt; min_error)\n                    {\n                        min_error = error;\n                        best_match = j;\n                    }\n                }\n            }\n\n            if (best_match &gt;= 0)\n            {\n                matched[best_match] = true;\n                errors[best_match] = min_error;\n                float expected = expected_evs[best_match];\n                rel_errors[best_match] = (fabsf(expected) &gt; 1e-6f) ? (min_error / fabsf(expected)) : min_error;\n\n                std::cout &lt;&lt; \"Eigenvalue \" &lt;&lt; i &lt;&lt; \": \" &lt;&lt; ev &lt;&lt; \" (Expected: \" &lt;&lt; expected \n                          &lt;&lt; \", Error: \" &lt;&lt; min_error &lt;&lt; \", Rel Error: \" &lt;&lt; (rel_errors[best_match] * 100.0f) &lt;&lt; \"%) \";\n\n                bool pass = (fabsf(expected) &lt; 0.1f) ? (min_error &lt; 0.1f) : (rel_errors[best_match] &lt; 0.15f);\n                std::cout &lt;&lt; (pass ? \"[PASS]\" : \"[FAIL - error too large]\") &lt;&lt; \"\\n\";\n            }\n        }\n\n        bool overall_pass = true;\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            bool pass = (fabsf(expected_evs[i]) &lt; 0.1f) ? (errors[i] &lt; 0.1f) : (rel_errors[i] &lt; 0.15f);\n            if (!pass) overall_pass = false;\n        }\n        std::cout &lt;&lt; \"Overall eigenvalue check: \" &lt;&lt; (overall_pass ? \"[PASS]\" : \"[FAIL - some eigenvalues have large errors]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.53: Parameter validation - tolerance &lt; 0\n    {\n        std::cout &lt;&lt; \"\\n[E3.53] Parameter Validation - tolerance &lt; 0\\n\";\n        tiny::Mat test_mat(2, 2);\n        test_mat(0, 0) = 2.0f; test_mat(0, 1) = 1.0f;\n        test_mat(1, 0) = 1.0f; test_mat(1, 1) = 2.0f;\n\n        tiny::Mat::EigenDecomposition result_neg = test_mat.eigendecompose(-1e-6f);\n        std::cout &lt;&lt; \"tolerance = -1e-6: Status = \" &lt;&lt; (result_neg.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_neg.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.54: eigendecompose() - Boundary case - empty matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.54] eigendecompose() - Boundary Case - Empty Matrix (0x0)\\n\";\n        tiny::Mat empty_mat(0, 0);\n\n        tiny::Mat::EigenDecomposition result_empty = empty_mat.eigendecompose(1e-6f);\n        // Error case: empty matrix should return error status, eigenvalues may be 0x0 or 1x1 error matrix\n        bool empty_correct = (result_empty.status != TINY_OK) &amp;&amp; \n                            ((result_empty.eigenvalues.row == 0 &amp;&amp; result_empty.eigenvalues.col == 0) || \n                             (result_empty.eigenvalues.data == nullptr) ||\n                             (result_empty.eigenvalues.row == 1 &amp;&amp; result_empty.eigenvalues.col == 1 &amp;&amp; result_empty.eigenvalues.data != nullptr));\n        std::cout &lt;&lt; \"Empty matrix: Status = \" &lt;&lt; (result_empty.status == TINY_OK ? \"OK\" : \"Error\") \n                  &lt;&lt; \", eigenvalues rows = \" &lt;&lt; result_empty.eigenvalues.row \n                  &lt;&lt; \" (Expected: Error status, eigenvalues is 0x0 or error state) \" &lt;&lt; (empty_correct ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.55: eigendecompose() - Error handling - non-square matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.55] eigendecompose() - Error Handling - Non-Square Matrix\\n\";\n        tiny::Mat non_square(2, 3);\n        tiny::Mat::EigenDecomposition result_non_square = non_square.eigendecompose(1e-6f);\n        std::cout &lt;&lt; \"Non-square matrix (2x3): Status = \" &lt;&lt; (result_non_square.status == TINY_OK ? \"OK\" : \"Error (Expected)\") \n                  &lt;&lt; \" \" &lt;&lt; (result_non_square.status != TINY_OK ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.6: SHM Application Scenario - Structural Dynamics\n    std::cout &lt;&lt; \"\\n[E3.6] SHM Application - Structural Dynamics Analysis\\n\";\n\n    // Create a simple 4-DOF structural system (mass-spring system)\n    {\n        std::cout &lt;&lt; \"\\n[E3.61] 4-DOF Mass-Spring System\\n\";\n        tiny::Mat K(4, 4);  // Stiffness matrix\n        K(0, 0) = 2.0f; K(0, 1) = -1.0f; K(0, 2) = 0.0f; K(0, 3) = 0.0f;\n        K(1, 0) = -1.0f; K(1, 1) = 2.0f; K(1, 2) = -1.0f; K(1, 3) = 0.0f;\n        K(2, 0) = 0.0f; K(2, 1) = -1.0f; K(2, 2) = 2.0f; K(2, 3) = -1.0f;\n        K(3, 0) = 0.0f; K(3, 1) = 0.0f; K(3, 2) = -1.0f; K(3, 3) = 1.0f;\n\n        std::cout &lt;&lt; \"Stiffness Matrix K:\\n\";\n        K.print_matrix(true);\n        std::cout &lt;&lt; \"Is symmetric: \" &lt;&lt; (K.is_symmetric(1e-6f) ? \"Yes\" : \"No\") &lt;&lt; \"\\n\";\n\n        // Quick frequency identification using power iteration\n        std::cout &lt;&lt; \"\\n[Quick Analysis] Primary frequency using power_iteration():\\n\";\n        std::cout &lt;&lt; \"[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected primary eigenvalue: ~3.53 (largest eigenvalue)\\n\";\n        std::cout &lt;&lt; \"  Expected primary frequency: sqrt(3.53) \u2248 1.88 rad/s\\n\";\n\n        tiny::Mat::EigenPair primary = K.power_iteration(500, 1e-6f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"  Primary eigenvalue: \" &lt;&lt; primary.eigenvalue &lt;&lt; \" (Expected: ~3.53)\\n\";\n        std::cout &lt;&lt; \"  Primary frequency: \" &lt;&lt; sqrtf(primary.eigenvalue) &lt;&lt; \" rad/s (Expected: ~1.88 rad/s)\\n\";\n        std::cout &lt;&lt; \"  Iterations: \" &lt;&lt; primary.iterations &lt;&lt; \"\\n\";\n        float error_primary = fabsf(primary.eigenvalue - 3.53f);\n        std::cout &lt;&lt; \"  Error from expected: \" &lt;&lt; error_primary &lt;&lt; (error_primary &lt; 0.2f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n\n        // Complete modal analysis using Jacobi\n        std::cout &lt;&lt; \"\\n[Complete Analysis] Full modal analysis using eigendecompose_jacobi():\\n\";\n        std::cout &lt;&lt; \"[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues (approximate): 3.53, 2.35, 1.00, 0.12\\n\";\n        std::cout &lt;&lt; \"  Expected natural frequencies: 1.88, 1.53, 1.00, 0.35 rad/s\\n\";\n        std::cout &lt;&lt; \"  Note: These are approximate values for the 4-DOF system\\n\";\n\n        tiny::Mat::EigenDecomposition modal = K.eigendecompose_jacobi(1e-5f, 100);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"All eigenvalues (natural frequencies squared):\\n\";\n        modal.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Natural frequencies (rad/s):\\n\";\n        float expected_freqs_4dof[4] = {1.88f, 1.53f, 1.00f, 0.35f};\n        for (int i = 0; i &lt; modal.eigenvalues.row; ++i)\n        {\n            float freq = sqrtf(modal.eigenvalues(i, 0));\n            std::cout &lt;&lt; \"  Mode \" &lt;&lt; i &lt;&lt; \": \" &lt;&lt; freq &lt;&lt; \" rad/s\";\n            // Check if frequency matches any expected value\n            bool matched = false;\n            for (int j = 0; j &lt; 4; ++j)\n            {\n                if (fabsf(freq - expected_freqs_4dof[j]) &lt; 0.15f)\n                {\n                    std::cout &lt;&lt; \" (Expected: ~\" &lt;&lt; expected_freqs_4dof[j] &lt;&lt; \" rad/s) [PASS]\";\n                    matched = true;\n                    break;\n                }\n            }\n            if (!matched) std::cout &lt;&lt; \" [CHECK]\";\n            std::cout &lt;&lt; \"\\n\";\n        }\n        std::cout &lt;&lt; \"Mode shapes (eigenvectors):\\n\";\n        modal.eigenvectors.print_matrix(true);\n        std::cout &lt;&lt; \"Total iterations: \" &lt;&lt; modal.iterations &lt;&lt; \"\\n\";\n    }\n\n    // E3.7: Edge Cases and Error Handling\n    std::cout &lt;&lt; \"\\n[E3.7] Edge Cases and Error Handling\\n\";\n\n    // E3.71: 1x1 matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.71] 1x1 Matrix\\n\";\n        tiny::Mat mat1x1(1, 1);\n        mat1x1(0, 0) = 5.0f;\n        std::cout &lt;&lt; \"Matrix: [5.0]\\n\";\n        std::cout &lt;&lt; \"[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalue: 5.0 (the matrix element itself)\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvector: [1.0] (normalized)\\n\";\n\n        tiny::Mat::EigenDecomposition result_1x1 = mat1x1.eigendecompose(1e-6f);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalue: \" &lt;&lt; result_1x1.eigenvalues(0, 0) &lt;&lt; \" (Expected: 5.0)\\n\";\n        std::cout &lt;&lt; \"Eigenvector:\\n\";\n        result_1x1.eigenvectors.print_matrix(true);\n        float error = fabsf(result_1x1.eigenvalues(0, 0) - 5.0f);\n        std::cout &lt;&lt; \"Error from expected: \" &lt;&lt; error &lt;&lt; (error &lt; 0.01f ? \" [PASS]\" : \" [FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.72: Zero matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.72] Zero Matrix\\n\";\n        tiny::Mat zero_mat(3, 3);\n        zero_mat.clear();\n        tiny::Mat::EigenPair result_zero = zero_mat.power_iteration(100, 1e-6f);\n        std::cout &lt;&lt; \"Status: \" &lt;&lt; (result_zero.status == TINY_OK ? \"OK\" : \"Error (Expected)\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.73: Identity matrix\n    {\n        std::cout &lt;&lt; \"\\n[E3.73] Identity Matrix\\n\";\n        tiny::Mat I = tiny::Mat::eye(3);\n        std::cout &lt;&lt; \"Matrix (3x3 Identity):\\n\";\n        I.print_matrix(true);\n        std::cout &lt;&lt; \"\\n[Expected Results]\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvalues: 1.0, 1.0, 1.0 (all eigenvalues are 1)\\n\";\n        std::cout &lt;&lt; \"  Expected eigenvectors: Any orthonormal basis (e.g., standard basis vectors)\\n\";\n        std::cout &lt;&lt; \"  Expected iterations: 1 (should converge immediately)\\n\";\n\n        tiny::Mat::EigenDecomposition result_I = I.eigendecompose_jacobi(1e-6f, 10);\n        std::cout &lt;&lt; \"\\n[Actual Results]\\n\";\n        std::cout &lt;&lt; \"Eigenvalues (should all be 1.0):\\n\";\n        result_I.eigenvalues.print_matrix(true);\n        std::cout &lt;&lt; \"Eigenvectors:\\n\";\n        result_I.eigenvectors.print_matrix(true);\n        std::cout &lt;&lt; \"Iterations: \" &lt;&lt; result_I.iterations &lt;&lt; \" (Expected: 1)\\n\";\n\n        // Check all eigenvalues are 1.0\n        bool all_one = true;\n        for (int i = 0; i &lt; result_I.eigenvalues.row; ++i)\n        {\n            if (fabsf(result_I.eigenvalues(i, 0) - 1.0f) &gt; 0.01f)\n            {\n                all_one = false;\n                break;\n            }\n        }\n        std::cout &lt;&lt; \"All eigenvalues = 1.0: \" &lt;&lt; (all_one ? \"[PASS]\" : \"[FAIL]\") &lt;&lt; \"\\n\";\n    }\n\n    // E3.8: Performance Test for SHM Applications\n    std::cout &lt;&lt; \"\\n[E3.8] Performance Test for SHM Applications\\n\";\n\n    // E3.81: Power iteration performance (fast method for dominant eigenvalue)\n    std::cout &lt;&lt; \"\\n[E3.81] Power Iteration Performance (Real-time SHM - Dominant Eigenvalue)\\n\";\n    TIME_OPERATION(\n        tiny::Mat::EigenPair perf_result = stiffness.power_iteration(500, 1e-6f);\n        (void)perf_result;\n    , \"Power Iteration (3x3 matrix)\");\n\n    // E3.82: Inverse power iteration performance (system identification - smallest eigenvalue)\n    std::cout &lt;&lt; \"\\n[E3.82] Inverse Power Iteration Performance (System Identification - Smallest Eigenvalue)\\n\";\n    TIME_OPERATION(\n        tiny::Mat::EigenPair perf_inv_result = stiffness.inverse_power_iteration(500, 1e-6f);\n        (void)perf_inv_result;\n    , \"Inverse Power Iteration (3x3 matrix)\");\n\n    // E3.83: Jacobi method performance (complete eigendecomposition for symmetric matrices)\n    std::cout &lt;&lt; \"\\n[E3.83] Jacobi Method Performance (Complete Eigendecomposition - Symmetric Matrices)\\n\";\n    TIME_OPERATION(\n        tiny::Mat::EigenDecomposition perf_jacobi = stiffness.eigendecompose_jacobi(1e-5f, 100);\n        (void)perf_jacobi;\n    , \"Jacobi Decomposition (3x3 symmetric matrix)\");\n\n    // E3.84: QR method performance (complete eigendecomposition for general matrices)\n    std::cout &lt;&lt; \"\\n[E3.84] QR Method Performance (Complete Eigendecomposition - General Matrices)\\n\";\n    TIME_OPERATION(\n        tiny::Mat::EigenDecomposition perf_qr = non_sym_mat.eigendecompose_qr(100, 1e-5f);\n        (void)perf_qr;\n    , \"QR Decomposition (3x3 general matrix)\");\n\n    std::cout &lt;&lt; \"\\n[Eigenvalue Decomposition Tests Complete]\\n\";\n}\n\nvoid tiny_matrix_test()\n{\n    std::cout &lt;&lt; \"============ [tiny_matrix_test start] ============\\n\";\n    std::cout &lt;&lt; \"\\n[Test Organization: Application-Oriented Logic]\\n\";\n    std::cout &lt;&lt; \"  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\\n\\n\";\n\n    // ========================================================================\n    // Phase 1: Object Foundation (A)\n    // ========================================================================\n    // Purpose: Learn to create and manipulate matrix objects\n    // A1: Constructor &amp; Destructor\n    // test_constructor_destructor();\n\n    // A2: Element Access\n    // test_element_access();\n\n    // A3: ROI Operations\n    // test_roi_operations();\n\n    // ========================================================================\n    // Phase 2: Basic Operations (B)\n    // ========================================================================\n    // Purpose: Learn basic arithmetic operations\n    // B1-B8: Arithmetic Operators\n    // test_assignment_operator();      // B1\n    // test_matrix_addition();         // B2\n    // test_constant_addition();       // B3\n    // test_matrix_subtraction();      // B4\n    // test_constant_subtraction();    // B5\n    // test_matrix_division();          // B6\n    // test_constant_division();       // B7\n    // test_matrix_exponentiation();    // B8\n\n    // ========================================================================\n    // Phase 3: Matrix Properties (C)\n    // ========================================================================\n    // Purpose: Understand matrix properties and basic linear algebra\n    // C1-C8: Matrix Properties\n    // test_matrix_transpose();        // C1\n    // test_matrix_cofactor();         // C2\n    // test_matrix_determinant();       // C3\n    // test_matrix_adjoint();           // C4\n    // test_matrix_normalize();         // C5\n    // test_matrix_norm();              // C6\n    // test_inverse_adjoint_adjoint();  // C7\n    // test_matrix_utilities();         // C8\n\n    // ========================================================================\n    // Phase 4: Linear System Solving (D)\n    // ========================================================================\n    // Purpose: Core application - solving linear systems Ax = b\n    // D1-D7: Linear System Solving\n    // test_gaussian_eliminate();       // D1\n    // test_row_reduce_from_gaussian(); // D2\n    // test_inverse_gje();             // D3\n    // test_dotprod();                 // D4\n    // test_solve();                   // D5\n    // test_band_solve();              // D6\n    // test_roots();                   // D7\n\n    // ========================================================================\n    // Phase 5: Advanced Linear Algebra (E1+2)\n    // ========================================================================\n    // Purpose: Advanced linear algebra operations for stable and efficient solving\n    // E1: Matrix Decomposition\n    // test_matrix_decomposition();\n\n    // E2: Gram-Schmidt Orthogonalization\n    // test_gram_schmidt_orthogonalize();\n\n    // ========================================================================\n    // Phase 6: System Identification Applications (E3)\n    // ========================================================================\n    // Purpose: Eigenvalue decomposition for SHM and modal analysis\n    // E3: Eigenvalue Decomposition\n    // test_eigenvalue_decomposition();\n\n    // ========================================================================\n    // Phase 7: Auxiliary Functions (F)\n    // ========================================================================\n    // Purpose: Convenience functions and I/O operations\n    // F1: Stream Operators\n    // test_stream_operators();\n\n    // F2: Global Arithmetic Operators\n    // test_matrix_operations();\n\n    // ========================================================================\n    // Phase 8: Quality Assurance (G)\n    // ========================================================================\n    // Purpose: Ensure robustness, performance, and correctness\n    // G1: Boundary Conditions and Error Handling\n    test_boundary_conditions();\n\n    // G2: Performance Benchmarks\n    test_performance_benchmarks();\n\n    // G3: Memory Layout\n    test_memory_layout();\n\n    std::cout &lt;&lt; \"============ [tiny_matrix_test end] ============\\n\";\n\n    // Remove current task from watchdog after all tests complete\n    // This prevents watchdog timeout after app_main() returns\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (task_wdt_added)\n    {\n        esp_task_wdt_delete(NULL);  // Remove current task from watchdog\n        task_wdt_added = false;\n    }\n#endif\n}\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#test-outputs","title":"TEST OUTPUTS","text":""},{"location":"MATH/MATRIX/tiny-matrix-test/#phase-1-object-foundation-a","title":"Phase 1: Object Foundation (A)","text":"<pre><code>[Test Organization: Application-Oriented Logic]\n  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\n\n\n[A1: Constructor &amp; Destructor Tests]\n[A1.1] Default Constructor\nMatrix Info &gt;&gt;&gt;\nrows            1\ncols            1\nelements        1\npaddings        0\nstride          1\nmemory          1\ndata pointer    0x3fce9a78\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n[A1.2] Constructor with Rows and Cols\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        0\nstride          4\nmemory          12\ndata pointer    0x3fce9a9c\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            0            0            0       |\n           0            0            0            0       |\n           0            0            0            0       |\n&lt;&lt;&lt; Matrix Elements\n\n[A1.3] Constructor with Rows, Cols and Stride\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fce9ad0\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            0            0            0       |      0 \n           0            0            0            0       |      0 \n           0            0            0            0       |      0 \n&lt;&lt;&lt; Matrix Elements\n\n[A1.4] Constructor with External Data\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        0\nstride          4\nmemory          12\ndata pointer    0x3fc9a49c\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            1            2            3       |\n           4            5            6            7       |\n           8            9           10           11       |\n&lt;&lt;&lt; Matrix Elements\n\n[A1.5] Constructor with External Data and Stride\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a4f0\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            1            2            3       |      0 \n           4            5            6            7       |      0 \n           8            9           10           11       |      0 \n&lt;&lt;&lt; Matrix Elements\n\n[A1.6] Copy Constructor\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fce9bd8\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            1            2            3       |2.10195e-44 \n           4            5            6            7       |1.61399 \n           8            9           10           11       |1.61413 \n&lt;&lt;&lt; Matrix Elements\n\n\n[A2: Element Access Tests]\n[A2.1] Non-const Access\nMatrix Info &gt;&gt;&gt;\nrows            2\ncols            3\nelements        6\npaddings        0\nstride          3\nmemory          6\ndata pointer    0x3fce9a9c\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         1.1          2.2          3.3       |\n         4.4          5.5          6.6       |\n&lt;&lt;&lt; Matrix Elements\n\n[A2.2] Const Access\nconst_mat(0, 0): 1.1\n\n[A3: ROI Operations Tests]\n[Material Matrices]\nmatA:\nMatrix Info &gt;&gt;&gt;\nrows            2\ncols            3\nelements        6\npaddings        0\nstride          3\nmemory          6\ndata pointer    0x3fce9a9c\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         0.1          0.2          0.3       |\n         0.4          0.5          0.6       |\n&lt;&lt;&lt; Matrix Elements\n\nmatB:\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            1            2            3       |      0 \n           4            5            6            7       |      0 \n           8            9           10           11       |      0 \n&lt;&lt;&lt; Matrix Elements\n\nmatC:\nMatrix Info &gt;&gt;&gt;\nrows            1\ncols            1\nelements        1\npaddings        0\nstride          1\nmemory          1\ndata pointer    0x3fce9a78\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n[A3.1] Copy ROI - Over Range Case\n[Error] copy_paste: source matrix exceeds destination column boundary: col_pos=2, src.cols=3, dest.cols=4\nmatB after copy_paste matA at (1, 2):\nMatrix Elements &gt;&gt;&gt;\n           0            1            2            3       |      0 \n           4            5            6            7       |      0 \n           8            9           10           11       |      0 \n&lt;&lt;&lt; Matrix Elements\n\nnothing changed.\n[A3.2] Copy ROI - Suitable Range Case\nmatB after copy_paste matA at (1, 1):\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            1            2            3       |      0 \n           4          0.1          0.2          0.3       |      0 \n           8          0.4          0.5          0.6       |      0 \n&lt;&lt;&lt; Matrix Elements\n\nsuccessfully copied.\n[A3.3] Copy Head\nmatC after copy_head matB:\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            1            2            3       |      0 \n           4          0.1          0.2          0.3       |      0 \n           8          0.4          0.5          0.6       |      0 \n&lt;&lt;&lt; Matrix Elements\n\n[A3.4] Copy Head - Memory Sharing Check\nmatB(0, 0) = 99.99f\n\n[A3.5] copy_paste() - Error Handling - Negative Position\n[Error] copy_paste: invalid position: row_pos=-1, col_pos=0 (must be non-negative)\ncopy_paste with row_pos=-1: error = 258 (Expected: TINY_ERR_INVALID_ARG) [PASS]\n[Error] copy_paste: invalid position: row_pos=0, col_pos=-1 (must be non-negative)\ncopy_paste with col_pos=-1: error = 258 (Expected: TINY_ERR_INVALID_ARG) [PASS]\n\n[A3.6] copy_paste() - Error Handling - Out of Bounds\n[Error] copy_paste: source matrix exceeds destination row boundary: row_pos=0, src.rows=3, dest.rows=2\ncopy_paste 3x3 into 2x2 at (0,0): error = 258 (Expected: TINY_ERR_INVALID_ARG) [PASS]\n[Error] copy_paste: source matrix exceeds destination row boundary: row_pos=1, src.rows=2, dest.rows=2\ncopy_paste 2x2 into 2x2 at (1,1): error = 258 (Expected: TINY_ERR_INVALID_ARG) [PASS]\n\n[A3.7] copy_paste() - Boundary Case - Empty Source Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] copy_paste: source matrix data pointer is null\ncopy_paste empty matrix: error = 258 (Expected: TINY_ERR_INVALID_ARG) [PASS]\n\n[A3.8] copy_head() - Error Handling - Source Owns Its Memory\n[Error] copy_head: source matrix owns its memory (ext_buff=false). Cannot share pointer - would cause double-free. Use copy assignment or copy constructor instead.\ncopy_head from matrix with owned memory: error = 258 (Expected: TINY_ERR_INVALID_ARG) [PASS]\nmatC (should be unchanged):\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n       99.99            1            2            3       |      0 \n           4          0.1          0.2          0.3       |      0 \n           8          0.4          0.5          0.6       |      0 \n&lt;&lt;&lt; Matrix Elements\n\n[A3.9] Get a View of ROI - Low Level Function\nget a view of ROI with overrange dimensions - rows:\n[Error] view_roi: ROI exceeds row boundary: start_row=1, roi_rows=3, source.rows=3\nget a view of ROI with overrange dimensions - cols:\n[Error] view_roi: ROI exceeds column boundary: start_col=1, roi_cols=4, source.cols=4\nget a view of ROI with suitable dimensions:\nroi3:\nMatrix Info &gt;&gt;&gt;\nrows            2\ncols            2\nelements        4\npaddings        3\nstride          5\nmemory          10\ndata pointer    0x3fc9a29c\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      1   (This is a Sub-Matrix View)\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         0.1          0.2       |    0.3            0            8 \n         0.4          0.5       |    0.6            0   4.2039e-45 \n&lt;&lt;&lt; Matrix Elements\n\n[A3.10] Get a View of ROI - Using ROI Structure\nMatrix Info &gt;&gt;&gt;\nrows            2\ncols            2\nelements        4\npaddings        3\nstride          5\nmemory          10\ndata pointer    0x3fc9a29c\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      1   (This is a Sub-Matrix View)\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         0.1          0.2       |    0.3            0            8 \n         0.4          0.5       |    0.6            0   4.2039e-45 \n&lt;&lt;&lt; Matrix Elements\n\n[A3.11] Copy ROI - Low Level Function\nMatrix Info &gt;&gt;&gt;\nrows            2\ncols            2\nelements        4\npaddings        0\nstride          2\nmemory          4\ndata pointer    0x3fce9ca8\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         0.1          0.2       |\n         0.4          0.5       |\n&lt;&lt;&lt; Matrix Elements\n\n[A3.12] Copy ROI - Using ROI Structure\ntime for copy_roi using ROI structure: 46 ms\nMatrix Info &gt;&gt;&gt;\nrows            2\ncols            2\nelements        4\npaddings        0\nstride          2\nmemory          4\ndata pointer    0x3fce9cbc\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         0.1          0.2       |\n         0.4          0.5       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[A3.13] ROI resize_roi() Function\nInitial ROI: pos_x=0, pos_y=0, width=2, height=2\nAfter resize_roi(1, 1, 3, 3): pos_x=1, pos_y=1, width=3, height=3\nROI resize test: [PASS]\n\n[A3.14] ROI area_roi() Function\nROI(0, 0, 3, 4) area: 12 (Expected: 12) [PASS]\nROI(1, 2, 5, 6) area: 30 (Expected: 30) [PASS]\n[A3.15] Block\ntime for block: 50 ms\nMatrix Info &gt;&gt;&gt;\nrows            2\ncols            2\nelements        4\npaddings        0\nstride          2\nmemory          4\ndata pointer    0x3fce9cd0\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         0.1          0.2       |\n         0.4          0.5       |\n&lt;&lt;&lt; Matrix Elements\n\n[A3.16] Swap Rows\nmatB before swap rows:\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n       99.99            1            2            3       |      0 \n           4          0.1          0.2          0.3       |      0 \n           8          0.4          0.5          0.6       |      0 \n&lt;&lt;&lt; Matrix Elements\n\nmatB after swap_rows(0, 2):\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           8          0.4          0.5          0.6       |      0 \n           4          0.1          0.2          0.3       |      0 \n       99.99            1            2            3       |      0 \n&lt;&lt;&lt; Matrix Elements\n\n[A3.17] Swap Columns\nmatB before swap columns:\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           8          0.4          0.5          0.6       |      0 \n           4          0.1          0.2          0.3       |      0 \n       99.99            1            2            3       |      0 \n&lt;&lt;&lt; Matrix Elements\n\nmatB after swap_cols(0, 2):\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         0.5          0.4            8          0.6       |      0 \n         0.2          0.1            4          0.3       |      0 \n           2            1        99.99            3       |      0 \n&lt;&lt;&lt; Matrix Elements\n\n[A3.18] Clear\nmatB before clear:\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n         0.5          0.4            8          0.6       |      0 \n         0.2          0.1            4          0.3       |      0 \n           2            1        99.99            3       |      0 \n&lt;&lt;&lt; Matrix Elements\n\nmatB after clear:\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a284\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n           0            0            0            0       |      0 \n           0            0            0            0       |      0 \n           0            0            0            0       |      0 \n&lt;&lt;&lt; Matrix Elements\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#phase-2-basic-operations-b","title":"Phase 2: Basic Operations (B)","text":"<pre><code>[Test Organization: Application-Oriented Logic]\n  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\n\n\n[B1: Assignment Operator Tests]\n\n[B1.1] Assignment (Same Dimensions)\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B1.2] Assignment (Different Dimensions)\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B1.3] Assignment to Sub-Matrix (Expect Error)\n[Error] Assignment to a sub-matrix is not allowed.\nMatrix Elements &gt;&gt;&gt;\n           5            6       |      7            0            8 \n           9           10       |     11            0   4.2039e-45 \n&lt;&lt;&lt; Matrix Elements\n\n\n[B1.4] Self-Assignment\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B2: Matrix Addition Tests]\n\n[B2.1] Matrix Addition (Same Dimensions)\nMatrix Elements &gt;&gt;&gt;\n           2            3            4       |\n           5            6            7       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B2.2] Sub-Matrix Addition\nMatrix Elements &gt;&gt;&gt;\n          10           12       |      7            0            8 \n          18           20       |     11            0           12 \n&lt;&lt;&lt; Matrix Elements\n\n\n[B2.3] Full Matrix + Sub-Matrix Addition\nMatrix Elements &gt;&gt;&gt;\n          12           14       |\n          20           22       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B2.4] Addition Dimension Mismatch (Expect Error)\n[Error] Matrix addition failed: Dimension mismatch (2x2 vs 3x3)\n\n[B3: Constant Addition Tests]\n\n[B3.1] Full Matrix + Constant\nMatrix Elements &gt;&gt;&gt;\n           5            6            7       |\n           8            9           10       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B3.2] Sub-Matrix + Constant\nMatrix Elements &gt;&gt;&gt;\n           8            9       |      7            0            8 \n          12           13       |     11            0           12 \n&lt;&lt;&lt; Matrix Elements\n\n\n[B3.3] Add Zero\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B3.4] Add Negative Constant\nMatrix Elements &gt;&gt;&gt;\n          -5            5       |\n          15           25       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B4: Matrix Subtraction Tests]\n\n[B4.1] Matrix Subtraction\nMatrix Elements &gt;&gt;&gt;\n           4            5       |\n           6            7       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B4.2] Subtraction Dimension Mismatch (Expect Error)\n[Error] Matrix subtraction failed: Dimension mismatch (2x2 vs 3x3)\n\n[B5: Constant Subtraction Tests]\n\n[B5.1] Full Matrix - Constant\nMatrix Elements &gt;&gt;&gt;\n          -1            0            1       |\n           2            3            4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B5.2] Sub-Matrix - Constant\nMatrix Elements &gt;&gt;&gt;\n         3.5          4.5       |      7            0            8 \n         7.5          8.5       |     11            0   4.2039e-45 \n&lt;&lt;&lt; Matrix Elements\n\n\n[B6: Matrix Element-wise Division Tests]\n\n[B6.1] Element-wise Division (Same Dimensions, No Zero)\nMatrix Elements &gt;&gt;&gt;\n           5            5       |\n           6            5       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B6.2] Dimension Mismatch (Expect Error)\n[Error] Matrix division failed: Dimension mismatch (2x2 vs 3x3)\n\n[B6.3] Division by Matrix Containing Zero (Expect Error)\n[Error] Matrix division failed: Division by zero detected at position (0, 1)\nMatrix Elements &gt;&gt;&gt;\n           5           10       |\n          15           20       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B7: Matrix Division by Constant Tests]\n\n[B7.1] Divide Full Matrix by Positive Constant\nMatrix Elements &gt;&gt;&gt;\n           1          1.5            2       |\n         2.5            3          3.5       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B7.2] Divide Matrix by Negative Constant\nMatrix Elements &gt;&gt;&gt;\n          -2           -4       |\n          -6           -8       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B7.3] Division by Zero Constant (Expect Error)\n[Error] Matrix division by zero is undefined (divisor=0)\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B8: Matrix Exponentiation Tests]\n\n[B8.1] Raise Each Element to Power of 2\nMatrix Elements &gt;&gt;&gt;\n           4            9       |\n          16           25       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B8.2] Raise Each Element to Power of 0\nMatrix Elements &gt;&gt;&gt;\n           1            1       |\n           1            1       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B8.3] Raise Each Element to Power of 1\nMatrix Elements &gt;&gt;&gt;\n           9            8       |\n           7            6       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B8.4] Raise Each Element to Power of -1 (Expect Error or Warning)\n[Error] Negative exponent not supported in operator^ (exponent=-1)\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           4            5       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[B8.5] Raise Matrix Containing Zero to Power of 3\nMatrix Elements &gt;&gt;&gt;\n           0            8       |\n          -1           27       |\n&lt;&lt;&lt; Matrix Elements\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#pphase-3-matrix-properties-c","title":"PPhase 3: Matrix Properties (C)","text":"<pre><code>[Test Organization: Application-Oriented Logic]\n  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\n\n\n[C1: Matrix Transpose Tests]\n\n[C1.1] Transpose of 2x3 Matrix\nOriginal 2x3 Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\nTransposed 3x2 Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            4       |\n           2            5       |\n           3            6       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C1.2] Transpose of 3x3 Square Matrix\nOriginal 3x3 Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\nTransposed 3x3 Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            4            7       |\n           2            5            8       |\n           3            6            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C1.3] Transpose of Matrix with Padding\nOriginal 4x2 Matrix (with padding):\nMatrix Elements &gt;&gt;&gt;\n           1            2       |      0 \n           3            4       |      0 \n           5            6       |      0 \n           7            8       |      0 \n&lt;&lt;&lt; Matrix Elements\n\nTransposed 2x4 Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            3            5            7       |\n           2            4            6            8       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C1.4] Transpose of Empty Matrix\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2: Matrix Minor and Cofactor Tests]\n\n[C2.1] Minor of 3x3 Matrix (Remove Row 1, Col 1)\nOriginal 3x3 Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\nMinor Matrix (remove row 1, col 1, no sign):\nMatrix Elements &gt;&gt;&gt;\n           1            3       |\n           7            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.2] Cofactor of 3x3 Matrix (Remove Row 1, Col 1)\nNote: Cofactor matrix is the same as minor matrix.\n      The sign (-1)^(i+j) is applied when computing cofactor value, not to matrix elements.\nCofactor Matrix (same as minor):\nMatrix Elements &gt;&gt;&gt;\n           1            3       |\n           7            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.3] Minor (Remove Row 0, Col 0)\nMatrix Elements &gt;&gt;&gt;\n           5            6       |\n           8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.4] Cofactor (Remove Row 0, Col 0)\nNote: Cofactor matrix is the same as minor matrix.\nMatrix Elements &gt;&gt;&gt;\n           5            6       |\n           8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.5] Cofactor (Remove Row 0, Col 1)\nNote: Cofactor matrix is the same as minor matrix.\n      When computing cofactor value, sign (-1)^(0+1) = -1 would be applied.\nCofactor Matrix (same as minor):\nMatrix Elements &gt;&gt;&gt;\n           4            6       |\n           7            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.6] Minor (Remove Row 2, Col 2)\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           4            5       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.7] Cofactor (Remove Row 2, Col 2)\nNote: Cofactor matrix is the same as minor matrix.\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           4            5       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.8] Minor of 4x4 Matrix (Remove Row 2, Col 1)\nMatrix Elements &gt;&gt;&gt;\n           1            2            3            4       |\n           5            6            7            8       |\n           9           10           11           12       |\n          13           14           15           16       |\n&lt;&lt;&lt; Matrix Elements\n\nMinor Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            3            4       |\n           5            7            8       |\n          13           15           16       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.9] Cofactor of 4x4 Matrix (Remove Row 2, Col 1)\nNote: Cofactor matrix is the same as minor matrix.\n      When computing cofactor value, sign (-1)^(2+1) = -1 would be applied.\nCofactor Matrix (same as minor):\nMatrix Elements &gt;&gt;&gt;\n           1            3            4       |\n           5            7            8       |\n          13           15           16       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C2.10] Non-square Matrix (Expect Error)\nTesting minor():\n[Error] Minor requires square matrix (got 3x4)\nminor() result: Non-empty (Error) [FAIL]\nTesting cofactor():\n[Error] Minor requires square matrix (got 3x4)\ncofactor() result: Non-empty (Error) [FAIL]\n\n[C2.11] minor() - Boundary Case - Out of Bounds Indices\n[Error] minor: target_row=-1 is out of range [0, 2]\nminor(-1, 0): Non-empty (Error) [FAIL]\n[Error] minor: target_col=-1 is out of range [0, 2]\nminor(0, -1): Non-empty (Error) [FAIL]\n[Error] minor: target_row=3 is out of range [0, 2]\nminor(3, 0) (out of bounds): Non-empty (Error) [FAIL]\n\n[C2.12] minor() - Boundary Case - 1x1 Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n1x1 matrix minor(0,0): Empty matrix (Expected) [PASS]\n\n[C3: Matrix Determinant Tests]\n\n[C3.1] 1x1 Matrix Determinant\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           7       |\n&lt;&lt;&lt; Matrix Elements\n\nDeterminant: 7  (Expected: 7)\n\n[C3.2] 2x2 Matrix Determinant\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           3            8       |\n           4            6       |\n&lt;&lt;&lt; Matrix Elements\n\nDeterminant: -14  (Expected: -14)\n\n[C3.3] 3x3 Matrix Determinant\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           0            4            5       |\n           1            0            6       |\n&lt;&lt;&lt; Matrix Elements\n\nDeterminant: 22  (Expected: 22)\n\n[C3.4] 4x4 Matrix Determinant\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3            4       |\n           5            6            7            8       |\n           9           10           11           12       |\n          13           14           15           16       |\n&lt;&lt;&lt; Matrix Elements\n\nNote: This matrix has linearly dependent rows (each row differs by constant 4),\n      so the determinant should be 0.\nDeterminant: 0  (Expected: 0)\n\n[C3.5] 5x5 Matrix Determinant (Tests Auto-select to LU Method)\nMatrix (5x5, tridiagonal):\nMatrix Elements &gt;&gt;&gt;\n           2            1            0            0            0       |\n           1            2            1            0            0       |\n           0            1            2            1            0       |\n           0            0            1            2            1       |\n           0            0            0            1            2       |\n&lt;&lt;&lt; Matrix Elements\n\nDeterminant (auto-select, should use LU for n &gt; 4): 6\nNote: For n = 5 &gt; 4, auto-select should use LU decomposition (O(n\u00b3)).\n\n[C3.6] Non-square Matrix (Expect Error)\nMatrix (3x4, non-square):\nMatrix Elements &gt;&gt;&gt;\n           0            0            0            0       |\n           0            0            0            0       |\n           0            0            0            0       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] Determinant requires a square matrix (got 3x4)\nDeterminant: 0  (Expected: 0 with error message)\n\n[C3.7] Comparison of Different Methods (5x5 Matrix)\nMatrix (5x5):\nMatrix Elements &gt;&gt;&gt;\n           2            2            3            4            5       |\n           2            5            6            8           10       |\n           3            6           10           12           15       |\n           4            8           12           17           20       |\n           5           10           15           20           26       |\n&lt;&lt;&lt; Matrix Elements\n\nDeterminant (auto-select): 56  (should use LU for n &gt; 4)\nDeterminant (Laplace):     56  (O(n!), slow for n=5)\nDeterminant (LU):          56  (O(n\u00b3), efficient)\nDeterminant (Gaussian):    56  (O(n\u00b3), efficient)\nNote: All methods should give the same result (within numerical precision).\n      Auto-select should use LU for n &gt; 4, avoiding slow Laplace expansion.\n\n[C3.8] Large Matrix (6x6) - Tests Efficient Methods\nMatrix (6x6, showing first 4x4 block):\n       1.5          2          3          4 ...\n         2        4.5          6          8 ...\n         3          6        9.5         12 ...\n         4          8         12       16.5 ...\n...\nDeterminant (auto-select, uses LU): 2.85938\nDeterminant (LU):                   2.85938\nDeterminant (Gaussian):             2.85938\nNote: For n &gt; 4, auto-select uses LU decomposition (O(n\u00b3) instead of O(n!)).\n\n[C3.9] Large Matrix (8x8) - Performance Comparison\nMatrix (8x8, showing first 4x4 block):\n         1          2          3          4 ...\n         2          4          6          8 ...\n         3          6          9         12 ...\n         4          8         12         16 ...\n...\n[Error] LU decomposition: Matrix is singular or near-singular.\n[Warning] determinant_lu: LU decomposition failed (status=458754), matrix may be singular\nDeterminant (LU):       0\nDeterminant (Gaussian): 0\nNote: Both methods are O(n\u00b3) and should be much faster than Laplace expansion.\n\n[C3.10] determinant_laplace() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] determinant_laplace: matrix data pointer is null\nEmpty matrix determinant (Laplace): 0 (Expected: 1.0) [FAIL]\n\n[C3.11] determinant_lu() - Boundary Case - Empty Matrix\n[Error] determinant_lu: matrix data pointer is null\nEmpty matrix determinant (LU): 0 (Expected: 1.0) [FAIL]\n\n[C3.12] determinant_gaussian() - Boundary Case - Empty Matrix\n[Error] determinant_gaussian: matrix data pointer is null\nEmpty matrix determinant (Gaussian): 0 (Expected: 1.0) [FAIL]\n\n[C3.13] Determinant Methods - Non-Square Matrix\n[Error] Determinant requires a square matrix (got 2x3)\n[Error] Determinant requires a square matrix (got 2x3)\n[Error] Determinant requires a square matrix (got 2x3)\nNon-square matrix (2x3) determinant (Laplace): 0 (Expected: 0.0) [PASS]\nNon-square matrix (2x3) determinant (LU): 0 (Expected: 0.0) [PASS]\nNon-square matrix (2x3) determinant (Gaussian): 0 (Expected: 0.0) [PASS]\n\n[C4: Matrix Adjoint Tests]\n\n[C4.1] Adjoint of 1x1 Matrix\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           5       |\n&lt;&lt;&lt; Matrix Elements\n\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] adjoint: failed to create cofactor matrix at (0, 0)\nAdjoint Matrix:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C4.2] Adjoint of 2x2 Matrix\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nAdjoint Matrix:\nMatrix Elements &gt;&gt;&gt;\n           4           -2       |\n          -3            1       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C4.3] Adjoint of 3x3 Matrix\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           0            4            5       |\n           1            0            6       |\n&lt;&lt;&lt; Matrix Elements\n\nAdjoint Matrix:\nMatrix Elements &gt;&gt;&gt;\n          24          -12           -2       |\n           5            3           -5       |\n          -4            2            4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C4.4] Adjoint of Non-Square Matrix (Expect Error)\nOriginal Matrix (2x3, non-square):\nMatrix Elements &gt;&gt;&gt;\n           0            0            0       |\n           0            0            0       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] Adjoint requires a square matrix (got 2x3)\nAdjoint Matrix (should be empty due to error):\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C5: Matrix Normalization Tests]\n\n[C5.1] Normalize a Standard 2x2 Matrix\nBefore normalization:\nMatrix Elements &gt;&gt;&gt;\n           3            4       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nAfter normalization (Expected L2 norm = 1):\nMatrix Elements &gt;&gt;&gt;\n    0.424264     0.565685       |\n    0.424264     0.565685       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C5.2] Normalize a 2x2 Matrix with Stride=4 (Padding Test)\nBefore normalization:\nMatrix Elements &gt;&gt;&gt;\n           3            4       |      0            0 \n           3            4       |      0            0 \n&lt;&lt;&lt; Matrix Elements\n\nAfter normalization:\nMatrix Elements &gt;&gt;&gt;\n    0.424264     0.565685       |      0            0 \n    0.424264     0.565685       |      0            0 \n&lt;&lt;&lt; Matrix Elements\n\n\n[C5.3] Normalize a Zero Matrix (Expect Warning)\nMatrix Elements &gt;&gt;&gt;\n           0            0       |\n           0            0       |\n&lt;&lt;&lt; Matrix Elements\n\n[Warning] normalize: matrix norm is zero (matrix is all zeros), normalization skipped\n\n[C6: Matrix Norm Calculation Tests]\n\n[C6.1] 2x2 Matrix Norm (Expect 5.0)\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           3            4       |\n           0            0       |\n&lt;&lt;&lt; Matrix Elements\n\nCalculated Norm: 5\n\n[C6.2] Zero Matrix Norm (Expect 0.0)\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           0            0            0       |\n           0            0            0       |\n           0            0            0       |\n&lt;&lt;&lt; Matrix Elements\n\nCalculated Norm: 0\n\n[C6.3] Matrix with Negative Values\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n          -1           -2       |\n          -3           -4       |\n&lt;&lt;&lt; Matrix Elements\n\nCalculated Norm: 5.47723  (Expect sqrt(30) \u2248 5.477)\n\n[C6.4] 2x2 Matrix with Stride=4 (Padding Test)\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |      0            0 \n           3            4       |      0            0 \n&lt;&lt;&lt; Matrix Elements\n\nCalculated Norm: 5.47723  (Expect sqrt(30) \u2248 5.477)\n\n[C7: Matrix Inversion Tests]\n\n[C7.1] Inverse of 2x2 Matrix\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           4            7       |\n           2            6       |\n&lt;&lt;&lt; Matrix Elements\n\nInverse Matrix:\nMatrix Elements &gt;&gt;&gt;\n         0.6         -0.7       |\n        -0.2          0.4       |\n&lt;&lt;&lt; Matrix Elements\n\nExpected Approx:\n[ 0.6  -0.7 ]\n[ -0.2  0.4 ]\n\n[C7.2] Singular Matrix (Expect Error)\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           2            4       |\n&lt;&lt;&lt; Matrix Elements\n\nNote: This matrix is singular (determinant = 0), so inverse should fail.\n[Error] inverse_adjoint: matrix is singular (det=0), cannot compute inverse\nInverse Matrix (Should be zero matrix):\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C7.3] Inverse of 3x3 Matrix\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           3            0            2       |\n           2            0           -2       |\n           0            1            1       |\n&lt;&lt;&lt; Matrix Elements\n\nInverse Matrix:\nMatrix Elements &gt;&gt;&gt;\n         0.2          0.2           -0       |\n        -0.2          0.3            1       |\n         0.2         -0.3            0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C7.4] Non-Square Matrix (Expect Error)\nOriginal Matrix (2x3, non-square):\nMatrix Elements &gt;&gt;&gt;\n           0            0            0       |\n           0            0            0       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] inverse_adjoint: requires square matrix (got 2x3)\nInverse Matrix (should be empty due to error):\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C8: Matrix Utilities Tests]\n\n[C8.1] Generate Identity Matrix (eye)\n3x3 Identity Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            0            0       |\n           0            1            0       |\n           0            0            1       |\n&lt;&lt;&lt; Matrix Elements\n\n5x5 Identity Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            0            0            0            0       |\n           0            1            0            0            0       |\n           0            0            1            0            0       |\n           0            0            0            1            0       |\n           0            0            0            0            1       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C8.2] Generate Ones Matrix\n3x4 Ones Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            1            1            1       |\n           1            1            1            1       |\n           1            1            1            1       |\n&lt;&lt;&lt; Matrix Elements\n\n4x4 Ones Matrix (Square):\nMatrix Elements &gt;&gt;&gt;\n           1            1            1            1       |\n           1            1            1            1       |\n           1            1            1            1       |\n           1            1            1            1       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C8.3] Augment Two Matrices Horizontally [A | B]\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix B:\nMatrix Elements &gt;&gt;&gt;\n           5            6            7       |\n           8            9           10       |\n&lt;&lt;&lt; Matrix Elements\n\nAugmented Matrix [A | B]:\nMatrix Elements &gt;&gt;&gt;\n           1            2            5            6            7       |\n           3            4            8            9           10       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C8.4] Augment with Row Mismatch (Expect Error)\n[Error] augment: row counts must match (A: 2, B: 3)\nMatrix Info &gt;&gt;&gt;\nrows            1\ncols            1\nelements        1\npaddings        0\nstride          1\nmemory          1\ndata pointer    0x3fce9c54\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\n\n[C8.5] Vertically Stack Two Matrices [A; B]\nMatrix A (top):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix B (bottom):\nMatrix Elements &gt;&gt;&gt;\n           7            8            9       |\n          10           11           12       |\n&lt;&lt;&lt; Matrix Elements\n\nVertically Stacked Matrix [A; B]:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n          10           11           12       |\n&lt;&lt;&lt; Matrix Elements\n\nExpected: 4x3 matrix with A on top, B on bottom\n\n[C8.6] Vertical Stack with Different Row Counts (Same Columns)\nMatrix A (1x3):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix B (3x3):\nMatrix Elements &gt;&gt;&gt;\n           4            5            6       |\n           7            8            9       |\n          10           11           12       |\n&lt;&lt;&lt; Matrix Elements\n\nVertically Stacked Matrix [A; B] (1x3 + 3x3 = 4x3):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n          10           11           12       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[C8.7] VStack with Column Mismatch (Expect Error)\nMatrix A (2x2):\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix B (2x3, different columns):\nMatrix Elements &gt;&gt;&gt;\n           5            6            7       |\n           8            9           10       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] vstack: column counts must match (A: 2, B: 3)\nResult (should be empty due to error):\nMatrix Info &gt;&gt;&gt;\nrows            1\ncols            1\nelements        1\npaddings        0\nstride          1\nmemory          1\ndata pointer    0x3fce9e1c\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#phase-4-linear-system-solving-d","title":"Phase 4: Linear System Solving (D)","text":"<pre><code>[Test Organization: Application-Oriented Logic]\n  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\n\n\n[D1: Gaussian Elimination Tests]\n\n[D1.1] 3x3 Matrix (Simple Upper Triangular)\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           2            1           -1       |\n          -3           -1            2       |\n          -2            1            2       |\n&lt;&lt;&lt; Matrix Elements\n\nAfter Gaussian Elimination (Should be upper triangular):\nMatrix Elements &gt;&gt;&gt;\n           2            1           -1       |\n           0          0.5          0.5       |\n           0            0           -1       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D1.2] 3x4 Augmented Matrix (Linear System Ax = b)\nOriginal Augmented Matrix [A | b]:\nMatrix Elements &gt;&gt;&gt;\n           1            2           -1            8       |\n          -3           -1            2          -11       |\n          -2            1            2           -3       |\n&lt;&lt;&lt; Matrix Elements\n\nAfter Gaussian Elimination (Row Echelon Form):\nMatrix Elements &gt;&gt;&gt;\n           1            2           -1            8       |\n           0            5           -1           13       |\n           0            0            1            0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D1.3] Singular Matrix (No Unique Solution)\nOriginal Singular Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           2            4       |\n&lt;&lt;&lt; Matrix Elements\n\nAfter Gaussian Elimination (Should show rows of zeros):\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           0            0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D1.4] Zero Matrix\nMatrix Elements &gt;&gt;&gt;\n           0            0            0       |\n           0            0            0       |\n           0            0            0       |\n&lt;&lt;&lt; Matrix Elements\n\nAfter Gaussian Elimination (Should be a zero matrix):\nMatrix Elements &gt;&gt;&gt;\n           0            0            0       |\n           0            0            0       |\n           0            0            0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D1.5] gaussian_eliminate() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] gaussian_eliminate: matrix data pointer is null\nEmpty matrix gaussian_eliminate: Empty matrix or error state (Expected) [PASS]\n\n[D1.6] gaussian_eliminate() - Boundary Case - 1x1 Matrix\n1x1 matrix after gaussian_eliminate:\nMatrix Elements &gt;&gt;&gt;\n           5       |\n&lt;&lt;&lt; Matrix Elements\n\n1x1 matrix gaussian_eliminate: [PASS]\n\n[D2: Row Reduce from Gaussian (RREF) Tests]\n\n[D2.1] 3x4 Augmented Matrix\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2           -1           -4       |\n           2            3           -1          -11       |\n          -2            0           -3           22       |\n&lt;&lt;&lt; Matrix Elements\n\nRREF Result:\nMatrix Elements &gt;&gt;&gt;\n           1            0            0           -8       |\n           0            1            0            1       |\n           0            0            1           -2       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D2.2] 2x3 Matrix\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\nRREF Result:\nMatrix Elements &gt;&gt;&gt;\n           1            0           -1       |\n           0            1            2       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D2.3] Already Reduced Matrix\nOriginal Matrix:\nMatrix Elements &gt;&gt;&gt;\n           1            0            2       |\n           0            1            3       |\n&lt;&lt;&lt; Matrix Elements\n\nRREF Result:\nMatrix Elements &gt;&gt;&gt;\n           1            0            2       |\n           0            1            3       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D2.4] row_reduce_from_gaussian() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] row_reduce_from_gaussian: matrix data pointer is null\nEmpty matrix row_reduce_from_gaussian: Empty matrix or error state (Expected) [PASS]\n\n[D3: Gaussian Inverse Tests]\n\n[D3.1] 2x2 Matrix Inverse\nOriginal matrix (mat1):\nMatrix Elements &gt;&gt;&gt;\n           4            7       |\n           2            6       |\n&lt;&lt;&lt; Matrix Elements\n\nInverse matrix (mat1):\nMatrix Elements &gt;&gt;&gt;\n         0.6         -0.7       |\n        -0.2          0.4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D3.2] Identity Matrix Inverse\nOriginal matrix (Identity):\nMatrix Elements &gt;&gt;&gt;\n           1            0            0       |\n           0            1            0       |\n           0            0            1       |\n&lt;&lt;&lt; Matrix Elements\n\nInverse matrix (Identity):\nMatrix Elements &gt;&gt;&gt;\n           1            0            0       |\n           0            1            0       |\n           0            0            1       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D3.3] Singular Matrix (Expected: No Inverse)\nOriginal matrix (singular):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] inverse_gje: matrix is singular (not invertible), left half is not identity matrix at (0, 2): expected=0, actual=-1\nInverse matrix (singular):\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D3.4] 3x3 Matrix Inverse\nOriginal matrix (mat4):\nMatrix Elements &gt;&gt;&gt;\n           4            7            2       |\n           3            5            1       |\n           8            6            9       |\n&lt;&lt;&lt; Matrix Elements\n\nInverse matrix (mat4):\nMatrix Elements &gt;&gt;&gt;\n    -1.85714      2.42857     0.142857       |\n    0.904762    -0.952381   -0.0952381       |\n     1.04762     -1.52381     0.047619       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D3.5] Non-square Matrix Inverse (Expected Error)\nOriginal matrix (non-square):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] inverse_gje: requires square matrix (got 2x3)\nInverse matrix (non-square):\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D4: Dot Product Tests]\n\n[D4.1] Valid Dot Product (Same Length Vectors)\nVector A:\nMatrix Elements &gt;&gt;&gt;\n           1       |\n           2       |\n           3       |\n&lt;&lt;&lt; Matrix Elements\n\nVector B:\nMatrix Elements &gt;&gt;&gt;\n           4       |\n           5       |\n           6       |\n&lt;&lt;&lt; Matrix Elements\n\nDot product of vectorA and vectorB: 32\n\n[D4.2] Invalid Dot Product (Dimension Mismatch)\nVector A (3x1):\nMatrix Elements &gt;&gt;&gt;\n           1       |\n           2       |\n           3       |\n&lt;&lt;&lt; Matrix Elements\n\nVector C (2x1, different size):\nMatrix Elements &gt;&gt;&gt;\n           1       |\n           2       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] dotprod: matrices must have the same size (A: 3x1, B: 2x1)\nDot product (dimension mismatch): 0\n\n[D4.3] Dot Product of Zero Vectors\nZero Vector A:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n           0       |\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\nZero Vector B:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n           0       |\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\nDot product of zero vectors: 0\n\n[D5: Solve Linear System Tests]\n\n[D5.1] Solving a Simple 2x2 System Ax = b\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           2            1       |\n           1            3       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           5       |\n           6       |\n&lt;&lt;&lt; Matrix Elements\n\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n         1.8       |\n         1.4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D5.2] Solving a 3x3 System Ax = b\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2            1       |\n           2            0            3       |\n           3            2            1       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           9       |\n           8       |\n           7       |\n&lt;&lt;&lt; Matrix Elements\n\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n          -1       |\n     3.33333       |\n     3.33333       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D5.3] Solving a System Where One Row is All Zeros (Expect Failure or Infinite Solutions)\nMatrix A (has zero row):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           0            0            0       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           9       |\n           0       |\n          15       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] solve: pivot at (1, 1) is zero or too small (0), matrix is singular or near-singular\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D5.4] Solving a System with Zero Determinant (Singular Matrix)\nMatrix A (singular, determinant = 0):\nMatrix Elements &gt;&gt;&gt;\n           2            4            1       |\n           1            2            3       |\n           3            6            2       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           5       |\n           6       |\n           7       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] solve: pivot at (1, 1) is zero or too small (0), matrix is singular or near-singular\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D5.5] Solving a System with Linearly Dependent Rows (Expect Failure or Infinite Solutions)\nMatrix A (all rows linearly dependent):\nMatrix Elements &gt;&gt;&gt;\n           1            1            1       |\n           2            2            2       |\n           3            3            3       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           6       |\n          12       |\n          18       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] solve: pivot at (1, 1) is zero or too small (0), matrix is singular or near-singular\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D5.6] Solving a Larger 4x4 System Ax = b\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           4            2            3            1       |\n           2            5            1            2       |\n           3            1            6            3       |\n           1            2            3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n          10       |\n          12       |\n          14       |\n          16       |\n&lt;&lt;&lt; Matrix Elements\n\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n     1.80645       |\n    0.258065       |\n   -0.516129       |\n     3.80645       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D5.7] solve() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] solve: matrix A data pointer is null\nEmpty system solve: Empty matrix or error state (Expected) [PASS]\n\n[D5.8] solve() - Error Handling - Dimension Mismatch\n[Error] solve: dimensions do not match (A: 2x2, b: 3x1, expected b: 2x1)\nDimension mismatch solve: Empty matrix or error state (Expected) [PASS]\n\n[D6: Band Solve Tests]\n\n[D6.1] Simple 3x3 Band Matrix\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           2            1            0       |\n           1            3            2       |\n           0            1            4       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           5       |\n           6       |\n           7       |\n&lt;&lt;&lt; Matrix Elements\n\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n         2.5       |\n           0       |\n        1.75       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D6.2] 4x4 Band Matrix\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           2            1            0            0       |\n           1            3            2            0       |\n           0            1            4            2       |\n           0            0            1            5       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           8       |\n           9       |\n          10       |\n          11       |\n&lt;&lt;&lt; Matrix Elements\n\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n     3.51429       |\n    0.971429       |\n     1.28571       |\n     1.94286       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D6.3] Incompatible Dimensions (Expect Error)\nMatrix A (3x3):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b (2x1, incompatible):\nMatrix Elements &gt;&gt;&gt;\n          10       |\n          11       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] band_solve: dimensions do not match (A: 3x3, b: 2x1, expected b: 3x1)\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D6.4] Singular Matrix (No Unique Solution)\nMatrix A (singular, linearly dependent rows):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           2            4            6       |\n           3            6            9       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n          10       |\n          20       |\n          30       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] band_solve: zero or near-zero pivot detected at (1, 1) = 0, matrix is singular or near-singular\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D6.5] band_solve() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] band_solve: matrix A data pointer is null\nEmpty system band_solve: Empty matrix or error state (Expected) [PASS]\n\n[D6.6] band_solve() - Error Handling - Invalid Bandwidth\n[Error] band_solve: bandwidth k must be &gt;= 1 (got -1)\nband_solve with k=-1: Empty matrix or error state (Expected) [PASS]\n\n[D7: Roots Tests]\n\n[D7.1] Solving a Simple 2x2 System Ax = b\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           2            1       |\n           1            3       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           5       |\n           6       |\n&lt;&lt;&lt; Matrix Elements\n\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n         1.8       |\n         1.4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D7.2] Solving a 3x3 System Ax = b\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2            1       |\n           2            0            3       |\n           3            2            1       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           9       |\n           8       |\n           7       |\n&lt;&lt;&lt; Matrix Elements\n\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n          -1       |\n     3.33333       |\n     3.33333       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D7.3] Singular Matrix (No Unique Solution)\nMatrix A (singular, linearly dependent rows):\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           2            4       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b:\nMatrix Elements &gt;&gt;&gt;\n           5       |\n           6       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] roots: pivot is zero or too small at (1, 1) = 0, system may have no solution\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[D7.4] Incompatible Dimensions (Expect Error)\nMatrix A (3x3):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\nVector b (2x1, incompatible):\nMatrix Elements &gt;&gt;&gt;\n          10       |\n          11       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] roots: dimensions do not match (A: 3x3, y: 2x1, expected y: 3x1)\nDimension mismatch roots: Empty matrix or error state (Expected) [PASS]\n\n[D7.5] roots() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] roots: matrix A data pointer is null\nEmpty system roots: Empty matrix or error state (Expected) [PASS]\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#phase-5-advanced-linear-algebra-e12","title":"Phase 5: Advanced Linear Algebra (E1+2)","text":"<pre><code>[Test Organization: Application-Oriented Logic]\n  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\n\n\n[E1: Matrix Decomposition Tests]\n\n[E1.1] is_positive_definite() - Basic Functionality\n\n[E1.11] Positive Definite 3x3 Matrix\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           4            1            0       |\n           1            3            0       |\n           0            0            2       |\n&lt;&lt;&lt; Matrix Elements\n\nIs positive definite: True (Expected: True) [PASS]\n\n[E1.12] Non-Positive Definite Matrix\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           2            1       |\n&lt;&lt;&lt; Matrix Elements\n\nIs positive definite: False (Expected: False) [PASS]\n\n[E1.13] max_minors_to_check Parameter Testing\nmax_minors_to_check = -1 (check all): True (Expected: True) [PASS]\nmax_minors_to_check = 3 (check first 3): True (Expected: True) [PASS]\n[Error] is_positive_definite: max_minors_to_check must be &gt; 0 or -1 (got 0)\nmax_minors_to_check = 0 (invalid): False (Expected: False) [PASS]\n\n[E1.14] Parameter Validation - Negative Tolerance\n[Error] is_positive_definite: tolerance must be non-negative (got -1e-06)\ntolerance = -1e-6 (invalid): False (Expected: False) [PASS]\n\n[E1.15] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] is_positive_definite: matrix data pointer is null\nEmpty matrix (0x0): False (Expected: False, empty matrix is invalid) [PASS]\n\n[E1.16] Boundary Case - Invalid Dimensions\nNon-square matrix (2x3): False (Expected: False) [PASS]\n\n[E1.2] LU Decomposition\n\n[E1.21] 3x3 Matrix - LU Decomposition with Pivoting\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           2            1            1       |\n           4            3            3       |\n           2            1            2       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nStatus: OK\nL matrix (lower triangular):\nMatrix Elements &gt;&gt;&gt;\n           1            0            0       |\n         0.5            1            0       |\n         0.5            1            1       |\n&lt;&lt;&lt; Matrix Elements\n\nU matrix (upper triangular):\nMatrix Elements &gt;&gt;&gt;\n           4            3            3       |\n           0         -0.5         -0.5       |\n           0            0            1       |\n&lt;&lt;&lt; Matrix Elements\n\nP matrix (permutation):\nMatrix Elements &gt;&gt;&gt;\n           0            1            0       |\n           1            0            0       |\n           0            0            1       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Verification] P * A should equal L * U\nTotal difference: 0 [PASS]\n\n[E1.22] Solve Linear System using LU Decomposition\nSystem: A * x = b\nA:\nMatrix Elements &gt;&gt;&gt;\n           2            1            1       |\n           4            3            3       |\n           2            1            2       |\n&lt;&lt;&lt; Matrix Elements\n\nb:\nMatrix Elements &gt;&gt;&gt;\n           1       |\n           2       |\n           3       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n         0.5       |\n          -2       |\n           2       |\n&lt;&lt;&lt; Matrix Elements\n\nVerification error: 0 [PASS]\n\n[E1.26] solve_lu() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] lu_decompose: matrix data pointer is null\n[Error] solve_lu: invalid LU decomposition (status: 458759)\nEmpty system: x rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.27] solve_lu() - Invalid LU Decomposition\n[Error] solve_lu: invalid LU decomposition (status: 258)\nInvalid LU decomposition: x rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.23] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] lu_decompose: matrix data pointer is null\nEmpty matrix: Status = Error, L rows = 1 (Expected: Error status, L is 0x0 or error state) [PASS]\n\n[E1.24] LU Decomposition without Pivoting\nStatus: OK\nPivoted: No (Expected) [PASS]\nVerification (A = L * U): difference = 0 [PASS]\n\n[E1.25] lu_decompose() - Error Handling - Non-Square Matrix\n[Error] lu_decompose: requires square matrix (got 2x3)\nNon-square matrix (2x3): Status = Error (Expected) [PASS]\n\n[E1.3] Cholesky Decomposition\n\n[E1.31] SPD Matrix - Cholesky Decomposition\nMatrix A (SPD):\nMatrix Elements &gt;&gt;&gt;\n           4            2            0       |\n           2            5            1       |\n           0            1            3       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nStatus: OK\nL matrix (lower triangular):\nMatrix Elements &gt;&gt;&gt;\n           2            0            0       |\n           1            2            0       |\n           0          0.5      1.65831       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Verification] L * L^T should equal A\nTotal difference: 2.38419e-07 [PASS]\n\n[E1.32] Solve Linear System using Cholesky Decomposition\nSolution x:\nMatrix Elements &gt;&gt;&gt;\n    0.272727       |\n    0.454545       |\n    0.181818       |\n&lt;&lt;&lt; Matrix Elements\n\nVerification error: 0 [PASS]\n\n[E1.35] solve_cholesky() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] cholesky_decompose: matrix data pointer is null\n[Error] solve_cholesky: invalid Cholesky decomposition (status: 458759)\nEmpty system: x rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.36] solve_cholesky() - Invalid Cholesky Decomposition\n[Error] solve_cholesky: invalid Cholesky decomposition (status: 258)\nInvalid Cholesky decomposition: x rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.33] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] cholesky_decompose: matrix data pointer is null\nEmpty matrix: Status = Error, L rows = 1 (Expected: Error status, L is 0x0 or error state) [PASS]\n\n[E1.34] Non-Symmetric Matrix (Should Fail)\n[Error] cholesky_decompose: requires symmetric matrix\nNon-symmetric matrix: Status = Error (Expected) [PASS]\n\n[E1.37] solve_cholesky() - Error Handling - Dimension Mismatch\n[Error] solve_cholesky: dimension mismatch - b must be 3x1 vector (got 4x1)\nDimension mismatch solve_cholesky: Empty matrix or error state (Expected) [PASS]\n\n[E1.4] QR Decomposition\n\n[E1.41] General 3x3 Matrix - QR Decomposition\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nStatus: OK\nQ matrix (orthogonal):\nMatrix Elements &gt;&gt;&gt;\n    0.123091     0.904534     0.408248       |\n    0.492366     0.301511    -0.816497       |\n     0.86164    -0.301511     0.408248       |\n&lt;&lt;&lt; Matrix Elements\n\nR matrix (upper triangular):\nMatrix Elements &gt;&gt;&gt;\n     8.12404      9.60114      11.0782       |\n           0     0.904534      1.80907       |\n           0            0            0       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Verification] Q * R should equal A\nTotal difference: 1.66893e-06 [PASS]\nQ orthogonality error: 2.83733e-07 [PASS]\n\n[E1.42] Least Squares Solution using QR Decomposition\nOverdetermined system: A * x \u2248 b\nA:\nMatrix Elements &gt;&gt;&gt;\n           1            1       |\n           1            2       |\n           1            3       |\n&lt;&lt;&lt; Matrix Elements\n\nb:\nMatrix Elements &gt;&gt;&gt;\n           2       |\n           3       |\n           4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nLeast squares solution x:\nMatrix Elements &gt;&gt;&gt;\n           1       |\n           1       |\n&lt;&lt;&lt; Matrix Elements\n\nResidual norm ||A*x - b||: 4.12953e-07\n\n[E1.46] solve_qr() - Boundary Case - Empty Matrix\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] qr_decompose: matrix data pointer is null\n[Error] solve_qr: invalid QR decomposition (status: 458759)\nEmpty system: x rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.47] solve_qr() - Invalid QR Decomposition\n[Error] solve_qr: invalid QR decomposition (status: 258)\nInvalid QR decomposition: x rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.43] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] qr_decompose: matrix data pointer is null\nEmpty matrix: Status = Error, Q rows = 1 (Expected: Error status, Q is 0x0 or error state) [PASS]\n\n[E1.44] Boundary Case - Zero Rows or Columns\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] qr_decompose: matrix data pointer is null\nMatrix with 0 rows (0x3): Status = Error [PASS]\n[Error] qr_decompose: matrix data pointer is null\nMatrix with 0 cols (3x0): Status = Error [PASS]\n\n[E1.45] solve_qr() - Error Handling - Dimension Mismatch\n[Error] solve_qr: dimension mismatch - b must be 3x1 vector (got 4x1)\nDimension mismatch solve_qr: Empty matrix or error state (Expected) [PASS]\n\n[E1.5] Singular Value Decomposition (SVD)\n\n[E1.51] General 3x3 Matrix - SVD Decomposition\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nStatus: OK\nSingular values:\nMatrix Elements &gt;&gt;&gt;\n     1.06837       |\n     16.8481       |\n           0       |\n&lt;&lt;&lt; Matrix Elements\n\nNumerical rank: 2\nIterations: 7\nReconstruction error: 1.68085e-05 [PASS]\n\n[E1.52] Pseudo-inverse using SVD\nMatrix A (3x2):\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n           5            6       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nPseudo-inverse A^+ (2x3):\nMatrix Elements &gt;&gt;&gt;\n    -1.33333    -0.333333     0.666666       |\n     1.08333     0.333333    -0.416666       |\n&lt;&lt;&lt; Matrix Elements\n\nVerification error (A * A^+ * A \u2248 A): 5.72205e-06 [PASS]\n\n[E1.57] pseudo_inverse() - Parameter Validation - tolerance &lt; 0\n[Error] pseudo_inverse: tolerance must be &gt;= 0 (got -1e-06)\ntolerance = -1e-6: A_plus rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.58] pseudo_inverse() - Invalid SVD Decomposition\n[Error] pseudo_inverse: invalid SVD decomposition (status: 258)\nInvalid SVD decomposition: A_plus rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.53] Parameter Validation - max_iter &lt;= 0\n[Error] svd_decompose: max_iter must be &gt; 0 (got 0)\nmax_iter = 0: Status = Error (Expected) [PASS]\n[Error] svd_decompose: max_iter must be &gt; 0 (got -1)\nmax_iter = -1: Status = Error (Expected) [PASS]\n\n[E1.54] Parameter Validation - tolerance &lt; 0\n[Error] svd_decompose: tolerance must be &gt;= 0 (got -1e-06)\ntolerance = -1e-6: Status = Error (Expected) [PASS]\n\n[E1.55] Boundary Case - Empty Matrix (m=0 or n=0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] svd_decompose: matrix data pointer is null\nMatrix with 0 rows (0x3): Status = Error [PASS]\n[Error] svd_decompose: matrix data pointer is null\nMatrix with 0 cols (3x0): Status = Error [PASS]\n\n[E1.56] pseudo_inverse() - Error Handling - Invalid SVD Decomposition\n[Error] pseudo_inverse: invalid SVD decomposition (status: 258)\nInvalid SVD decomposition: A_plus rows = 1 (Expected: 0 or error state) [PASS]\n\n[E1.6] Matrix Decomposition Performance Tests\n\n[E1.61] LU Decomposition Performance\n[Performance] LU Decomposition (4x4 matrix): 142.00 us\n\n[E1.62] Cholesky Decomposition Performance\n[Performance] Cholesky Decomposition (4x4 SPD matrix): 90.00 us\n\n[E1.63] QR Decomposition Performance\n[Performance] QR Decomposition (4x4 matrix): 188.00 us\n\n[E1.64] SVD Decomposition Performance\n[Performance] SVD Decomposition (4x4 matrix): 373.00 us\n\n[Matrix Decomposition Tests Complete]\n\n[E2: Gram-Schmidt Orthogonalization Tests]\n\n[E2.1] Basic Orthogonalization - Linearly Independent Vectors\nInput vectors (each column is a vector):\nMatrix Elements &gt;&gt;&gt;\n        1.00         1.00         0.00       |\n        0.00         1.00         1.00       |\n        1.00         0.00         1.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nStatus: OK\nOrthogonalized vectors Q (each column is orthogonal):\nMatrix Elements &gt;&gt;&gt;\n        0.71         0.41        -0.58       |\n        0.00         0.82         0.58       |\n        0.71        -0.41         0.58       |\n&lt;&lt;&lt; Matrix Elements\n\nCoefficients R (upper triangular):\nMatrix Elements &gt;&gt;&gt;\n        1.41         0.71         0.71       |\n        0.00         1.22         0.41       |\n        0.00         0.00         1.15       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Verification] Q^T * Q should be identity\nOrthogonality error: 0.00 [PASS]\n\n[Verification] Each column of Q should be normalized\n  Column 0 norm: 1.00 (error: 0.00) [PASS]\n  Column 1 norm: 1.00 (error: 0.00) [PASS]\n  Column 2 norm: 1.00 (error: 0.00) [PASS]\n\n[Verification] Q * R should reconstruct original vectors\nReconstruction error: 0.00 [PASS]\n\n[E2.2] Orthogonalization - Near-Linear-Dependent Vectors\nInput vectors (third vector is nearly linear dependent):\nMatrix Elements &gt;&gt;&gt;\n        1.00         0.00         1.00       |\n        0.00         1.00         1.00       |\n        0.00         0.00         0.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nStatus: OK\nOrthogonalized vectors Q:\nMatrix Elements &gt;&gt;&gt;\n        1.00         0.00         0.00       |\n        0.00         1.00         0.00       |\n        0.00         0.00         1.00       |\n&lt;&lt;&lt; Matrix Elements\n\nCoefficients R:\nMatrix Elements &gt;&gt;&gt;\n        1.00         0.00         1.00       |\n        0.00         1.00         1.00       |\n        0.00         0.00         0.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Note] Third column norm: 1.00 (should be 0 if linearly dependent, or 1 if orthogonalized)\n\n[E2.3] Orthogonalization - 2D Vectors (2x2)\nInput vectors:\nMatrix Elements &gt;&gt;&gt;\n        3.00         1.00       |\n        1.00         2.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\nStatus: OK\nOrthogonalized vectors Q:\nMatrix Elements &gt;&gt;&gt;\n        0.95        -0.32       |\n        0.32         0.95       |\n&lt;&lt;&lt; Matrix Elements\n\nCoefficients R:\nMatrix Elements &gt;&gt;&gt;\n        3.16         1.58       |\n        0.00         1.58       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Verification] Dot product of Q columns: 0.00 (should be ~0 for orthogonal) [PASS]\n\n[E2.4] Error Handling - Invalid Input\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] gram_schmidt_orthogonalize: Input matrix is null.\nEmpty matrix test: PASS (correctly rejected)\n\n[E2.5] gram_schmidt_orthogonalize() - Parameter Validation - Negative Tolerance\n[Error] gram_schmidt_orthogonalize: tolerance must be non-negative (got -1e-06)\ntolerance = -1e-6: PASS (correctly rejected)\n\n[E2.6] gram_schmidt_orthogonalize() - Boundary Case - Zero Rows\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] gram_schmidt_orthogonalize: Input matrix is null.\nZero rows (0x2): PASS (correctly rejected)\n\n[E2.7] gram_schmidt_orthogonalize() - Boundary Case - Zero Columns\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] gram_schmidt_orthogonalize: Input matrix is null.\nZero columns (2x0): PASS (correctly rejected)\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#phase-6-system-identification-applications-e3","title":"Phase 6: System Identification Applications (E3)","text":"<pre><code>[Test Organization: Application-Oriented Logic]\n  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\n\n\n[E3: Eigenvalue Decomposition Tests]\n\n[E3.1] is_symmetric() - Basic Functionality\n[E3.11] Symmetric 3x3 Matrix\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           4            1            2       |\n           1            3            0       |\n           2            0            5       |\n&lt;&lt;&lt; Matrix Elements\n\nIs symmetric: True (Expected: True)\n\n[E3.12] Non-Symmetric 3x3 Matrix\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\nIs symmetric: False (Expected: False)\n\n[E3.13] Non-Square Matrix (2x3)\nIs symmetric: False (Expected: False)\n\n[E3.14] Symmetric Matrix with Small Numerical Errors\nMatrix with error 1e-05:\nMatrix Elements &gt;&gt;&gt;\n           1      2.00001       |\n           2            3       |\n&lt;&lt;&lt; Matrix Elements\n\nDifference: |A(0,1) - A(1,0)| = 1.001358e-05 (Expected: 0.000010)\nA(0,1) stored value: 2.00001001 (Expected: 2.00001001)\nIs symmetric (tolerance=1e-4): True (Expected: True, tolerance &gt; error) [PASS]\nIs symmetric (tolerance=1e-6): False (Expected: False, tolerance &lt; error) [PASS]\nDifference accuracy: |actual_diff - expected_diff| = 1.36e-08 [PASS - difference stored correctly]\n\n[E3.15] Parameter Validation - Negative Tolerance\n[Error] is_symmetric: tolerance must be &gt;= 0 (got -1e-06)\ntolerance = -1e-6 (invalid): False (Expected: False) [PASS]\n\n[E3.16] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] is_symmetric: matrix data pointer is null\nEmpty matrix (0x0): False (Expected: False, empty matrix is invalid) [PASS]\n\n[E3.2] power_iteration() - Dominant Eigenvalue\n\n[E3.21] Simple 2x2 Matrix\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n        2.00         1.00       |\n        1.00         2.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Expected eigenvalues: 3.0 (largest), 1.0 (smallest)\n  Expected dominant eigenvector (for \u03bb=3): approximately [0.707, 0.707] or [-0.707, -0.707] (normalized)\n  Expected dominant eigenvector (for \u03bb=1): approximately [0.707, -0.707] or [-0.707, 0.707] (normalized)\n\n[Actual Results]\n  Dominant eigenvalue: 3.00 (Expected: 3.0, largest eigenvalue)\n  Iterations: 2\n  Status: OK\n  Dominant eigenvector:\nMatrix Elements &gt;&gt;&gt;\n        0.71       |\n        0.71       |\n&lt;&lt;&lt; Matrix Elements\n\n  Error from expected (3.0): 0.00 [PASS]\n\n[E3.22] 3x3 Stiffness Matrix (SHM Application)\nStiffness Matrix:\nMatrix Elements &gt;&gt;&gt;\n        2.00        -1.00         0.00       |\n       -1.00         2.00        -1.00       |\n        0.00        -1.00         2.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Expected eigenvalues (approximate): 3.414 (largest), 2.000, 0.586 (smallest)\n  Expected primary frequency: sqrt(3.414) \u2248 1.848 rad/s\n\n[Actual Results]\n  Dominant eigenvalue (primary frequency squared): 3.41\n  Primary frequency: 1.85 rad/s (Expected: ~1.848 rad/s)\n  Iterations: 8\n  Status: OK\n  Error from expected (3.41): 0.00 [PASS]\n\n[E3.23] Non-Square Matrix (Expect Error)\n[Error] power_iteration: requires square matrix (got 2x3)\nStatus: Error (Expected)\n\n[E3.25] Parameter Validation - max_iter &lt;= 0\n[Error] power_iteration: max_iter must be &gt; 0 (got 0)\nmax_iter = 0: Status = Error (Expected) [PASS]\n[Error] power_iteration: max_iter must be &gt; 0 (got -1)\nmax_iter = -1: Status = Error (Expected) [PASS]\n\n[E3.26] Parameter Validation - tolerance &lt; 0\n[Error] power_iteration: tolerance must be &gt;= 0 (got -1e-06)\ntolerance = -1e-6: Status = Error (Expected) [PASS]\n\n[E3.27] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] power_iteration: matrix data pointer is null\nEmpty matrix: Status = Error, eigenvalue = 0.00 (Expected: Error status) [PASS]\n\n[E3.24] inverse_power_iteration() - Smallest Eigenvalue (System Identification)\n\n[E3.28] Simple 2x2 Matrix - Smallest Eigenvalue\nMatrix (same as E3.21):\nMatrix Elements &gt;&gt;&gt;\n        2.00         1.00       |\n        1.00         2.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Expected eigenvalues: 3.0 (largest), 1.0 (smallest)\n  Expected smallest eigenvalue: 1.0\n  Expected smallest eigenvector (for \u03bb=1): approximately [0.707, -0.707] or [-0.707, 0.707] (normalized)\n  Note: This is critical for system identification - smallest eigenvalue = fundamental frequency\n\n[Actual Results]\n  Smallest eigenvalue: 1.00 (Expected: 1.0, smallest eigenvalue)\n  Iterations: 6\n  Status: OK\n  Smallest eigenvector:\nMatrix Elements &gt;&gt;&gt;\n        0.71       |\n       -0.71       |\n&lt;&lt;&lt; Matrix Elements\n\n  Error from expected (1.0): 0.00 [PASS]\n\n[Comparison] Power vs Inverse Power Iteration:\n  Power iteration (\u03bb_max): 3.00\n  Inverse power iteration (\u03bb_min): 1.00\n  Ratio (\u03bb_max/\u03bb_min): 3.00 (Expected: ~3.0) [PASS]\n\n[E3.29] 3x3 Stiffness Matrix - Smallest Eigenvalue (SHM Application)\nStiffness Matrix (same as E3.22):\nMatrix Elements &gt;&gt;&gt;\n        2.00        -1.00         0.00       |\n       -1.00         2.00        -1.00       |\n        0.00        -1.00         2.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Expected eigenvalues (approximate): 3.414 (largest), 2.000, 0.586 (smallest)\n  Expected smallest eigenvalue: ~0.586 (fundamental frequency squared)\n  Expected fundamental frequency: sqrt(0.586) \u2248 0.765 rad/s\n  Note: Smallest eigenvalue is critical for system identification - represents fundamental mode\n\n[Actual Results]\n  Smallest eigenvalue (fundamental frequency squared): 0.59\n  Fundamental frequency: 0.77 rad/s (Expected: ~0.765 rad/s)\n  Iterations: 8\n  Status: OK\n  Smallest eigenvector (fundamental mode shape):\nMatrix Elements &gt;&gt;&gt;\n        0.50       |\n        0.71       |\n        0.50       |\n&lt;&lt;&lt; Matrix Elements\n\n  Error from expected (0.59): 0.00 [PASS]\n\n[Comparison] Power vs Inverse Power Iteration for SHM:\n  Power iteration (primary frequency\u00b2): 3.41 \u2192 frequency: 1.85 rad/s\n  Inverse power iteration (fundamental frequency\u00b2): 0.59 \u2192 frequency: 0.77 rad/s\n  Frequency ratio: 2.41 (Expected: ~2.4, ratio of highest to lowest mode)\n\n[E3.210] Non-Square Matrix (Expect Error)\n[Error] inverse_power_iteration: requires square matrix (got 2x3)\nStatus: Error (Expected)\nError handling: [PASS]\n\n[E3.211] Near-Singular Matrix (Edge Case)\nMatrix (near-singular but invertible):\nMatrix Elements &gt;&gt;&gt;\n        1.00         0.00         0.00       |\n        0.00         1.00         0.00       |\n        0.00         0.00         1.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Results]\n  Status: OK\n  Smallest eigenvalue: 1.00\n  Iterations: 2\n  Note: Successfully handled near-singular matrix [PASS]\n\n[E3.212] Parameter Validation - max_iter &lt;= 0\n[Error] inverse_power_iteration: max_iter must be &gt; 0 (got 0)\nmax_iter = 0: Status = Error (Expected) [PASS]\n[Error] inverse_power_iteration: max_iter must be &gt; 0 (got -1)\nmax_iter = -1: Status = Error (Expected) [PASS]\n\n[E3.213] Parameter Validation - tolerance &lt; 0\n[Error] inverse_power_iteration: tolerance must be &gt;= 0 (got -1e-06)\ntolerance = -1e-6: Status = Error (Expected) [PASS]\n\n[E3.214] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] inverse_power_iteration: matrix data pointer is null\nEmpty matrix: Status = Error, eigenvalue = 0.00 (Expected: Error status) [PASS]\n\n[E3.215] Singular Matrix (Should Fail)\n[Error] solve: pivot at (1, 1) is zero or too small (0), matrix is singular or near-singular\n[Error] solve: pivot at (1, 1) is zero or too small (0), matrix is singular or near-singular\n[Error] solve: pivot at (1, 1) is zero or too small (0), matrix is singular or near-singular\nSingular matrix: Status = OK (Expected: Error or OK with eigenvalue \u2248 0) [FAIL]\n\n[E3.3] eigendecompose_jacobi() - Symmetric Matrix Decomposition\n\n[E3.31] 2x2 Symmetric Matrix - Complete Decomposition\n[Expected Results]\n  Expected eigenvalues: 3.0, 1.0 (in any order)\n  Expected eigenvectors (for \u03bb=3): [0.707, 0.707] or [-0.707, -0.707] (normalized)\n  Expected eigenvectors (for \u03bb=1): [0.707, -0.707] or [-0.707, 0.707] (normalized)\n\n[Actual Results]\nEigenvalues:\nMatrix Elements &gt;&gt;&gt;\n        1.00       |\n        3.00       |\n&lt;&lt;&lt; Matrix Elements\n\nEigenvectors (each column is an eigenvector):\nMatrix Elements &gt;&gt;&gt;\n        0.71         0.71       |\n       -0.71         0.71       |\n&lt;&lt;&lt; Matrix Elements\n\nIterations: 2\nStatus: OK\nEigenvalue check (should be 3.0 and 1.0): [PASS]\n\n[Verification] Check A * v = lambda * v for first eigenvector:\nA * v:\nMatrix Elements &gt;&gt;&gt;\n        0.71       |\n       -0.71       |\n&lt;&lt;&lt; Matrix Elements\n\nlambda * v:\nMatrix Elements &gt;&gt;&gt;\n        0.71       |\n       -0.71       |\n&lt;&lt;&lt; Matrix Elements\n\nVerification (A*v = \u03bb*v): [PASS]\n\n[E3.32] 3x3 Stiffness Matrix (SHM Application)\n[Expected Results]\n  Expected eigenvalues (approximate): 3.414, 2.000, 0.586\n  Expected natural frequencies: 1.848, 1.414, 0.765 rad/s\n  Note: Eigenvalues may appear in any order\n\n[Actual Results]\nEigenvalues (natural frequencies squared):\nMatrix Elements &gt;&gt;&gt;\n        3.41       |\n        0.59       |\n        2.00       |\n&lt;&lt;&lt; Matrix Elements\n\nNatural frequencies (rad/s):\n  Mode 0: 1.85 rad/s (Expected: ~1.85 rad/s) [PASS]\n  Mode 1: 0.77 rad/s (Expected: ~0.76 rad/s) [PASS]\n  Mode 2: 1.41 rad/s (Expected: ~1.41 rad/s) [PASS]\nEigenvectors (mode shapes):\nMatrix Elements &gt;&gt;&gt;\n        0.50         0.50        -0.71       |\n       -0.71         0.71         0.00       |\n        0.50         0.50         0.71       |\n&lt;&lt;&lt; Matrix Elements\n\nIterations: 9\nStatus: OK\n\n[E3.33] Diagonal Matrix (Eigenvalues on diagonal)\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n        5.00         0.00         0.00       |\n        0.00         3.00         0.00       |\n        0.00         0.00         1.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Expected eigenvalues: 5.0, 3.0, 1.0 (diagonal elements, may be in any order)\n  Expected eigenvectors: standard basis vectors [1,0,0], [0,1,0], [0,0,1] (or their negatives)\n  Expected iterations: 1 (diagonal matrix should converge immediately)\n\n[Actual Results]\nEigenvalues:\nMatrix Elements &gt;&gt;&gt;\n        5.00       |\n        3.00       |\n        1.00       |\n&lt;&lt;&lt; Matrix Elements\n\nEigenvectors:\nMatrix Elements &gt;&gt;&gt;\n        1.00         0.00         0.00       |\n        0.00         1.00         0.00       |\n        0.00         0.00         1.00       |\n&lt;&lt;&lt; Matrix Elements\n\nIterations: 1 (Expected: 1)\nEigenvalue check (should be 5.0, 3.0, 1.0): [PASS]\n\n[E3.34] Parameter Validation - tolerance &lt; 0\n[Error] eigendecompose_jacobi: tolerance must be &gt;= 0 (got -1e-06)\ntolerance = -1e-6: Status = Error (Expected) [PASS]\n\n[E3.35] Parameter Validation - max_iter &lt;= 0\n[Error] eigendecompose_jacobi: max_iter must be &gt; 0 (got 0)\nmax_iter = 0: Status = Error (Expected) [PASS]\n[Error] eigendecompose_jacobi: max_iter must be &gt; 0 (got -1)\nmax_iter = -1: Status = Error (Expected) [PASS]\n\n[E3.36] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] eigendecompose_jacobi: matrix data pointer is null\nEmpty matrix: Status = Error, eigenvalues rows = 1 (Expected: Error status, eigenvalues is 0x0 or error state) [PASS]\n\n[E3.4] eigendecompose_qr() - General Matrix Decomposition\n\n[E3.41] General 2x2 Matrix\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n        1.00         2.00       |\n        3.00         4.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Expected eigenvalues: (5+\u221a33)/2 \u2248 5.372, (5-\u221a33)/2 \u2248 -0.372\n  Note: This is a non-symmetric matrix, eigenvalues are real but may have complex eigenvectors\n\n[Actual Results]\nEigenvalues:\nMatrix Elements &gt;&gt;&gt;\n        5.37       |\n       -0.37       |\n&lt;&lt;&lt; Matrix Elements\n\nEigenvectors:\nMatrix Elements &gt;&gt;&gt;\n        0.42         0.91       |\n        0.91        -0.42       |\n&lt;&lt;&lt; Matrix Elements\n\nIterations: 6\nStatus: OK\nEigenvalue 1: 5.37 (Expected: 5.37, Error: 0.00, Rel Error: 0.01%) [PASS]\nEigenvalue 2: -0.37 (Expected: -0.37, Error: 0.00, Rel Error: 0.07%) [PASS]\nOverall eigenvalue check: [PASS]\n\n[E3.42] Non-Symmetric 3x3 Matrix\nMatrix [1,2,3; 4,5,6; 7,8,9]:\nMatrix Elements &gt;&gt;&gt;\n        1.00         2.00         3.00       |\n        4.00         5.00         6.00       |\n        7.00         8.00         9.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Expected eigenvalues (theoretical): 16.12, -1.12, 0.00\n  Note: This matrix is rank-deficient (determinant = 0), so one eigenvalue is 0\n  Note: QR algorithm may have numerical errors, especially for non-symmetric matrices\n  Acceptable range: largest eigenvalue ~15-18, smallest eigenvalue near 0\n\n[Actual Results]\nEigenvalues:\nMatrix Elements &gt;&gt;&gt;\n       16.12       |\n       -1.12       |\n        0.00       |\n&lt;&lt;&lt; Matrix Elements\n\nEigenvectors:\nMatrix Elements &gt;&gt;&gt;\n        0.23         0.88         0.41       |\n        0.53         0.24        -0.82       |\n        0.82        -0.40         0.41       |\n&lt;&lt;&lt; Matrix Elements\n\nIterations: 6\nStatus: OK\nEigenvalue 0: 16.12 (Expected: 16.12, Error: 0.00, Rel Error: 0.02%) [PASS]\nEigenvalue 1: -1.12 (Expected: -1.12, Error: 0.00, Rel Error: 0.28%) [PASS]\nEigenvalue 2: 0.00 (Expected: 0.00, Error: 0.00, Rel Error: 0.00%) [PASS]\nOverall eigenvalue check: [PASS]\n\n[E3.43] Parameter Validation - max_iter &lt;= 0\n[Error] eigendecompose_qr: max_iter must be &gt; 0 (got 0)\nmax_iter = 0: Status = Error (Expected) [PASS]\n[Error] eigendecompose_qr: max_iter must be &gt; 0 (got -1)\nmax_iter = -1: Status = Error (Expected) [PASS]\n\n[E3.44] Parameter Validation - tolerance &lt; 0\n[Error] eigendecompose_qr: tolerance must be &gt;= 0 (got -1e-06)\ntolerance = -1e-6: Status = Error (Expected) [PASS]\n\n[E3.45] Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] eigendecompose_qr: matrix data pointer is null\nEmpty matrix: Status = Error, eigenvalues rows = 1 (Expected: Error status, eigenvalues is 0x0 or error state) [PASS]\n\n[E3.5] eigendecompose() - Automatic Method Selection\n\n[E3.51] Symmetric Matrix (Auto-select: Jacobi)\nMatrix:\nMatrix Elements &gt;&gt;&gt;\n        4.00         1.00         2.00       |\n        1.00         3.00         0.00       |\n        2.00         0.00         5.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Method: Should automatically use Jacobi (symmetric matrix detected)\n  Expected eigenvalues (approximate): 6.67, 3.48, 1.85\n  Note: Eigenvalues may appear in any order\n\n[Actual Results]\nEigenvalues:\nMatrix Elements &gt;&gt;&gt;\n        1.85       |\n        3.48       |\n        6.67       |\n&lt;&lt;&lt; Matrix Elements\n\nIterations: 8\nStatus: OK\nMethod used: Jacobi (auto-selected for symmetric matrix)\n\n[E3.52] Non-Symmetric Matrix (Auto-select: QR)\n[Expected Results]\n  Method: Should automatically use QR (non-symmetric matrix detected)\n  Expected eigenvalues (theoretical): 16.12, -1.12, 0.00\n  Note: One eigenvalue should be near 0 (rank-deficient matrix)\n  Note: QR algorithm may have numerical errors for non-symmetric matrices\n  Acceptable: largest ~15-18, smallest near 0, one near -1 to -3\n\n[Actual Results]\nEigenvalues:\nMatrix Elements &gt;&gt;&gt;\n       16.12       |\n       -1.12       |\n        0.00       |\n&lt;&lt;&lt; Matrix Elements\n\nIterations: 6\nStatus: OK\nMethod used: QR (auto-selected for non-symmetric matrix)\nEigenvalue 0: 16.12 (Expected: 16.12, Error: 0.00, Rel Error: 0.02%) [PASS]\nEigenvalue 1: -1.12 (Expected: -1.12, Error: 0.00, Rel Error: 0.28%) [PASS]\nEigenvalue 2: 0.00 (Expected: 0.00, Error: 0.00, Rel Error: 0.00%) [PASS]\nOverall eigenvalue check: [PASS]\n\n[E3.53] Parameter Validation - tolerance &lt; 0\n[Error] eigendecompose: tolerance must be &gt;= 0 (got -1e-06)\ntolerance = -1e-6: Status = Error (Expected) [PASS]\n\n[E3.54] eigendecompose() - Boundary Case - Empty Matrix (0x0)\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] eigendecompose: matrix data pointer is null\nEmpty matrix: Status = Error, eigenvalues rows = 1 (Expected: Error status, eigenvalues is 0x0 or error state) [PASS]\n\n[E3.55] eigendecompose() - Error Handling - Non-Square Matrix\n[Error] eigendecompose_qr: requires square matrix (got 2x3)\nNon-square matrix (2x3): Status = Error (Expected) [PASS]\n\n[E3.6] SHM Application - Structural Dynamics Analysis\n\n[E3.61] 4-DOF Mass-Spring System\nStiffness Matrix K:\nMatrix Elements &gt;&gt;&gt;\n        2.00        -1.00         0.00         0.00       |\n       -1.00         2.00        -1.00         0.00       |\n        0.00        -1.00         2.00        -1.00       |\n        0.00         0.00        -1.00         1.00       |\n&lt;&lt;&lt; Matrix Elements\n\nIs symmetric: Yes\n\n[Quick Analysis] Primary frequency using power_iteration():\n[Expected Results]\n  Expected primary eigenvalue: ~3.53 (largest eigenvalue)\n  Expected primary frequency: sqrt(3.53) \u2248 1.88 rad/s\n\n[Actual Results]\n  Primary eigenvalue: 3.53 (Expected: ~3.53)\n  Primary frequency: 1.88 rad/s (Expected: ~1.88 rad/s)\n  Iterations: 13\n  Error from expected: 0.00 [PASS]\n\n[Complete Analysis] Full modal analysis using eigendecompose_jacobi():\n[Expected Results]\n  Expected eigenvalues (approximate): 3.53, 2.35, 1.00, 0.12\n  Expected natural frequencies: 1.88, 1.53, 1.00, 0.35 rad/s\n  Note: These are approximate values for the 4-DOF system\n\n[Actual Results]\nAll eigenvalues (natural frequencies squared):\nMatrix Elements &gt;&gt;&gt;\n        3.53       |\n        1.00       |\n        2.35       |\n        0.12       |\n&lt;&lt;&lt; Matrix Elements\n\nNatural frequencies (rad/s):\n  Mode 0: 1.88 rad/s (Expected: ~1.88 rad/s) [PASS]\n  Mode 1: 1.00 rad/s (Expected: ~1.00 rad/s) [PASS]\n  Mode 2: 1.53 rad/s (Expected: ~1.53 rad/s) [PASS]\n  Mode 3: 0.35 rad/s (Expected: ~0.35 rad/s) [PASS]\nMode shapes (eigenvectors):\nMatrix Elements &gt;&gt;&gt;\n        0.43         0.58        -0.66         0.23       |\n       -0.66         0.58         0.23         0.43       |\n        0.58        -0.00         0.58         0.58       |\n       -0.23        -0.58        -0.43         0.66       |\n&lt;&lt;&lt; Matrix Elements\n\nTotal iterations: 17\n\n[E3.7] Edge Cases and Error Handling\n\n[E3.71] 1x1 Matrix\nMatrix: [5.0]\n[Expected Results]\n  Expected eigenvalue: 5.0 (the matrix element itself)\n  Expected eigenvector: [1.0] (normalized)\n\n[Actual Results]\nEigenvalue: 5.00 (Expected: 5.0)\nEigenvector:\nMatrix Elements &gt;&gt;&gt;\n        1.00       |\n&lt;&lt;&lt; Matrix Elements\n\nError from expected: 0.00 [PASS]\n\n[E3.72] Zero Matrix\n[Error] power_iteration: computed vector norm too small\nStatus: Error (Expected)\n\n[E3.73] Identity Matrix\nMatrix (3x3 Identity):\nMatrix Elements &gt;&gt;&gt;\n        1.00         0.00         0.00       |\n        0.00         1.00         0.00       |\n        0.00         0.00         1.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[Expected Results]\n  Expected eigenvalues: 1.0, 1.0, 1.0 (all eigenvalues are 1)\n  Expected eigenvectors: Any orthonormal basis (e.g., standard basis vectors)\n  Expected iterations: 1 (should converge immediately)\n\n[Actual Results]\nEigenvalues (should all be 1.0):\nMatrix Elements &gt;&gt;&gt;\n        1.00       |\n        1.00       |\n        1.00       |\n&lt;&lt;&lt; Matrix Elements\n\nEigenvectors:\nMatrix Elements &gt;&gt;&gt;\n        1.00         0.00         0.00       |\n        0.00         1.00         0.00       |\n        0.00         0.00         1.00       |\n&lt;&lt;&lt; Matrix Elements\n\nIterations: 1 (Expected: 1)\nAll eigenvalues = 1.0: [PASS]\n\n[E3.8] Performance Test for SHM Applications\n\n[E3.81] Power Iteration Performance (Real-time SHM - Dominant Eigenvalue)\n[Performance] Power Iteration (3x3 matrix): 112.00 us\n\n[E3.82] Inverse Power Iteration Performance (System Identification - Smallest Eigenvalue)\n[Performance] Inverse Power Iteration (3x3 matrix): 543.00 us\n\n[E3.83] Jacobi Method Performance (Complete Eigendecomposition - Symmetric Matrices)\n[Performance] Jacobi Decomposition (3x3 symmetric matrix): 166.00 us\n\n[E3.84] QR Method Performance (Complete Eigendecomposition - General Matrices)\n[Performance] QR Decomposition (3x3 general matrix): 818.00 us\n\n[Eigenvalue Decomposition Tests Complete]\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#phase-7-auxiliary-functions-f","title":"Phase 7: Auxiliary Functions (F)","text":"<pre><code>[Test Organization: Application-Oriented Logic]\n  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\n\n\n[F1: Stream Operators Tests]\n\n[F1.1] Stream Insertion Operator (&lt;&lt;) for Mat\nMatrix mat1:\n1 2 3\n4 5 6\n7 8 9\n\n\n[F1.2] Stream Insertion Operator (&lt;&lt;) for Mat::ROI\nROI created: ROI(pos_x=1, pos_y=2, width=3, height=4)\nExpected output:\n  row start: 2 (pos_y)\n  col start: 1 (pos_x)\n  row count: 4 (height)\n  col count: 3 (width)\n\nActual output:\nrow start 2\ncol start 1\nrow count 4\ncol count 3\n\n\n[F1.3] Stream Extraction Operator (&gt;&gt;) for Mat\nSimulated input: \"10 20 30 40\"\nMatrix mat2 after input:\n10 20\n30 40\n\nExpected: [10, 20; 30, 40]\n\n[F1.4] Stream Extraction Operator (&gt;&gt;) for Mat (2x3 matrix)\nSimulated input: \"1.5 2.5 3.5 4.5 5.5 6.5\"\nMatrix mat3 after input:\n1.5 2.5 3.5\n4.5 5.5 6.5\n\nExpected: [1.5, 2.5, 3.5; 4.5, 5.5, 6.5]\n\n[F2: Global Arithmetic Operators Tests]\n\n[F2.1] Matrix Addition (operator+)\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix B:\nMatrix Elements &gt;&gt;&gt;\n           5            6       |\n           7            8       |\n&lt;&lt;&lt; Matrix Elements\n\nmatA + matB:\n6 8\n10 12\n\n\n[F2.2] Matrix Addition with Constant (operator+)\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nConstant: 5.0\nmatA + 5.0f:\n6 7\n8 9\n\n\n[F2.3] Matrix Subtraction (operator-)\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix B:\nMatrix Elements &gt;&gt;&gt;\n           5            6       |\n           7            8       |\n&lt;&lt;&lt; Matrix Elements\n\nmatA - matB:\n-4 -4\n-4 -4\n\n\n[F2.4] Matrix Subtraction with Constant (operator-)\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nConstant: 2.0\nmatA - 2.0f:\n-1 0\n1 2\n\n\n[F2.5] Matrix Multiplication (operator*)\nMatrix C (2x3):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix D (3x2):\nMatrix Elements &gt;&gt;&gt;\n           7            8       |\n           9           10       |\n          11           12       |\n&lt;&lt;&lt; Matrix Elements\n\nmatC * matD:\n58 64\n139 154\n\n\n[F2.6] Matrix Multiplication with Constant (operator*)\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nConstant: 2.0\nmatA * 2.0f:\n2 4\n6 8\n\n\n[F2.7] Matrix Division (operator/)\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nConstant: 2.0\nmatA / 2.0f:\n0.5 1\n1.5 2\n\n\n[F2.8] Matrix Division Element-wise (operator/)\nMatrix A:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix B:\nMatrix Elements &gt;&gt;&gt;\n           5            6       |\n           7            8       |\n&lt;&lt;&lt; Matrix Elements\n\nmatA / matB:\n0.2 0.333333\n0.428571 0.5\n\n\n[F2.9] Matrix Comparison (operator==)\nMatrix E:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix F:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nmatE == matF: True\n\nAfter modifying matF(0,0) = 5:\nMatrix E:\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\nMatrix F:\nMatrix Elements &gt;&gt;&gt;\n           5            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\noperator == Error: 0 0, m1.data=1, m2.data=5, diff=4\nmatE == matF after modification: False\n</code></pre>"},{"location":"MATH/MATRIX/tiny-matrix-test/#phase-8-quality-assurance-g","title":"Phase 8: Quality Assurance (G)","text":"<pre><code>[Test Organization: Application-Oriented Logic]\n  Foundation \u2192 Basic Ops \u2192 Properties \u2192 Linear Systems \u2192 Decompositions \u2192 Applications \u2192 Quality\n\n\n[G1: Quality Assurance - Boundary Conditions and Error Handling Tests]\n\n[G1.1] Null Pointer Handling in print_matrix\n[Error] Cannot print matrix: data pointer is null.\n\n[G1.2] Null Pointer Handling in operator&lt;&lt;\n[Error] Cannot print matrix: data pointer is null.\n\n\n[G1.3] Invalid Block Parameters\n[Error] block: invalid position: start_row=-1, start_col=0 (must be non-negative)\nblock(-1, 0, 2, 2): Error\n[Error] block: block exceeds row boundary: start_row=2, block_rows=2, source.rows=3\nblock(2, 2, 2, 2) on 3x3 matrix: Error\n[Error] block: invalid block size: block_rows=0, block_cols=2 (must be positive)\nblock(0, 0, 0, 2): Error\n\n[G1.4] Invalid swap_rows Parameters\nBefore invalid swap_rows:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] swap_rows: row1 index out of range: row1=-1, matrix.rows=3\nAfter swap_rows(-1, 1):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] swap_rows: row2 index out of range: row2=5, matrix.rows=3\nAfter swap_rows(0, 5):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[G1.5] Invalid swap_cols Parameters\nBefore invalid swap_cols:\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] swap_cols: col1 index out of range: col1=-1, matrix.cols=3\nAfter swap_cols(-1, 1):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n[Error] swap_cols: col2 index out of range: col2=5, matrix.cols=3\nAfter swap_cols(0, 5):\nMatrix Elements &gt;&gt;&gt;\n           1            2            3       |\n           4            5            6       |\n           7            8            9       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[G1.6] Division by Zero\n[Error] Division by zero in operator/.\nmat3 / 0.0f: Error\n\n[G1.7] Matrix Division with Zero Elements\n[Error] Matrix division failed: Division by zero detected at position (0, 1)\nmat4 /= divisor (with zero):\nMatrix Elements &gt;&gt;&gt;\n           1            2       |\n           3            4       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[G1.8] Empty Matrix Operations\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[&gt;&gt;&gt; Error ! &lt;&lt;&lt;] Memory allocation failed in alloc_mem()\n[Error] operator+=: this matrix data pointer is null\nEmpty matrix addition: Empty matrix or error state (Expected) [PASS]\n\n[G2: Quality Assurance - Performance Benchmarks Tests]\n\n[G2.1] Matrix Addition Performance\n[Performance] 50x50 Matrix Addition (100 iterations): 18155.00 us total, 181.55 us avg\n\n[G2.2] Matrix Multiplication Performance\n[Performance] 30x30 Matrix Multiplication (100 iterations): 66752.00 us total, 667.52 us avg\n\n[G2.3] Matrix Transpose Performance\n[Performance] 50x30 Matrix Transpose (100 iterations): 22005.00 us total, 220.05 us avg\n\n[G2.4] Determinant Calculation Performance Comparison\n\n[G2.4.1] Small Matrix (4x4) - Laplace Expansion\n[Performance] 4x4 Determinant (Laplace, 10 iterations): 3121.00 us total, 312.10 us avg\n\n[G2.4.2] Large Matrix (8x8) - LU Decomposition\n[Performance] 8x8 Determinant (LU, 10 iterations): 2027.00 us total, 202.70 us avg\n\n[G2.4.3] Large Matrix (8x8) - Gaussian Elimination\n[Performance] 8x8 Determinant (Gaussian, 10 iterations): 461.00 us total, 46.10 us avg\n\n[G2.4.4] Large Matrix (8x8) - Auto-select Method\n[Performance] 8x8 Determinant (auto-select, 10 iterations): 2013.00 us total, 201.30 us avg\n\n[Note] Performance Summary:\n  - Laplace expansion (O(n!)): Suitable only for small matrices (n &lt;= 4)\n  - LU decomposition (O(n\u00b3)): Efficient for large matrices, auto-selected for n &gt; 4\n  - Gaussian elimination (O(n\u00b3)): Alternative efficient method for large matrices\n  - Auto-select: Automatically chooses the best method based on matrix size\n\n[G2.5] Matrix Copy with Padding Performance\n[Performance] 8x8 Copy ROI (with padding) (100 iterations): 2587.00 us total, 25.87 us avg\n\n[G2.6] Element Access Performance\n[Performance] Computing element access (warmup)...\n[Performance] 50x50 Element Access (all elements) (100 iterations): 9685.00 us total, 96.85 us avg\n\n[G3: Quality Assurance - Memory Layout Tests (Padding and Stride)]\n\n[G3.1] Contiguous Memory (no padding)\nMatrix 3x4 (stride=4, pad=0):\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        0\nstride          4\nmemory          12\ndata pointer    0x3fce9af0\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n        0.00         1.00         2.00         3.00       |\n        4.00         5.00         6.00         7.00       |\n        8.00         9.00        10.00        11.00       |\n&lt;&lt;&lt; Matrix Elements\n\n\n[G3.2] Padded Memory (stride &gt; col)\nMatrix 3x4 (stride=5, pad=1):\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fc9a3f4\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n        0.00         1.00         2.00         3.00       |   0.00 \n        4.00         5.00         6.00         7.00       |   0.00 \n        8.00         9.00        10.00        11.00       |   0.00 \n&lt;&lt;&lt; Matrix Elements\n\n\n[G3.3] Addition with Padded Matrices\nResult of padded matrix addition:\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        1\nstride          5\nmemory          15\ndata pointer    0x3fce9c64\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n       11.00        22.00        33.00        44.00       |  20.00 \n       55.00        66.00        77.00        88.00       |  25.00 \n       99.00       110.00       121.00       132.00       |   1.61 \n&lt;&lt;&lt; Matrix Elements\n\n\n[G3.4] ROI Operations with Padded Matrices\nROI (1,1,2,2) from padded matrix:\nMatrix Info &gt;&gt;&gt;\nrows            2\ncols            2\nelements        4\npaddings        3\nstride          5\nmemory          10\ndata pointer    0x3fc9a40c\ntemp pointer    0\next_buff        1   (External buffer or View)\nsub_matrix      1   (This is a Sub-Matrix View)\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n        5.00         6.00       |   7.00         0.00         8.00 \n        9.00        10.00       |  11.00         0.00         0.00 \n&lt;&lt;&lt; Matrix Elements\n\n\n[G3.5] Copy Operations Preserve Stride\nCopied matrix (should have stride=4, no padding):\nMatrix Info &gt;&gt;&gt;\nrows            3\ncols            4\nelements        12\npaddings        0\nstride          4\nmemory          12\ndata pointer    0x3fce9d98\ntemp pointer    0\next_buff        0\nsub_matrix      0\n&lt;&lt;&lt; Matrix Info\nMatrix Elements &gt;&gt;&gt;\n        0.00         1.00         2.00         3.00       |\n        4.00         5.00         6.00         7.00       |\n        8.00         9.00        10.00        11.00       |\n&lt;&lt;&lt; Matrix Elements\n</code></pre>"},{"location":"MATH/USAGE/usage/","title":"USAGE INSTRUCTIONS","text":"<p>Usage Instructions</p> <p>This document provides usage instructions for the <code>math</code> module in Python.  It includes examples and explanations of various functions and methods available in the module.</p>"},{"location":"MATH/USAGE/usage/#import-tinymath-as-a-whole","title":"Import TinyMath as a Whole","text":"<p>Info</p> <p>Suitable for C projects or projects with a simple structure in C++.</p> <pre><code>#include \"tiny_math.h\"\n</code></pre>"},{"location":"MATH/USAGE/usage/#import-tinymath-by-module","title":"Import TinyMath by Module","text":"<p>Info</p> <p>Suitable for projects that require precise control over module imports or complex C++ projects.</p> <pre><code>#include \"tiny_vec.h\" // Import vector module\n#include \"tiny_mat.h\" // Import matrix module\n</code></pre> <pre><code>#include \"tiny_matrix.hpp\" // Import advanced matrix module\n</code></pre> <p>Note</p> <ul> <li> <p><code>tiny_vec.h</code> and <code>tiny_mat.h</code> are header files for the C language version, suitable for C programming.</p> </li> <li> <p><code>tiny_matrix.hpp</code> is a header file for the C++ language version, suitable for C++ programming.</p> </li> </ul> <p>In simple terms, C language projects can only use <code>tiny_vec.h</code> and <code>tiny_mat.h</code>, while C++ projects can use <code>tiny_vec.h</code>, <code>tiny_mat.h</code>, and <code>tiny_matrix.hpp</code>.</p> <p>Tip</p> <p>For specific usage methods, please refer to the test code.</p>"},{"location":"MATH/VECTOR/api/","title":"VECTOR OPERATIONS","text":""},{"location":"MATH/VECTOR/api/#list-of-functions","title":"LIST OF FUNCTIONS","text":"<pre><code>// Addition\ntiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Subtraction\ntiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Multiplication\ntiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Division\ntiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\ntiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\n// Square root\ntiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\n// Dot product\ntiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\ntiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n</code></pre>"},{"location":"MATH/VECTOR/api/#addition","title":"ADDITION","text":""},{"location":"MATH/VECTOR/api/#addition-of-two-vectors","title":"Addition of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>Function: Computes the element-wise addition of two vectors.</p> <p>Parameters:</p> <ul> <li><code>input1</code>: Pointer to the first input vector.</li> <li><code>input2</code>: Pointer to the second input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#addition-of-a-vector-and-a-constant","title":"Addition of a Vector and a Constant","text":"<pre><code>tiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>Function: Computes the element-wise addition of a vector and a constant.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> <li><code>C</code>: Constant value to be added.</li> <li><code>step_in</code>: Step size for the input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#subtraction","title":"SUBTRACTION","text":""},{"location":"MATH/VECTOR/api/#subtraction-of-two-vectors","title":"Subtraction of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>Function: Computes the element-wise subtraction of two vectors.</p> <p>Parameters:</p> <ul> <li><code>input1</code>: Pointer to the first input vector.</li> <li><code>input2</code>: Pointer to the second input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#subtraction-of-a-vector-and-a-constant","title":"Subtraction of a Vector and a Constant","text":"<pre><code>tiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>Function: Computes the element-wise subtraction of a vector and a constant.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> <li><code>C</code>: Constant value to be subtracted.</li> <li><code>step_in</code>: Step size for the input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#multiplication","title":"MULTIPLICATION","text":""},{"location":"MATH/VECTOR/api/#multiplication-of-two-vectors","title":"Multiplication of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>Function: Computes the element-wise multiplication of two vectors.</p> <p>Parameters:</p> <ul> <li><code>input1</code>: Pointer to the first input vector.</li> <li><code>input2</code>: Pointer to the second input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#multiplication-of-a-vector-and-a-constant","title":"Multiplication of a Vector and a Constant","text":"<pre><code>tiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>Function: Computes the element-wise multiplication of a vector and a constant.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> <li><code>C</code>: Constant value to be multiplied.</li> <li><code>step_in</code>: Step size for the input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#division","title":"DIVISION","text":""},{"location":"MATH/VECTOR/api/#division-of-two-vectors","title":"Division of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\n</code></pre> <p>Function: Computes the element-wise division of two vectors.</p> <p>Parameters:</p> <ul> <li><code>input1</code>: Pointer to the first input vector.</li> <li><code>input2</code>: Pointer to the second input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> <li><code>allow_divide_by_zero</code>: Flag to allow division by zero (true or false).</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#division-of-a-vector-and-a-constant","title":"Division of a Vector and a Constant","text":"<pre><code>tiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\n</code></pre> <p>Function: Computes the element-wise division of a vector and a constant.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> <li><code>C</code>: Constant value to be divided.</li> <li><code>step_in</code>: Step size for the input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> <li><code>allow_divide_by_zero</code>: Flag to allow division by zero (true or false).</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#square-root","title":"SQUARE ROOT","text":""},{"location":"MATH/VECTOR/api/#square-root-of-a-vector","title":"Square Root of a Vector","text":"<pre><code>tiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\n</code></pre> <p>Function: Computes the element-wise square root of a vector.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#square-root-of-a-vector-fast","title":"Square Root of a Vector (Fast)","text":"<pre><code>tiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\n</code></pre> <p>Function: Computes the element-wise square root of a vector (fast version).</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#inverse-square-root-of-a-vector","title":"Inverse Square Root of a Vector","text":"<pre><code>tiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\n</code></pre> <p>Function: Computes the element-wise inverse square root of a vector.</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#inverse-square-root-of-a-vector-fast","title":"Inverse Square Root of a Vector (Fast)","text":"<pre><code>tiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\n</code></pre> <p>Function: Computes the element-wise inverse square root of a vector (fast version).</p> <p>Parameters:</p> <ul> <li><code>input</code>: Pointer to the input vector.</li> <li><code>output</code>: Pointer to the output vector.</li> <li><code>len</code>: Length of the vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#dot-product","title":"DOT PRODUCT","text":""},{"location":"MATH/VECTOR/api/#dot-product-of-two-vectors","title":"Dot Product of Two Vectors","text":"<pre><code>tiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\n</code></pre> <p>Function: Computes the dot product of two vectors.</p> <p>Parameters:</p> <ul> <li><code>src1</code>: Pointer to the first input vector.</li> <li><code>src2</code>: Pointer to the second input vector.</li> <li><code>dest</code>: Pointer to the output scalar value.</li> <li><code>len</code>: Length of the vectors.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/api/#dot-product-of-two-vectors-with-different-steps","title":"Dot Product of Two Vectors with Different Steps","text":"<pre><code>tiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n</code></pre> <p>Function: Computes the dot product of two vectors with different step sizes.</p> <p>Parameters:</p> <ul> <li><code>src1</code>: Pointer to the first input vector.</li> <li><code>src2</code>: Pointer to the second input vector.</li> <li><code>dest</code>: Pointer to the output scalar value.</li> <li><code>len</code>: Length of the vectors.</li> <li><code>step1</code>: Step size for the first input vector.</li> <li><code>step2</code>: Step size for the second input vector.</li> <li><code>step_out</code>: Step size for the output vector.</li> </ul> <p>Returns: Returns a <code>tiny_error_t</code> type error code indicating whether the operation was successful.</p>"},{"location":"MATH/VECTOR/code/","title":"CODE","text":""},{"location":"MATH/VECTOR/code/#tiny_vech","title":"tiny_vec.h","text":"<pre><code>/**\n * @file tiny_vec.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the submodule vec of the tiny_math middleware. This module is correspondign to the math &amp; dotprod functions in the ESP-DSP library.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_math_config.h\"\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32 // ESP32 DSP library\n\n#include \"dsps_math.h\" // math operations\n#include \"dsps_dotprod.h\" // dot product\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* FUNCTION PROTOTYPES */\ntiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\ntiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\ntiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\ntiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\ntiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\ntiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\ntiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/VECTOR/code/#tiny_vecc","title":"tiny_vec.c","text":"<pre><code>/**\n * @file tiny_vec.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the source file for the submodule vec of the tiny_math middleware. This module is correspondign to the math &amp; dotprod functions in the ESP-DSP library.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n *\n * @note IMPORTANT: Buffer Overflow Prevention\n *       When using step parameters, ensure that array bounds are respected:\n *       - For input arrays: (len-1) * step &lt; array_size\n *       - For output arrays: (len-1) * step_out &lt; array_size\n *       Example: If array has 10 elements and step=2, max safe len is 5.\n *       The library does not perform runtime bounds checking for performance reasons.\n *       Users must ensure valid array sizes before calling these functions.\n */\n\n#include \"tiny_vec.h\"\n\n// #ifdef __cplusplus\n\n/* ADDITION */\n\n// vector + vector | float\n\n/**\n * @name tiny_vec_add_f32\n * @brief Adds two vectors element-wise.\n * @param input1 Pointer to the first input vector.\n * @param input2 Pointer to the second input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param step1 Step size for the first input vector.\n * @param step2 Step size for the second input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function performs element-wise addition of two vectors with specified step sizes, and the output is also specified with a step size.\n */\ntiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector addition\n    dsps_add_f32(input1, input2, output, len, step1, step2, step_out);\n#else\n    // Fallback to a simple loop for vector addition\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input1[i * step1] + input2[i * step2];\n    }\n\n#endif\n\n    return TINY_OK;\n}\n\n// vector + constant | float\n/**\n * @name tiny_vec_addc_f32\n * @brief Adds a constant to each element of a vector.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param C Constant value to be added.\n * @param step_in Step size for the input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function adds a constant value to each element of the input vector, with specified step sizes for both input and output vectors.\n */\ntiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector addition\n    dsps_addc_f32(input, output, len, C, step_in, step_out);\n#else\n    // Fallback to a simple loop for vector addition\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input[i * step_in] + C;\n    }\n#endif\n    return TINY_OK;\n}\n\n/* SUBTRACTION */\n\n// vector - vector | float\n/**\n * @name tiny_vec_sub_f32\n * @brief Subtracts two vectors element-wise.\n * @param input1 Pointer to the first input vector.\n * @param input2 Pointer to the second input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param step1 Step size for the first input vector.\n * @param step2 Step size for the second input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function performs element-wise subtraction of two vectors with specified step sizes, and the output is also specified with a step size.\n */\ntiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector subtraction\n    dsps_sub_f32(input1, input2, output, len, step1, step2, step_out);\n#else\n    // Fallback to a simple loop for vector subtraction\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input1[i * step1] - input2[i * step2];\n    }\n#endif\n    return TINY_OK;\n}\n\n// vector - constant (add -c) | float\n/**\n * @name tiny_vec_subc_f32\n * @brief Subtracts a constant from each element of a vector.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param C Constant value to be subtracted.\n * @param step_in Step size for the input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function subtracts a constant value from each element of the input vector, with specified step sizes for both input and output vectors.\n */\ntiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector subtraction\n    dsps_addc_f32(input, output, len, -C, step_in, step_out);\n#else\n    // Fallback to a simple loop for vector subtraction\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input[i * step_in] - C;\n    }\n#endif\n    return TINY_OK;\n}\n\n/* MULTIPLICATION */\n\n// vector * vector (elementwise) | float\n/**\n * @name tiny_vec_mul_f32\n * @brief Multiplies two vectors element-wise.\n * @param input1 Pointer to the first input vector.\n * @param input2 Pointer to the second input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param step1 Step size for the first input vector.\n * @param step2 Step size for the second input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function performs element-wise multiplication of two vectors with specified step sizes, and the output is also specified with a step size.\n */\ntiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector multiplication\n    dsps_mul_f32(input1, input2, output, len, step1, step2, step_out);\n#else\n    // Fallback to a simple loop for vector multiplication\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input1[i * step1] * input2[i * step2];\n    }\n#endif\n    return TINY_OK;\n}\n\n// vector * constant | float\n/**\n * @name tiny_vec_mulc_f32\n * @brief Multiplies each element of a vector by a constant.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param C Constant value to be multiplied.\n * @param step_in Step size for the input vector.\n * @param step_out Step size for the output vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function multiplies each element of the input vector by a constant value, with specified step sizes for both input and output vectors.\n */\ntiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized vector multiplication\n    dsps_mulc_f32(input, output, len, C, step_in, step_out);\n#else\n    // Fallback to a simple loop for vector multiplication\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input[i * step_in] * C;\n    }\n#endif\n    return TINY_OK;\n}\n\n/* DIVISION */\n\n// vector / vector (elementwise) | float\n/**\n * @name tiny_vec_div_f32\n * @brief Divides one vector by another element-wise.\n * @param input1 Pointer to the numerator vector.\n * @param input2 Pointer to the denominator vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param step1 Step size for the numerator vector.\n * @param step2 Step size for the denominator vector.\n * @param step_out Step size for the output vector.\n * @param allow_divide_by_zero Whether to safely handle zero denominators (true: set output to 0; false: return error if any zero is found).\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function performs element-wise division with specified step sizes.\n *       If allow_divide_by_zero is false, the function will first scan for zero denominators and return an error immediately if any are found.\n */\ntiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero)\n{\n    if (NULL == input1 || NULL == input2 || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    const float epsilon = TINY_MATH_MIN_DENOMINATOR;\n\n    // Step 1: Pre-check for zero denominators if not allowed\n    if (!allow_divide_by_zero)\n    {\n        for (int i = 0; i &lt; len; i++)\n        {\n            if (fabsf(input2[i * step2]) &lt; epsilon)\n            {\n                return TINY_ERR_MATH_ZERO_DIVISION;\n            }\n        }\n    }\n\n    // Step 2: Perform element-wise division\n    // Note: If allow_divide_by_zero=false, pre-check already passed, but we double-check for safety\n    for (int i = 0; i &lt; len; i++)\n    {\n        float denom = input2[i * step2];\n        float numer = input1[i * step1];\n\n        if (fabsf(denom) &lt; epsilon)\n        {\n            if (allow_divide_by_zero)\n            {\n                // Handle division by near-zero: mathematically correct behavior\n                if (fabsf(numer) &lt; epsilon)\n                {\n                    // 0/0 case: undefined, return 0.0f as safe fallback\n                    output[i * step_out] = 0.0f;\n                }\n                else\n                {\n                    // Non-zero divided by near-zero: return signed infinity\n                    // Use large number instead of INFINITY for compatibility\n                    output[i * step_out] = (numer &gt; 0.0f) ? TINY_MATH_LARGE_VALUE_F32 : -TINY_MATH_LARGE_VALUE_F32;\n                }\n            }\n            else\n            {\n                // This should not happen if pre-check passed, but return error for safety\n                return TINY_ERR_MATH_ZERO_DIVISION;\n            }\n        }\n        else\n        {\n            output[i * step_out] = numer / denom;\n        }\n    }\n\n    return TINY_OK;\n}\n\n// vector / constant | float\n/**\n * @name tiny_vec_divc_f32\n * @brief Divides each element of a vector by a constant using multiplication for performance.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @param C Constant value to divide by.\n * @param step_in Step size for the input vector.\n * @param step_out Step size for the output vector.\n * @param allow_divide_by_zero Whether to safely handle zero constant (true: set output to 0; false: return error if C is near zero).\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function divides each element of the input vector by a constant using multiplication for performance.\n *       If allow_divide_by_zero is false and C is near zero, the function returns an error.\n *       Otherwise, 1/C is precomputed and used as a multiplier.\n */\ntiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0 || step_in &lt;= 0 || step_out &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    const float epsilon = TINY_MATH_MIN_DENOMINATOR;\n\n    // Step 1: Handle constant C\n    if (fabsf(C) &lt; epsilon)\n    {\n        if (!allow_divide_by_zero)\n        {\n            return TINY_ERR_MATH_ZERO_DIVISION;\n        }\n\n        // Handle division by near-zero constant: mathematically correct behavior\n        // For vector / near-zero, each element should approach infinity\n        for (int i = 0; i &lt; len; i++)\n        {\n            float val = input[i * step_in];\n            if (fabsf(val) &lt; epsilon)\n            {\n                // 0 / near-zero: undefined, return 0.0f as safe fallback\n                output[i * step_out] = 0.0f;\n            }\n            else\n            {\n                // Non-zero divided by near-zero: return signed large value\n                output[i * step_out] = (val &gt; 0.0f) ? TINY_MATH_LARGE_VALUE_F32 : -TINY_MATH_LARGE_VALUE_F32;\n            }\n        }\n        return TINY_OK;\n    }\n\n    // Step 2: Use 1/C for performance\n    float invC = 1.0f / C;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_mulc_f32(input, output, len, invC, step_in, step_out);\n#else\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i * step_out] = input[i * step_in] * invC;\n    }\n#endif\n\n    return TINY_OK;\n}\n\n/* SQUARE ROOT */\n\n// vector ^ 0.5 (sqrt-based)| float\n/**\n * @name tiny_vec_sqrt_f32\n * @brief Computes the square root of each element in a vector using standard library sqrtf.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function provides accurate results using math library sqrtf().\n *       It returns TINY_ERR_MATH_NEGATIVE_SQRT immediately if any element is negative.\n */\ntiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    // Pre-check: validate all inputs before processing to avoid partial results\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (input[i] &lt; 0.0f)\n        {\n            return TINY_ERR_MATH_NEGATIVE_SQRT;\n        }\n    }\n\n    // All inputs validated, now perform computation\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = sqrtf(input[i]);  // high-precision sqrt\n    }\n\n    return TINY_OK;\n}\n\n// single value sqrt\n/**\n * @name tiny_sqrtf_f32\n * @brief Computes the square root of a single float value using bit manipulation.\n * @param f Input float value.\n * @return Square root of the input value.\n * @note This function uses bit manipulation to compute the square root of a float value.\n *       It returns 0.0f for negative inputs to prevent sqrt of negative values.\n *       WARNING: This is a fast approximation algorithm. Typical relative error is &lt; 1%.\n *       For high-precision applications, use tiny_vec_sqrt_f32() instead.\n */\ninline float tiny_sqrtf_f32(float f)\n{\n    if (f &lt; 0.0f) {\n        return 0.0f;  // Prevent sqrt of negative values\n    }\n\n    // Use union to avoid strict aliasing violation\n    union {\n        float f;\n        uint32_t i;\n    } input_conv = {f};\n\n    union {\n        float f;\n        uint32_t i;\n    } result_conv;\n\n    result_conv.i = 0x1fbb4000 + (input_conv.i &gt;&gt; 1);\n    return result_conv.f;\n}\n\n// vector ^ 0.5 (sqrtf-based)| float\n/**\n * @name tiny_vec_sqrtf_f32\n * @brief Computes the square root of each element in a vector using fast approximation.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function computes the square root of each element using fast bit manipulation.\n *       It returns TINY_ERR_MATH_NEGATIVE_SQRT immediately if any element is negative.\n *       WARNING: This is a fast approximation. Typical relative error is &lt; 1%.\n *       For high-precision applications, use tiny_vec_sqrt_f32() instead.\n *       NOTE: Ensure input/output arrays have sufficient size: at least len elements.\n *       When using step parameters, ensure: (len-1)*step &lt; array_size to avoid buffer overflow.\n */\ntiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    // Pre-check: validate all inputs before processing to avoid partial results\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (input[i] &lt; 0.0f)\n        {\n            return TINY_ERR_MATH_NEGATIVE_SQRT;\n        }\n    }\n\n    // All inputs validated, now perform computation\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = tiny_sqrtf_f32(input[i]);\n    }\n\n    return TINY_OK;\n}\n\n// vector ^ -0.5 (sqrt-based) | float\n/**\n * @name tiny_vec_inv_sqrt_f32\n * @brief Computes the inverse square root of each element in a vector using standard sqrtf().\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function provides accurate inverse square root results using 1.0f / sqrtf(x).\n *       It returns TINY_ERR_NOT_ALLOWED immediately if any element is less than TINY_MATH_MIN_POSITIVE_INPUT_F32.\n */\ntiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    // Pre-check: validate all inputs before processing to avoid partial results\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (input[i] &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            return TINY_ERR_NOT_ALLOWED;\n        }\n    }\n\n    // All inputs validated, now perform computation\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = 1.0f / sqrtf(input[i]);  // Accurate inverse square root\n    }\n\n    return TINY_OK;\n}\n\n\n// single value inv sqrt\n/**\n * @name tiny_inverted_sqrtf_f32\n * @brief Computes the inverse square root of a single float value using bit manipulation (Quake algorithm).\n * @param data Input float value.\n * @return Inverse square root of the input value.\n * @note This function uses the famous Quake III fast inverse square root algorithm.\n *       It returns 0.0f for negative or near-zero inputs to prevent division by zero.\n *       WARNING: This is a fast approximation. Typical relative error is &lt; 0.2%.\n *       For high-precision applications, use tiny_vec_inv_sqrt_f32() instead.\n */\nfloat tiny_inverted_sqrtf_f32(float data)\n{\n    if (data &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32) {\n        return 0.0f;  // Avoid division by near-zero or zero\n    }\n\n    const float x2 = data * 0.5F;\n    const float threehalfs = 1.5F;\n\n    union {\n        float f;\n        uint32_t i;\n    } conv = {data};\n\n    conv.i  = 0x5f3759df - (conv.i &gt;&gt; 1);\n    conv.f  = conv.f * (threehalfs - (x2 * conv.f * conv.f));\n\n    return conv.f;\n}\n\n// vector ^ -0.5 (sqrtf-based) | float\n/**\n * @name tiny_vec_inv_sqrtf_f32\n * @brief Computes the inverse square root of each element in a vector using fast approximation.\n * @param input Pointer to the input vector.\n * @param output Pointer to the output vector.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function computes the inverse square root using the Quake III fast algorithm.\n *       If any element is less than TINY_MATH_MIN_POSITIVE_INPUT_F32, the function returns TINY_ERR_NOT_ALLOWED.\n *       WARNING: This is a fast approximation. Typical relative error is &lt; 0.2%.\n *       For high-precision applications, use tiny_vec_inv_sqrt_f32() instead.\n *       NOTE: Ensure input/output arrays have sufficient size: at least len elements.\n *       When using step parameters, ensure: (len-1)*step &lt; array_size to avoid buffer overflow.\n */\ntiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len)\n{\n    if (NULL == input || NULL == output)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n\n    // Pre-check: validate all inputs before processing to avoid partial results\n    for (int i = 0; i &lt; len; i++)\n    {\n        if (input[i] &lt; TINY_MATH_MIN_POSITIVE_INPUT_F32)\n        {\n            return TINY_ERR_NOT_ALLOWED;\n        }\n    }\n\n    // All inputs validated, now perform computation\n    for (int i = 0; i &lt; len; i++)\n    {\n        output[i] = tiny_inverted_sqrtf_f32(input[i]);\n    }\n\n    return TINY_OK;\n}\n\n/* DOT PRODUCT */\n\n// vector * vector (dot product) | float\n/**\n * @name tiny_vec_dotprod_f32\n * @brief Computes the dot product of two vectors.\n * @param src1 Pointer to the first input vector.\n * @param src2 Pointer to the second input vector.\n * @param dest Pointer to the output scalar result.\n * @param len Length of the vectors.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function computes the dot product of two vectors and stores the result in a single float value.\n *       It returns TINY_ERR_MATH_NULL_POINTER if any pointer is NULL.\n *       The function uses the ESP-DSP library for optimized computation.\n */\ntiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len)\n{\n    if (NULL == src1 || NULL == src2 || NULL == dest)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized dot product\n    dsps_dotprod_f32(src1, src2, dest, len);\n#else\n    // Fallback to a simple loop for dot product\n    float acc = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        acc += src1[i] * src2[i];\n    }\n    *dest = acc;\n#endif\n    return TINY_OK;\n}\n\n// vector * vector (dot product - step support) | float\n/**\n * @name tiny_vec_dotprode_f32\n * @brief Computes the dot product of two vectors with step support.\n * @param src1 Pointer to the first input vector.\n * @param src2 Pointer to the second input vector.\n * @param dest Pointer to the output scalar result.\n * @param len Length of the vectors.\n * @param step1 Step size for the first input vector.\n * @param step2 Step size for the second input vector.\n * @return tiny_error_t Error code indicating success or failure.\n * @note This function computes the dot product of two vectors with specified step sizes and stores the result in a single float value.\n */\ntiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2)\n{\n    if (NULL == src1 || NULL == src2 || NULL == dest)\n    {\n        return TINY_ERR_MATH_NULL_POINTER;\n    }\n\n    if (len &lt;= 0 || step1 &lt;= 0 || step2 &lt;= 0)\n    {\n        return TINY_ERR_INVALID_ARG;\n    }\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // Use the ESP-DSP library for optimized dot product with step support\n    dsps_dotprode_f32(src1, src2, dest, len, step1, step2);\n#else\n    // Fallback to a simple loop for dot product with step support\n    float acc = 0.0f;\n    for (int i = 0; i &lt; len; i++)\n    {\n        acc += src1[i * step1] * src2[i * step2];\n    }\n    *dest = acc;\n#endif\n    return TINY_OK;\n}\n</code></pre>"},{"location":"MATH/VECTOR/test/","title":"VECTOR OPERATIONS TEST","text":"<p>Vector Operations Test</p> <p>This test is designed to evaluate the performance of vector-related functions.</p>"},{"location":"MATH/VECTOR/test/#test-code","title":"Test Code","text":""},{"location":"MATH/VECTOR/test/#tiny_vec_testh","title":"tiny_vec_test.h","text":"<pre><code>/**\n * @file tiny_vec_test.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the test header file for the submodule vec of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n */\n\n#pragma once\n\n#include \"tiny_math_config.h\"\n#include \"tiny_vec.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /**\n     * @name tiny_vec_test\n     * @brief Run unit tests and timing benchmarks for the tiny_vec module.\n     */\n    void tiny_vec_test(void);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"MATH/VECTOR/test/#tiny_vec_testc","title":"tiny_vec_test.c","text":"<pre><code>/**\n * @file tiny_vec_test.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file implements test functions for the submodule vec of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n */\n\n#include \"tiny_vec_test.h\"\n\n#define LEN 6\n#define ITERATIONS 10000 // Number of iterations for performance benchmarking\n\n#define RUN_VEC_TEST(FUNC, ...)                                                \\\n    do                                                                         \\\n    {                                                                          \\\n        tiny_error_t err = TINY_OK;                                            \\\n        int actual_iter = 0;                                                   \\\n        TinyTimeMark_t t0 = tiny_get_running_time();                           \\\n        for (int iter = 0; iter &lt; ITERATIONS; iter++)                          \\\n        {                                                                      \\\n            err = FUNC(__VA_ARGS__);                                           \\\n            actual_iter++;                                                     \\\n            if (err != TINY_OK)                                                \\\n                break;                                                         \\\n        }                                                                      \\\n        TinyTimeMark_t t1 = tiny_get_running_time();                           \\\n        double dt_total = (double)(t1 - t0);                                   \\\n        double dt_avg = (actual_iter &gt; 0) ? dt_total / actual_iter : 0.0;     \\\n        printf(\"%-24s | Output: \", #FUNC);                                     \\\n        for (int i = 0; i &lt; LEN; i++)                                          \\\n        {                                                                      \\\n            printf(\"%10.6f \", out[i]);                                         \\\n        }                                                                      \\\n        printf(\"| Total: %8.2f us | Avg: %6.2f us | Iter: %d | Error: %d\\n\\r\", \\\n               dt_total, dt_avg, actual_iter, err);                            \\\n    } while (0)\n\nvoid tiny_vec_test(void)\n{\n    float a[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f};\n    float b[] = {6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f};\n    float out[LEN];\n    float C = 2.0f;\n    float dot_result = 0.0f;\n\n    printf(\"============ [tiny_vec_test] ============\\n\\r\");\n    printf(\"Benchmark Settings: %d iterations per test\\n\\r\", ITERATIONS);\n\n    printf(\"Input Vector a:        \");\n    for (int i = 0; i &lt; LEN; i++)\n        printf(\"%10.6f \", a[i]);\n    printf(\"\\n\\r\");\n\n    printf(\"Input Vector b:        \");\n    for (int i = 0; i &lt; LEN; i++)\n        printf(\"%10.6f \", b[i]);\n    printf(\"\\n\\r\");\n\n    printf(\"Constant C:            %10.6f\\n\\r\\n\\r\", C);\n\n    RUN_VEC_TEST(tiny_vec_add_f32, a, b, out, LEN, 1, 1, 1);\n    RUN_VEC_TEST(tiny_vec_addc_f32, a, out, LEN, C, 1, 1);\n    RUN_VEC_TEST(tiny_vec_sub_f32, a, b, out, LEN, 1, 1, 1);\n    RUN_VEC_TEST(tiny_vec_subc_f32, a, out, LEN, C, 1, 1);\n    RUN_VEC_TEST(tiny_vec_mul_f32, a, b, out, LEN, 1, 1, 1);\n    RUN_VEC_TEST(tiny_vec_mulc_f32, a, out, LEN, C, 1, 1);\n    RUN_VEC_TEST(tiny_vec_div_f32, a, b, out, LEN, 1, 1, 1, true);\n    RUN_VEC_TEST(tiny_vec_divc_f32, a, out, LEN, C, 1, 1, true);\n    RUN_VEC_TEST(tiny_vec_sqrt_f32, a, out, LEN);\n    RUN_VEC_TEST(tiny_vec_sqrtf_f32, a, out, LEN);\n    RUN_VEC_TEST(tiny_vec_inv_sqrt_f32, a, out, LEN);\n    RUN_VEC_TEST(tiny_vec_inv_sqrtf_f32, a, out, LEN);\n\n    // Dot product (non-strided)\n    {\n        tiny_error_t err = TINY_OK;\n        int actual_iter = 0;\n        TinyTimeMark_t t0 = tiny_get_running_time();\n        for (int iter = 0; iter &lt; ITERATIONS; iter++)\n        {\n            err = tiny_vec_dotprod_f32(a, b, &amp;dot_result, LEN);\n            actual_iter++;\n            if (err != TINY_OK)\n                break;\n        }\n        TinyTimeMark_t t1 = tiny_get_running_time();\n        double dt_total = (double)(t1 - t0);\n        double dt_avg = (actual_iter &gt; 0) ? dt_total / actual_iter : 0.0;\n        printf(\"%-24s | Output: %10.6f | Total: %8.2f us | Avg: %6.2f us | Iter: %d | Error: %d\\n\\r\",\n               \"tiny_vec_dotprod_f32\", dot_result, dt_total, dt_avg, actual_iter, err);\n    }\n\n    // Dot product (strided)\n    {\n        tiny_error_t err = TINY_OK;\n        int actual_iter = 0;\n        TinyTimeMark_t t0 = tiny_get_running_time();\n        for (int iter = 0; iter &lt; ITERATIONS; iter++)\n        {\n            err = tiny_vec_dotprode_f32(a, b, &amp;dot_result, LEN, 1, 1);\n            actual_iter++;\n            if (err != TINY_OK)\n                break;\n        }\n        TinyTimeMark_t t1 = tiny_get_running_time();\n        double dt_total = (double)(t1 - t0);\n        double dt_avg = (actual_iter &gt; 0) ? dt_total / actual_iter : 0.0;\n        printf(\"%-24s | Output: %10.6f | Total: %8.2f us | Avg: %6.2f us | Iter: %d | Error: %d\\n\\r\",\n               \"tiny_vec_dotprode_f32\", dot_result, dt_total, dt_avg, actual_iter, err);\n    }\n\n    printf(\"============ [test complete] ============\\n\\r\");\n}\n</code></pre>"},{"location":"MATH/VECTOR/test/#maincpp","title":"main.cpp","text":"<pre><code>#include \"tiny_vec_test.h\"\n\nextern \"C\" void app_main(void)\n{\n    tiny_vec_test();\n}\n</code></pre>"},{"location":"MATH/VECTOR/test/#test-output","title":"Test Output","text":"<p>Basic C computation results</p> <p></p> <p>ESP-DSP accelerated results</p> <p></p> <p>You can see that with ESP-DSP acceleration enabled, the performance of vector operations is significantly improved.</p>"},{"location":"PREREQUISITE/prerequisite/","title":"PREREQUISITES","text":""},{"location":"PREREQUISITE/prerequisite/#hardware-and-software-requirements","title":"HARDWARE AND SOFTWARE REQUIREMENTS","text":"<p>ESP32 development board, please refer to the following projects for details:</p> <ul> <li> <p> NexNode</p> <p>  Repo </p> <p>  Online Doc </p> </li> </ul> <p>We will build upon the code in this project for further development.</p>"},{"location":"PREREQUISITE/prerequisite/#dependency-components","title":"DEPENDENCY COMPONENTS","text":"<p>To enhance the computational efficiency of our framework, we first introduce the ESP-DSP library and ESP-DL library, which provide efficient implementations for digital signal processing and deep learning respectively.</p> <p>Tip</p> <p>Note that these two libraries seem to be developed by different teams, so many of their functions overlap.</p> <pre><code>- espressif__esp-dsp\n- espressif__esp-dl\n   - espressif__dl_fft\n   - espressif__esp_new_jpeg\n</code></pre> <p>We can find and download these components from the ESP-REGISTRY into our project. In this project, I moved the downloaded components and their dependencies into the <code>middleware</code> folder and removed the configuration files to avoid version locking and network dependencies.</p>"},{"location":"TOOLBOX/toolbox/","title":"TOOLBOX","text":"<p>tiny_toolbox</p> <p>tiny_toolbox is a library designed for platform adaptation and optimization, providing various practical tools to serve edge computing and application development. Note that the adaptation and tools are included in the same library because many tools utilize the functions provided by the platform at a lower level. Therefore, placing platform adaptation and various tools together facilitates usage and maintenance.</p> <p>Warning</p> <p>Currently, development is based on ESP32, and migration to platforms like STM32 requires some modifications to the adaptation layer.</p>"},{"location":"TOOLBOX/toolbox/#architecture-and-function-directory","title":"ARCHITECTURE AND FUNCTION DIRECTORY","text":"<pre><code>    tiny_toolbox\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 tiny_toolbox.h // serves as a directory, integrating all submodules\n    \u251c\u2500\u2500 time\n    \u2502   \u251c\u2500\u2500 tiny_time.h // submodule for time management - header file\n    \u2502   \u251c\u2500\u2500 tiny_time.c // submodule for time management - source file\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"TOOLBOX/toolbox/#time","title":"TIME","text":"<ul> <li>Get Running Time: <code>tiny_get_running_time()</code></li> <li>SNTP Time Synchronization: <code>sync_time_with_timezone(\"CST-8\")</code></li> <li>Get World Time: <code>tiny_get_current_datetime(1)</code></li> </ul> <p>TODO:</p> <ul> <li>Local Time Synchronization for Wireless Sensor Networks - Microsecond Level</li> </ul>"},{"location":"TOOLBOX/toolbox/#code","title":"CODE","text":"<p>Tip</p> <p>tiny_toolbox.h serves merely as a directory, integrating all submodules. The specific functionalities are implemented in each submodule. tiny_toolbox.c is just a formal source file without specific functionality.</p>"},{"location":"TOOLBOX/toolbox/#cmakeliststxt","title":"CMakeLists.txt","text":"<pre><code>set(src_dirs\n    .\n    time\n)\n\nset(include_dirs\n    .\n    time\n)\n\nset(requires\n    esp_timer\n    node_rtc\n    espressif__esp-dsp\n    espressif__esp_new_jpeg\n    espressif__dl_fft\n    espressif__esp-dl\n)\n\nidf_component_register(SRC_DIRS ${src_dirs} INCLUDE_DIRS ${include_dirs} REQUIRES ${requires})\n</code></pre>"},{"location":"TOOLBOX/toolbox/#tiny_toolboxh","title":"tiny_toolbox.h","text":"<pre><code>/**\n * @file tiny_toolbox.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the tiny_toolbox middleware.\n * @version 1.0\n * @date 2025-03-26\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* DEPENDENCIES */\n// system\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"esp_log.h\"\n#include \"esp_timer.h\"\n#include \"esp_heap_caps.h\"\n\n// customized drivers\n#include \"node_rtc.h\"\n\n/* SUBMODULES */\n#include \"tiny_time.h\" // Time\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"TOOLBOX/TIME/code/","title":"TIME","text":""},{"location":"TOOLBOX/TIME/code/#tiny_timeh","title":"tiny_time.h","text":"<pre><code>/**\n * @file tiny_time.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief Submodule for TinyToolbox - header file\n * @version 1.0\n * @date 2025-04-10\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* CONFIGURATIONS */\n\n/* ================================ DEPENDENCIES ================================ */\n#include &lt;stdbool.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;time.h&gt;\n#include &lt;sys/time.h&gt;\n#include \"esp_log.h\"\n#include \"esp_timer.h\"\n#include \"esp_sntp.h\"\n// customized drivers\n#include \"node_rtc.h\"\n\n    /* ================================ DEFINITIONS ================================= */\n    // Use int64_t to match esp_timer_get_time() return type and avoid overflow\n    // esp_timer_get_time() returns microseconds since boot (int64_t)\n    typedef int64_t TinyTimeMark_t;\n\n    /**\n     * @brief Structure to hold date and time\n     */\n    typedef struct TinyDateTime_t\n    {\n        int year;\n        int month;\n        int day;\n        int hour;\n        int minute;\n        int second;\n        int32_t microsecond; // Microseconds (0-999999), using int32_t for portability\n    } TinyDateTime_t;\n\n    /* ================================ FUNCTIONS =================================== */\n    /* LOCAL RUNNING TIME IN MICROSECONDS */\n    /**\n     * @brief Get the running time in microseconds\n     * @return TinyTimeMark_t\n     */\n    TinyTimeMark_t tiny_get_running_time(void);\n\n    /* WORLD CURRENT TIME - SNTP */\n    /**\n     * @brief Obtain the current time with timezone\n     * @param timezone_str Timezone string (e.g., \"CST-8\" or \"GMT+8\")\n     * @note The timezone string format should be compatible with POSIX TZ format (e.g., \"CST-8\", \"GMT+8\")\n     * @note To use this function, in application, after internet connection, call sync_time_with_timezone(\"CST-8\")\n     * @return None\n     */\n    void sync_time_with_timezone(const char *timezone_str);\n\n    /* WORLD CURRENT TIME - GET TIME */\n    /**\n     * @name tiny_get_current_datetime\n     * @brief Get the current time as a TinyDateTime_t struct\n     * @param print_flag Flag to indicate whether to print the time\n     * @return TinyDateTime_t structure containing the current date and time\n     */\n    TinyDateTime_t tiny_get_current_datetime(bool print_flag);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"TOOLBOX/TIME/code/#tiny_timec","title":"tiny_time.c","text":"<pre><code>/**\n * @file tiny_time.c\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief Submodule for TinyToolbox - source file\n * @version 1.0\n * @date 2025-04-10\n * @copyright Copyright (c) 2025\n *\n */\n\n/* ================================ DEPENDENCIES\n * ================================ */\n#include \"tiny_time.h\" // Time\n\n/* ================================ DEFINITIONS\n * ================================= */\n/* CONFIGURATIONS */\n#define MIN_VALID_YEAR_OFFSET \\\n    (2020 - 1900) // Minimum valid year offset (year 2020)\n\n/* TAGS */\nstatic const char *TAG_SNTP = \"NTP_SYNC\";\nstatic const char *TAG_TIME = \"TIME\";\n\n/* ================================ FUNCTIONS\n * =================================== */\n/* LOCAL RUNNING TIME IN MICROSECONDS */\n/**\n * @brief Get the running time in microseconds\n * @return TinyTimeMark_t\n */\nTinyTimeMark_t tiny_get_running_time(void) { return esp_timer_get_time(); }\n\n/* WORLD CURRENT TIME - SNTP */\n/**\n * @brief Callback function for time synchronization notification\n * @param tv Pointer to the timeval structure containing the synchronized time\n * @return None\n */\nstatic void time_sync_notification_cb(struct timeval *tv)\n{\n    ESP_LOGI(TAG_SNTP, \"Time synchronized!\");\n}\n\n/**\n * @brief Initialize SNTP\n * @note This function can be called multiple times if needed\n * @return None\n */\nstatic void initialize_sntp(void)\n{\n    ESP_LOGI(TAG_SNTP, \"Initializing SNTP\");\n    esp_sntp_setoperatingmode(SNTP_OPMODE_POLL);\n    esp_sntp_setservername(0, \"pool.ntp.org\"); // NTP server // pool.ntp.org // ntp.aliyun.com\n    esp_sntp_set_time_sync_notification_cb(time_sync_notification_cb);\n    esp_sntp_init();\n}\n\n/**\n * @brief Obtain the current time with timezone\n * @param timezone_str Timezone string (e.g., \"CST-8\" or \"GMT+8\")\n * @note The timezone string format should be compatible with POSIX TZ format\n * (e.g., \"CST-8\", \"GMT+8\")\n * @note To use this function, in application, after internet connection, call\n * sync_time_with_timezone(\"CST-8\")\n * @return None\n */\nvoid sync_time_with_timezone(const char *timezone_str)\n{\n    // Validate input parameter\n    if (timezone_str == NULL)\n    {\n        ESP_LOGE(TAG_SNTP, \"timezone_str is NULL\");\n        return;\n    }\n\n    // Set system timezone\n    if (setenv(\"TZ\", timezone_str, 1) != 0)\n    {\n        ESP_LOGE(TAG_SNTP, \"Failed to set timezone environment variable\");\n        return;\n    }\n    tzset();\n\n    // Initialize SNTP and start time sync\n    initialize_sntp();\n\n    // Wait for system time to be set\n    time_t now = 0;\n    struct tm timeinfo = {0};\n    int retry = 0;\n    const int retry_count = 15;\n\n    while (timeinfo.tm_year &lt; MIN_VALID_YEAR_OFFSET &amp;&amp; ++retry &lt; retry_count)\n    {\n        ESP_LOGI(TAG_SNTP, \"Waiting for system time to be set... (%d/%d)\", retry,\n                 retry_count);\n        vTaskDelay(2000 / portTICK_PERIOD_MS);\n        time(&amp;now);\n        if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n        {\n            ESP_LOGW(TAG_SNTP, \"Failed to convert time to local time\");\n            continue;\n        }\n    }\n\n    if (timeinfo.tm_year &gt;= MIN_VALID_YEAR_OFFSET)\n    {\n        rtc_set_time(timeinfo.tm_year + 1900, timeinfo.tm_mon + 1, timeinfo.tm_mday,\n                     timeinfo.tm_hour, timeinfo.tm_min,\n                     timeinfo.tm_sec); // defined in esp_rtc.c\n        ESP_LOGI(TAG_SNTP, \"System time is set.\");\n    }\n    else\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to sync time.\");\n        return;\n    }\n\n    // Log current local time (using thread-safe formatting)\n    char time_str[64];\n    if (strftime(time_str, sizeof(time_str), \"%a %b %d %H:%M:%S %Y\", &amp;timeinfo) ==\n        0)\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to format time string\");\n    }\n    else\n    {\n        ESP_LOGI(TAG_SNTP, \"Current time: %s\", time_str);\n    }\n\n    // vTaskDelay(10000 / portTICK_PERIOD_MS); // Wait for 10 second\n    // rtc_get_time(); // uncomment to check the RTC time\n    // ESP_LOGI(TAG_SNTP, \"Current RTC time: %04d-%02d-%02d %02d:%02d:%02d\",\n    //          calendar.year, calendar.month, calendar.date,\n    //          calendar.hour, calendar.min, calendar.sec); // uncomment to check\n    //          the RTC time\n}\n\n/* WORLD CURRENT TIME - GET TIME */\n/**\n * @name tiny_get_current_datetime\n * @brief Get the current time as a TinyDateTime_t struct\n * @param print_flag Flag to indicate whether to print the time\n * @return TinyDateTime_t structure containing the current date and time\n */\nTinyDateTime_t tiny_get_current_datetime(bool print_flag)\n{\n    TinyDateTime_t result = {0}; // Initialize to zero\n    struct timeval tv;\n\n    // Get current time (seconds + microseconds)\n    if (gettimeofday(&amp;tv, NULL) != 0)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to get time of day\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    time_t now = tv.tv_sec;\n    struct tm timeinfo;\n    if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to convert time to local time\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    result.year = timeinfo.tm_year + 1900;\n    result.month = timeinfo.tm_mon + 1;\n    result.day = timeinfo.tm_mday;\n    result.hour = timeinfo.tm_hour;\n    result.minute = timeinfo.tm_min;\n    result.second = timeinfo.tm_sec;\n    result.microsecond = (int32_t)tv.tv_usec; // Explicit cast for portability\n\n    if (print_flag)\n    {\n        ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06d\",\n                 result.year, result.month, result.day, result.hour, result.minute,\n                 result.second, result.microsecond);\n    }\n\n    return result;\n}\n</code></pre>"},{"location":"TOOLBOX/TIME/code/#maincpp","title":"main.cpp","text":"<pre><code>/**\n * @file main.cpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief Main program for testing tiny_time module\n * @version 1.0\n * @date 2025-10-22\n * \n * @copyright Copyright (c) 2024\n * \n */\n\n/* DEPENDENCIES */\n// ESP\n#include \"nvs_flash.h\"\n#include \"esp_log.h\"\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n// FreeRTOS (must be inside extern \"C\" for C++ files)\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"freertos/event_groups.h\"\n#include \"freertos/semphr.h\"\n\n// ESP Timer (high-precision timer)\n#include \"esp_timer.h\"\n\n// WiFi (required for time sync)\n#include \"node_wifi.h\"\n\n// TinyToolbox\n#include \"tiny_time.h\"\n\n/* Variables */\nconst char *TAG = \"tiny_time_test\";\n\n/* Timer precision test variables */\n#define TIMESTAMP_COUNT 15\nstatic TinyTimeMark_t s_timestamps[TIMESTAMP_COUNT] = {0};\nstatic int s_timestamp_index = 0;\nstatic bool s_timer_test_complete = false;\nstatic esp_timer_handle_t s_timer_handle = NULL;\nstatic SemaphoreHandle_t s_timer_mutex = NULL;\n\n/**\n * @brief Timer callback function - records timestamp at the very beginning\n * @param arg Timer argument (not used)\n * @return None\n */\nstatic void timer_precision_callback(void *arg)\n{\n    // CRITICAL: Get timestamp IMMEDIATELY at the start of callback\n    // to avoid any execution overhead affecting the measurement\n    TinyTimeMark_t timestamp = tiny_get_running_time();\n\n    // Store timestamp in array (thread-safe access)\n    if (xSemaphoreTake(s_timer_mutex, portMAX_DELAY) == pdTRUE)\n    {\n        if (s_timestamp_index &lt; TIMESTAMP_COUNT)\n        {\n            s_timestamps[s_timestamp_index++] = timestamp;\n\n            // Stop timer when we have collected all timestamps\n            if (s_timestamp_index &gt;= TIMESTAMP_COUNT)\n            {\n                s_timer_test_complete = true;\n                esp_timer_stop(s_timer_handle);\n            }\n        }\n        xSemaphoreGive(s_timer_mutex);\n    }\n}\n\n/**\n * @brief Entry point of the program - Testing tiny_time module\n * @param None\n * @retval None\n */\nvoid app_main(void)\n{\n    esp_err_t ret;\n\n    // Initialize NVS (required for WiFi)\n    ret = nvs_flash_init();\n    if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND)\n    {\n        ESP_ERROR_CHECK(nvs_flash_erase());\n        ret = nvs_flash_init();\n    }\n    ESP_ERROR_CHECK(ret);\n\n    ESP_LOGI(TAG, \"========================================\");\n    ESP_LOGI(TAG, \"  tiny_time Module Test Program\");\n    ESP_LOGI(TAG, \"========================================\");\n\n    // Initialize WiFi (required for time synchronization)\n    ESP_LOGI(TAG, \"Initializing WiFi...\");\n    ret = wifi_sta_wpa2_init();\n    if (ret != ESP_OK)\n    {\n        ESP_LOGE(TAG, \"WiFi initialization failed!\");\n        return;\n    }\n    ESP_LOGI(TAG, \"WiFi initialized successfully\");\n\n    // Wait for WiFi connection\n    ESP_LOGI(TAG, \"Waiting for WiFi connection...\");\n    EventBits_t ev = xEventGroupWaitBits(wifi_event_group, CONNECTED_BIT, \n                                         pdTRUE, pdFALSE, portMAX_DELAY);\n    if (ev &amp; CONNECTED_BIT)\n    {\n        ESP_LOGI(TAG, \"WiFi connected!\");\n\n        // ============================================================\n        // Test 1: Get running time (microseconds since boot)\n        // ============================================================\n        ESP_LOGI(TAG, \"\\n--- Test 1: Get Running Time ---\");\n        TinyTimeMark_t start_time = tiny_get_running_time();\n        ESP_LOGI(TAG, \"Running time: %lld microseconds\", start_time);\n        ESP_LOGI(TAG, \"Running time: %.3f seconds\", start_time / 1000000.0);\n\n        // ============================================================\n        // Test 2: Sync time with timezone\n        // ============================================================\n        ESP_LOGI(TAG, \"\\n--- Test 2: Sync Time with Timezone ---\");\n        ESP_LOGI(TAG, \"Syncing time with timezone CST-8...\");\n        sync_time_with_timezone(\"CST-8\");\n\n        // Wait for time synchronization (SNTP may take a few seconds)\n        ESP_LOGI(TAG, \"Waiting for time synchronization...\");\n        vTaskDelay(5000 / portTICK_PERIOD_MS);\n\n        // ============================================================\n        // Test 3: Get current datetime\n        // ============================================================\n        ESP_LOGI(TAG, \"\\n--- Test 3: Get Current DateTime ---\");\n        (void)tiny_get_current_datetime(true);  // Function prints internally\n\n        // ============================================================\n        // Test 4: Measure time elapsed\n        // ============================================================\n        ESP_LOGI(TAG, \"\\n--- Test 4: Measure Time Elapsed ---\");\n        TinyTimeMark_t end_time = tiny_get_running_time();\n        TinyTimeMark_t elapsed = end_time - start_time;\n        ESP_LOGI(TAG, \"Time elapsed: %lld microseconds\", elapsed);\n        ESP_LOGI(TAG, \"Time elapsed: %.3f seconds\", elapsed / 1000000.0);\n\n        ESP_LOGI(TAG, \"\\n========================================\");\n        ESP_LOGI(TAG, \"  Initial Tests Completed\");\n        ESP_LOGI(TAG, \"========================================\\n\");\n    }\n    else\n    {\n        ESP_LOGE(TAG, \"WiFi connection failed!\");\n        return;\n    }\n\n    // ============================================================\n    // Timer precision test: Record 15 timestamps at 2-second intervals\n    // ============================================================\n    ESP_LOGI(TAG, \"\\n========================================\");\n    ESP_LOGI(TAG, \"  Timer Precision Test\");\n    ESP_LOGI(TAG, \"========================================\");\n    ESP_LOGI(TAG, \"Recording 15 timestamps at 2-second intervals...\");\n    ESP_LOGI(TAG, \"No printing during recording to avoid timing overhead.\\n\");\n\n    // Create mutex for thread-safe access to timestamp array\n    s_timer_mutex = xSemaphoreCreateMutex();\n    if (s_timer_mutex == NULL)\n    {\n        ESP_LOGE(TAG, \"Failed to create mutex!\");\n        return;\n    }\n\n    // Initialize timer\n    const uint64_t TIMER_PERIOD_US = 2000000;  // 2 seconds in microseconds\n    esp_timer_create_args_t timer_args;\n    timer_args.callback = &amp;timer_precision_callback;\n    timer_args.arg = NULL;\n    timer_args.dispatch_method = ESP_TIMER_TASK;  // Execute callback in timer task\n    timer_args.name = \"precision_timer\";\n    timer_args.skip_unhandled_events = false;  // Don't skip events\n\n    ret = esp_timer_create(&amp;timer_args, &amp;s_timer_handle);\n    if (ret != ESP_OK)\n    {\n        ESP_LOGE(TAG, \"Failed to create timer: %s\", esp_err_to_name(ret));\n        vSemaphoreDelete(s_timer_mutex);\n        return;\n    }\n\n    // Start periodic timer\n    ret = esp_timer_start_periodic(s_timer_handle, TIMER_PERIOD_US);\n    if (ret != ESP_OK)\n    {\n        ESP_LOGE(TAG, \"Failed to start timer: %s\", esp_err_to_name(ret));\n        esp_timer_delete(s_timer_handle);\n        vSemaphoreDelete(s_timer_mutex);\n        return;\n    }\n\n    // Wait for all timestamps to be collected\n    ESP_LOGI(TAG, \"Timer started. Waiting for %d timestamps...\", TIMESTAMP_COUNT);\n    while (!s_timer_test_complete)\n    {\n        vTaskDelay(100 / portTICK_PERIOD_MS);  // Check every 100ms\n    }\n\n    // Wait a bit more to ensure timer has stopped\n    vTaskDelay(100 / portTICK_PERIOD_MS);\n\n    // Print all results\n    ESP_LOGI(TAG, \"\\n========================================\");\n    ESP_LOGI(TAG, \"  Timer Precision Test Results\");\n    ESP_LOGI(TAG, \"========================================\");\n    ESP_LOGI(TAG, \"Expected interval: 2000000 microseconds (2.000000 seconds)\\n\");\n\n    for (int i = 0; i &lt; TIMESTAMP_COUNT; i++)\n    {\n        if (i == 0)\n        {\n            // First timestamp - show absolute time\n            ESP_LOGI(TAG, \"Timestamp #%2d: %lld microseconds (%.6f seconds) [baseline]\",\n                     i + 1, s_timestamps[i], s_timestamps[i] / 1000000.0);\n        }\n        else\n        {\n            // Calculate interval from previous timestamp\n            TinyTimeMark_t interval = s_timestamps[i] - s_timestamps[i - 1];\n            int64_t error = interval - 2000000;  // Expected 2 seconds = 2000000 microseconds\n            double error_ms = error / 1000.0;\n\n            ESP_LOGI(TAG, \"Timestamp #%2d: %lld microseconds (%.6f seconds) | \"\n                     \"Interval: %lld us (%.6f s) | Error: %lld us (%.3f ms)\",\n                     i + 1, \n                     s_timestamps[i], \n                     s_timestamps[i] / 1000000.0,\n                     interval,\n                     interval / 1000000.0,\n                     error,\n                     error_ms);\n        }\n    }\n\n    // Calculate statistics\n    ESP_LOGI(TAG, \"\\n--- Statistics ---\");\n    int64_t total_interval = s_timestamps[TIMESTAMP_COUNT - 1] - s_timestamps[0];\n    int64_t expected_total = 2000000 * (TIMESTAMP_COUNT - 1);\n    int64_t total_error = total_interval - expected_total;\n\n    ESP_LOGI(TAG, \"Total time: %lld microseconds (%.6f seconds)\", \n             total_interval, total_interval / 1000000.0);\n    ESP_LOGI(TAG, \"Expected total: %lld microseconds (%.6f seconds)\", \n             expected_total, expected_total / 1000000.0);\n    ESP_LOGI(TAG, \"Total error: %lld microseconds (%.3f milliseconds)\", \n             total_error, total_error / 1000.0);\n\n    // Calculate average interval\n    double avg_interval = (double)total_interval / (TIMESTAMP_COUNT - 1);\n    ESP_LOGI(TAG, \"Average interval: %.6f seconds (%.3f microseconds)\", \n             avg_interval / 1000000.0, avg_interval);\n\n    // Cleanup\n    esp_timer_delete(s_timer_handle);\n    vSemaphoreDelete(s_timer_mutex);\n\n    ESP_LOGI(TAG, \"\\n========================================\");\n    ESP_LOGI(TAG, \"  Test Complete\");\n    ESP_LOGI(TAG, \"========================================\\n\");\n\n    // Main loop: Keep running\n    while (1)\n    {\n        vTaskDelay(10000 / portTICK_PERIOD_MS);\n    }\n}\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"TOOLBOX/TIME/code/#output","title":"output","text":"<pre><code>I (25) boot: ESP-IDF v6.0-dev-1833-g758939caec 2nd stage bootloader\nI (25) boot: compile time Nov  4 2025 23:13:16\nI (25) boot: Multicore bootloader\nI (27) boot: chip revision: v0.2\nI (30) boot: efuse block revision: v1.3\nI (33) qio_mode: Enabling default flash chip QIO\nI (38) boot.esp32s3: Boot SPI Speed : 80MHz\nI (41) boot.esp32s3: SPI Mode       : QIO\nI (45) boot.esp32s3: SPI Flash Size : 16MB\nI (49) boot: Enabling RNG early entropy source...\nI (54) boot: Partition Table:\nI (56) boot: ## Label            Usage          Type ST Offset   Length\nI (62) boot:  0 nvs              WiFi data        01 02 00009000 00006000\nI (69) boot:  1 phy_init         RF data          01 01 0000f000 00001000\nI (75) boot:  2 factory          factory app      00 00 00010000 001f0000\nI (82) boot:  3 vfs              Unknown data     01 81 00200000 00a00000\nI (89) boot:  4 storage          Unknown data     01 82 00c00000 00400000\nI (95) boot: End of partition table\nI (98) esp_image: segment 0: paddr=00010020 vaddr=3c0b0020 size=1df80h (122752) map\nI (124) esp_image: segment 1: paddr=0002dfa8 vaddr=3fc99300 size=02070h (  8304) load\nI (126) esp_image: segment 2: paddr=00030020 vaddr=42000020 size=a26fch (665340) map\nI (227) esp_image: segment 3: paddr=000d2724 vaddr=3fc9b370 size=030e0h ( 12512) load\nI (229) esp_image: segment 4: paddr=000d580c vaddr=40374000 size=152ech ( 86764) load\nI (247) esp_image: segment 5: paddr=000eab00 vaddr=50000000 size=00020h (    32) load\nI (256) boot: Loaded app from partition at offset 0x10000\nI (256) boot: Disabling RNG early entropy source...\nI (266) octal_psram: vendor id    : 0x0d (AP)\nI (267) octal_psram: dev id       : 0x02 (generation 3)\nI (267) octal_psram: density      : 0x03 (64 Mbit)\nI (269) octal_psram: good-die     : 0x01 (Pass)\nI (273) octal_psram: Latency      : 0x01 (Fixed)\nI (277) octal_psram: VCC          : 0x01 (3V)\nI (281) octal_psram: SRF          : 0x01 (Fast Refresh)\nI (286) octal_psram: BurstType    : 0x01 (Hybrid Wrap)\nI (291) octal_psram: BurstLen     : 0x01 (32 Byte)\nI (296) octal_psram: Readlatency  : 0x02 (10 cycles@Fixed)\nI (301) octal_psram: DriveStrength: 0x00 (1/1)\nI (306) MSPI Timing: PSRAM timing tuning index: 5\nI (310) esp_psram: Found 8MB PSRAM device\nI (313) esp_psram: Speed: 80MHz\nI (316) cpu_start: Multicore app\nI (752) esp_psram: SPI SRAM memory test OK\nI (760) cpu_start: GPIO 44 and 43 are used as console UART I/O pins\nI (761) cpu_start: Pro cpu start user code\nI (761) cpu_start: cpu freq: 240000000 Hz\nI (762) app_init: Application information:\nI (766) app_init: Project name:     AIoTNode\nI (770) app_init: App version:      0a79117-dirty\nI (775) app_init: Compile time:     Nov  4 2025 23:13:38\nI (780) app_init: ELF file SHA256:  a5e0090b4...\nI (784) app_init: ESP-IDF:          v6.0-dev-1833-g758939caec\nI (789) efuse_init: Min chip rev:     v0.0\nI (793) efuse_init: Max chip rev:     v0.99 \nI (797) efuse_init: Chip rev:         v0.2\nI (801) heap_init: Initializing. RAM available for dynamic allocation:\nI (807) heap_init: At 3FCA2918 len 00046DF8 (283 KiB): RAM\nI (812) heap_init: At 3FCE9710 len 00005724 (21 KiB): RAM\nI (818) heap_init: At 3FCF0000 len 00008000 (32 KiB): DRAM\nI (823) heap_init: At 600FE000 len 00001FE8 (7 KiB): RTCRAM\nI (828) esp_psram: Adding pool of 8192K of PSRAM memory to heap allocator\nI (835) spi_flash: detected chip: boya\nI (838) spi_flash: flash io: qio\nI (841) sleep_gpio: Configure to isolate all GPIO pins in sleep state\nI (847) sleep_gpio: Enable automatic switching of GPIO sleep configuration\nI (854) main_task: Started on CPU0\nI (878) esp_psram: Reserving pool of 32K of internal memory for DMA/internal allocations\nI (878) main_task: Calling app_main()\nI (883) tiny_time_test: ========================================\nI (884) tiny_time_test:   tiny_time Module Test Program\nI (889) tiny_time_test: ========================================\nI (895) tiny_time_test: Initializing WiFi...\nI (900) pp: pp rom version: e7ae62f\nI (902) net80211: net80211 rom version: e7ae62f\nI (907) wifi:wifi driver task: 3fcaf644, prio:23, stack:6656, core=0\nI (915) wifi:wifi firmware version: 14da9b7\nI (916) wifi:wifi certification version: v7.0\nI (920) wifi:config NVS flash: enabled\nI (924) wifi:config nano formatting: disabled\nI (928) wifi:Init data frame dynamic rx buffer num: 32\nI (933) wifi:Init static rx mgmt buffer num: 5\nI (937) wifi:Init management short buffer num: 32\nI (941) wifi:Init dynamic tx buffer num: 32\nI (945) wifi:Init static tx FG buffer num: 2\nI (949) wifi:Init static rx buffer size: 1600\nI (953) wifi:Init static rx buffer num: 10\nI (957) wifi:Init dynamic rx buffer num: 32\nI (961) wifi_init: rx ba win: 6\nI (964) wifi_init: accept mbox: 6\nI (967) wifi_init: tcpip mbox: 32\nI (970) wifi_init: udp mbox: 6\nI (973) wifi_init: tcp mbox: 6\nI (975) wifi_init: tcp tx win: 5760\nI (979) wifi_init: tcp rx win: 5760\nI (982) wifi_init: tcp mss: 1440\nI (985) wifi_init: WiFi IRAM OP enabled\nI (988) wifi_init: WiFi RX IRAM OP enabled\nI (992) NODE-WIFI: Setting WiFi configuration SSID NTUSECURE...\nI (999) phy_init: phy_version 701,f4f1da3a,Mar  3 2025,15:50:10\nI (1037) wifi:mode : sta (cc:ba:97:09:a7:50)\nI (1038) wifi:enable tsf\nI (1039) tiny_time_test: WiFi initialized successfully\nI (1040) tiny_time_test: Waiting for WiFi connection...\nI (1107) wifi:new:&lt;1,0&gt;, old:&lt;1,0&gt;, ap:&lt;255,255&gt;, sta:&lt;1,0&gt;, prof:1, snd_ch_cfg:0x0\nI (1108) wifi:state: init -&gt; auth (0xb0)\nI (1111) wifi:state: auth -&gt; assoc (0x0)\nI (1115) wifi:state: assoc -&gt; run (0x10)\nI (1430) wifi:connected with NTUSECURE, aid = 2, channel 1, BW20, bssid = a8:9d:21:3c:12:b1\nI (1430) wifi:security: WPA2-ENT, phy: bgn, rssi: -66\nI (1432) wifi:pm start, type: 1\n\nI (1435) wifi:dp: 1, bi: 104448, li: 2, scale listen interval from 307200 us to 208896 us\nI (1443) wifi:set rx beacon pti, rx_bcn_pti: 0, bcn_timeout: 25000, mt_pti: 0, mt_time: 10000\nI (1459) wifi:&lt;ba-add&gt;idx:0 (ifx:0, a8:9d:21:3c:12:b1), tid:0, ssn:1200, winSize:64\nI (1488) wifi:AP's beacon interval = 104448 us, DTIM period = 1\nI (2467) esp_netif_handlers: sta ip: 10.91.180.236, mask: 255.255.0.0, gw: 10.91.255.254\nI (2467) tiny_time_test: WiFi connected!\nI (2467) tiny_time_test: \n--- Test 1: Get Running Time ---\nI (2473) tiny_time_test: Running time: 1644833 microseconds\nI (2478) tiny_time_test: Running time: 1.645 seconds\nI (2483) tiny_time_test: \n--- Test 2: Sync Time with Timezone ---\nI (2489) tiny_time_test: Syncing time with timezone CST-8...\nI (2494) NTP_SYNC: Initializing SNTP\nI (2498) NTP_SYNC: Waiting for system time to be set... (1/15)\nI (4503) NTP_SYNC: Waiting for system time to be set... (2/15)\nI (4715) NTP_SYNC: Time synchronized!\nI (6503) NTP_SYNC: System time is set.\nI (6503) NTP_SYNC: Current time: Tue Nov 04 23:15:34 2025\nI (6503) tiny_time_test: Waiting for time synchronization...\nI (11506) tiny_time_test: \n--- Test 3: Get Current DateTime ---\nI (11506) TIME: Current Time: 2025-11-04 23:15:39.003179\nI (11506) tiny_time_test: \n--- Test 4: Measure Time Elapsed ---\nI (11511) tiny_time_test: Time elapsed: 9038406 microseconds\nI (11517) tiny_time_test: Time elapsed: 9.038 seconds\nI (11521) tiny_time_test: \n========================================\nI (11527) tiny_time_test:   Initial Tests Completed\nI (11532) tiny_time_test: ========================================\n\nI (11538) tiny_time_test: \n========================================\nI (11544) tiny_time_test:   Timer Precision Test\nI (11548) tiny_time_test: ========================================\nI (11554) tiny_time_test: Recording 15 timestamps at 2-second intervals...\nI (11561) tiny_time_test: No printing during recording to avoid timing overhead.\n\nI (11568) tiny_time_test: Timer started. Waiting for 15 timestamps...\nI (41674) tiny_time_test: \n========================================\nI (41674) tiny_time_test:   Timer Precision Test Results\nI (41674) tiny_time_test: ========================================\nI (41680) tiny_time_test: Expected interval: 2000000 microseconds (2.000000 seconds)\n\nI (41687) tiny_time_test: Timestamp # 1: 12740383 microseconds (12.740383 seconds) [baseline]\nI (41696) tiny_time_test: Timestamp # 2: 14740381 microseconds (14.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41708) tiny_time_test: Timestamp # 3: 16740383 microseconds (16.740383 seconds) | Interval: 2000002 us (2.000002 s) | Error: 2 us (0.002 ms)\nI (41721) tiny_time_test: Timestamp # 4: 18740383 microseconds (18.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41733) tiny_time_test: Timestamp # 5: 20740383 microseconds (20.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41746) tiny_time_test: Timestamp # 6: 22740383 microseconds (22.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41759) tiny_time_test: Timestamp # 7: 24740382 microseconds (24.740382 seconds) | Interval: 1999999 us (1.999999 s) | Error: -1 us (-0.001 ms)\nI (41771) tiny_time_test: Timestamp # 8: 26740383 microseconds (26.740383 seconds) | Interval: 2000001 us (2.000001 s) | Error: 1 us (0.001 ms)\nI (41784) tiny_time_test: Timestamp # 9: 28740383 microseconds (28.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41797) tiny_time_test: Timestamp #10: 30740383 microseconds (30.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41809) tiny_time_test: Timestamp #11: 32740383 microseconds (32.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41822) tiny_time_test: Timestamp #12: 34740381 microseconds (34.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41834) tiny_time_test: Timestamp #13: 36740383 microseconds (36.740383 seconds) | Interval: 2000002 us (2.000002 s) | Error: 2 us (0.002 ms)\nI (41847) tiny_time_test: Timestamp #14: 38740383 microseconds (38.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41860) tiny_time_test: Timestamp #15: 40740381 microseconds (40.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41872) tiny_time_test: \n--- Statistics ---\nI (41877) tiny_time_test: Total time: 27999998 microseconds (27.999998 seconds)\nI (41884) tiny_time_test: Expected total: 28000000 microseconds (28.000000 seconds)\nI (41891) tiny_time_test: Total error: -2 microseconds (-0.002 milliseconds)\nI (41898) tiny_time_test: Average interval: 2.000000 seconds (1999999.857 microseconds)\nI (41906) tiny_time_test: \n========================================\nI (41912) tiny_time_test:   Test Complete\nI (41915) tiny_time_test: ========================================\n</code></pre>"},{"location":"TOOLBOX/TIME/log/","title":"LOG","text":"<p>2025-04-10</p> <ul> <li>Get Running Time: <code>tiny_get_running_time()</code></li> <li>SNTP Time Synchronization: <code>sync_time_with_timezone(\"CST-8\")</code></li> <li>Get World Time: <code>tiny_get_current_datetime(1)</code></li> </ul> <p>TODO:</p> <ul> <li>Local Time Synchronization for Wireless Sensor Networks - Microsecond Level</li> </ul>"},{"location":"TOOLBOX/TIME/notes/","title":"TIME","text":"<p>Time</p> <p>Time related functions are of vital importance for MCU devices. This section provides a series of time related definitions and functions for developers to use.</p> <p>In MCU, time can be divided into the following types:</p> <ul> <li> <p>Running Time: The time from the power-on of the MCU to now.</p> </li> <li> <p>World Time: The time of the time zone where the MCU is located. World time can be represented by standard year, month, day, hour, minute, and second, or it can be represented as a UNIX timestamp.</p> </li> </ul>"},{"location":"TOOLBOX/TIME/notes/#running-time","title":"RUNNING TIME","text":"<p>ESP has its own function to get the running time, <code>esp_timer_get_time</code>, which depends on the <code>esp_timer</code> library. This function returns the time from power-on to now, in microseconds.</p> <p>To facilitate usage, TinyToolbox redefines the data type <code>TinyTimeMark_t</code> and provides a function <code>tiny_get_running_time</code> to get the running time. The time returned by this function is in the unit of int64_t, which is long enough to avoid overflow.</p> <pre><code>typedef int64_t TinyTimeMark_t;\n</code></pre> <pre><code>/**\n * @brief Get the running time in microseconds\n * @return TinyTimeMark_t\n */\nTinyTimeMark_t tiny_get_running_time(void) { return esp_timer_get_time(); }\n</code></pre> <p>Usage reference:</p> <pre><code>void app_main(void)\n{\n    // Get running time\n    TinyTimeMark_t running_time = tiny_get_running_time();\n    ESP_LOGI(TAG_TIME, \"Running Time: %lld us\", running_time);\n}\n</code></pre>"},{"location":"TOOLBOX/TIME/notes/#world-time","title":"WORLD TIME","text":"<p>Warning</p> <p>Note that obtaining world time requires a successful network connection. In other words, the function to obtain world time needs to be called after the network connection is successfully established.</p>"},{"location":"TOOLBOX/TIME/notes/#ntp-time-synchronization","title":"NTP TIME SYNCHRONIZATION","text":"<p>NTP Time Synchronization</p> <p>NTP (Network Time Protocol) is a protocol used to synchronize time in computer networks. It can obtain accurate time information through the Internet or local area network. NTP protocol uses UDP for communication, with the default port being 123. NTP servers periodically send time information to clients, and clients adjust their system time based on this information.</p> <pre><code>    Client                      Server\n      |-------------------&gt;      |     T1\uff1aRequest sent\n      |                          |\n      |         &lt;--------------- |     T2/T3\uff1aServer received &amp; replied\n      |                          |\n      |-------------------&gt;      |     T4\uff1aClient received response\n</code></pre> <p>NTP Time Synchronization Principle</p> <p>NTP time synchronization is based on four timestamps: 1. Timestamp T1 when the client sends the request 2. Timestamp T2 when the server receives the request 3. Timestamp T3 when the server sends the response 4. Timestamp T4 when the client receives the response. Based on these four timestamps, we can calculate Network Delay Delay = (T4 - T1) - (T3 - T2), and Time Offset Offset = ((T2 - T1) + (T3 - T4)) / 2.</p> <p>ESP32 SNTP Time Synchronization</p> <p>In ESP32, SNTP (Simple Network Time Protocol) is used. SNTP is a simplified version of NTP, suitable for scenarios where time accuracy is not critical. The time synchronization in ESP32 relies on the <code>esp_sntp</code> library. The working principle of SNTP is similar to that of NTP, but the implementation of SNTP is relatively simple, making it suitable for embedded devices. Its accuracy is usually at the millisecond level, which is sufficient for most application scenarios.</p> <p>First, define a callback function to receive time synchronization notifications:</p> <pre><code>/* WORLD CURRENT TIME - SNTP */\n/**\n * @brief Callback function for time synchronization notification\n * @param tv Pointer to the timeval structure containing the synchronized time\n * @return None\n */\nstatic void time_sync_notification_cb(struct timeval *tv)\n{\n    ESP_LOGI(TAG_SNTP, \"Time synchronized!\");\n}\n</code></pre> <p>Next is the SNTP initialization function, which is also the core function of time synchronization. It is usually called when the system is initialized and the network is connected. Note that the time synchronization server address can be modified as needed. After the time synchronization is completed, ESP32 will set the local time at the bottom layer.</p> <pre><code>/**\n * @brief Initialize SNTP\n * @note This function can be called multiple times if needed\n * @return None\n */\nstatic void initialize_sntp(void)\n{\n    ESP_LOGI(TAG_SNTP, \"Initializing SNTP\");\n    esp_sntp_setoperatingmode(SNTP_OPMODE_POLL);\n    esp_sntp_setservername(0, \"pool.ntp.org\"); // NTP server // pool.ntp.org // ntp.aliyun.com\n    esp_sntp_set_time_sync_notification_cb(time_sync_notification_cb);\n    esp_sntp_init();\n}\n</code></pre> <p>Next is a further encapsulation of the above functions, including time zone settings. Note that the following function includes the RTC setting <code>rtc_set_time</code>, which depends on the RTC driver at the driver layer. Here I use my custom rtc driver, if there is no related function, you can comment it out directly.</p> <pre><code>/**\n * @brief Obtain the current time with timezone\n * @param timezone_str Timezone string (e.g., \"CST-8\" or \"GMT+8\")\n * @note The timezone string format should be compatible with POSIX TZ format\n * (e.g., \"CST-8\", \"GMT+8\")\n * @note To use this function, in application, after internet connection, call\n * sync_time_with_timezone(\"CST-8\")\n * @return None\n */\nvoid sync_time_with_timezone(const char *timezone_str)\n{\n    // Validate input parameter\n    if (timezone_str == NULL)\n    {\n        ESP_LOGE(TAG_SNTP, \"timezone_str is NULL\");\n        return;\n    }\n\n    // Set system timezone\n    if (setenv(\"TZ\", timezone_str, 1) != 0)\n    {\n        ESP_LOGE(TAG_SNTP, \"Failed to set timezone environment variable\");\n        return;\n    }\n    tzset();\n\n    // Initialize SNTP and start time sync\n    initialize_sntp();\n\n    // Wait for system time to be set\n    time_t now = 0;\n    struct tm timeinfo = {0};\n    int retry = 0;\n    const int retry_count = 15;\n\n    while (timeinfo.tm_year &lt; MIN_VALID_YEAR_OFFSET &amp;&amp; ++retry &lt; retry_count)\n    {\n        ESP_LOGI(TAG_SNTP, \"Waiting for system time to be set... (%d/%d)\", retry,\n                 retry_count);\n        vTaskDelay(2000 / portTICK_PERIOD_MS);\n        time(&amp;now);\n        if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n        {\n            ESP_LOGW(TAG_SNTP, \"Failed to convert time to local time\");\n            continue;\n        }\n    }\n\n    if (timeinfo.tm_year &gt;= MIN_VALID_YEAR_OFFSET)\n    {\n        rtc_set_time(timeinfo.tm_year + 1900, timeinfo.tm_mon + 1, timeinfo.tm_mday,\n                     timeinfo.tm_hour, timeinfo.tm_min,\n                     timeinfo.tm_sec); // defined in esp_rtc.c\n        ESP_LOGI(TAG_SNTP, \"System time is set.\");\n    }\n    else\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to sync time.\");\n        return;\n    }\n\n    // Log current local time (using thread-safe formatting)\n    char time_str[64];\n    if (strftime(time_str, sizeof(time_str), \"%a %b %d %H:%M:%S %Y\", &amp;timeinfo) ==\n        0)\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to format time string\");\n    }\n    else\n    {\n        ESP_LOGI(TAG_SNTP, \"Current time: %s\", time_str);\n    }\n\n    // vTaskDelay(10000 / portTICK_PERIOD_MS); // Wait for 10 second\n    // rtc_get_time(); // uncomment to check the RTC time\n    // ESP_LOGI(TAG_SNTP, \"Current RTC time: %04d-%02d-%02d %02d:%02d:%02d\",\n    //          calendar.year, calendar.month, calendar.date,\n    //          calendar.hour, calendar.min, calendar.sec); // uncomment to check\n    //          the RTC time\n}\n</code></pre>"},{"location":"TOOLBOX/TIME/notes/#world-time-getting","title":"WORLD TIME GETTING","text":"<p>In order to facilitate the acquisition of world time, we first define a data structure <code>DateTime_t</code> to store information such as year, month, day, hour, minute, and second. Then we define a function <code>tiny_get_current_datetime</code> to obtain the current world time. This function returns a <code>DateTime_t</code> structure, which contains the current year, month, day, hour, minute, and second information. When using it, pass in a Boolean value <code>print_flag</code> to control whether to print the current time.</p> <pre><code>/**\n * @brief Structure to hold date and time\n */\ntypedef struct TinyDateTime_t\n{\n    int year;\n    int month;\n    int day;\n    int hour;\n    int minute;\n    int second;\n    long microsecond;\n} TinyDateTime_t; \n</code></pre> <pre><code>/* WORLD CURRENT TIME - GET TIME */\n/**\n * @name tiny_get_current_datetime\n * @brief Get the current time as a TinyDateTime_t struct\n * @param print_flag Flag to indicate whether to print the time\n * @return TinyDateTime_t structure containing the current date and time\n */\nTinyDateTime_t tiny_get_current_datetime(bool print_flag)\n{\n    TinyDateTime_t result = {0}; // Initialize to zero\n    struct timeval tv;\n\n    // Get current time (seconds + microseconds)\n    if (gettimeofday(&amp;tv, NULL) != 0)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to get time of day\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    time_t now = tv.tv_sec;\n    struct tm timeinfo;\n    if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to convert time to local time\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    result.year = timeinfo.tm_year + 1900;\n    result.month = timeinfo.tm_mon + 1;\n    result.day = timeinfo.tm_mday;\n    result.hour = timeinfo.tm_hour;\n    result.minute = timeinfo.tm_min;\n    result.second = timeinfo.tm_sec;\n    result.microsecond = (int32_t)tv.tv_usec; // Explicit cast for portability\n\n    if (print_flag)\n    {\n        ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06d\",\n                 result.year, result.month, result.day, result.hour, result.minute,\n                 result.second, result.microsecond);\n    }\n\n    return result;\n}\n</code></pre> <p>Usage</p> <pre><code>void app_main(void)\n{\n    // Initialize SNTP and sync time\n    sync_time_with_timezone(\"CST-8\");\n\n    // Get current time\n    TinyDateTime_t current_time = tiny_get_current_datetime(true);\n\n    // Print current time\n    ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06ld\",\n             current_time.year, current_time.month, current_time.day,\n             current_time.hour, current_time.minute, current_time.second, current_time.microsecond);\n}\n</code></pre> <p>Example Output</p> <p></p> <p>Danger</p> <p>The SNTP accuracy when syncing to RTC is at the second level, so the microsecond part when obtaining world time may not be accurate and is for reference only.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"zh/","title":"TINYAUTON: \u9762\u5411\u5fae\u63a7\u5236\u5668\u7684\u5206\u5e03\u5f0f\u667a\u80fd\u6846\u67b6","text":""},{"location":"zh/#_1","title":"\u5173\u4e8e\u672c\u9879\u76ee","text":"<p>\u8fd9\u4e2a\u9879\u76ee\u81f4\u529b\u4e8e\u5f00\u53d1\u4e00\u4e2a\u8fd0\u884c\u5728 MCU \u8bbe\u5907\u4e0a\u7684\u5c0f\u578b\u667a\u80fd\u4f53\u76f8\u5173\u7684\u8ba1\u7b97\u5e93\uff0c\u4ee5\u670d\u52a1\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6db5\u76d6\u6570\u5b66\u8fd0\u7b97\u3001\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u548c TinyML\u3002</p> <p>\u540d\u5b57\u7684\u7531\u6765</p> <p>\"TinyAuton\" \u662f \"Tiny\" \u548c \"Auton\" \u7684\u7ec4\u5408\u3002\"Tiny\" \u610f\u5473\u7740\u667a\u80fd\u4f53\u88ab\u8bbe\u8ba1\u4e3a\u8fd0\u884c\u5728 MCU \u8bbe\u5907\u4e0a\uff0c\u800c \"Auton\" \u662f \"Autonomous Agent\" \u7684\u7f29\u5199\u3002</p>"},{"location":"zh/#_2","title":"\u76ee\u6807\u786c\u4ef6","text":"<ul> <li>MCU \u8bbe\u5907\uff08\u76ee\u524d\u4ee5 ESP32 \u4e3a\u4e3b\u8981\u76ee\u6807\uff09</li> </ul>"},{"location":"zh/#_3","title":"\u8986\u76d6\u8303\u56f4","text":"<ul> <li>\u5e73\u53f0\u9002\u914d\u4e0e\u5404\u7c7b\u5404\u7c7b\u5de5\u5177\uff08\u65f6\u95f4\u3001\u901a\u8baf\u7b49\uff09</li> <li>\u57fa\u672c\u6570\u5b66\u8fd0\u7b97</li> <li>\u6570\u5b57\u4fe1\u53f7\u5904\u7406</li> <li>TinyML / \u8fb9\u7f18\u4eba\u5de5\u667a\u80fd</li> </ul>"},{"location":"zh/#_4","title":"\u5f00\u53d1\u8f7d\u4f53","text":"<p>Tip</p> <p>\u4ee5\u4e0b\u786c\u4ef6\u4ec5\u505a\u5c55\u793a\u7528\u9014\uff0c\u672c\u9879\u76ee\u5e76\u4e0d\u5c40\u9650\u4e8e\u6b64\uff0c\u53ef\u4ee5\u79fb\u690d\u5230\u5176\u4ed6\u7c7b\u578b\u7684\u786c\u4ef6\u4e0a\u3002</p> <ul> <li>Alientek \u7684 DNESP32S3M\uff08ESP32-S3\uff09</li> </ul> <p></p> <p></p> <ul> <li> <p> NexNode</p> <p>  \u4ee3\u7801 </p> <p>  \u6587\u6863 </p> </li> </ul>"},{"location":"zh/#_5","title":"\u9879\u76ee\u67b6\u6784","text":"<pre><code>+------------------------------+\n| \u5e94\u7528\u5c42                        |\n+------------------------------+\n|   - TinyAI                   | &lt;-- AI \u51fd\u6570\n|   - TinyDSP                  | &lt;-- DSP \u51fd\u6570\n|   - TinyMath                 | &lt;-- \u5e38\u7528\u6570\u5b66\u51fd\u6570\n|   - TinyToolbox              | &lt;-- \u5e73\u53f0\u5e95\u5c42\u4f18\u5316 + \u5404\u79cd\u5de5\u5177\n| \u4e2d\u95f4\u4ef6                        |\n+------------------------------+\n| \u9a71\u52a8\u5c42                        |\n+------------------------------+\n| \u786c\u4ef6\u5c42                        |\n+------------------------------+\n</code></pre>"},{"location":"zh/AI/ai/","title":"\u4eba\u5de5\u667a\u80fd","text":""},{"location":"zh/ARCHITECTURE/architecture/","title":"\u67b6\u6784","text":""},{"location":"zh/ARCHITECTURE/architecture/#_2","title":"\u5206\u5c42\u67b6\u6784","text":"<pre><code>+------------------------------+\n| AI                           | &lt;-- \u57fa\u4e8e\u4f4e\u7ea7\u51fd\u6570\u7684\u8fb9\u7f18\u8bbe\u5907 AI/ML \u51fd\u6570\n+------------------------------+\n| DSP                          | &lt;-- \u6570\u5b57\u4fe1\u53f7\u5904\u7406\u51fd\u6570\n+------------------------------+\n| Math Operations              | &lt;-- \u5404\u79cd\u5e94\u7528\u7684\u5e38\u7528\u6570\u5b66\u51fd\u6570\n+------------------------------+\n| Adaptation/Toolbox Layer     | &lt;-- \u7528\u5e73\u53f0\u4f18\u5316/\u7279\u5b9a\u51fd\u6570\u66ff\u6362\u6807\u51c6 C \u4e2d\u7684\u51fd\u6570\n+------------------------------+\n</code></pre>"},{"location":"zh/DSP/dsp/","title":"\u6570\u5b57\u4fe1\u53f7\u5904\u7406","text":"<p>Note</p> <p>\u8be5\u7ec4\u4ef6\u7528\u4e8e\u65e8\u5728\u4e3a\u8fb9\u7f18\u8bbe\u5907\u63d0\u4f9b\u4fe1\u53f7\u5904\u7406\u7684\u4e00\u7cfb\u5217\u51fd\u6570\uff0c\u8bbe\u8ba1\u4e3b\u65e8\u4e3a\u8f7b\u91cf\u9ad8\u6548\uff0c\u8303\u56f4\u4e3a\u5e38\u7528\u91cd\u8981\u7684\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5\u3002</p> <p>Note</p> <p>\u8be5\u7ec4\u4ef6\u57fa\u4e8eESP32\u5b98\u65b9\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u5e93 ESP-DSP \u8fdb\u884c\u5c01\u88c5\u548c\u6269\u5c55\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u5c42\u6b21\u7684API\u63a5\u53e3\u3002\u5148\u524dTinyMath\u5df2\u7ecf\u5bf9\u5e94\u4e86ESP-DSP\u4e2d\u7684Math, Matrix, DotProduct\u6a21\u5757\uff0cESP-DSP\u4e2d\u7684\u5176\u4f59\u6a21\u5757\u5bf9\u5e94\u672c\u7ec4\u4ef6TinyDSP\u5e93\u3002\u9664\u6b64\u4ee5\u5916\uff0cTinyDSP\u8fd8\u63d0\u4f9b\u4e86ESP-DSP\u4e2d\u672a\u66fe\u63d0\u4f9b\u7684\u4e00\u4e9b\u529f\u80fd\uff0c\u91cd\u70b9\u8986\u76d6\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u7b49\u573a\u666f\u3002</p>"},{"location":"zh/DSP/dsp/#_2","title":"\u7ec4\u4ef6\u4f9d\u8d56","text":"<pre><code>set(src_dirs\n    .\n    signal\n    filter\n    transform\n    support\n)\n\nset(include_dirs\n    .\n    include\n    signal\n    filter\n    transform\n    support\n)\n\nset(requires\n    tiny_math\n)\n\nidf_component_register(SRC_DIRS ${src_dirs} INCLUDE_DIRS ${include_dirs} REQUIRES ${requires})\n</code></pre>"},{"location":"zh/DSP/dsp/#_3","title":"\u67b6\u6784\u4e0e\u529f\u80fd\u76ee\u5f55","text":""},{"location":"zh/DSP/dsp/#_4","title":"\u4f9d\u8d56\u5173\u7cfb\u793a\u610f\u56fe","text":""},{"location":"zh/DSP/dsp/#_5","title":"\u4ee3\u7801\u6811","text":"<pre><code>tiny_dsp/\n\u251c\u2500\u2500 include/                     \n\u2502   \u251c\u2500\u2500 tiny_dsp.h               # entrance header file\n\u2502   \u2514\u2500\u2500 tiny_dsp_config.h        # dsp module configuration file\n\u2502\n\u251c\u2500\u2500 signal/\n\u2502   \u251c\u2500\u2500 tiny_conv.h              # convolution - header file\n\u2502   \u251c\u2500\u2500 tiny_conv.c              # convolution - source file\n\u2502   \u251c\u2500\u2500 tiny_conv_test.h         # convolution - test header file\n\u2502   \u251c\u2500\u2500 tiny_conv_test.c         # convolution - test source file\n\u2502   \u251c\u2500\u2500 tiny_corr.h              # correlation - header file\n\u2502   \u251c\u2500\u2500 tiny_corr.c              # correlation - source file\n\u2502   \u251c\u2500\u2500 tiny_corr_test.h         # correlation - test header file\n\u2502   \u251c\u2500\u2500 tiny_corr_test.c         # correlation - test source file\n\u2502   \u251c\u2500\u2500 tiny_resample.h          # resampling - header file\n\u2502   \u251c\u2500\u2500 tiny_resample.c          # resampling - source file\n\u2502   \u251c\u2500\u2500 tiny_resample_test.h     # resampling - test header file\n\u2502   \u2514\u2500\u2500 tiny_resample_test.c     # resampling - test source file\n\u2502\n\u251c\u2500\u2500 filter/\n\u2502   \u251c\u2500\u2500 tiny_fir.h               # FIR filter - header file\n\u2502   \u251c\u2500\u2500 tiny_fir.c               # FIR filter - source file\n\u2502   \u251c\u2500\u2500 tiny_fir_test.h          # FIR filter - test header file\n\u2502   \u251c\u2500\u2500 tiny_fir_test.c          # FIR filter - test source file\n\u2502   \u251c\u2500\u2500 tiny_iir.h               # IIR filter - header file\n\u2502   \u251c\u2500\u2500 tiny_iir.c               # IIR filter - source file\n\u2502   \u251c\u2500\u2500 tiny_iir_test.h          # IIR filter - test header file\n\u2502   \u2514\u2500\u2500 tiny_iir_test.c          # IIR filter - test source file\n\u2502\n\u251c\u2500\u2500 transform/\n\u2502   \u251c\u2500\u2500 tiny_fft.h               # fast fourier transform - header file\n\u2502   \u251c\u2500\u2500 tiny_fft.c               # fast fourier transform - source file\n\u2502   \u251c\u2500\u2500 tiny_fft_test.h          # fast fourier transform - test header file\n\u2502   \u251c\u2500\u2500 tiny_fft_test.c          # fast fourier transform - test source file\n\u2502   \u251c\u2500\u2500 tiny_dwt.h               # discrete wavelet transform - header file\n\u2502   \u251c\u2500\u2500 tiny_dwt.c               # discrete wavelet transform - source file\n\u2502   \u251c\u2500\u2500 tiny_dwt_test.h          # discrete wavelet transform - test header file\n\u2502   \u251c\u2500\u2500 tiny_dwt_test.c          # discrete wavelet transform - test source file\n\u2502   \u251c\u2500\u2500 tiny_ica.h               # independent component analysis - header file\n\u2502   \u251c\u2500\u2500 tiny_ica.c               # independent component analysis - source file\n\u2502   \u251c\u2500\u2500 tiny_ica_test.h          # independent component analysis - test header file\n\u2502   \u2514\u2500\u2500 tiny_ica_test.c          # independent component analysis - test source file\n\u2502\n\u2514\u2500\u2500 support/\n    \u251c\u2500\u2500 tiny_view.h              # signal view/support - header file\n    \u251c\u2500\u2500 tiny_view.c              # signal view/support - source file\n    \u251c\u2500\u2500 tiny_view_test.h         # signal view/support - test header file\n    \u2514\u2500\u2500 tiny_view_test.c         # signal view/support - test source file\n</code></pre>"},{"location":"zh/DSP/FILTER/FIR/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/FILTER/FIR/notes/","title":"\u8bf4\u660e","text":"<p>\u8bf4\u660e</p> <p>\u6709\u9650\u8109\u51b2\u54cd\u5e94\uff08FIR\uff09\u6ee4\u6ce2\u5668\u662f\u6ca1\u6709\u53cd\u9988\u7684\u6570\u5b57\u6ee4\u6ce2\u5668\uff0c\u56e0\u6b64\u59cb\u7ec8\u7a33\u5b9a\u3002FIR \u6ee4\u6ce2\u5668\u53ef\u4ee5\u5b9e\u73b0\u7ebf\u6027\u76f8\u4f4d\u54cd\u5e94\uff0c\u8fd9\u5bf9\u4e8e\u9700\u8981\u4fdd\u6301\u76f8\u4f4d\u7684\u5e94\u7528\u5f88\u91cd\u8981\u3002\u5b83\u4eec\u901a\u8fc7\u5377\u79ef\u5b9e\u73b0\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u97f3\u9891\u5904\u7406\u3001\u901a\u4fe1\u548c\u4fe1\u53f7\u8c03\u7406\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#fir","title":"FIR \u6ee4\u6ce2\u5668\u6982\u8ff0","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#_2","title":"\u6570\u5b66\u539f\u7406","text":"<p>FIR \u6ee4\u6ce2\u5668\u7531\u5176\u6709\u9650\u957f\u5ea6\u7684\u8109\u51b2\u54cd\u5e94 \\( h[n] \\) \u5b9a\u4e49\u3002\u8f93\u51fa \\( y[n] \\) \u8ba1\u7b97\u4e3a\uff1a</p> \\[ y[n] = \\sum_{k=0}^{M-1} h[k] \\cdot x[n-k] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( x[n] \\) \u662f\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\\( h[k] \\) \u662f\u6ee4\u6ce2\u5668\u7cfb\u6570\uff08\u62bd\u5934\uff09</p> </li> <li> <p>\\( M \\) \u662f\u6ee4\u6ce2\u5668\u62bd\u5934\u6570</p> </li> <li> <p>\\( y[n] \\) \u662f\u8f93\u51fa\u4fe1\u53f7</p> </li> </ul> <p>\u4f20\u9012\u51fd\u6570\uff1a</p> \\[ H(z) = \\sum_{k=0}^{M-1} h[k] \\cdot z^{-k} \\] <p>\u5173\u952e\u7279\u6027\uff1a</p> <ul> <li> <p>\u59cb\u7ec8\u7a33\u5b9a\uff1a\u65e0\u6781\u70b9\uff0c\u53ea\u6709\u96f6\u70b9</p> </li> <li> <p>\u7ebf\u6027\u76f8\u4f4d\uff1a\u4f7f\u7528\u5bf9\u79f0\u7cfb\u6570\u53ef\u5b9e\u73b0</p> </li> <li> <p>\u6709\u9650\u5185\u5b58\uff1a\u4ec5\u9700\u8981 \\( M \\) \u4e2a\u8fc7\u53bb\u6837\u672c</p> </li> <li> <p>\u65e0\u53cd\u9988\uff1a\u8f93\u51fa\u4ec5\u4f9d\u8d56\u4e8e\u8f93\u5165</p> </li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_3","title":"\u6ee4\u6ce2\u5668\u7c7b\u578b","text":"<p>\u5e93\u652f\u6301\u56db\u79cd\u57fa\u672c\u6ee4\u6ce2\u5668\u7c7b\u578b\uff1a</p> <ul> <li>\u4f4e\u901a\uff1a\u901a\u8fc7\u622a\u6b62\u9891\u7387\u4ee5\u4e0b\u7684\u9891\u7387\uff0c\u8870\u51cf\u4ee5\u4e0a\u9891\u7387</li> <li>\u9ad8\u901a\uff1a\u901a\u8fc7\u622a\u6b62\u9891\u7387\u4ee5\u4e0a\u7684\u9891\u7387\uff0c\u8870\u51cf\u4ee5\u4e0b\u9891\u7387</li> <li>\u5e26\u901a\uff1a\u901a\u8fc7\u9891\u5e26\u5185\u7684\u9891\u7387\uff0c\u8870\u51cf\u5916\u90e8\u9891\u7387</li> <li>\u5e26\u963b\uff08\u9677\u6ce2\uff09\uff1a\u8870\u51cf\u9891\u5e26\u5185\u7684\u9891\u7387\uff0c\u901a\u8fc7\u5916\u90e8\u9891\u7387</li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_4","title":"\u6ee4\u6ce2\u5668\u8bbe\u8ba1","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#_5","title":"\u7a97\u51fd\u6570\u6cd5","text":"<p>\u5e93\u4f7f\u7528\u7a97\u51fd\u6570\u6cd5\u8fdb\u884c FIR \u6ee4\u6ce2\u5668\u8bbe\u8ba1\uff1a</p> <ol> <li>\u751f\u6210\u7406\u60f3\u6ee4\u6ce2\u5668\uff1a\u521b\u5efa\u7406\u60f3\u9891\u7387\u54cd\u5e94</li> <li>\u5e94\u7528\u7a97\u51fd\u6570\uff1a\u4e58\u4ee5\u7a97\u51fd\u6570\u4ee5\u51cf\u5c11\u5409\u5e03\u65af\u73b0\u8c61</li> <li>\u622a\u65ad\uff1a\u9650\u5236\u4e3a\u6709\u9650\u6570\u91cf\u7684\u62bd\u5934</li> </ol> <p>\u652f\u6301\u7684\u7a97\u51fd\u6570\uff1a</p> <ul> <li> <p>\u77e9\u5f62\uff1a\u65e0\u7a97\uff08\u6700\u5feb\uff0c\u4f46\u53ef\u80fd\u6709\u632f\u94c3\uff09</p> </li> <li> <p>\u6c49\u660e\uff08Hamming\uff09\uff1a\u4e3b\u74e3\u5bbd\u5ea6\u548c\u65c1\u74e3\u6291\u5236\u7684\u826f\u597d\u5e73\u8861</p> </li> <li> <p>\u6c49\u5b81\uff08Hanning\uff09\uff1a\u4e0e\u6c49\u660e\u7c7b\u4f3c\uff0c\u65c1\u74e3\u6291\u5236\u7a0d\u597d</p> </li> <li> <p>\u5e03\u83b1\u514b\u66fc\uff08Blackman\uff09\uff1a\u6700\u4f73\u65c1\u74e3\u6291\u5236\uff0c\u4e3b\u74e3\u66f4\u5bbd</p> </li> </ul> <p>\u7a97\u51fd\u6570\u9009\u62e9\u6307\u5357\uff1a</p> <ul> <li> <p>\u6c49\u660e\uff1a\u901a\u7528\uff0c\u826f\u597d\u5e73\u8861</p> </li> <li> <p>\u6c49\u5b81\uff1a\u65c1\u74e3\u6291\u5236\u4f18\u4e8e\u6c49\u660e</p> </li> <li> <p>\u5e03\u83b1\u514b\u66fc\uff1a\u6700\u9002\u5408\u9700\u8981\u4f4e\u65c1\u74e3\u7684\u5e94\u7528</p> </li> <li> <p>\u77e9\u5f62\uff1a\u4ec5\u7528\u4e8e\u975e\u5e38\u7b80\u5355\u7684\u5e94\u7528</p> </li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_6","title":"\u8bbe\u8ba1\u53c2\u6570","text":"<ul> <li>\u622a\u6b62\u9891\u7387\uff1a\u5f52\u4e00\u5316\u9891\u7387\uff080.0 \u5230 0.5\uff0c\u5176\u4e2d 0.5 = \u5948\u594e\u65af\u7279\u9891\u7387\uff09</li> <li>\u62bd\u5934\u6570\uff1a\u5e94\u4e3a\u5947\u6570\u4ee5\u5b9e\u73b0\u7ebf\u6027\u76f8\u4f4d\uff08I \u578b\u6ee4\u6ce2\u5668\uff09</li> <li>\u7a97\u51fd\u6570\u7c7b\u578b\uff1a\u5f71\u54cd\u8fc7\u6e21\u5e26\u5bbd\u548c\u65c1\u74e3\u6c34\u5e73</li> </ul> <p>\u5f52\u4e00\u5316\u9891\u7387\uff1a</p> \\[ f_{norm} = \\frac{f_{cutoff}}{f_s / 2} \\] <p>\u5176\u4e2d \\( f_s \\) \u662f\u91c7\u6837\u7387\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#_7","title":"\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u51fd\u6570","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_design_lowpass","title":"tiny_fir_design_lowpass","text":"<pre><code>/**\n * @name tiny_fir_design_lowpass\n * @brief Design a low-pass FIR filter using window method\n * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n * @param num_taps Number of filter taps (should be odd)\n * @param window Window function to use\n * @param coefficients Output array for filter coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_design_lowpass(float cutoff_freq, int num_taps,\n                                     tiny_fir_window_t window,\n                                     float *coefficients);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4f7f\u7528\u7a97\u51fd\u6570\u6cd5\u8bbe\u8ba1\u4f4e\u901a FIR \u6ee4\u6ce2\u5668\u3002\u751f\u6210\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u7684\u8109\u51b2\u54cd\u5e94\uff0c\u7136\u540e\u52a0\u7a97\u4ee5\u51cf\u5c11\u5409\u5e03\u65af\u73b0\u8c61\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>cutoff_freq</code>: \u5f52\u4e00\u5316\u622a\u6b62\u9891\u7387\uff080.0 \u5230 0.5\uff0c\u5176\u4e2d 0.5 = \u5948\u594e\u65af\u7279\u9891\u7387\uff09\u3002</p> </li> <li> <p><code>num_taps</code>: \u6ee4\u6ce2\u5668\u62bd\u5934\u6570\u3002\u5fc5\u987b\u4e3a\u5947\u6570\u4ee5\u5b9e\u73b0\u7ebf\u6027\u76f8\u4f4d\u54cd\u5e94\u3002</p> </li> <li> <p><code>window</code>: \u6765\u81ea <code>tiny_fir_window_t</code> \u679a\u4e3e\u7684\u7a97\u51fd\u6570\u7c7b\u578b\u3002</p> </li> <li> <p><code>coefficients</code>: \u6ee4\u6ce2\u5668\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>num_taps</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u622a\u6b62\u9891\u7387\u5df2\u5f52\u4e00\u5316\uff1a<code>cutoff_freq = actual_freq / (sample_rate / 2)</code>\u3002\u4f8b\u5982\uff0c\u5728 1 kHz \u91c7\u6837\u7387\u4e0b 100 Hz \u622a\u6b62\u9891\u7387\u5c06\u4e3a <code>0.2</code>\uff08100 / 500\uff09\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_design_highpass","title":"tiny_fir_design_highpass","text":"<pre><code>/**\n * @name tiny_fir_design_highpass\n * @brief Design a high-pass FIR filter using window method\n * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n * @param num_taps Number of filter taps (should be odd)\n * @param window Window function to use\n * @param coefficients Output array for filter coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_design_highpass(float cutoff_freq, int num_taps,\n                                      tiny_fir_window_t window,\n                                      float *coefficients);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4f7f\u7528\u7a97\u51fd\u6570\u6cd5\u8bbe\u8ba1\u9ad8\u901a FIR \u6ee4\u6ce2\u5668\u3002\u751f\u6210\u7406\u60f3\u9ad8\u901a\u6ee4\u6ce2\u5668\u7684\u8109\u51b2\u54cd\u5e94\uff0c\u7136\u540e\u52a0\u7a97\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>cutoff_freq</code>: \u5f52\u4e00\u5316\u622a\u6b62\u9891\u7387\uff080.0 \u5230 0.5\uff09\u3002</p> </li> <li> <p><code>num_taps</code>: \u6ee4\u6ce2\u5668\u62bd\u5934\u6570\u3002\u5fc5\u987b\u4e3a\u5947\u6570\u3002</p> </li> <li> <p><code>window</code>: \u7a97\u51fd\u6570\u7c7b\u578b\u3002</p> </li> <li> <p><code>coefficients</code>: \u6ee4\u6ce2\u5668\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>num_taps</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_design_bandpass","title":"tiny_fir_design_bandpass","text":"<pre><code>/**\n * @name tiny_fir_design_bandpass\n * @brief Design a band-pass FIR filter using window method\n * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n * @param num_taps Number of filter taps (should be odd)\n * @param window Window function to use\n * @param coefficients Output array for filter coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_design_bandpass(float low_freq, float high_freq,\n                                      int num_taps,\n                                      tiny_fir_window_t window,\n                                      float *coefficients);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4f7f\u7528\u7a97\u51fd\u6570\u6cd5\u8bbe\u8ba1\u5e26\u901a FIR \u6ee4\u6ce2\u5668\u3002\u6ee4\u6ce2\u5668\u901a\u8fc7 <code>low_freq</code> \u548c <code>high_freq</code> \u4e4b\u95f4\u7684\u9891\u7387\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>low_freq</code>: \u4e0b\u622a\u6b62\u9891\u7387\uff08\u5f52\u4e00\u5316\uff0c0.0 \u5230 0.5\uff09\u3002\u5fc5\u987b\u5c0f\u4e8e <code>high_freq</code>\u3002</p> </li> <li> <p><code>high_freq</code>: \u4e0a\u622a\u6b62\u9891\u7387\uff08\u5f52\u4e00\u5316\uff0c0.0 \u5230 0.5\uff09\u3002\u5fc5\u987b\u5927\u4e8e <code>low_freq</code>\u3002</p> </li> <li> <p><code>num_taps</code>: \u6ee4\u6ce2\u5668\u62bd\u5934\u6570\u3002\u5fc5\u987b\u4e3a\u5947\u6570\u3002</p> </li> <li> <p><code>window</code>: \u7a97\u51fd\u6570\u7c7b\u578b\u3002</p> </li> <li> <p><code>coefficients</code>: \u6ee4\u6ce2\u5668\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>num_taps</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_design_bandstop","title":"tiny_fir_design_bandstop","text":"<pre><code>/**\n * @name tiny_fir_design_bandstop\n * @brief Design a band-stop (notch) FIR filter using window method\n * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n * @param num_taps Number of filter taps (should be odd)\n * @param window Window function to use\n * @param coefficients Output array for filter coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_design_bandstop(float low_freq, float high_freq,\n                                      int num_taps,\n                                      tiny_fir_window_t window,\n                                      float *coefficients);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4f7f\u7528\u7a97\u51fd\u6570\u6cd5\u8bbe\u8ba1\u5e26\u963b\uff08\u9677\u6ce2\uff09FIR \u6ee4\u6ce2\u5668\u3002\u6ee4\u6ce2\u5668\u8870\u51cf <code>low_freq</code> \u548c <code>high_freq</code> \u4e4b\u95f4\u7684\u9891\u7387\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>low_freq</code>: \u4e0b\u622a\u6b62\u9891\u7387\uff08\u5f52\u4e00\u5316\uff0c0.0 \u5230 0.5\uff09\u3002\u5fc5\u987b\u5c0f\u4e8e <code>high_freq</code>\u3002</p> </li> <li> <p><code>high_freq</code>: \u4e0a\u622a\u6b62\u9891\u7387\uff08\u5f52\u4e00\u5316\uff0c0.0 \u5230 0.5\uff09\u3002\u5fc5\u987b\u5927\u4e8e <code>low_freq</code>\u3002</p> </li> <li> <p><code>num_taps</code>: \u6ee4\u6ce2\u5668\u62bd\u5934\u6570\u3002\u5fc5\u987b\u4e3a\u5947\u6570\u3002</p> </li> <li> <p><code>window</code>: \u7a97\u51fd\u6570\u7c7b\u578b\u3002</p> </li> <li> <p><code>coefficients</code>: \u6ee4\u6ce2\u5668\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>num_taps</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#_8","title":"\u6ee4\u6ce2\u5668\u5e94\u7528","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#_9","title":"\u6279\u5904\u7406","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_filter_f32","title":"tiny_fir_filter_f32","text":"<pre><code>/**\n * @name tiny_fir_filter_f32\n * @brief Apply FIR filter to a signal (batch processing)\n * @param input Input signal array\n * @param input_len Length of input signal\n * @param coefficients FIR filter coefficients (taps)\n * @param num_taps Number of filter taps\n * @param output Output filtered signal array\n * @param padding_mode Padding mode for boundary handling\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_filter_f32(const float *input, int input_len,\n                                  const float *coefficients, int num_taps,\n                                  float *output,\n                                  tiny_padding_mode_t padding_mode);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4f7f\u7528\u5377\u79ef\u5c06 FIR \u6ee4\u6ce2\u5668\u5e94\u7528\u4e8e\u6574\u4e2a\u4fe1\u53f7\u3002\u9002\u7528\u4e8e\u6574\u4e2a\u4fe1\u53f7\u53ef\u7528\u7684\u6279\u5904\u7406\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u5185\u90e8\u4f7f\u7528\u5377\u79ef</p> </li> <li> <p>\u652f\u6301\u4e0d\u540c\u7684\u586b\u5145\u6a21\u5f0f\u4ee5\u5904\u7406\u8fb9\u754c</p> </li> <li> <p>\u8f93\u51fa\u957f\u5ea6\u7b49\u4e8e\u8f93\u5165\u957f\u5ea6</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>input_len</code>: \u8f93\u5165\u4fe1\u53f7\u957f\u5ea6\u3002</p> </li> <li> <p><code>coefficients</code>: FIR \u6ee4\u6ce2\u5668\u7cfb\u6570\uff08\u62bd\u5934\uff09\u6307\u9488\u3002</p> </li> <li> <p><code>num_taps</code>: \u6ee4\u6ce2\u5668\u62bd\u5934\u6570\u3002</p> </li> <li> <p><code>output</code>: \u6ee4\u6ce2\u4fe1\u53f7\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>input_len</code>\u3002</p> </li> <li> <p><code>padding_mode</code>: \u8fb9\u754c\u5904\u7406\u7684\u586b\u5145\u6a21\u5f0f\uff08\u4f8b\u5982\uff0c<code>TINY_PADDING_SYMMETRIC</code>\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#_10","title":"\u5b9e\u65f6\u5904\u7406","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_init","title":"tiny_fir_init","text":"<pre><code>/**\n * @name tiny_fir_init\n * @brief Initialize FIR filter structure for real-time filtering\n * @param filter Pointer to FIR filter structure\n * @param coefficients Filter coefficients (will be copied internally)\n * @param num_taps Number of filter taps\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_init(tiny_fir_filter_t *filter,\n                            const float *coefficients, int num_taps);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u521d\u59cb\u5316 FIR \u6ee4\u6ce2\u5668\u7ed3\u6784\u4ee5\u8fdb\u884c\u5b9e\u65f6\u9010\u6837\u672c\u5904\u7406\u3002\u4e3a\u7cfb\u6570\u548c\u5ef6\u8fdf\u7ebf\u5206\u914d\u5185\u5b58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>filter</code>: <code>tiny_fir_filter_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>coefficients</code>: \u6ee4\u6ce2\u5668\u7cfb\u6570\u6307\u9488\u3002\u5c06\u5728\u5185\u90e8\u590d\u5236\u3002</p> </li> <li> <p><code>num_taps</code>: \u6ee4\u6ce2\u5668\u62bd\u5934\u6570\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u5185\u5b58\u7ba1\u7406: </p> <p>\u51fd\u6570\u5728\u5185\u90e8\u5206\u914d\u5185\u5b58\u3002\u4f7f\u7528 <code>tiny_fir_deinit()</code> \u91ca\u653e\u5b83\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_deinit","title":"tiny_fir_deinit","text":"<pre><code>/**\n * @name tiny_fir_deinit\n * @brief Deinitialize FIR filter and free allocated memory\n * @param filter Pointer to FIR filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_deinit(tiny_fir_filter_t *filter);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u53d6\u6d88\u521d\u59cb\u5316 FIR \u6ee4\u6ce2\u5668\u5e76\u91ca\u653e\u6240\u6709\u5206\u914d\u7684\u5185\u5b58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>filter</code>: <code>tiny_fir_filter_t</code> \u7ed3\u6784\u6307\u9488\u3002</li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_process_sample","title":"tiny_fir_process_sample","text":"<pre><code>/**\n * @name tiny_fir_process_sample\n * @brief Process a single sample through FIR filter (real-time)\n * @param filter Pointer to initialized FIR filter structure\n * @param input Input sample value\n * @return Filtered output sample\n */\nfloat tiny_fir_process_sample(tiny_fir_filter_t *filter, float input);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u901a\u8fc7 FIR \u6ee4\u6ce2\u5668\u5904\u7406\u5355\u4e2a\u8f93\u5165\u6837\u672c\u5e76\u8fd4\u56de\u6ee4\u6ce2\u8f93\u51fa\u3002\u4f7f\u7528\u5faa\u73af\u7f13\u51b2\u533a\u5b9e\u73b0\u9ad8\u6548\u7684\u5ef6\u8fdf\u7ebf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>filter</code>: \u521d\u59cb\u5316\u7684 <code>tiny_fir_filter_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>input</code>: \u8f93\u5165\u6837\u672c\u503c\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6ee4\u6ce2\u540e\u7684\u8f93\u51fa\u6837\u672c\u3002</p> <p>\u6ce8\u610f: </p> <p>\u6ee4\u6ce2\u5668\u5728\u8c03\u7528\u4e4b\u95f4\u7ef4\u62a4\u5185\u90e8\u72b6\u6001\uff08\u5ef6\u8fdf\u7ebf\uff09\u3002\u4f7f\u7528 <code>tiny_fir_reset()</code> \u6e05\u9664\u72b6\u6001\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#tiny_fir_reset","title":"tiny_fir_reset","text":"<pre><code>/**\n * @name tiny_fir_reset\n * @brief Reset FIR filter state (clear delay line)\n * @param filter Pointer to FIR filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_fir_reset(tiny_fir_filter_t *filter);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u901a\u8fc7\u6e05\u9664\u5ef6\u8fdf\u7ebf\u6765\u91cd\u7f6e FIR \u6ee4\u6ce2\u5668\u72b6\u6001\u3002\u5728\u5f00\u59cb\u65b0\u4fe1\u53f7\u6216\u51fa\u73b0\u4e0d\u8fde\u7eed\u540e\u5f88\u6709\u7528\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>filter</code>: \u521d\u59cb\u5316\u7684 <code>tiny_fir_filter_t</code> \u7ed3\u6784\u6307\u9488\u3002</li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/FIR/notes/#_11","title":"\u4f7f\u7528\u6d41\u7a0b","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#_12","title":"\u6279\u5904\u7406\u6ee4\u6ce2\u6d41\u7a0b","text":"<ol> <li> <p>\u8bbe\u8ba1\u6ee4\u6ce2\u5668:    <pre><code>float coeffs[51];\ntiny_fir_design_lowpass(0.1f, 51, TINY_FIR_WINDOW_HAMMING, coeffs);\n</code></pre></p> </li> <li> <p>\u5e94\u7528\u6ee4\u6ce2\u5668:    <pre><code>float input[256], output[256];\ntiny_fir_filter_f32(input, 256, coeffs, 51, output, TINY_PADDING_SYMMETRIC);\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/FILTER/FIR/notes/#_13","title":"\u5b9e\u65f6\u6ee4\u6ce2\u6d41\u7a0b","text":"<ol> <li> <p>\u8bbe\u8ba1\u6ee4\u6ce2\u5668:    <pre><code>float coeffs[21];\ntiny_fir_design_lowpass(0.1f, 21, TINY_FIR_WINDOW_HAMMING, coeffs);\n</code></pre></p> </li> <li> <p>\u521d\u59cb\u5316\u6ee4\u6ce2\u5668:    <pre><code>tiny_fir_filter_t filter;\ntiny_fir_init(&amp;filter, coeffs, 21);\n</code></pre></p> </li> <li> <p>\u5904\u7406\u6837\u672c:    <pre><code>for (int i = 0; i &lt; num_samples; i++) {\n    float output = tiny_fir_process_sample(&amp;filter, input[i]);\n    // \u4f7f\u7528\u8f93\u51fa...\n}\n</code></pre></p> </li> <li> <p>\u6e05\u7406:    <pre><code>tiny_fir_deinit(&amp;filter);\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/FILTER/FIR/notes/#_14","title":"\u5e94\u7528\u573a\u666f","text":"<p>FIR \u6ee4\u6ce2\u5668\u5e7f\u6cdb\u5e94\u7528\u4e8e\uff1a</p> <ul> <li>\u97f3\u9891\u5904\u7406\uff1a\u5747\u8861\u3001\u964d\u566a\u3001\u6297\u6df7\u53e0</li> <li>\u901a\u4fe1\uff1a\u8109\u51b2\u6574\u5f62\u3001\u5339\u914d\u6ee4\u6ce2\u3001\u4fe1\u9053\u5747\u8861</li> <li>\u751f\u7269\u533b\u5b66\uff1aECG/EEG \u4fe1\u53f7\u8c03\u7406\u3001\u4f2a\u5f71\u53bb\u9664</li> <li>\u63a7\u5236\u7cfb\u7edf\uff1a\u4fe1\u53f7\u8c03\u7406\u3001\u566a\u58f0\u6ee4\u6ce2</li> <li>\u56fe\u50cf\u5904\u7406\uff1a\u8fb9\u7f18\u68c0\u6d4b\u3001\u5e73\u6ed1\u3001\u9510\u5316</li> <li>\u4f20\u611f\u5668\u4fe1\u53f7\u5904\u7406\uff1a\u964d\u566a\u3001\u4fe1\u53f7\u8c03\u7406</li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_15","title":"\u4f18\u7f3a\u70b9","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#_16","title":"\u4f18\u70b9","text":"<ul> <li>\u59cb\u7ec8\u7a33\u5b9a\uff1a\u65e0\u53cd\u9988\uff0c\u4fdd\u8bc1\u7a33\u5b9a\u6027</li> <li>\u7ebf\u6027\u76f8\u4f4d\uff1a\u53ef\u4ee5\u5b9e\u73b0\u7cbe\u786e\u7684\u7ebf\u6027\u76f8\u4f4d\u54cd\u5e94</li> <li>\u8bbe\u8ba1\u7b80\u5355\uff1a\u7a97\u51fd\u6570\u6cd5\u7b80\u5355\u76f4\u63a5</li> <li>\u65e0\u6781\u9650\u73af\uff1a\u65e0\u91cf\u5316\u5f15\u8d77\u7684\u632f\u8361</li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_17","title":"\u7f3a\u70b9","text":"<ul> <li>\u8ba1\u7b97\u6210\u672c\u8f83\u9ad8\uff1a\u76f8\u540c\u89c4\u683c\u4e0b\u6bd4 IIR \u9700\u8981\u66f4\u591a\u62bd\u5934</li> <li>\u5ef6\u8fdf\u66f4\u957f\uff1a\u7fa4\u5ef6\u8fdf\u4e0e\u6ee4\u6ce2\u5668\u957f\u5ea6\u6210\u6b63\u6bd4</li> <li>\u5185\u5b58\u9700\u6c42\uff1a\u9700\u8981\u5b58\u50a8\u6240\u6709\u6ee4\u6ce2\u5668\u62bd\u5934</li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_18","title":"\u8bbe\u8ba1\u8003\u8651","text":""},{"location":"zh/DSP/FILTER/FIR/notes/#_19","title":"\u62bd\u5934\u6570","text":"<ul> <li>\u66f4\u591a\u62bd\u5934\uff1a\u66f4\u9661\u7684\u8fc7\u6e21\uff0c\u66f4\u597d\u7684\u963b\u5e26\u8870\u51cf\uff0c\u4f46\u8ba1\u7b97\u91cf\u66f4\u5927</li> <li>\u66f4\u5c11\u62bd\u5934\uff1a\u8ba1\u7b97\u66f4\u5feb\uff0c\u4f46\u8fc7\u6e21\u5e26\u66f4\u5bbd</li> <li>\u7ecf\u9a8c\u6cd5\u5219\uff1a\u8fc7\u6e21\u5e26\u5bbd \u2248 4 / num_taps\uff08\u5bf9\u4e8e\u6c49\u660e\u7a97\uff09</li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_20","title":"\u7a97\u51fd\u6570\u9009\u62e9","text":"<ul> <li>\u6c49\u660e\uff1a\u826f\u597d\u7684\u901a\u7528\u9009\u62e9</li> <li>\u6c49\u5b81\uff1a\u65c1\u74e3\u6291\u5236\u4f18\u4e8e\u6c49\u660e</li> <li>\u5e03\u83b1\u514b\u66fc\uff1a\u6700\u4f73\u65c1\u74e3\u6291\u5236\uff0c\u8fc7\u6e21\u5e26\u66f4\u5bbd</li> <li>\u77e9\u5f62\uff1a\u4ec5\u7528\u4e8e\u975e\u5e38\u7b80\u5355\u7684\u5e94\u7528\uff08\u4e0d\u63a8\u8350\uff09</li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_21","title":"\u5f52\u4e00\u5316\u9891\u7387","text":"<p>\u8bb0\u4f4f\u8981\u5f52\u4e00\u5316\u9891\u7387\uff1a</p> <ul> <li> <p>\u5728 1 kHz \u91c7\u6837\u7387\u4e0b 100 Hz \u622a\u6b62\uff1a<code>0.2</code>\uff08100 / 500\uff09</p> </li> <li> <p>\u5728 10 kHz \u91c7\u6837\u7387\u4e0b 1 kHz \u622a\u6b62\uff1a<code>0.2</code>\uff081000 / 5000\uff09</p> </li> </ul>"},{"location":"zh/DSP/FILTER/FIR/notes/#_22","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>FIR \u6ee4\u6ce2\u5668\u59cb\u7ec8\u7a33\u5b9a\uff08\u65e0\u6781\u70b9\uff09</li> <li>\u7ebf\u6027\u76f8\u4f4d\u9700\u8981\u5947\u6570\u4e2a\u62bd\u5934\u548c\u5bf9\u79f0\u7cfb\u6570</li> <li>\u7a97\u51fd\u6570\u6cd5\u7b80\u5355\uff0c\u4f46\u53ef\u80fd\u4e0d\u662f\u6240\u6709\u5e94\u7528\u7684\u6700\u4f73\u9009\u62e9</li> <li>\u5bf9\u4e8e\u5b9e\u65f6\u5e94\u7528\uff0c\u4f7f\u7528 <code>tiny_fir_init()</code> \u548c <code>tiny_fir_process_sample()</code></li> <li>\u5bf9\u4e8e\u6279\u5904\u7406\uff0c\u4f7f\u7528 <code>tiny_fir_filter_f32()</code></li> </ul>"},{"location":"zh/DSP/FILTER/FIR/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/FILTER/FIR/test/#_2","title":"\u8f93\u51fa\u7ed3\u679c","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551          TinyFIR Filter Test Suite                      \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\n========== FIR Filter Design Test ==========\n\nTest 1: Low-Pass Filter Design\n  Parameters: cutoff=0.1 (normalized), taps=51, window=Hamming\n  \u2713 Low-pass filter designed successfully\n  Coefficient range: [-0.000000, 0.200000]\n\nTest 2: High-Pass Filter Design\n  Parameters: cutoff=0.2 (normalized), taps=51, window=Hanning\n  \u2713 High-pass filter designed successfully\n\nTest 3: Band-Pass Filter Design\n  Parameters: low=0.1, high=0.3 (normalized), taps=51, window=Blackman\n  \u2713 Band-pass filter designed successfully\n\nTest 4: Band-Stop Filter Design\n  Parameters: low=0.1, high=0.3 (normalized), taps=51, window=Hamming\n  \u2713 Band-stop filter designed successfully\n\n========================================\n\n========== FIR Batch Filtering Test ==========\n\nTest: Low-Pass FIR Filtering\n  Input signal: DC + 10Hz + 50Hz + 100Hz components\n  Filter: Low-pass, cutoff=100.0 Hz (normalized=0.100)\n  Taps: 51, Window: Hamming\n\n  \u2713 Filtering completed successfully\n\nSignal Visualization:\n\nOriginal Signal\nValue\n  3.02 |                                                                \n  2.65 |      *                                                *        \n  2.28 |     **                       **                      * *   *   \n  1.92 | *   * **  *              *  *  *  *              *   *  * **   \n  1.55 |* ***   * **             * ***   ** *            * ****  * **   \n  1.18 |*   *    *  *           *    *    *  *           *        ** *  \n  0.82 |*            *  *    *  *            *  *    *   *            * \n  0.45 |             * **   * ***             ** *  * ****            * \n  0.08 |              *  ***    *              *  * *                  *\n -0.28 |                  **                       **                   \n -0.65 |                   *                        *                   \n -1.02 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.018, 3.018], Length: 256\n\n\nFiltered Signal (Low-Pass)\nValue\n  2.88 |                                                                \n  2.54 |      *                        *                       *        \n  2.20 |     * *                      **                      * *       \n  1.85 |  *  *  *  *              *  *  *  **              *  *  *  *   \n  1.51 |** **   * **             * ***   ** *             * ***   ** *  \n  1.17 |    *    *  *           *         *  *           *           *  \n  0.83 |            *   *    *  *            *  *        *            * \n  0.49 |             * **   * * *             ** *   *** *             *\n  0.15 |              *  *  *  **              *  * *   *               \n -0.19 |                  **                      * *                   \n -0.53 |                   *                       **                   \n -0.87 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-0.872, 2.877], Length: 256\n\n\nStatistics:\n  Input:  mean=1.1294, power=1.9174\n  Output: mean=1.1321, power=1.8899\n  Power reduction: 1.43%\n\n========================================\n\n========== FIR Real-Time Filtering Test ==========\n\nTest: Real-Time FIR Filtering\n  Filter: Low-pass, taps=21\n  Processing samples one by one...\n\n  Input samples: 1.0 2.0 3.0 4.0 5.0 4.0 3.0 2.0 1.0 0.0 0.0 1.0 2.0 3.0 4.0 3.0 2.0 1.0 0.0 0.0 \n  Output samples: 0.000 -0.002 -0.011 -0.031 -0.063 -0.096 -0.092 0.006 0.265 0.733 1.400 2.184 2.934 3.472 3.652 3.419 2.845 2.109 1.446 1.063 \n\n  Testing filter reset...\n  \u2713 Filter reset successful\n\n========================================\n\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551          All FIR Tests Completed                          \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"zh/DSP/FILTER/IIR/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/FILTER/IIR/notes/","title":"\u8bf4\u660e","text":"<p>\u8bf4\u660e</p> <p>\u65e0\u9650\u8109\u51b2\u54cd\u5e94\uff08IIR\uff09\u6ee4\u6ce2\u5668\u662f\u4f7f\u7528\u53cd\u9988\u7684\u9012\u5f52\u6570\u5b57\u6ee4\u6ce2\u5668\uff0c\u5728\u76f8\u540c\u89c4\u683c\u4e0b\u6bd4 FIR \u6ee4\u6ce2\u5668\u66f4\u9ad8\u6548\u3002\u4f46\u662f\uff0c\u5982\u679c\u8bbe\u8ba1\u4e0d\u5f53\uff0cIIR \u6ee4\u6ce2\u5668\u53ef\u80fd\u4e0d\u7a33\u5b9a\u3002\u5b83\u4eec\u5e7f\u6cdb\u5e94\u7528\u4e8e\u97f3\u9891\u5904\u7406\u3001\u63a7\u5236\u7cfb\u7edf\u548c\u4fe1\u53f7\u8c03\u7406\uff0c\u5176\u4e2d\u8ba1\u7b97\u6548\u7387\u5f88\u91cd\u8981\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#iir","title":"IIR \u6ee4\u6ce2\u5668\u6982\u8ff0","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#_2","title":"\u6570\u5b66\u539f\u7406","text":"<p>IIR \u6ee4\u6ce2\u5668\u7531\u5176\u5dee\u5206\u65b9\u7a0b\u5b9a\u4e49\uff0c\u5305\u62ec\u524d\u9988\u9879\u548c\u53cd\u9988\u9879\uff1a</p> \\[ y[n] = \\sum_{k=0}^{M} b[k] \\cdot x[n-k] - \\sum_{k=1}^{N} a[k] \\cdot y[n-k] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( x[n] \\) \u662f\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\\( y[n] \\) \u662f\u8f93\u51fa\u4fe1\u53f7</p> </li> <li> <p>\\( b[k] \\) \u662f\u524d\u9988\uff08\u5206\u5b50\uff09\u7cfb\u6570</p> </li> <li> <p>\\( a[k] \\) \u662f\u53cd\u9988\uff08\u5206\u6bcd\uff09\u7cfb\u6570</p> </li> <li> <p>\\( M \\) \u662f\u5206\u5b50\u9636\u6570</p> </li> <li> <p>\\( N \\) \u662f\u5206\u6bcd\u9636\u6570</p> </li> </ul> <p>\u4f20\u9012\u51fd\u6570\uff1a</p> \\[ H(z) = \\frac{\\sum_{k=0}^{M} b[k] \\cdot z^{-k}}{1 + \\sum_{k=1}^{N} a[k] \\cdot z^{-k}} \\] <p>\u5173\u952e\u7279\u6027\uff1a</p> <ul> <li> <p>\u9012\u5f52\uff1a\u4f7f\u7528\u53cd\u9988\uff08\u5148\u524d\u7684\u8f93\u51fa\uff09</p> </li> <li> <p>\u9ad8\u6548\uff1a\u76f8\u540c\u89c4\u683c\u4e0b\u6bd4 FIR \u9700\u8981\u66f4\u5c11\u7684\u7cfb\u6570</p> </li> <li> <p>\u53ef\u80fd\u4e0d\u7a33\u5b9a\uff1a\u6781\u70b9\u5fc5\u987b\u5728\u5355\u4f4d\u5706\u5185</p> </li> <li> <p>\u975e\u7ebf\u6027\u76f8\u4f4d\uff1a\u901a\u5e38\u5177\u6709\u975e\u7ebf\u6027\u76f8\u4f4d\u54cd\u5e94</p> </li> </ul>"},{"location":"zh/DSP/FILTER/IIR/notes/#_3","title":"\u6ee4\u6ce2\u5668\u7c7b\u578b","text":"<p>\u5e93\u652f\u6301\u56db\u79cd\u57fa\u672c\u6ee4\u6ce2\u5668\u7c7b\u578b\uff1a</p> <ul> <li>\u4f4e\u901a\uff1a\u901a\u8fc7\u622a\u6b62\u9891\u7387\u4ee5\u4e0b\u7684\u9891\u7387\uff0c\u8870\u51cf\u4ee5\u4e0a\u9891\u7387</li> <li>\u9ad8\u901a\uff1a\u901a\u8fc7\u622a\u6b62\u9891\u7387\u4ee5\u4e0a\u7684\u9891\u7387\uff0c\u8870\u51cf\u4ee5\u4e0b\u9891\u7387</li> <li>\u5e26\u901a\uff1a\u901a\u8fc7\u9891\u5e26\u5185\u7684\u9891\u7387\uff0c\u8870\u51cf\u5916\u90e8\u9891\u7387</li> <li>\u5e26\u963b\uff08\u9677\u6ce2\uff09\uff1a\u8870\u51cf\u9891\u5e26\u5185\u7684\u9891\u7387\uff0c\u901a\u8fc7\u5916\u90e8\u9891\u7387</li> </ul>"},{"location":"zh/DSP/FILTER/IIR/notes/#_4","title":"\u6ee4\u6ce2\u5668\u8bbe\u8ba1","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#_5","title":"\u8bbe\u8ba1\u65b9\u6cd5","text":"<p>\u5e93\u652f\u6301 Butterworth \u6ee4\u6ce2\u5668\u8bbe\u8ba1\uff08\u8ba1\u5212\u652f\u6301 Chebyshev\u3001Elliptic \u548c Bessel\uff09\uff1a</p> <ul> <li>Butterworth\uff1a\u6700\u5927\u5e73\u5766\u901a\u5e26\uff0c\u5355\u8c03\u963b\u5e26</li> <li>Chebyshev Type I\uff1a\u7b49\u6ce2\u7eb9\u901a\u5e26\uff0c\u5355\u8c03\u963b\u5e26\uff08\u672a\u6765\uff09</li> <li>Chebyshev Type II\uff1a\u5355\u8c03\u901a\u5e26\uff0c\u7b49\u6ce2\u7eb9\u963b\u5e26\uff08\u672a\u6765\uff09</li> <li>Elliptic\uff1a\u901a\u5e26\u548c\u963b\u5e26\u90fd\u7b49\u6ce2\u7eb9\uff08\u672a\u6765\uff09</li> <li>Bessel\uff1a\u7ebf\u6027\u76f8\u4f4d\u54cd\u5e94\uff08\u672a\u6765\uff09</li> </ul>"},{"location":"zh/DSP/FILTER/IIR/notes/#_6","title":"\u53cc\u7ebf\u6027\u53d8\u6362","text":"<p>IIR \u6ee4\u6ce2\u5668\u4f7f\u7528\u53cc\u7ebf\u6027\u53d8\u6362\u8bbe\u8ba1\uff0c\u5c06\u6a21\u62df s \u5e73\u9762\u6620\u5c04\u5230\u6570\u5b57 z \u5e73\u9762\uff1a</p> \\[ s = \\frac{2}{T} \\cdot \\frac{1 - z^{-1}}{1 + z^{-1}} \\] <p>\u5176\u4e2d \\( T \\) \u662f\u91c7\u6837\u5468\u671f\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#_7","title":"\u8bbe\u8ba1\u53c2\u6570","text":"<ul> <li>\u622a\u6b62\u9891\u7387\uff1a\u5f52\u4e00\u5316\u9891\u7387\uff080.0 \u5230 0.5\uff0c\u5176\u4e2d 0.5 = \u5948\u594e\u65af\u7279\u9891\u7387\uff09</li> <li>\u6ee4\u6ce2\u5668\u9636\u6570\uff1a\u51b3\u5b9a\u8fc7\u6e21\u7684\u9661\u5ea6\u548c\u963b\u5e26\u8870\u51cf</li> <li>\u8bbe\u8ba1\u65b9\u6cd5\uff1a\u5f71\u54cd\u901a\u5e26/\u963b\u5e26\u7279\u6027</li> </ul> <p>\u5f52\u4e00\u5316\u9891\u7387\uff1a</p> \\[ f_{norm} = \\frac{f_{cutoff}}{f_s / 2} \\] <p>\u5176\u4e2d \\( f_s \\) \u662f\u91c7\u6837\u7387\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#_8","title":"\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u51fd\u6570","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_design_lowpass","title":"tiny_iir_design_lowpass","text":"<pre><code>/**\n * @name tiny_iir_design_lowpass\n * @brief Design a low-pass IIR filter\n * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n * @param order Filter order\n * @param design_method Design method (Butterworth, Chebyshev, etc.)\n * @param ripple_db Passband ripple in dB (for Chebyshev)\n * @param b_coeffs Output numerator coefficients (size: order + 1)\n * @param a_coeffs Output denominator coefficients (size: order + 1)\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_design_lowpass(float cutoff_freq, int order,\n                                      tiny_iir_design_method_t design_method,\n                                      float ripple_db,\n                                      float *b_coeffs, float *a_coeffs);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4f7f\u7528\u6307\u5b9a\u7684\u8bbe\u8ba1\u65b9\u6cd5\u8bbe\u8ba1\u4f4e\u901a IIR \u6ee4\u6ce2\u5668\u3002\u76ee\u524d\u652f\u6301 1 \u9636\u548c 2 \u9636\u7684 Butterworth \u8bbe\u8ba1\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>cutoff_freq</code>: \u5f52\u4e00\u5316\u622a\u6b62\u9891\u7387\uff080.0 \u5230 0.5\uff0c\u5176\u4e2d 0.5 = \u5948\u594e\u65af\u7279\u9891\u7387\uff09\u3002</p> </li> <li> <p><code>order</code>: \u6ee4\u6ce2\u5668\u9636\u6570\u3002\u76ee\u524d\u652f\u6301 1 \u548c 2 \u9636\u7684 Butterworth\u3002</p> </li> <li> <p><code>design_method</code>: \u6765\u81ea <code>tiny_iir_design_method_t</code> \u679a\u4e3e\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002\u76ee\u524d\u4ec5\u652f\u6301 <code>TINY_IIR_DESIGN_BUTTERWORTH</code>\u3002</p> </li> <li> <p><code>ripple_db</code>: \u901a\u5e26\u6ce2\u7eb9\uff08dB\uff09\uff08\u7528\u4e8e Chebyshev \u8bbe\u8ba1\uff0c\u5f53\u524d\u672a\u4f7f\u7528\uff09\u3002</p> </li> <li> <p><code>b_coeffs</code>: \u5206\u5b50\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>order + 1</code>\u3002</p> </li> <li> <p><code>a_coeffs</code>: \u5206\u6bcd\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>order + 1</code>\u3002\u6ce8\u610f\uff1a<code>a[0]</code> \u59cb\u7ec8\u4e3a 1.0\uff08\u5f52\u4e00\u5316\u5f62\u5f0f\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u7cfb\u6570\u91c7\u7528\u5f52\u4e00\u5316\u5f62\u5f0f\uff0c\u5176\u4e2d <code>a[0] = 1.0</code>\u3002\u66f4\u9ad8\u9636\u7684\u6ee4\u6ce2\u5668\u9700\u8981\u5206\u89e3\u4e3a\u7ea7\u8054\u53cc\u4e8c\u9636\uff08\u4e8c\u9636\u8282\uff09\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_design_highpass","title":"tiny_iir_design_highpass","text":"<pre><code>/**\n * @name tiny_iir_design_highpass\n * @brief Design a high-pass IIR filter\n * @param cutoff_freq Normalized cutoff frequency (0.0 to 0.5)\n * @param order Filter order\n * @param design_method Design method\n * @param ripple_db Passband ripple in dB\n * @param b_coeffs Output numerator coefficients (size: order + 1)\n * @param a_coeffs Output denominator coefficients (size: order + 1)\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_design_highpass(float cutoff_freq, int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4f7f\u7528\u6307\u5b9a\u7684\u8bbe\u8ba1\u65b9\u6cd5\u8bbe\u8ba1\u9ad8\u901a IIR \u6ee4\u6ce2\u5668\u3002\u76ee\u524d\u652f\u6301 1 \u9636\u548c 2 \u9636\u7684 Butterworth \u8bbe\u8ba1\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>cutoff_freq</code>: \u5f52\u4e00\u5316\u622a\u6b62\u9891\u7387\uff080.0 \u5230 0.5\uff09\u3002</p> </li> <li> <p><code>order</code>: \u6ee4\u6ce2\u5668\u9636\u6570\u3002\u76ee\u524d\u652f\u6301 1 \u548c 2 \u9636\u3002</p> </li> <li> <p><code>design_method</code>: \u8bbe\u8ba1\u65b9\u6cd5\u3002\u76ee\u524d\u4ec5\u652f\u6301 <code>TINY_IIR_DESIGN_BUTTERWORTH</code>\u3002</p> </li> <li> <p><code>ripple_db</code>: \u901a\u5e26\u6ce2\u7eb9\uff08dB\uff09\uff08\u5f53\u524d\u672a\u4f7f\u7528\uff09\u3002</p> </li> <li> <p><code>b_coeffs</code>: \u5206\u5b50\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>order + 1</code>\u3002</p> </li> <li> <p><code>a_coeffs</code>: \u5206\u6bcd\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>order + 1</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_design_bandpass","title":"tiny_iir_design_bandpass","text":"<pre><code>/**\n * @name tiny_iir_design_bandpass\n * @brief Design a band-pass IIR filter\n * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n * @param order Filter order\n * @param design_method Design method\n * @param ripple_db Passband ripple in dB\n * @param b_coeffs Output numerator coefficients\n * @param a_coeffs Output denominator coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_design_bandpass(float low_freq, float high_freq,\n                                       int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u8bbe\u8ba1\u5e26\u901a IIR \u6ee4\u6ce2\u5668\u3002\u76ee\u524d\u8fd4\u56de <code>TINY_ERR_NOT_SUPPORTED</code>\uff0c\u56e0\u4e3a\u5b8c\u6574\u7684\u5e26\u901a\u8bbe\u8ba1\u5c1a\u672a\u5b9e\u73b0\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>low_freq</code>: \u4e0b\u622a\u6b62\u9891\u7387\uff08\u5f52\u4e00\u5316\uff0c0.0 \u5230 0.5\uff09\u3002\u5fc5\u987b\u5c0f\u4e8e <code>high_freq</code>\u3002</p> </li> <li> <p><code>high_freq</code>: \u4e0a\u622a\u6b62\u9891\u7387\uff08\u5f52\u4e00\u5316\uff0c0.0 \u5230 0.5\uff09\u3002\u5fc5\u987b\u5927\u4e8e <code>low_freq</code>\u3002</p> </li> <li> <p><code>order</code>: \u6ee4\u6ce2\u5668\u9636\u6570\u3002</p> </li> <li> <p><code>design_method</code>: \u8bbe\u8ba1\u65b9\u6cd5\u3002</p> </li> <li> <p><code>ripple_db</code>: \u901a\u5e26\u6ce2\u7eb9\uff08dB\uff09\u3002</p> </li> <li> <p><code>b_coeffs</code>: \u5206\u5b50\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002</p> </li> <li> <p><code>a_coeffs</code>: \u5206\u6bcd\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u76ee\u524d\u8fd4\u56de <code>TINY_ERR_NOT_SUPPORTED</code>\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_design_bandstop","title":"tiny_iir_design_bandstop","text":"<pre><code>/**\n * @name tiny_iir_design_bandstop\n * @brief Design a band-stop (notch) IIR filter\n * @param low_freq Lower cutoff frequency (normalized, 0.0 to 0.5)\n * @param high_freq Upper cutoff frequency (normalized, 0.0 to 0.5)\n * @param order Filter order\n * @param design_method Design method\n * @param ripple_db Passband ripple in dB\n * @param b_coeffs Output numerator coefficients\n * @param a_coeffs Output denominator coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_design_bandstop(float low_freq, float high_freq,\n                                       int order,\n                                       tiny_iir_design_method_t design_method,\n                                       float ripple_db,\n                                       float *b_coeffs, float *a_coeffs);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u8bbe\u8ba1\u5e26\u963b\uff08\u9677\u6ce2\uff09IIR \u6ee4\u6ce2\u5668\u3002\u76ee\u524d\u8fd4\u56de <code>TINY_ERR_NOT_SUPPORTED</code>\uff0c\u56e0\u4e3a\u5b8c\u6574\u7684\u5e26\u963b\u8bbe\u8ba1\u5c1a\u672a\u5b9e\u73b0\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>low_freq</code>: \u4e0b\u622a\u6b62\u9891\u7387\uff08\u5f52\u4e00\u5316\uff0c0.0 \u5230 0.5\uff09\u3002\u5fc5\u987b\u5c0f\u4e8e <code>high_freq</code>\u3002</p> </li> <li> <p><code>high_freq</code>: \u4e0a\u622a\u6b62\u9891\u7387\uff08\u5f52\u4e00\u5316\uff0c0.0 \u5230 0.5\uff09\u3002\u5fc5\u987b\u5927\u4e8e <code>low_freq</code>\u3002</p> </li> <li> <p><code>order</code>: \u6ee4\u6ce2\u5668\u9636\u6570\u3002</p> </li> <li> <p><code>design_method</code>: \u8bbe\u8ba1\u65b9\u6cd5\u3002</p> </li> <li> <p><code>ripple_db</code>: \u901a\u5e26\u6ce2\u7eb9\uff08dB\uff09\u3002</p> </li> <li> <p><code>b_coeffs</code>: \u5206\u5b50\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002</p> </li> <li> <p><code>a_coeffs</code>: \u5206\u6bcd\u7cfb\u6570\u7684\u8f93\u51fa\u6570\u7ec4\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u76ee\u524d\u8fd4\u56de <code>TINY_ERR_NOT_SUPPORTED</code>\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#_9","title":"\u6ee4\u6ce2\u5668\u5e94\u7528","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#_10","title":"\u6279\u5904\u7406","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_filter_f32","title":"tiny_iir_filter_f32","text":"<pre><code>/**\n * @name tiny_iir_filter_f32\n * @brief Apply IIR filter to a signal (batch processing)\n * @param input Input signal array\n * @param input_len Length of input signal\n * @param b_coeffs Numerator coefficients\n * @param num_b Number of b coefficients\n * @param a_coeffs Denominator coefficients\n * @param num_a Number of a coefficients\n * @param output Output filtered signal array (size: input_len)\n * @param initial_state Initial state vector (can be NULL for zero initial conditions)\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_filter_f32(const float *input, int input_len,\n                                  const float *b_coeffs, int num_b,\n                                  const float *a_coeffs, int num_a,\n                                  float *output,\n                                  const float *initial_state);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4f7f\u7528\u76f4\u63a5\u578b II \u8f6c\u7f6e\u7ed3\u6784\u5c06 IIR \u6ee4\u6ce2\u5668\u5e94\u7528\u4e8e\u6574\u4e2a\u4fe1\u53f7\u3002\u9002\u7528\u4e8e\u6574\u4e2a\u4fe1\u53f7\u53ef\u7528\u7684\u6279\u5904\u7406\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u4f7f\u7528\u76f4\u63a5\u578b II \u8f6c\u7f6e\u5b9e\u73b0\uff08\u9ad8\u6548\uff09</p> </li> <li> <p>\u652f\u6301\u521d\u59cb\u72b6\u6001\u6761\u4ef6</p> </li> <li> <p>\u8f93\u51fa\u957f\u5ea6\u7b49\u4e8e\u8f93\u5165\u957f\u5ea6</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>input_len</code>: \u8f93\u5165\u4fe1\u53f7\u957f\u5ea6\u3002</p> </li> <li> <p><code>b_coeffs</code>: \u5206\u5b50\u7cfb\u6570\u6307\u9488\u3002</p> </li> <li> <p><code>num_b</code>: \u5206\u5b50\u7cfb\u6570\u6570\u91cf\u3002</p> </li> <li> <p><code>a_coeffs</code>: \u5206\u6bcd\u7cfb\u6570\u6307\u9488\u3002\u6ce8\u610f\uff1a<code>a[0]</code> \u5e94\u4e3a 1.0\uff08\u5f52\u4e00\u5316\u5f62\u5f0f\uff09\u3002</p> </li> <li> <p><code>num_a</code>: \u5206\u6bcd\u7cfb\u6570\u6570\u91cf\u3002</p> </li> <li> <p><code>output</code>: \u6ee4\u6ce2\u4fe1\u53f7\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>input_len</code>\u3002</p> </li> <li> <p><code>initial_state</code>: \u521d\u59cb\u72b6\u6001\u5411\u91cf\u3002\u53ef\u4ee5\u4e3a <code>NULL</code> \u8868\u793a\u96f6\u521d\u59cb\u6761\u4ef6\u3002\u5927\u5c0f\u5e94\u4e3a <code>max(num_b, num_a) - 1</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u6ee4\u6ce2\u5668\u4f7f\u7528\u76f4\u63a5\u578b II \u8f6c\u7f6e\u7ed3\u6784\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u9700\u8981\u6700\u5c11\u7684\u72b6\u6001\u5b58\u50a8\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#_11","title":"\u5b9e\u65f6\u5904\u7406","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_init","title":"tiny_iir_init","text":"<pre><code>/**\n * @name tiny_iir_init\n * @brief Initialize IIR filter structure for real-time filtering\n * @param filter Pointer to IIR filter structure\n * @param b_coeffs Numerator coefficients (will be copied)\n * @param num_b Number of b coefficients\n * @param a_coeffs Denominator coefficients (will be copied)\n * @param num_a Number of a coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_init(tiny_iir_filter_t *filter,\n                            const float *b_coeffs, int num_b,\n                            const float *a_coeffs, int num_a);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u521d\u59cb\u5316 IIR \u6ee4\u6ce2\u5668\u7ed3\u6784\u4ee5\u8fdb\u884c\u5b9e\u65f6\u9010\u6837\u672c\u5904\u7406\u3002\u4e3a\u7cfb\u6570\u548c\u72b6\u6001\u53d8\u91cf\u5206\u914d\u5185\u5b58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>filter</code>: <code>tiny_iir_filter_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>b_coeffs</code>: \u5206\u5b50\u7cfb\u6570\u6307\u9488\u3002\u5c06\u5728\u5185\u90e8\u590d\u5236\u3002</p> </li> <li> <p><code>num_b</code>: \u5206\u5b50\u7cfb\u6570\u6570\u91cf\u3002</p> </li> <li> <p><code>a_coeffs</code>: \u5206\u6bcd\u7cfb\u6570\u6307\u9488\u3002\u5c06\u5728\u5185\u90e8\u590d\u5236\u3002</p> </li> <li> <p><code>num_a</code>: \u5206\u6bcd\u7cfb\u6570\u6570\u91cf\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u5185\u5b58\u7ba1\u7406: </p> <p>\u51fd\u6570\u5728\u5185\u90e8\u5206\u914d\u5185\u5b58\u3002\u4f7f\u7528 <code>tiny_iir_deinit()</code> \u91ca\u653e\u5b83\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_deinit","title":"tiny_iir_deinit","text":"<pre><code>/**\n * @name tiny_iir_deinit\n * @brief Deinitialize IIR filter and free allocated memory\n * @param filter Pointer to IIR filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_deinit(tiny_iir_filter_t *filter);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u53d6\u6d88\u521d\u59cb\u5316 IIR \u6ee4\u6ce2\u5668\u5e76\u91ca\u653e\u6240\u6709\u5206\u914d\u7684\u5185\u5b58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>filter</code>: <code>tiny_iir_filter_t</code> \u7ed3\u6784\u6307\u9488\u3002</li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_process_sample","title":"tiny_iir_process_sample","text":"<pre><code>/**\n * @name tiny_iir_process_sample\n * @brief Process a single sample through IIR filter (real-time)\n * @param filter Pointer to initialized IIR filter structure\n * @param input Input sample value\n * @return Filtered output sample\n */\nfloat tiny_iir_process_sample(tiny_iir_filter_t *filter, float input);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u901a\u8fc7 IIR \u6ee4\u6ce2\u5668\u5904\u7406\u5355\u4e2a\u8f93\u5165\u6837\u672c\u5e76\u8fd4\u56de\u6ee4\u6ce2\u8f93\u51fa\u3002\u4f7f\u7528\u76f4\u63a5\u578b II \u8f6c\u7f6e\u7ed3\u6784\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>filter</code>: \u521d\u59cb\u5316\u7684 <code>tiny_iir_filter_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>input</code>: \u8f93\u5165\u6837\u672c\u503c\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6ee4\u6ce2\u540e\u7684\u8f93\u51fa\u6837\u672c\u3002</p> <p>\u6ce8\u610f: </p> <p>\u6ee4\u6ce2\u5668\u5728\u8c03\u7528\u4e4b\u95f4\u7ef4\u62a4\u5185\u90e8\u72b6\u6001\u3002\u4f7f\u7528 <code>tiny_iir_reset()</code> \u6e05\u9664\u72b6\u6001\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_reset","title":"tiny_iir_reset","text":"<pre><code>/**\n * @name tiny_iir_reset\n * @brief Reset IIR filter state (clear delay line)\n * @param filter Pointer to IIR filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_reset(tiny_iir_filter_t *filter);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u901a\u8fc7\u6e05\u9664\u72b6\u6001\u53d8\u91cf\u6765\u91cd\u7f6e IIR \u6ee4\u6ce2\u5668\u72b6\u6001\u3002\u5728\u5f00\u59cb\u65b0\u4fe1\u53f7\u6216\u51fa\u73b0\u4e0d\u8fde\u7eed\u540e\u5f88\u6709\u7528\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>filter</code>: \u521d\u59cb\u5316\u7684 <code>tiny_iir_filter_t</code> \u7ed3\u6784\u6307\u9488\u3002</li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#_12","title":"\u53cc\u4e8c\u9636\u6ee4\u6ce2\u5668","text":"<p>\u53cc\u4e8c\u9636\uff08\u4e8c\u9636\uff09\u6ee4\u6ce2\u5668\u662f IIR \u6ee4\u6ce2\u5668\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u7279\u522b\u9ad8\u6548\u4e14\u5e38\u7528\u3002\u9ad8\u9636\u6ee4\u6ce2\u5668\u901a\u5e38\u5206\u89e3\u4e3a\u7ea7\u8054\u53cc\u4e8c\u9636\u4ee5\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_biquad_init","title":"tiny_iir_biquad_init","text":"<pre><code>/**\n * @name tiny_iir_biquad_init\n * @brief Initialize a biquad (second-order) IIR filter\n * @param biquad Pointer to biquad filter structure\n * @param b0 Numerator coefficient b0\n * @param b1 Numerator coefficient b1\n * @param b2 Numerator coefficient b2\n * @param a1 Denominator coefficient a1 (a0 = 1.0)\n * @param a2 Denominator coefficient a2\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_biquad_init(tiny_iir_biquad_t *biquad,\n                                    float b0, float b1, float b2,\n                                    float a1, float a2);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u521d\u59cb\u5316\u53cc\u4e8c\u9636\uff08\u4e8c\u9636\uff09IIR \u6ee4\u6ce2\u5668\u3002\u53cc\u4e8c\u9636\u662f\u9ad8\u6548\u4e14\u5e38\u7528\u7684\u9ad8\u9636\u6ee4\u6ce2\u5668\u6784\u5efa\u5757\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>biquad</code>: <code>tiny_iir_biquad_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>b0</code>, <code>b1</code>, <code>b2</code>: \u5206\u5b50\u7cfb\u6570\u3002</p> </li> <li> <p><code>a1</code>, <code>a2</code>: \u5206\u6bcd\u7cfb\u6570\uff08a0 = 1.0\uff0c\u5f52\u4e00\u5316\u5f62\u5f0f\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_biquad_process_sample","title":"tiny_iir_biquad_process_sample","text":"<pre><code>/**\n * @name tiny_iir_biquad_process_sample\n * @brief Process a single sample through biquad filter (real-time)\n * @param biquad Pointer to initialized biquad filter structure\n * @param input Input sample value\n * @return Filtered output sample\n */\nfloat tiny_iir_biquad_process_sample(tiny_iir_biquad_t *biquad, float input);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u901a\u8fc7\u53cc\u4e8c\u9636\u6ee4\u6ce2\u5668\u5904\u7406\u5355\u4e2a\u8f93\u5165\u6837\u672c\u5e76\u8fd4\u56de\u6ee4\u6ce2\u8f93\u51fa\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>biquad</code>: \u521d\u59cb\u5316\u7684 <code>tiny_iir_biquad_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>input</code>: \u8f93\u5165\u6837\u672c\u503c\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6ee4\u6ce2\u540e\u7684\u8f93\u51fa\u6837\u672c\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#tiny_iir_biquad_reset","title":"tiny_iir_biquad_reset","text":"<pre><code>/**\n * @name tiny_iir_biquad_reset\n * @brief Reset biquad filter state\n * @param biquad Pointer to biquad filter structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_iir_biquad_reset(tiny_iir_biquad_t *biquad);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u901a\u8fc7\u6e05\u9664\u5185\u90e8\u72b6\u6001\u53d8\u91cf\u6765\u91cd\u7f6e\u53cc\u4e8c\u9636\u6ee4\u6ce2\u5668\u72b6\u6001\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>biquad</code>: <code>tiny_iir_biquad_t</code> \u7ed3\u6784\u6307\u9488\u3002</li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#_13","title":"\u4f7f\u7528\u6d41\u7a0b","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#_14","title":"\u6279\u5904\u7406\u6ee4\u6ce2\u6d41\u7a0b","text":"<ol> <li> <p>\u8bbe\u8ba1\u6ee4\u6ce2\u5668:    <pre><code>float b_coeffs[3], a_coeffs[3];\ntiny_iir_design_lowpass(0.1f, 2, TINY_IIR_DESIGN_BUTTERWORTH, 0.0f, b_coeffs, a_coeffs);\n</code></pre></p> </li> <li> <p>\u5e94\u7528\u6ee4\u6ce2\u5668:    <pre><code>float input[256], output[256];\ntiny_iir_filter_f32(input, 256, b_coeffs, 3, a_coeffs, 3, output, NULL);\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/FILTER/IIR/notes/#_15","title":"\u5b9e\u65f6\u6ee4\u6ce2\u6d41\u7a0b","text":"<ol> <li> <p>\u8bbe\u8ba1\u6ee4\u6ce2\u5668:    <pre><code>float b_coeffs[3], a_coeffs[3];\ntiny_iir_design_lowpass(0.1f, 2, TINY_IIR_DESIGN_BUTTERWORTH, 0.0f, b_coeffs, a_coeffs);\n</code></pre></p> </li> <li> <p>\u521d\u59cb\u5316\u6ee4\u6ce2\u5668:    <pre><code>tiny_iir_filter_t filter;\ntiny_iir_init(&amp;filter, b_coeffs, 3, a_coeffs, 3);\n</code></pre></p> </li> <li> <p>\u5904\u7406\u6837\u672c:    <pre><code>for (int i = 0; i &lt; num_samples; i++) {\n    float output = tiny_iir_process_sample(&amp;filter, input[i]);\n    // \u4f7f\u7528\u8f93\u51fa...\n}\n</code></pre></p> </li> <li> <p>\u6e05\u7406:    <pre><code>tiny_iir_deinit(&amp;filter);\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/FILTER/IIR/notes/#_16","title":"\u53cc\u4e8c\u9636\u6d41\u7a0b","text":"<ol> <li> <p>\u8bbe\u8ba1\u6ee4\u6ce2\u5668\uff08\u6216\u4f7f\u7528\u9884\u8bbe\u8ba1\u7684\u7cfb\u6570\uff09:    <pre><code>float b_coeffs[3], a_coeffs[3];\ntiny_iir_design_lowpass(0.1f, 2, TINY_IIR_DESIGN_BUTTERWORTH, 0.0f, b_coeffs, a_coeffs);\n</code></pre></p> </li> <li> <p>\u521d\u59cb\u5316\u53cc\u4e8c\u9636:    <pre><code>tiny_iir_biquad_t biquad;\ntiny_iir_biquad_init(&amp;biquad, b_coeffs[0], b_coeffs[1], b_coeffs[2],\n                     a_coeffs[1], a_coeffs[2]);\n</code></pre></p> </li> <li> <p>\u5904\u7406\u6837\u672c:    <pre><code>for (int i = 0; i &lt; num_samples; i++) {\n    float output = tiny_iir_biquad_process_sample(&amp;biquad, input[i]);\n    // \u4f7f\u7528\u8f93\u51fa...\n}\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/FILTER/IIR/notes/#_17","title":"\u5e94\u7528\u573a\u666f","text":"<p>IIR \u6ee4\u6ce2\u5668\u5e7f\u6cdb\u5e94\u7528\u4e8e\uff1a</p> <ul> <li>\u97f3\u9891\u5904\u7406\uff1a\u5747\u8861\u3001\u97f3\u8c03\u63a7\u5236\u3001\u97f3\u9891\u6548\u679c</li> <li>\u63a7\u5236\u7cfb\u7edf\uff1a\u4fe1\u53f7\u8c03\u7406\u3001\u566a\u58f0\u6ee4\u6ce2\u3001\u53cd\u9988\u63a7\u5236</li> <li>\u751f\u7269\u533b\u5b66\uff1aECG/EEG \u4fe1\u53f7\u8c03\u7406\u3001\u4f2a\u5f71\u53bb\u9664</li> <li>\u901a\u4fe1\uff1a\u4fe1\u9053\u5747\u8861\u3001\u964d\u566a</li> <li>\u4f20\u611f\u5668\u4fe1\u53f7\u5904\u7406\uff1a\u964d\u566a\u3001\u4fe1\u53f7\u8c03\u7406</li> <li>\u5b9e\u65f6\u7cfb\u7edf\uff1a\u8ba1\u7b97\u6548\u7387\u81f3\u5173\u91cd\u8981\u7684\u573a\u666f</li> </ul>"},{"location":"zh/DSP/FILTER/IIR/notes/#_18","title":"\u4f18\u7f3a\u70b9","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#_19","title":"\u4f18\u70b9","text":"<ul> <li>\u9ad8\u6548\uff1a\u76f8\u540c\u89c4\u683c\u4e0b\u6bd4 FIR \u9700\u8981\u66f4\u5c11\u7684\u7cfb\u6570</li> <li>\u9661\u5ced\u8fc7\u6e21\uff1a\u53ef\u4ee5\u7528\u4f4e\u9636\u5b9e\u73b0\u9661\u5ced\u7684\u9891\u7387\u54cd\u5e94</li> <li>\u4f4e\u5ef6\u8fdf\uff1a\u4e0e FIR \u76f8\u6bd4\u7fa4\u5ef6\u8fdf\u6700\u5c0f</li> <li>\u5185\u5b58\u9ad8\u6548\uff1a\u6bd4 FIR \u9700\u8981\u66f4\u5c11\u7684\u5185\u5b58</li> </ul>"},{"location":"zh/DSP/FILTER/IIR/notes/#_20","title":"\u7f3a\u70b9","text":"<ul> <li>\u6f5c\u5728\u4e0d\u7a33\u5b9a\uff1a\u5982\u679c\u6781\u70b9\u5728\u5355\u4f4d\u5706\u5916\u53ef\u80fd\u4e0d\u7a33\u5b9a</li> <li>\u975e\u7ebf\u6027\u76f8\u4f4d\uff1a\u901a\u5e38\u5177\u6709\u975e\u7ebf\u6027\u76f8\u4f4d\u54cd\u5e94</li> <li>\u8bbe\u8ba1\u590d\u6742\uff1a\u8bbe\u8ba1\u6bd4 FIR \u7a97\u51fd\u6570\u6cd5\u66f4\u590d\u6742</li> <li>\u6781\u9650\u73af\uff1a\u53ef\u80fd\u51fa\u73b0\u91cf\u5316\u5f15\u8d77\u7684\u6781\u9650\u73af</li> </ul>"},{"location":"zh/DSP/FILTER/IIR/notes/#_21","title":"\u7a33\u5b9a\u6027\u8003\u8651","text":"<p>\u5bf9\u4e8e IIR \u6ee4\u6ce2\u5668\u8981\u7a33\u5b9a\uff0c\u6240\u6709\u6781\u70b9\u5fc5\u987b\u4f4d\u4e8e z \u5e73\u9762\u7684\u5355\u4f4d\u5706\u5185\uff1a</p> \\[ |p_k| &lt; 1 \\quad \\forall k \\] <p>\u5176\u4e2d \\( p_k \\) \u662f\u4f20\u9012\u51fd\u6570\u7684\u6781\u70b9\u3002</p> <p>\u7a33\u5b9a\u6027\u68c0\u67e5\uff1a</p> <p>\u5206\u6bcd\u591a\u9879\u5f0f \\( A(z) = 1 + \\sum_{k=1}^{N} a[k] \\cdot z^{-k} \\) \u7684\u6240\u6709\u6839\u5fc5\u987b\u5728\u5355\u4f4d\u5706\u5185\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#_22","title":"\u8bbe\u8ba1\u8003\u8651","text":""},{"location":"zh/DSP/FILTER/IIR/notes/#_23","title":"\u6ee4\u6ce2\u5668\u9636\u6570","text":"<ul> <li>\u66f4\u9ad8\u9636\uff1a\u66f4\u9661\u7684\u8fc7\u6e21\uff0c\u66f4\u597d\u7684\u963b\u5e26\u8870\u51cf\uff0c\u4f46\u66f4\u590d\u6742</li> <li>\u66f4\u4f4e\u9636\uff1a\u66f4\u7b80\u5355\uff0c\u66f4\u5feb\uff0c\u4f46\u8fc7\u6e21\u5e26\u66f4\u5bbd</li> <li>Butterworth\uff1a\u9636\u6570\u51b3\u5b9a -3 dB \u70b9\u548c\u963b\u5e26\u8870\u51cf</li> </ul>"},{"location":"zh/DSP/FILTER/IIR/notes/#_24","title":"\u5f52\u4e00\u5316\u9891\u7387","text":"<p>\u8bb0\u4f4f\u8981\u5f52\u4e00\u5316\u9891\u7387\uff1a</p> <ul> <li>\u5728 1 kHz \u91c7\u6837\u7387\u4e0b 100 Hz \u622a\u6b62\uff1a<code>0.2</code>\uff08100 / 500\uff09</li> <li>\u5728 10 kHz \u91c7\u6837\u7387\u4e0b 1 kHz \u622a\u6b62\uff1a<code>0.2</code>\uff081000 / 5000\uff09</li> </ul>"},{"location":"zh/DSP/FILTER/IIR/notes/#_25","title":"\u7cfb\u6570\u5f52\u4e00\u5316","text":"<p>IIR \u6ee4\u6ce2\u5668\u4f7f\u7528\u5f52\u4e00\u5316\u7cfb\u6570\uff0c\u5176\u4e2d <code>a[0] = 1.0</code>\u3002\u8fd9\u662f\u6807\u51c6\u505a\u6cd5\uff0c\u7b80\u5316\u4e86\u5b9e\u73b0\u3002</p>"},{"location":"zh/DSP/FILTER/IIR/notes/#_26","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>IIR \u6ee4\u6ce2\u5668\u5982\u679c\u8bbe\u8ba1\u4e0d\u5f53\u53ef\u80fd\u4e0d\u7a33\u5b9a</li> <li>\u8bbe\u8ba1\u81ea\u5b9a\u4e49\u6ee4\u6ce2\u5668\u65f6\u59cb\u7ec8\u68c0\u67e5\u7a33\u5b9a\u6027</li> <li>\u5bf9\u4e8e\u66f4\u9ad8\u9636\uff0c\u5206\u89e3\u4e3a\u7ea7\u8054\u53cc\u4e8c\u9636\u4ee5\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027</li> <li>\u4f7f\u7528\u76f4\u63a5\u578b II \u8f6c\u7f6e\u5b9e\u73b0\u9ad8\u6548</li> <li>\u5bf9\u4e8e\u5b9e\u65f6\u5e94\u7528\uff0c\u4f7f\u7528 <code>tiny_iir_init()</code> \u548c <code>tiny_iir_process_sample()</code></li> <li>\u5bf9\u4e8e\u6279\u5904\u7406\uff0c\u4f7f\u7528 <code>tiny_iir_filter_f32()</code></li> <li>\u53cc\u4e8c\u9636\u6ee4\u6ce2\u5668\u63a8\u8350\u7528\u4e8e\u9ad8\u9636\u8bbe\u8ba1</li> </ul>"},{"location":"zh/DSP/FILTER/IIR/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/FILTER/IIR/test/#_2","title":"\u8f93\u51fa\u7ed3\u679c","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551          TinyIIR Filter Test Suite                       \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\n========== IIR Filter Design Test ==========\n\nTest 1: Low-Pass Butterworth Filter Design\n  Parameters: cutoff=0.1 (normalized), order=2\n  \u2713 Low-pass filter designed successfully\n  B coefficients: 0.067455 0.134911 0.067455 \n  A coefficients: 1.000000 -1.142980 0.412802 \n  Note: a[0] should be 1.0 (normalized)\n\nTest 2: High-Pass Butterworth Filter Design\n  Parameters: cutoff=0.2 (normalized), order=2\n  \u2713 High-pass filter designed successfully\n  B coefficients: 0.391336 -0.782672 0.391336 \n  A coefficients: 1.000000 -0.369527 0.195816 \n\nTest 3: Band-Pass Filter Design\n  Parameters: low=0.1, high=0.3 (normalized), order=2\n  \u26a0 Band-pass design not yet implemented (expected)\n\n========================================\n\n========== IIR Batch Filtering Test ==========\n\nTest: Low-Pass IIR Filtering (Butterworth)\n  Input signal: DC + 10Hz + 50Hz + 100Hz components\n  Filter: Low-pass Butterworth, cutoff=100.0 Hz (normalized=0.100)\n  Order: 2\n\n  \u2713 Filtering completed successfully\n\nSignal Visualization:\n\nOriginal Signal\nValue\n  3.02 |                                                                \n  2.65 |      *                                                *        \n  2.28 |     **                       **                      * *   *   \n  1.92 | *   * **  *              *  *  *  *              *   *  * **   \n  1.55 |* ***   * **             * ***   ** *            * ****  * **   \n  1.18 |*   *    *  *           *    *    *  *           *        ** *  \n  0.82 |*            *  *    *  *            *  *    *   *            * \n  0.45 |             * **   * ***             ** *  * ****            * \n  0.08 |              *  ***    *              *  * *                  *\n -0.28 |                  **                       **                   \n -0.65 |                   *                        *                   \n -1.02 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.018, 3.018], Length: 256\n\n\nFiltered Signal (Low-Pass IIR)\nValue\n  3.06 |                                                                \n  2.69 |      *                        *                       *        \n  2.32 |     **                       **                      * *       \n  1.94 | *   * **  *              *  *  ** **                 *  *  *   \n  1.57 |* ***   * **             * ***   ** *             *****   ** *  \n  1.20 |*   *    *  *            *   *    *  *           *    *    * *  \n  0.82 |*            *  *    *  *             * *        *            * \n  0.45 |*            * **   * ***             ** *   *****             *\n  0.07 |*             *  ** *   *             **  * *    *              \n -0.30 |                  **                   *   **                   \n -0.67 |                   *                        *                   \n -1.05 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.046, 3.064], Length: 256\n\n\nStatistics:\n  Input:  mean=1.1294, power=1.9174\n  Output: mean=1.1294, power=1.9329\n  Power reduction: -0.81%\n\n========================================\n\n========== IIR Real-Time Filtering Test ==========\n\nTest: Real-Time IIR Filtering\n  Filter: Low-pass Butterworth, order=2\n  Processing samples one by one...\n\n  Input samples: 1.0 2.0 3.0 4.0 5.0 4.0 3.0 2.0 1.0 0.0 0.0 1.0 2.0 3.0 4.0 3.0 2.0 1.0 0.0 0.0 \n  Output samples: 0.067 1.413 2.413 3.413 4.413 5.278 3.587 2.587 1.587 0.587 -0.345 0.067 1.413 2.413 3.413 4.278 2.587 1.587 0.587 -0.345 \n\n  Testing filter reset...\n  \u2713 Filter reset successful\n\n========================================\n\n========== IIR Biquad Filter Test ==========\n\nTest: Biquad (Second-Order) IIR Filter\n  Coefficients: b0=0.067455, b1=0.134911, b2=0.067455, a1=-1.142980, a2=0.412802\n\n  Input samples: 1.0 2.0 3.0 4.0 5.0 4.0 3.0 2.0 1.0 0.0 \n  Output samples: 0.067 0.347 0.908 1.704 2.652 3.542 4.033 3.957 3.398 2.520 \n\n  \u2713 Biquad reset successful\n\n========================================\n\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551          All IIR Tests Completed                          \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"zh/DSP/HEADER-FILE/tiny_dsp/","title":"TinyDSP \u5934\u6587\u4ef6","text":"<p>Info</p> <p>\u8fd9\u662fTinyDSP\u5e93\u7684\u4e3b\u5934\u6587\u4ef6\u3002\u5b83\u5305\u542b\u6240\u6709\u5fc5\u8981\u7684\u5934\u6587\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u63a5\u53e3\u6765\u4f7f\u7528\u5e93\u7684\u529f\u80fd\u3002\u5728\u9879\u76ee\u4e2d\u5b8c\u6210\u8be5\u5e93\u7684\u79fb\u690d\u540e\uff0c\u5728\u9700\u8981\u4f7f\u7528\u76f8\u5173\u51fd\u6570\u7684\u5730\u65b9\u63d2\u5165\u8be5\u5934\u6587\u4ef6\u5373\u53ef\u4f7f\u7528\u5e93\u5185\u7684\u6240\u6709\u51fd\u6570\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bf7\u4ee5\u5b9e\u9645\u4ee3\u7801\u4e3a\u51c6\u3002</p> <pre><code>/**\n * @file tiny_dsp.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief tiny_dsp | Main header file - Unified entry point for all DSP functionality\n * @version 1.0\n * @date 2025-04-28\n * @copyright Copyright (c) 2025\n *\n * @details\n * This header file provides a unified interface to all DSP (Digital Signal Processing)\n * functionality in the tiny_dsp middleware. It includes:\n *\n * - Signal Processing: Convolution, Correlation, Resampling\n * - Filters: FIR (Finite Impulse Response), IIR (Infinite Impulse Response)\n * - Transforms: FFT (Fast Fourier Transform), DWT (Discrete Wavelet Transform), ICA (Independent Component Analysis)\n * - Support: Signal visualization and analysis tools\n *\n * Usage:\n *   Simply include this header to access all DSP functions:\n *   @code\n *   #include \"tiny_dsp.h\"\n *   @endcode\n */\n\n#pragma once\n\n/* ============================================================================\n * DEPENDENCIES\n * ============================================================================ */\n\n// Core configuration\n#include \"tiny_dsp_config.h\"\n\n/* ============================================================================\n * SIGNAL PROCESSING MODULES\n * ============================================================================ */\n\n/**\n * @name Signal Processing - Convolution\n * @brief Convolution operations with various padding and output modes\n * @details\n * - Full, center, head, and tail convolution modes\n * - Zero, symmetric, and periodic padding options\n * - Platform-optimized for ESP32\n */\n#include \"tiny_conv.h\"\n#include \"tiny_conv_test.h\"\n\n/**\n * @name Signal Processing - Correlation\n * @brief Correlation and cross-correlation functions\n * @details\n * - Auto-correlation: Pattern matching, template matching\n * - Cross-correlation: Signal alignment, delay estimation\n * - Platform-optimized for ESP32\n */\n#include \"tiny_corr.h\"\n#include \"tiny_corr_test.h\"\n\n/**\n * @name Signal Processing - Resampling\n * @brief Signal resampling, upsampling, and downsampling\n * @details\n * - Linear interpolation resampling\n * - Zero-insertion upsampling\n * - Skip-based downsampling\n */\n#include \"tiny_resample.h\"\n#include \"tiny_resample_test.h\"\n\n/* ============================================================================\n * FILTER MODULES\n * ============================================================================ */\n\n/**\n * @name Filter - FIR (Finite Impulse Response)\n * @brief FIR filter design and application\n * @details\n * - Always stable (no poles, only zeros)\n * - Linear phase response possible\n * - Window-based design methods (Hamming, Hanning, Blackman)\n * - Support for low-pass, high-pass, band-pass, band-stop\n * - Real-time and batch processing modes\n * - Platform-optimized for ESP32\n */\n#include \"tiny_fir.h\"\n#include \"tiny_fir_test.h\"\n\n/**\n * @name Filter - IIR (Infinite Impulse Response)\n * @brief IIR filter design and application\n * @details\n * - Recursive filter with feedback\n * - More efficient than FIR for same specifications\n * - Butterworth, Chebyshev design methods\n * - Support for low-pass, high-pass, band-pass, band-stop\n * - Direct Form II transposed structure\n * - Biquad (second-order) cascade support\n * - Real-time and batch processing modes\n * - Platform-optimized for ESP32\n */\n#include \"tiny_iir.h\"\n#include \"tiny_iir_test.h\"\n\n/* ============================================================================\n * TRANSFORM MODULES\n * ============================================================================ */\n\n/**\n * @name Transform - Discrete Wavelet Transform (DWT)\n * @brief Multi-level wavelet decomposition and reconstruction\n * @details\n * - Support for Daubechies wavelets (DB1-DB10)\n * - Single-level and multi-level decomposition\n * - Perfect reconstruction capability\n * - Energy preservation analysis\n */\n#include \"tiny_dwt.h\"\n#include \"tiny_dwt_test.h\"\n\n/**\n * @name Transform - Fast Fourier Transform (FFT)\n * @brief FFT/IFFT and frequency domain analysis\n * @details\n * - Forward and inverse FFT\n * - Power spectrum density calculation\n * - Peak frequency detection with parabolic interpolation\n * - Top N frequencies detection with peak merging\n * - Window functions: Hanning, Hamming, Blackman\n * - Platform-optimized for ESP32\n */\n#include \"tiny_fft.h\"\n#include \"tiny_fft_test.h\"\n\n/**\n * @name Transform - Independent Component Analysis (ICA)\n * @brief Blind source separation using ICA\n * @details\n * Independent Component Analysis for blind source separation from mixed observations.\n * \n * Algorithm:\n * - FastICA algorithm implementation (default)\n * - Blind source separation model: X = A * S\n *   where X is mixed signals, A is mixing matrix, S is independent sources\n * \n * Preprocessing:\n * - Centering: Subtract mean from each observation\n * - Whitening: Decorrelate and normalize variance using eigenvalue decomposition\n * \n * Features:\n * - Multiple nonlinearity functions:\n *   - tanh: Good for super-Gaussian sources (default)\n *   - exp(-u\u00b2/2): Good for sub-Gaussian sources\n *   - u\u00b3: Alternative for super-Gaussian sources\n * - Orthogonalization: Ensures extracted components are independent\n * - Iterative convergence with configurable tolerance\n * \n * API Modes:\n * - Batch processing: Direct separation via tiny_ica_separate_f32()\n * - Structure-based: Initialize once, fit model, transform multiple times\n *   (efficient for repeated separations with same mixing model)\n * \n * Requirements:\n * - num_sources &lt;= num_obs (cannot extract more sources than observations)\n * - Sufficient samples for stable statistics (recommended: &gt; 100 samples)\n * - Sources must be statistically independent and non-Gaussian\n * \n * Dependencies:\n * - Reuses tiny_math matrix operations (tiny_mat_mult_f32)\n * - Implements eigenvalue decomposition for whitening (Jacobi method)\n * \n * Applications:\n * - Audio source separation (cocktail party problem)\n * - Signal denoising and artifact removal\n * - Feature extraction from sensor arrays\n * - Biomedical signal processing (EEG, ECG artifact removal)\n */\n#include \"tiny_ica.h\"\n#include \"tiny_ica_test.h\"\n\n/* ============================================================================\n * SUPPORT MODULES\n * ============================================================================ */\n\n/**\n * @name Support - Signal Visualization\n * @brief ASCII-based signal and spectrum visualization tools\n * @details\n * - Signal plotting with configurable resolution\n * - Spectrum visualization\n * - Array formatting and statistics\n * - Console-based output (similar to ESP-DSP built-in features)\n */\n#include \"tiny_view.h\"\n#include \"tiny_view_test.h\"\n\n/* ============================================================================\n * C++ COMPATIBILITY\n * ============================================================================ */\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    // All DSP functions are C-compatible and can be called from C++\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/DSP/HEADER-FILE/tiny_dsp_config/","title":"TinyDSP \u914d\u7f6e","text":"<p>Info</p> <p>\u8fd9\u4e2a\u5934\u6587\u4ef6\u8d77\u5230\u914d\u7f6e\u6574\u4e2aTinyDSP\u6a21\u5757\u7684\u4f5c\u7528\uff0c\u6bcf\u4e2a\u5b50\u6a21\u5757\u90fd\u5305\u542b\u4e86\u6b64\u5934\u6587\u4ef6\u3002\u5b83\u5b9a\u4e49\u4e86TinyDSP\u7684\u914d\u7f6e\u9009\u9879\u548c\u5b8f\uff0c\u5141\u8bb8\u7528\u6237\u6839\u636e\u9700\u8981\u8fdb\u884c\u81ea\u5b9a\u4e49\u8bbe\u7f6e\u3002\u901a\u8fc7\u4fee\u6539\u8fd9\u4e2a\u5934\u6587\u4ef6\u4e2d\u7684\u914d\u7f6e\u9009\u9879\uff0c\u7528\u6237\u53ef\u4ee5\u8f7b\u677e\u5730\u8c03\u6574TinyDSP\u7684\u884c\u4e3a\u548c\u529f\u80fd\uff0c\u4ee5\u6ee1\u8db3\u7279\u5b9a\u7684\u9700\u6c42\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4f1a\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bf7\u4ee5\u4ee3\u7801\u4e3a\u51c6\u3002</p> <p>Tip</p> <p>\u5e73\u53f0\u52a0\u901f\u9009\u9879\u8bf7\u5230TinyMath\u914d\u7f6e\u6587\u4ef6\u4e2d\u8fdb\u884c\u8bbe\u7f6e\u3002</p> <pre><code>/**\n * @file tiny_dsp_config.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_dsp middleware.\n * @version 1.0\n * @date 2025-04-27\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n#include \"tiny_math.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/DSP/SIGNAL/CONVOLUTION/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/SIGNAL/CONVOLUTION/notes/","title":"\u8bf4\u660e","text":""},{"location":"zh/DSP/SIGNAL/CONVOLUTION/notes/#_2","title":"\u5377\u79ef\u7684\u6570\u5b66\u539f\u7406","text":"<p>\u5377\u79ef\u662f\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u4e00\u79cd\u91cd\u8981\u64cd\u4f5c\uff0c\u7528\u4e8e\u63cf\u8ff0\u4e24\u4e2a\u4fe1\u53f7\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5b83\u53ef\u4ee5\u770b\u4f5c\u662f\u4e00\u4e2a\u4fe1\u53f7\u4e0e\u53e6\u4e00\u4e2a\u4fe1\u53f7\u7684\u52a0\u6743\u5e73\u5747\u3002\u5377\u79ef\u7684\u6570\u5b66\u5b9a\u4e49\u5982\u4e0b\uff1a</p> \\[y(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) d\\tau\\] <p>\u5176\u4e2d\uff0c\\(x(t)\\) \u662f\u8f93\u5165\u4fe1\u53f7\uff0c\\(h(t)\\) \u662f\u7cfb\u7edf\u7684\u8109\u51b2\u54cd\u5e94\uff0c\\(y(t)\\) \u662f\u8f93\u51fa\u4fe1\u53f7\u3002\u5377\u79ef\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u65b0\u7684\u4fe1\u53f7\uff0c\u5b83\u5305\u542b\u4e86\u8f93\u5165\u4fe1\u53f7\u548c\u7cfb\u7edf\u8109\u51b2\u54cd\u5e94\u4e4b\u95f4\u7684\u6240\u6709\u4fe1\u606f\u3002</p> <p></p> <ul> <li> <p> \u5377\u79ef\u7684\u7269\u7406\u610f\u4e49</p> <p>  \u4f20\u9001\u95e8 </p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/CONVOLUTION/notes/#_3","title":"\u7f16\u7a0b\u601d\u8def","text":"<p>\u672c\u5e93\u4e2d\u7684\u5377\u79ef\u64cd\u4f5c\u5b9e\u9645\u4e0a\u662f\u5c06\u5377\u79ef\u6838\u8c03\u8f6c\u65b9\u5411\u7136\u540e\u4e0e\u8f93\u5165\u4fe1\u53f7\u8fdb\u884c\u9010\u70b9\u76f8\u4e58\u5e76\u6c42\u548c\u3002</p>"},{"location":"zh/DSP/SIGNAL/CONVOLUTION/notes/#tiny_conv_f32","title":"tiny_conv_f32","text":"<pre><code>/**\n * @name: tiny_conv_f32\n * @brief Convolution function\n *\n * @param Signal The input signal array\n * @param siglen The length of the input signal array\n * @param Kernel The input kernel array\n * @param kernlen The length of the input kernel array\n * @param convout The output array for the convolution result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_conv_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *convout)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == convout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n    if (siglen &lt;= 0 || kernlen &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n    if (siglen &lt; kernlen)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    // ESP32 DSP library\n    dsps_conv_f32(Signal, siglen, Kernel, kernlen, convout);\n#else\n    float *sig = (float *)Signal;\n    float *kern = (float *)Kernel;\n    int lsig = siglen;\n    int lkern = kernlen;\n\n    // stage I\n    for (int n = 0; n &lt; lkern; n++)\n    {\n        size_t k;\n\n        convout[n] = 0;\n\n        for (k = 0; k &lt;= n; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n\n    // stage II\n    for (int n = lkern; n &lt; lsig; n++)\n    {\n        size_t kmin, kmax, k;\n\n        convout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = n;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n\n    // stage III\n    for (int n = lsig; n &lt; lsig + lkern - 1; n++)\n    {\n        size_t kmin, kmax, k;\n\n        convout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = lsig - 1;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            convout[n] += sig[k] * kern[n - k];\n        }\n    }\n#endif\n\n    return TINY_OK;\n}\n</code></pre> <p>\u63cf\u8ff0\uff1a</p> <p>\u8be5\u51fd\u6570\u5b9e\u73b0\u4e86\u5bf9\u8f93\u5165\u4fe1\u53f7\u548c\u5377\u79ef\u6838\u7684\u5377\u79ef\u64cd\u4f5c\u3002\u5b83\u9996\u5148\u68c0\u67e5\u8f93\u5165\u53c2\u6570\u662f\u5426\u4e3aNULL\uff0c\u7136\u540e\u6839\u636e\u5e73\u53f0\u9009\u62e9\u4f7f\u7528ESP32 DSP\u5e93\u6216\u6807\u51c6C\u5b9e\u73b0\u8fdb\u884c\u5377\u79ef\u8ba1\u7b97\u3002\u51fd\u6570\u8fd4\u56de\u5377\u79ef\u7ed3\u679c\u3002</p> <p>\u7279\u70b9\uff1a</p> <ul> <li> <p>\u652f\u6301ESP32 DSP\u5e93\u52a0\u901f</p> </li> <li> <p>\u652f\u6301\u5377\u79ef\u6838\u548c\u4fe1\u53f7\u4e92\u6362\u4ee5\u4fdd\u8bc1\u4fe1\u53f7\u957f\u5ea6\u5927\u4e8e\u5377\u79ef\u6838\u957f\u5ea6</p> </li> </ul> <p>\u53c2\u6570\uff1a</p> <ul> <li> <p><code>Signal</code>\uff1a\u8f93\u5165\u4fe1\u53f7\u6570\u7ec4</p> </li> <li> <p><code>siglen</code>\uff1a\u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>Kernel</code>\uff1a\u8f93\u5165\u5377\u79ef\u6838\u6570\u7ec4</p> </li> <li> <p><code>kernlen</code>\uff1a\u8f93\u5165\u5377\u79ef\u6838\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>convout</code>\uff1a\u8f93\u51fa\u6570\u7ec4\uff0c\u7528\u4e8e\u5b58\u50a8\u5377\u79ef\u7ed3\u679c</p> </li> </ul> <p>\u8fd4\u56de\u503c\uff1a</p> <ul> <li> <p><code>TINY_OK</code>\uff1a\u5377\u79ef\u6210\u529f</p> </li> <li> <p><code>TINY_ERR_DSP_NULL_POINTER</code>\uff1a\u8f93\u5165\u53c2\u6570\u4e3aNULL</p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/CONVOLUTION/notes/#tiny_conv_ex_f32","title":"tiny_conv_ex_f32","text":"<pre><code>/**\n * @name: tiny_conv_ex_f32\n * @brief Extended convolution function with padding and mode options\n *\n * @param Signal The input signal array\n * @param siglen The length of the input signal array\n * @param Kernel The input kernel array\n * @param kernlen The length of the input kernel array\n * @param convout The output array for the convolution result\n * @param padding_mode Padding mode (zero, symmetric, periodic)\n * @param conv_mode Convolution mode (full, head, center, tail)\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_conv_ex_f32(const float *Signal, const int siglen,\n                              const float *Kernel, const int kernlen,\n                              float *convout,\n                              tiny_padding_mode_t padding_mode,\n                              tiny_conv_mode_t conv_mode)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == convout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n    if (siglen &lt;= 0 || kernlen &lt;= 0)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n    if (siglen &lt; kernlen)\n    {\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    if (padding_mode == TINY_PADDING_ZERO &amp;&amp; conv_mode == TINY_CONV_FULL)\n    {\n        dsps_conv_f32(Signal, siglen, Kernel, kernlen, convout);\n        return TINY_OK;\n    }\n#endif\n\n    int pad_len = kernlen - 1;\n    int padded_len = siglen + 2 * pad_len;\n    float *padded_signal = (float *)calloc(padded_len, sizeof(float));\n    if (padded_signal == NULL)\n    {\n        return TINY_ERR_DSP_MEMORY_ALLOC;\n    }\n\n    // Fill padded signal\n    switch (padding_mode)\n    {\n    case TINY_PADDING_ZERO:\n        // Middle copy only, left and right are zeros (calloc already zeroed)\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen);\n        break;\n\n    case TINY_PADDING_SYMMETRIC:\n        for (int i = 0; i &lt; pad_len; i++)\n        {\n            padded_signal[pad_len - 1 - i] = Signal[i];                   // Mirror left\n            padded_signal[pad_len + siglen + i] = Signal[siglen - 1 - i]; // Mirror right\n        }\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen); // Copy center\n        break;\n\n    case TINY_PADDING_PERIODIC:\n        for (int i = 0; i &lt; pad_len; i++)\n        {\n            padded_signal[pad_len - 1 - i] = Signal[(siglen - pad_len + i) % siglen]; // Wrap left\n            padded_signal[pad_len + siglen + i] = Signal[i % siglen];                 // Wrap right\n        }\n        memcpy(padded_signal + pad_len, Signal, sizeof(float) * siglen); // Copy center\n        break;\n\n    default:\n        free(padded_signal);\n        return TINY_ERR_DSP_INVALID_PARAM;\n    }\n\n    // Full convolution\n    int convlen_full = siglen + kernlen - 1;\n    for (int n = 0; n &lt; convlen_full; n++)\n    {\n        float sum = 0.0f;\n        for (int k = 0; k &lt; kernlen; k++)\n        {\n            sum += padded_signal[n + k] * Kernel[kernlen - 1 - k]; // Convolution is flip+slide\n        }\n        convout[n] = sum;\n    }\n\n    free(padded_signal);\n\n    // Handle output mode\n    if (conv_mode == TINY_CONV_FULL)\n    {\n        return TINY_OK;\n    }\n    else\n    {\n        int start_idx = 0;\n        int out_len = 0;\n\n        switch (conv_mode)\n        {\n        case TINY_CONV_HEAD:\n            start_idx = 0;\n            out_len = kernlen;\n            break;\n        case TINY_CONV_CENTER:\n            start_idx = (kernlen - 1) / 2;\n            out_len = siglen;\n            break;\n        case TINY_CONV_TAIL:\n            start_idx = siglen - 1;\n            out_len = kernlen;\n            break;\n        default:\n            return TINY_ERR_DSP_INVALID_MODE;\n        }\n\n        // Copy the selected part to the beginning\n        for (int i = 0; i &lt; out_len; i++)\n        {\n            convout[i] = convout[start_idx + i];\n        }\n    }\n\n    return TINY_OK;\n}\n</code></pre> <p>\u63cf\u8ff0\uff1a</p> <p>\u8be5\u51fd\u6570\u5b9e\u73b0\u4e86\u5bf9\u8f93\u5165\u4fe1\u53f7\u548c\u5377\u79ef\u6838\u7684\u6269\u5c55\u5377\u79ef\u64cd\u4f5c\uff0c\u652f\u6301\u4e0d\u540c\u7684\u586b\u5145\u6a21\u5f0f\u548c\u8f93\u51fa\u6a21\u5f0f\u3002\u5b83\u9996\u5148\u68c0\u67e5\u8f93\u5165\u53c2\u6570\u662f\u5426\u4e3aNULL\uff0c\u7136\u540e\u6839\u636e\u5e73\u53f0\u9009\u62e9\u4f7f\u7528ESP32 DSP\u5e93\u6216\u6807\u51c6C\u5b9e\u73b0\u8fdb\u884c\u5377\u79ef\u8ba1\u7b97\u3002\u51fd\u6570\u8fd4\u56de\u5377\u79ef\u7ed3\u679c\u3002</p> <p>\u7279\u70b9\uff1a</p> <ul> <li> <p>\u652f\u6301ESP32 DSP\u5e93\u52a0\u901f</p> </li> <li> <p>\u652f\u6301\u591a\u79cd\u586b\u5145\u6a21\u5f0f\uff08\u96f6\u586b\u5145\u3001\u5bf9\u79f0\u586b\u5145\u3001\u5468\u671f\u586b\u5145\uff09</p> </li> <li> <p>\u652f\u6301\u591a\u79cd\u8f93\u51fa\u6a21\u5f0f\uff08\u5b8c\u6574\u5377\u79ef\u3001\u5934\u90e8\u5377\u79ef\u3001\u4e2d\u5fc3\u5377\u79ef\u3001\u5c3e\u90e8\u5377\u79ef\uff09</p> </li> </ul> <p>\u53c2\u6570\uff1a</p> <ul> <li> <p><code>Signal</code>\uff1a\u8f93\u5165\u4fe1\u53f7\u6570\u7ec4</p> </li> <li> <p><code>siglen</code>\uff1a\u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>Kernel</code>\uff1a\u8f93\u5165\u5377\u79ef\u6838\u6570\u7ec4</p> </li> <li> <p><code>kernlen</code>\uff1a\u8f93\u5165\u5377\u79ef\u6838\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>convout</code>\uff1a\u8f93\u51fa\u6570\u7ec4\uff0c\u7528\u4e8e\u5b58\u50a8\u5377\u79ef\u7ed3\u679c</p> </li> <li> <p><code>padding_mode</code>\uff1a\u586b\u5145\u6a21\u5f0f\uff08\u96f6\u586b\u5145\u3001\u5bf9\u79f0\u586b\u5145\u3001\u5468\u671f\u586b\u5145\uff09</p> </li> <li> <p><code>conv_mode</code>\uff1a\u5377\u79ef\u6a21\u5f0f\uff08\u5b8c\u6574\u5377\u79ef\u3001\u5934\u90e8\u5377\u79ef\u3001\u4e2d\u5fc3\u5377\u79ef\u3001\u5c3e\u90e8\u5377\u79ef\uff09</p> </li> </ul> <p>\u8fd4\u56de\u503c\uff1a</p> <ul> <li> <p><code>TINY_OK</code>\uff1a\u5377\u79ef\u6210\u529f</p> </li> <li> <p><code>TINY_ERR_DSP_NULL_POINTER</code>\uff1a\u8f93\u5165\u53c2\u6570\u4e3aNULL</p> </li> <li> <p><code>TINY_ERR_DSP_INVALID_PARAM</code>\uff1a\u8f93\u5165\u53c2\u6570\u65e0\u6548</p> </li> <li> <p><code>TINY_ERR_DSP_MEMORY_ALLOC</code>\uff1a\u5185\u5b58\u5206\u914d\u5931\u8d25</p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/CONVOLUTION/notes/#_4","title":"\u51fd\u6570\u5bf9\u6bd4","text":"<p>\u4e3a\u4e86\u5e2e\u52a9\u8bfb\u8005\u6839\u636e\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u51fd\u6570\uff0c\u4ee5\u4e0b\u662f <code>tiny_conv_f32</code> \u548c <code>tiny_conv_ex_f32</code> \u7684\u5bf9\u6bd4\uff1a</p> \u7279\u6027 <code>tiny_conv_f32</code> <code>tiny_conv_ex_f32</code> \u586b\u5145\u6a21\u5f0f \u4ec5\u96f6\u586b\u5145\uff08\u9690\u5f0f\uff09 \u96f6\u586b\u5145\u3001\u5bf9\u79f0\u586b\u5145\u6216\u5468\u671f\u586b\u5145\uff08\u663e\u5f0f\uff09 \u8f93\u51fa\u6a21\u5f0f \u4ec5\u5b8c\u6574\u5377\u79ef \u5b8c\u6574\u3001\u5934\u90e8\u3001\u4e2d\u5fc3\u6216\u5c3e\u90e8\u6a21\u5f0f \u8f93\u51fa\u957f\u5ea6 <code>siglen + kernlen - 1</code> \u6839\u636e <code>conv_mode</code> \u53ef\u914d\u7f6e \u5185\u5b58\u4f7f\u7528 \u65e0\u52a8\u6001\u5206\u914d \u9700\u8981\u4e3a\u586b\u5145\u4fe1\u53f7\u52a8\u6001\u5206\u914d\u5185\u5b58 \u6027\u80fd \u4f18\u5316\uff08ESP32 \u652f\u6301\u786c\u4ef6\u52a0\u901f\uff09 \u4ec5\u5728 ESP32 \u4e0a\u4f7f\u7528\u96f6\u586b\u5145+\u5b8c\u6574\u6a21\u5f0f\u65f6\u4f18\u5316 \u4f7f\u7528\u573a\u666f \u7b80\u5355\u7684\u96f6\u586b\u5145\u5b8c\u6574\u5377\u79ef \u9700\u8981\u81ea\u5b9a\u4e49\u586b\u5145\u548c\u8f93\u51fa\u6a21\u5f0f\u7684\u9ad8\u7ea7\u5377\u79ef"},{"location":"zh/DSP/SIGNAL/CONVOLUTION/notes/#tiny_conv_f32_1","title":"\u4f55\u65f6\u4f7f\u7528 <code>tiny_conv_f32</code>","text":"<p>\u5728\u4ee5\u4e0b\u60c5\u51b5\u4e0b\u4f7f\u7528 <code>tiny_conv_f32</code>\uff1a</p> <ul> <li> <p>\u9700\u8981\u7b80\u5355\u7684\u5b8c\u6574\u5377\u79ef\u7ed3\u679c</p> </li> <li> <p>\u96f6\u586b\u5145\u5904\u7406\u8fb9\u754c\u662f\u53ef\u63a5\u53d7\u7684</p> </li> <li> <p>\u9700\u8981\u6700\u4f73\u6027\u80fd\uff08\u7279\u522b\u662f\u5728\u652f\u6301\u786c\u4ef6\u52a0\u901f\u7684 ESP32 \u4e0a\uff09</p> </li> <li> <p>\u5e0c\u671b\u907f\u514d\u52a8\u6001\u5185\u5b58\u5206\u914d</p> </li> <li> <p>\u8f93\u51fa\u957f\u5ea6 <code>siglen + kernlen - 1</code> \u662f\u53ef\u63a5\u53d7\u7684</p> </li> </ul> <p>\u793a\u4f8b\u573a\u666f\uff1a</p> <ul> <li> <p>\u57fa\u672c\u4fe1\u53f7\u6ee4\u6ce2</p> </li> <li> <p>\u7b80\u5355\u7684\u76f8\u5173\u8fd0\u7b97</p> </li> <li> <p>\u9700\u8981\u907f\u514d\u5185\u5b58\u5206\u914d\u7684\u5b9e\u65f6\u5904\u7406</p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/CONVOLUTION/notes/#tiny_conv_ex_f32_1","title":"\u4f55\u65f6\u4f7f\u7528 <code>tiny_conv_ex_f32</code>","text":"<p>\u5728\u4ee5\u4e0b\u60c5\u51b5\u4e0b\u4f7f\u7528 <code>tiny_conv_ex_f32</code>\uff1a</p> <ul> <li> <p>\u9700\u8981\u4e0d\u540c\u7684\u586b\u5145\u7b56\u7565\uff08\u5bf9\u79f0\u6216\u5468\u671f\u586b\u5145\uff09\u6765\u5904\u7406\u4fe1\u53f7\u8fb9\u754c</p> </li> <li> <p>\u9700\u8981\u63d0\u53d6\u5377\u79ef\u7ed3\u679c\u7684\u7279\u5b9a\u90e8\u5206\uff08\u5934\u90e8\u3001\u4e2d\u5fc3\u6216\u5c3e\u90e8\uff09</p> </li> <li> <p>\u9700\u8981\u8f93\u51fa\u957f\u5ea6\u7b49\u4e8e\u8f93\u5165\u4fe1\u53f7\u957f\u5ea6\uff08\u4e2d\u5fc3\u6a21\u5f0f\uff09</p> </li> <li> <p>\u5904\u7406\u7684\u4fe1\u53f7\u8fb9\u754c\u6548\u5e94\u5f88\u91cd\u8981\uff08\u4f8b\u5982\u56fe\u50cf\u5904\u7406\u3001\u5468\u671f\u4fe1\u53f7\uff09</p> </li> <li> <p>\u53ef\u4ee5\u63a5\u53d7\u52a8\u6001\u5185\u5b58\u5206\u914d</p> </li> </ul> <p>\u793a\u4f8b\u573a\u666f\uff1a</p> <ul> <li> <p>\u4f7f\u7528\u5bf9\u79f0\u586b\u5145\u8fdb\u884c\u56fe\u50cf\u6ee4\u6ce2\u4ee5\u51cf\u5c11\u8fb9\u754c\u4f2a\u5f71</p> </li> <li> <p>\u4f7f\u7528\u5468\u671f\u586b\u5145\u5904\u7406\u5468\u671f\u4fe1\u53f7</p> </li> <li> <p>\u5f53\u8f93\u51fa\u957f\u5ea6\u9700\u8981\u5339\u914d\u8f93\u5165\u65f6\uff0c\u4ec5\u63d0\u53d6\u6709\u6548\u5377\u79ef\u533a\u57df\uff08\u4e2d\u5fc3\u6a21\u5f0f\uff09</p> </li> <li> <p>\u8fb9\u754c\u5904\u7406\u81f3\u5173\u91cd\u8981\u7684\u9ad8\u7ea7\u4fe1\u53f7\u5904\u7406</p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/CONVOLUTION/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/SIGNAL/CONVOLUTION/test/#_2","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<pre><code>===== tiny_conv_f32 and tiny_conv_ex_f32 Test Start =====\nSignal: 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 11.00 \nKernel: 0.20 0.50 0.30 \n\n[Test] tiny_conv_f32 basic full convolution...\n[PASS] tiny_conv_f32 full convolution completed.\n\n[Test] tiny_conv_ex_f32 padding=zero, mode=full...\n[PASS] tiny_conv_ex_f32 matches tiny_conv_f32 (zero padding, full mode).\n\n[Test] tiny_conv_ex_f32 padding=ZERO, mode=FULL...\n[PASS] tiny_conv_ex_f32 completed (padding=ZERO, mode=FULL).\nOutput:\n0.20000 0.90000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 8.50000 3.30000 \n\n[Test] tiny_conv_ex_f32 padding=ZERO, mode=HEAD...\n[PASS] tiny_conv_ex_f32 completed (padding=ZERO, mode=HEAD).\nOutput:\n0.20000 0.90000 1.90000 \n\n[Test] tiny_conv_ex_f32 padding=ZERO, mode=CENTER...\n[PASS] tiny_conv_ex_f32 completed (padding=ZERO, mode=CENTER).\nOutput:\n0.90000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 8.50000 \n\n[Test] tiny_conv_ex_f32 padding=ZERO, mode=TAIL...\n[PASS] tiny_conv_ex_f32 completed (padding=ZERO, mode=TAIL).\nOutput:\n9.90000 8.50000 3.30000 \n\n[Test] tiny_conv_ex_f32 padding=SYMMETRIC, mode=FULL...\n[PASS] tiny_conv_ex_f32 completed (padding=SYMMETRIC, mode=FULL).\nOutput:\n1.30000 1.20000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 10.70000 10.80000 \n\n[Test] tiny_conv_ex_f32 padding=SYMMETRIC, mode=HEAD...\n[PASS] tiny_conv_ex_f32 completed (padding=SYMMETRIC, mode=HEAD).\nOutput:\n1.30000 1.20000 1.90000 \n\n[Test] tiny_conv_ex_f32 padding=SYMMETRIC, mode=CENTER...\n[PASS] tiny_conv_ex_f32 completed (padding=SYMMETRIC, mode=CENTER).\nOutput:\n1.20000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 10.70000 \n\n[Test] tiny_conv_ex_f32 padding=SYMMETRIC, mode=TAIL...\n[PASS] tiny_conv_ex_f32 completed (padding=SYMMETRIC, mode=TAIL).\nOutput:\n9.90000 10.70000 10.80000 \n\n[Test] tiny_conv_ex_f32 padding=PERIODIC, mode=FULL...\n[PASS] tiny_conv_ex_f32 completed (padding=PERIODIC, mode=FULL).\nOutput:\n8.50000 3.90000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 8.70000 4.20000 \n\n[Test] tiny_conv_ex_f32 padding=PERIODIC, mode=HEAD...\n[PASS] tiny_conv_ex_f32 completed (padding=PERIODIC, mode=HEAD).\nOutput:\n8.50000 3.90000 1.90000 \n\n[Test] tiny_conv_ex_f32 padding=PERIODIC, mode=CENTER...\n[PASS] tiny_conv_ex_f32 completed (padding=PERIODIC, mode=CENTER).\nOutput:\n3.90000 1.90000 2.90000 3.90000 4.90000 5.90000 6.90000 7.90000 8.90000 9.90000 8.70000 \n\n[Test] tiny_conv_ex_f32 padding=PERIODIC, mode=TAIL...\n[PASS] tiny_conv_ex_f32 completed (padding=PERIODIC, mode=TAIL).\nOutput:\n9.90000 8.70000 4.20000 \n\n===== tiny_conv_f32 and tiny_conv_ex_f32 Test End =====\n</code></pre>"},{"location":"zh/DSP/SIGNAL/CORRELATION/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/","title":"\u8bf4\u660e","text":"<p>\u8bf4\u660e</p> <p>\u76f8\u5173\u6027\u662f\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u6982\u5ff5\uff0c\u901a\u5e38\u7528\u4e8e\u5206\u6790\u4fe1\u53f7\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u6216\u4f9d\u8d56\u6027\u3002\u5b83\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\u90fd\u5f88\u6709\u7528\uff0c\u4f8b\u5982\u6a21\u5f0f\u8bc6\u522b\u3001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u548c\u4fe1\u53f7\u68c0\u6d4b\u3002</p>"},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#_2","title":"\u6ed1\u52a8\u76f8\u5173","text":""},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#_3","title":"\u6570\u5b66\u539f\u7406","text":"<p>\u76f8\u5173\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a</p> \\[ \\text{Correlation}[n] = \\sum_{m=0}^{L_p - 1} S[n + m] \\cdot P[m] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( S \\) \u4e3a\u8f93\u5165\u4fe1\u53f7\uff0c\u957f\u5ea6\u4e3a \\( L_s \\)</p> </li> <li> <p>\\( P \\) \u4e3a\u6a21\u5f0f\u5e8f\u5217\uff08Pattern\uff09\uff0c\u957f\u5ea6\u4e3a \\( L_p \\)</p> </li> <li> <p>\\( n \\in [0, L_s - L_p] \\)</p> </li> </ul> <p>\u8f93\u51fa\u957f\u5ea6\u8ba1\u7b97\uff1a</p> \\[ L_{\\text{out}} = L_s - L_p + 1 \\]"},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#tiny_corr_f32","title":"tiny_corr_f32","text":"<pre><code>/**\n * @name: tiny_corr_f32\n * @brief Correlation function\n *\n * @param Signal: input signal array\n * @param siglen: length of the signal array\n * @param Pattern: input pattern array\n * @param patlen: length of the pattern array\n * @param dest: output array for the correlation result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_corr_f32(const float *Signal, const int siglen, const float *Pattern, const int patlen, float *dest)\n{\n    if (NULL == Signal || NULL == Pattern || NULL == dest)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    if (siglen &lt; patlen) // signal length shoudl be greater than pattern length\n    {\n        return TINY_ERR_DSP_MISMATCH;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_corr_f32(Signal, siglen, Pattern, patlen, dest);\n#else\n\n    for (size_t n = 0; n &lt;= (siglen - patlen); n++)\n    {\n        float k_corr = 0;\n        for (size_t m = 0; m &lt; patlen; m++)\n        {\n            k_corr += Signal[n + m] * Pattern[m];\n        }\n        dest[n] = k_corr;\n    }\n\n#endif\n\n    return TINY_OK;\n}\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u8ba1\u7b97\u4fe1\u53f7\u548c\u6a21\u5f0f\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002</p> <p>\u7279\u70b9</p> <ul> <li>\u652f\u6301\u5e73\u53f0\u52a0\u901f</li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>Signal</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4</p> </li> <li> <p><code>siglen</code>: \u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>Pattern</code>: \u8f93\u5165\u6a21\u5f0f\u6570\u7ec4</p> </li> <li> <p><code>patlen</code>: \u6a21\u5f0f\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>dest</code>: \u8f93\u51fa\u6570\u7ec4\uff0c\u7528\u4e8e\u5b58\u50a8\u76f8\u5173\u6027\u7ed3\u679c</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#_4","title":"\u4ea4\u53c9\u76f8\u5173\u51fd\u6570","text":""},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#_5","title":"\u6570\u5b66\u539f\u7406","text":"<p>\u4e92\u76f8\u5173\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a</p> \\[ R_{xy}[n] = \\sum_{k} x[k] \\cdot y[k + n] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( x \\) \u4e3a\u4fe1\u53f7\u5e8f\u5217\uff0c\u957f\u5ea6\u4e3a \\( L_x \\)</p> </li> <li> <p>\\( y \\) \u4e3a\u5377\u79ef\u6838\uff08Kernel\uff09\uff0c\u957f\u5ea6\u4e3a \\( L_y \\)</p> </li> <li> <p>\\( n \\in [0, L_x + L_y - 2] \\)</p> </li> </ul> <p>\u8f93\u51fa\u957f\u5ea6\u8ba1\u7b97\uff1a</p> \\[ L_{\\text{out}} = L_x + L_y - 1 \\]"},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#tiny_ccorr_f32","title":"tiny_ccorr_f32","text":"<pre><code>/**\n * @name: tiny_ccorr_f32\n * @brief Cross-correlation function\n *\n * @param Signal: input signal array\n * @param siglen: length of the signal array\n * @param Kernel: input kernel array\n * @param kernlen: length of the kernel array\n * @param corrvout: output array for the cross-correlation result\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_ccorr_f32(const float *Signal, const int siglen, const float *Kernel, const int kernlen, float *corrvout)\n{\n    if (NULL == Signal || NULL == Kernel || NULL == corrvout)\n    {\n        return TINY_ERR_DSP_NULL_POINTER;\n    }\n\n    float *sig = (float *)Signal;\n    float *kern = (float *)Kernel;\n    int lsig = siglen;\n    int lkern = kernlen;\n\n    // swap signal and kernel if needed\n    if (siglen &lt; kernlen)\n    {\n        sig = (float *)Kernel;\n        kern = (float *)Signal;\n        lsig = kernlen;\n        lkern = siglen;\n    }\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n    dsps_ccorr_f32(Signal, siglen, Kernel, kernlen, corrvout);\n#else\n    // stage I\n    for (int n = 0; n &lt; lkern; n++)\n    {\n        size_t k;\n        size_t kmin = lkern - 1 - n;\n        corrvout[n] = 0;\n\n        for (k = 0; k &lt;= n; k++)\n        {\n            corrvout[n] += sig[k] * kern[kmin + k];\n        }\n    }\n\n    // stage II\n    for (int n = lkern; n &lt; lsig; n++)\n    {\n        size_t kmin, kmax, k;\n\n        corrvout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = n;\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            corrvout[n] += sig[k] * kern[k - kmin];\n        }\n    }\n\n    // stage III\n    for (int n = lsig; n &lt; lsig + lkern - 1; n++)\n    {\n        size_t kmin, kmax, k;\n\n        corrvout[n] = 0;\n\n        kmin = n - lkern + 1;\n        kmax = lsig - 1;\n\n        for (k = kmin; k &lt;= kmax; k++)\n        {\n            corrvout[n] += sig[k] * kern[k - kmin];\n        }\n    }\n#endif\n    return TINY_OK;\n}\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u8ba1\u7b97\u4fe1\u53f7\u548c\u5377\u79ef\u6838\u4e4b\u95f4\u7684\u4e92\u76f8\u5173\u6027\u3002</p> <p>\u7279\u70b9</p> <ul> <li>\u652f\u6301\u5e73\u53f0\u52a0\u901f</li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>Signal</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4</p> </li> <li> <p><code>siglen</code>: \u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>Kernel</code>: \u8f93\u5165\u5377\u79ef\u6838\u6570\u7ec4</p> </li> <li> <p><code>kernlen</code>: \u5377\u79ef\u6838\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>corrvout</code>: \u8f93\u51fa\u6570\u7ec4\uff0c\u7528\u4e8e\u5b58\u50a8\u4e92\u76f8\u5173\u6027\u7ed3\u679c</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#_6","title":"\u5bf9\u6bd4\u4e0e\u603b\u7ed3","text":""},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#_7","title":"\u4e3b\u8981\u533a\u522b","text":"\u7279\u6027 <code>tiny_corr_f32</code> <code>tiny_ccorr_f32</code> \u8f93\u51fa\u957f\u5ea6 \\( L_{\\text{out}} = L_s - L_p + 1 \\) \\( L_{\\text{out}} = L_x + L_y - 1 \\) \u957f\u5ea6\u8981\u6c42 \u4fe1\u53f7\u957f\u5ea6\u5fc5\u987b \u2265 \u6a21\u5f0f\u957f\u5ea6 \u4efb\u610f\u957f\u5ea6\u5747\u53ef\uff08\u9700\u8981\u65f6\u81ea\u52a8\u4ea4\u6362\uff09 \u8ba1\u7b97\u7c7b\u578b \u6ed1\u52a8\u76f8\u5173\uff08\u4ec5\u6709\u6548\u533a\u57df\uff09 \u5b8c\u5168\u4e92\u76f8\u5173\uff08\u5305\u542b\u90e8\u5206\u91cd\u53e0\uff09 \u5b9e\u73b0\u65b9\u5f0f \u5355\u9636\u6bb5\u5d4c\u5957\u5faa\u73af \u4e09\u9636\u6bb5\u8ba1\u7b97 \u5e94\u7528\u573a\u666f \u6a21\u5f0f\u5339\u914d\u3001\u6a21\u677f\u68c0\u6d4b \u5b8c\u5168\u76f8\u5173\u5206\u6790\u3001\u4fe1\u53f7\u5bf9\u9f50"},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#_8","title":"\u4f55\u65f6\u4f7f\u7528\u54ea\u4e2a\u51fd\u6570","text":"<p>\u4f7f\u7528 <code>tiny_corr_f32</code> \u5f53\uff1a</p> <ul> <li> <p>\u9700\u8981\u5728\u8f83\u957f\u7684\u4fe1\u53f7\u4e2d\u67e5\u627e\u6a21\u5f0f\uff08\u6a21\u5f0f\u5339\u914d\uff09</p> </li> <li> <p>\u53ea\u5173\u5fc3\u6a21\u5f0f\u4e0e\u4fe1\u53f7\u5b8c\u5168\u91cd\u53e0\u7684\u4f4d\u7f6e</p> </li> <li> <p>\u4fe1\u53f7\u957f\u5ea6\u4fdd\u8bc1\u5927\u4e8e\u6a21\u5f0f\u957f\u5ea6</p> </li> <li> <p>\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6a21\u677f\u5339\u914d\u8ba1\u7b97</p> </li> <li> <p>\u9700\u8981\u5728\u4fe1\u53f7\u4e2d\u68c0\u6d4b\u5df2\u77e5\u6a21\u5f0f\u7684\u51fa\u73b0</p> </li> </ul> <p>\u5178\u578b\u5e94\u7528\uff1a</p> <ul> <li> <p>\u56fe\u50cf\u5904\u7406\u4e2d\u7684\u6a21\u677f\u5339\u914d</p> </li> <li> <p>\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6a21\u5f0f\u68c0\u6d4b</p> </li> <li> <p>\u4fe1\u53f7\u68c0\u6d4b\u4e0e\u8bc6\u522b</p> </li> <li> <p>\u7279\u5f81\u5339\u914d</p> </li> </ul> <p>\u4f7f\u7528 <code>tiny_ccorr_f32</code> \u5f53\uff1a</p> <ul> <li> <p>\u9700\u8981\u5305\u542b\u90e8\u5206\u91cd\u53e0\u7684\u5b8c\u5168\u4e92\u76f8\u5173</p> </li> <li> <p>\u4e24\u4e2a\u5e8f\u5217\u7684\u957f\u5ea6\u53ef\u4ee5\u662f\u4efb\u610f\u7684\uff08\u4efb\u4e00\u5e8f\u5217\u90fd\u53ef\u80fd\u66f4\u957f\uff09</p> </li> <li> <p>\u9700\u8981\u5206\u6790\u4e24\u4e2a\u4fe1\u53f7\u4e4b\u95f4\u6240\u6709\u53ef\u80fd\u7684\u5bf9\u9f50\u65b9\u5f0f</p> </li> <li> <p>\u9700\u8981\u627e\u5230\u4e24\u4e2a\u4fe1\u53f7\u4e4b\u95f4\u7684\u6700\u4f73\u5bf9\u9f50\u6216\u65f6\u95f4\u5ef6\u8fdf</p> </li> <li> <p>\u9700\u8981\u5b8c\u6574\u7684\u76f8\u5173\u51fd\u6570\u8fdb\u884c\u8fdb\u4e00\u6b65\u5206\u6790</p> </li> </ul> <p>\u5178\u578b\u5e94\u7528\uff1a</p> <ul> <li> <p>\u4e24\u4e2a\u4fe1\u53f7\u4e4b\u95f4\u7684\u65f6\u95f4\u5ef6\u8fdf\u4f30\u8ba1</p> </li> <li> <p>\u4fe1\u53f7\u5bf9\u9f50\u4e0e\u540c\u6b65</p> </li> <li> <p>\u5b8c\u5168\u76f8\u5173\u5206\u6790</p> </li> <li> <p>\u4fe1\u53f7\u957f\u5ea6\u672a\u77e5\u6216\u53ef\u53d8\u7684\u60c5\u51b5</p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/CORRELATION/notes/#_9","title":"\u603b\u7ed3","text":"<ul> <li> <p><code>tiny_corr_f32</code> \u9488\u5bf9 \u6a21\u5f0f\u5339\u914d \u573a\u666f\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u7528\u4e8e\u5728\u8f83\u957f\u7684\u4fe1\u53f7\u4e2d\u641c\u7d22\u8f83\u77ed\u7684\u6a21\u5f0f\u3002\u5b83\u53ea\u8ba1\u7b97\u6a21\u5f0f\u5b8c\u5168\u91cd\u53e0\u65f6\u7684\u76f8\u5173\u6027\uff0c\u8f93\u51fa\u66f4\u77ed\uff0c\u8ba1\u7b97\u66f4\u5feb\u3002</p> </li> <li> <p><code>tiny_ccorr_f32</code> \u8ba1\u7b97\u4efb\u610f\u957f\u5ea6\u7684\u4e24\u4e2a\u5e8f\u5217\u4e4b\u95f4\u7684 \u5b8c\u5168\u4e92\u76f8\u5173 \uff0c\u5305\u62ec\u6240\u6709\u90e8\u5206\u91cd\u53e0\u3002\u8fd9\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u76f8\u5173\u4fe1\u606f\uff0c\u4f46\u9700\u8981\u66f4\u591a\u8ba1\u7b97\u5e76\u4ea7\u751f\u66f4\u957f\u7684\u8f93\u51fa\u3002</p> </li> </ul> <p>\u9009\u62e9\u5efa\u8bae\uff1a </p> <p>\u9700\u8981\u9ad8\u6548\u7684\u6a21\u5f0f\u5339\u914d\u65f6\u9009\u62e9 <code>tiny_corr_f32</code>\uff0c\u9700\u8981\u5168\u9762\u7684\u76f8\u5173\u5206\u6790\u6216\u4fe1\u53f7\u957f\u5ea6\u53ef\u53d8\u65f6\u9009\u62e9 <code>tiny_ccorr_f32</code>\u3002</p>"},{"location":"zh/DSP/SIGNAL/CORRELATION/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/SIGNAL/CORRELATION/test/#_2","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<pre><code>========== Correlation &amp; Cross-Correlation Test ==========\n\n--- Test 1: tiny_corr_f32 ---\nInput Signal : [1.00, 2.00, 3.00, 4.00, 2.00, 1.00]\nPattern      : [2.00, 1.00, 0.00]\nOutput vs Expected:\n  [0] Output = 4.000 | Expected = 4.000\n  [1] Output = 7.000 | Expected = 7.000\n  [2] Output = 10.000 | Expected = 10.000\n  [3] Output = 10.000 | Expected = 10.000\n[tiny_corr_f32 Test] [PASS]\n\n--- Test 2: tiny_ccorr_f32 ---\nInput Signal X: [1.00, 3.00, 2.00, 0.00, 1.00, 2.00]\nInput Signal Y: [2.00, 1.00, 0.00, -1.00]\nOutput vs Expected:\n  [0] Output = -1.000 | Expected = -1.000\n  [1] Output = -3.000 | Expected = -3.000\n  [2] Output = -1.000 | Expected = -1.000\n  [3] Output = 5.000 | Expected = 5.000\n  [4] Output = 7.000 | Expected = 7.000\n  [5] Output = 2.000 | Expected = 2.000\n  [6] Output = 1.000 | Expected = 1.000\n  [7] Output = 4.000 | Expected = 4.000\n  [8] Output = 4.000 | Expected = 4.000\n[tiny_ccorr_f32 Test] [PASS]\n==========================================================\n</code></pre>"},{"location":"zh/DSP/SIGNAL/RESAMPLE/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/SIGNAL/RESAMPLE/notes/","title":"\u8bf4\u660e","text":"<p>\u8bf4\u660e</p> <p>\u91cd\u91c7\u6837\u662f\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u6b65\u9aa4\uff0c\u901a\u5e38\u7528\u4e8e\u6539\u53d8\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u3002\u5b83\u53ef\u4ee5\u7528\u4e8e\u97f3\u9891\u3001\u89c6\u9891\u548c\u5176\u4ed6\u7c7b\u578b\u7684\u4fe1\u53f7\u5904\u7406\u3002</p>"},{"location":"zh/DSP/SIGNAL/RESAMPLE/notes/#-","title":"\u4fe1\u53f7\u4e0b\u91c7\u6837 - \u8df3\u8dc3","text":"<p>\u4fe1\u53f7\u8df3\u8dc3\u4e0b\u91c7\u6837\u662f\u6307\u5728\u539f\u59cb\u4fe1\u53f7\u4e2d\u4ee5\u4e00\u5b9a\u95f4\u9694\u9009\u62e9\u6837\u672c\u3002\u5b83\u901a\u5e38\u7528\u4e8e\u964d\u4f4e\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u3002\u6ce8\u610f\u533a\u522b\u4e8edecimation\uff0cdecimation\u662f\u5148\u6ee4\u6ce2\u518d\u4e0b\u91c7\u6837\u3002</p> <pre><code>/**\n * @name tiny_downsample_skip_f32\n * @brief Downsample a signal by a given factor using skipping\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param output_len pointer to the length of the output signal array\n * @param keep number of samples to keep\n * @param skip number of samples to skip\n *\n * @return tiny_error_t\n */\ntiny_error_t tiny_downsample_skip_f32(const float *input, int input_len, float *output, int *output_len, int keep, int skip)\n{\n    if (!input || !output || !output_len)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || keep &lt;= 0 || skip &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    int out_len = input_len / skip;\n    *output_len = out_len;\n\n    for (int i = 0; i &lt; out_len; i++)\n    {\n        output[i] = input[i * skip];\n    }\n\n    return TINY_OK;\n}\n</code></pre> <p>\u63cf\u8ff0\uff1a</p> <p>\u4fe1\u53f7\u8df3\u8dc3\u4e0b\u91c7\u6837\u51fd\u6570\uff0c\u901a\u8fc7\u4e24\u4e2a\u6574\u6570\u53c2\u6570<code>keep</code>\u548c<code>skip</code>\u6765\u63a7\u5236\u8df3\u8dc3\u4e0b\u91c7\u6837\u7684\u8fc7\u7a0b\u3002<code>keep</code>\u8868\u793a\u8981\u4fdd\u7559\u7684\u6837\u672c\u6570\uff0c<code>skip</code>\u8868\u793a\u8981\u8df3\u8fc7\u7684\u6837\u672c\u6570\u3002</p> <p>\u7279\u70b9\uff1a</p> <ul> <li> <p>\u6574\u6570\u500d\u4e0b\u91c7\u6837</p> </li> <li> <p>\u8df3\u8dc3\u4e0b\u91c7\u6837</p> </li> </ul> <p>\u53c2\u6570\uff1a</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u7684\u6307\u9488</p> </li> <li> <p><code>input_len</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u4fe1\u53f7\u6570\u7ec4\u7684\u6307\u9488</p> </li> <li> <p><code>output_len</code>: \u8f93\u51fa\u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6\u7684\u6307\u9488</p> </li> <li> <p><code>keep</code>: \u8981\u4fdd\u7559\u7684\u6837\u672c\u6570</p> </li> <li> <p><code>skip</code>: \u8981\u8df3\u8fc7\u7684\u6837\u672c\u6570</p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/RESAMPLE/notes/#-0","title":"\u4fe1\u53f7\u4e0a\u91c7\u6837 - 0\u586b\u5145","text":"<p>\u4fe1\u53f7\u4e0a\u91c7\u6837\u662f\u6307\u5728\u539f\u59cb\u4fe1\u53f7\u4e2d\u63d2\u5165\u96f6\u4ee5\u589e\u52a0\u91c7\u6837\u7387\u3002\u5b83\u901a\u5e38\u7528\u4e8e\u63d0\u9ad8\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u3002\u6ce8\u610f\u533a\u522b\u4e8einterpolation\uff0c\u4e0a\u91c7\u6837\u662f\u5148\u586b\u5145\u518d\u63d2\u503c\u3002</p> <pre><code>/**\n * @name tiny_upsample_zero_f32\n * @brief Upsample a signal using zero-insertion between samples\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param target_len target length for the output signal array\n * @return tiny_error_t\n */\ntiny_error_t tiny_upsample_zero_f32(const float *input, int input_len, float *output, int target_len)\n{\n    if (!input || !output)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || target_len &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    int factor = target_len / input_len;\n    if (factor &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    for (int i = 0; i &lt; target_len; i++)\n    {\n        output[i] = (i % factor == 0) ? input[i / factor] : 0.0f;\n    }\n\n    return TINY_OK;\n}\n</code></pre> <p>\u63cf\u8ff0\uff1a</p> <p>\u4fe1\u53f7\u4e0a\u91c7\u6837\u51fd\u6570\uff0c\u901a\u8fc7\u5728\u539f\u59cb\u4fe1\u53f7\u4e2d\u63d2\u5165\u96f6\u6765\u589e\u52a0\u91c7\u6837\u7387\u3002\u5b83\u901a\u5e38\u7528\u4e8e\u63d0\u9ad8\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u3002</p> <p>\u7279\u70b9\uff1a</p> <ul> <li> <p>\u6574\u6570\u500d\u4e0a\u91c7\u6837</p> </li> <li> <p>0\u586b\u5145</p> </li> </ul> <p>\u53c2\u6570\uff1a</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u7684\u6307\u9488</p> </li> <li> <p><code>input_len</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u4fe1\u53f7\u6570\u7ec4\u7684\u6307\u9488</p> </li> <li> <p><code>target_len</code>: \u76ee\u6807\u957f\u5ea6\uff0c\u7528\u4e8e\u8f93\u51fa\u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/RESAMPLE/notes/#-_1","title":"\u4fe1\u53f7\u91cd\u91c7\u6837 - \u4efb\u610f\u500d\u6570\u4e0a\u4e0b\u91c7\u6837 - \u7ebf\u6027\u63d2\u503c","text":"<p>\u91cd\u91c7\u6837\u662f\u6307\u5c06\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u4ece\u4e00\u4e2a\u503c\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u503c\u3002\u8fd9\u91cc\u6211\u4eec\u91c7\u7528\u6700\u76f4\u63a5\u7684\u7ebf\u6027\u63d2\u503c\u6cd5\u3002\u9996\u5148\u8ba1\u7b97\u65b0\u4fe1\u53f7\u4e2d\u70b9\u5728\u8001\u4fe1\u53f7\u4e2d\u7684\u5927\u6982\u4f4d\u7f6e\uff0c\u7ed3\u5408\u8d77\u4f4d\u7f6e\u5e73\u8861\u5de6\u53f3\u70b9\u6570\u503c\u8fdb\u884c\u751f\u6210\u3002</p> <pre><code>/**\n * @name: tiny_resample_f32\n * @brief Resample a signal to a target length\n *\n * @param input pointer to the input signal array\n * @param input_len length of the input signal array\n * @param output pointer to the output signal array\n * @param target_len target length for the output signal array\n * @return tiny_error_t\n */\ntiny_error_t tiny_resample_f32(const float *input,\n                               int input_len,\n                               float *output,\n                               int target_len)\n{\n    if (!input || !output)\n        return TINY_ERR_DSP_NULL_POINTER;\n\n    if (input_len &lt;= 0 || target_len &lt;= 0)\n        return TINY_ERR_DSP_INVALID_PARAM;\n\n    float ratio = (float)(target_len) / (float)(input_len);\n\n    for (int i = 0; i &lt; target_len; i++)\n    {\n        float pos = i / ratio;\n        int index = (int)floorf(pos);\n        float frac = pos - index;\n\n        if (index &gt;= input_len - 1)\n            output[i] = input[input_len - 1]; // Clamp at end\n        else\n            output[i] = input[index] * (1.0f - frac) + input[index + 1] * frac;\n    }\n\n    return TINY_OK;\n}\n</code></pre> <p>\u63cf\u8ff0\uff1a</p> <p>\u4fe1\u53f7\u91cd\u91c7\u6837\u662f\u6307\u5c06\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u4ece\u4e00\u4e2a\u503c\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u503c\u3002\u5b83\u901a\u5e38\u7528\u4e8e\u97f3\u9891\u548c\u89c6\u9891\u5904\u7406\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u7684\u64ad\u653e\u8bbe\u5907\u6216\u7f51\u7edc\u5e26\u5bbd\u3002</p> <p>\u7279\u70b9\uff1a</p> <ul> <li> <p>\u4efb\u610f\u500d\u6570\u4e0a\u4e0b\u91c7\u6837</p> </li> <li> <p>\u7ebf\u6027\u63d2\u503c</p> </li> </ul> <p>\u53c2\u6570\uff1a</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u7684\u6307\u9488</p> </li> <li> <p><code>input_len</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u4fe1\u53f7\u6570\u7ec4\u7684\u6307\u9488</p> </li> <li> <p><code>target_len</code>: \u76ee\u6807\u957f\u5ea6\uff0c\u7528\u4e8e\u8f93\u51fa\u4fe1\u53f7\u6570\u7ec4\u7684\u957f\u5ea6</p> </li> </ul>"},{"location":"zh/DSP/SIGNAL/RESAMPLE/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/SIGNAL/RESAMPLE/test/#_2","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<pre><code>========== TinyResample Test ==========\n\nOriginal Signal (length=8):\n  Input:  1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00\n\nTest 1: Downsampling (keep=1, skip=2)\n  Description: Keep every 2nd sample, discard others\n  Input:   1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00  (length=8)\n  Output:  1.00 3.00 5.00 7.00  (length=4)\n  Mapping: input[0,2,4,6] -&gt; output[0,1,2,3] = [1.00, 3.00, 5.00, 7.00]\n\nTest 2: Upsampling (Zero-insertion)\n  Description: Insert zeros between samples to increase length\n  Input:   1.00 3.00 5.00 7.00  (length=4)\n  Output:  1.00 0.00 0.00 0.00 3.00 0.00 0.00 0.00 5.00 0.00 0.00 0.00 7.00 0.00 0.00 0.00  (length=16)\n  Mapping: input[0,1,2,3] -&gt; output[0,4,8,12] = [1.00, 3.00, 5.00, 7.00]\n           (zeros inserted at positions 1,2,3,5,6,7,9,10,11,13,14,15)\n\nTest 3: Resampling (Linear Interpolation)\n  Description: Resample from 8 to 12 samples using linear interpolation\n  Input:   1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00  (length=8)\n  Output:  1.00 1.67 2.33 3.00 3.67 4.33 5.00 5.67 6.33 7.00 7.67 8.00  (length=12)\n  Mapping: Linear interpolation between input samples\n           output[0,2,4,6,8,10] = input[0,1,2,3,4,5] = [1.00, 2.00, 3.00, 4.00, 5.00, 6.00]\n           output[1,3,5,7,9,11] = interpolated midpoints\n\nTest 4: Validation - Verify Linear Interpolation Correctness\n  Purpose: Verify that interpolated values are correctly calculated\n           using the formula: output[i] = input[index]*(1-frac) + input[index+1]*frac\n           where pos = i/ratio, index = floor(pos), frac = pos - index\n\n  Sample verification (checking a few key points):\n    output[ 0]: pos=0.000, index=0, frac=0.000 -&gt; 1.00 (expected: 1.00) \u2713\n    output[ 1]: pos=0.667, index=0, frac=0.667 -&gt; 1.67 (expected: 1.67) \u2713\n    output[ 2]: pos=1.333, index=1, frac=0.333 -&gt; 2.33 (expected: 2.33) \u2713\n    output[ 6]: pos=4.000, index=4, frac=0.000 -&gt; 5.00 (expected: 5.00) \u2713\n    output[11]: pos=7.333, index=7, frac=0.333 -&gt; 8.00 (expected: 8.00) \u2713\n  \u2713 All interpolated values are correct!\n\n========================================\n</code></pre>"},{"location":"zh/DSP/SUPPORT/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/SUPPORT/notes/","title":"\u8bf4\u660e","text":"<p>\u8bf4\u660e</p> <p>\u652f\u6301\u6a21\u5757\u4e3a\u4fe1\u53f7\u5904\u7406\u63d0\u4f9b\u53ef\u89c6\u5316\u548c\u5206\u6790\u5de5\u5177\u3002\u8fd9\u4e9b\u51fd\u6570\u5e2e\u52a9\u5f00\u53d1\u8005\u53ef\u89c6\u5316\u4fe1\u53f7\u3001\u5206\u6790\u6570\u636e\u5e76\u8c03\u8bd5 DSP \u7b97\u6cd5\uff0c\u901a\u8fc7\u63d0\u4f9b\u57fa\u4e8e ASCII \u7684\u56fe\u8868\u548c\u683c\u5f0f\u5316\u8f93\u51fa\u3002\u8fd9\u5728\u53ef\u80fd\u6ca1\u6709\u56fe\u5f62\u663e\u793a\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u7279\u522b\u6709\u7528\u3002</p>"},{"location":"zh/DSP/SUPPORT/notes/#_2","title":"\u6982\u8ff0","text":"<p>\u652f\u6301\u6a21\u5757\u5305\u62ec\u56db\u4e2a\u4e3b\u8981\u51fd\u6570\uff1a</p> <ol> <li>\u4fe1\u53f7\u53ef\u89c6\u5316\uff1a\u4ee5 ASCII \u683c\u5f0f\u7ed8\u5236\u4fe1\u53f7\uff08\u7c7b\u4f3c\u793a\u6ce2\u5668\uff09</li> <li>\u9891\u8c31\u53ef\u89c6\u5316\uff1a\u53ef\u89c6\u5316\u529f\u7387\u9891\u8c31\uff0c\u5e26\u9891\u7387\u8f74\u6807\u7b7e</li> <li>\u6570\u7ec4\u6253\u5370\uff1a\u4ee5\u683c\u5f0f\u5316\u8868\u683c\u6253\u5370\u6570\u7ec4</li> <li>\u7edf\u8ba1\u4fe1\u606f\uff1a\u8ba1\u7b97\u5e76\u663e\u793a\u4fe1\u53f7\u7684\u7edf\u8ba1\u4fe1\u606f</li> </ol>"},{"location":"zh/DSP/SUPPORT/notes/#_3","title":"\u4fe1\u53f7\u53ef\u89c6\u5316","text":""},{"location":"zh/DSP/SUPPORT/notes/#tiny_view_signal_f32","title":"tiny_view_signal_f32","text":"<pre><code>/**\n * @name: tiny_view_signal_f32\n * @brief Visualize a signal in ASCII format (like oscilloscope)\n * @param data Input signal array\n * @param len Length of the signal\n * @param width Width of the plot in characters (default: 64)\n * @param height Height of the plot in lines (default: 16)\n * @param min Minimum Y-axis value (auto-detect if min == max)\n * @param max Maximum Y-axis value (auto-detect if min == max)\n * @param title Optional title for the plot (NULL for no title)\n * @return tiny_error_t\n */\ntiny_error_t tiny_view_signal_f32(const float *data, int len, int width, int height, float min, float max, const char *title);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4ee5 ASCII \u683c\u5f0f\u53ef\u89c6\u5316\u4fe1\u53f7\uff0c\u7c7b\u4f3c\u4e8e\u793a\u6ce2\u5668\u663e\u793a\u3002\u8be5\u51fd\u6570\u521b\u5efa\u4e00\u4e2a\u57fa\u4e8e\u5b57\u7b26\u7684\u56fe\u8868\uff0c\u663e\u793a\u4fe1\u53f7\u6ce2\u5f62\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u9ad8\u5206\u8fa8\u7387\u7ed8\u5236\uff0c\u6570\u636e\u70b9\u4e4b\u95f4\u7ebf\u6027\u63d2\u503c</p> </li> <li> <p>\u5f53 min == max \u65f6\u81ea\u52a8\u68c0\u6d4b Y \u8f74\u8303\u56f4</p> </li> <li> <p>\u53ef\u81ea\u5b9a\u4e49\u56fe\u8868\u5c3a\u5bf8\uff08\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff09</p> </li> <li> <p>\u53ef\u9009\u7684\u6807\u9898\u663e\u793a</p> </li> <li> <p>Y \u8f74\u6807\u7b7e\u663e\u793a\u503c\u8303\u56f4</p> </li> <li> <p>X \u8f74\u6807\u7b7e\u663e\u793a\u91c7\u6837\u7d22\u5f15</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>data</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>len</code>: \u4fe1\u53f7\u6570\u7ec4\u957f\u5ea6\u3002</p> </li> <li> <p><code>width</code>: \u56fe\u8868\u5bbd\u5ea6\uff08\u5b57\u7b26\u6570\uff0c\u901a\u5e38\u4e3a 64\uff09\u3002</p> </li> <li> <p><code>height</code>: \u56fe\u8868\u9ad8\u5ea6\uff08\u884c\u6570\uff0c\u901a\u5e38\u4e3a 16\uff09\u3002</p> </li> <li> <p><code>min</code>: Y \u8f74\u6700\u5c0f\u503c\u3002\u5982\u679c <code>min == max</code>\uff0c\u51fd\u6570\u5c06\u81ea\u52a8\u68c0\u6d4b\u8303\u56f4\u3002</p> </li> <li> <p><code>max</code>: Y \u8f74\u6700\u5927\u503c\u3002\u5982\u679c <code>min == max</code>\uff0c\u51fd\u6570\u5c06\u81ea\u52a8\u68c0\u6d4b\u8303\u56f4\u3002</p> </li> <li> <p><code>title</code>: \u56fe\u8868\u7684\u53ef\u9009\u6807\u9898\u5b57\u7b26\u4e32\u3002\u4f20\u9012 <code>NULL</code> \u8868\u793a\u65e0\u6807\u9898\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u8f93\u51fa\u683c\u5f0f:</p> <p>\u51fd\u6570\u6253\u5370\uff1a</p> <ul> <li> <p>\u6807\u9898\uff08\u5982\u679c\u63d0\u4f9b\uff09</p> </li> <li> <p>\u5e26\u503c\u8303\u56f4\u7684 Y \u8f74\u6807\u7b7e</p> </li> <li> <p>\u7528 '*' \u5b57\u7b26\u8868\u793a\u4fe1\u53f7\u7684 ASCII \u56fe\u8868</p> </li> <li> <p>\u5e26\u91c7\u6837\u7d22\u5f15\u6807\u7b7e\u7684 X \u8f74</p> </li> <li> <p>\u5305\u542b\u503c\u8303\u56f4\u548c\u4fe1\u53f7\u957f\u5ea6\u7684\u6458\u8981\u884c</p> </li> </ul> <p>\u793a\u4f8b\u8f93\u51fa:</p> <pre><code>Test Signal: 10 Hz Sine Wave\nValue\n  1.20 |                                        \n  1.00 |                                        \n  0.80 |                                        \n  0.60 |                                        \n  0.40 |                                        \n  0.20 |                                        \n  0.00 |                                        \n -0.20 |                                        \n -0.40 |                                        \n -0.60 |                                        \n -0.80 |                                        \n -1.00 |                                        \n -1.20 |                                        \n       ------------------------------------------------------------------------\n       0        8       16      24      32      40      48      56 (Sample Index)\nRange: [-1.200, 1.200], Length: 64\n</code></pre>"},{"location":"zh/DSP/SUPPORT/notes/#_4","title":"\u9891\u8c31\u53ef\u89c6\u5316","text":""},{"location":"zh/DSP/SUPPORT/notes/#tiny_view_spectrum_f32","title":"tiny_view_spectrum_f32","text":"<pre><code>/**\n * @name: tiny_view_spectrum_f32\n * @brief Visualize power spectrum in ASCII format (optimized for frequency domain)\n * @param power_spectrum Power spectrum array\n * @param len Length of the spectrum\n * @param sample_rate Sampling rate (Hz) for frequency axis labels\n * @param title Optional title for the plot (NULL for no title)\n * @return tiny_error_t\n */\ntiny_error_t tiny_view_spectrum_f32(const float *power_spectrum, int len, float sample_rate, const char *title);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4ee5 ASCII \u683c\u5f0f\u53ef\u89c6\u5316\u529f\u7387\u9891\u8c31\uff0c\u5e26\u9891\u7387\u8f74\u6807\u7b7e\u3002\u8be5\u51fd\u6570\u521b\u5efa\u4e00\u4e2a\u6761\u5f62\u56fe\uff0c\u663e\u793a\u4e0d\u540c\u9891\u7387\u5904\u7684\u529f\u7387\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u6761\u5f62\u56fe\u53ef\u89c6\u5316\uff08\u5782\u76f4\u6761\u5f62\uff09</p> </li> <li> <p>\u57fa\u4e8e\u91c7\u6837\u7387\u81ea\u52a8\u9891\u7387\u8f74\u6807\u7b7e</p> </li> <li> <p>\u9488\u5bf9\u9891\u57df\u6570\u636e\u4f18\u5316\uff08\u4f7f\u7528\u9891\u8c31\u7684\u524d\u534a\u90e8\u5206\uff09</p> </li> <li> <p>\u9891\u7387\u6807\u7b7e\u4ee5 Hz \u4e3a\u5355\u4f4d</p> </li> <li> <p>\u5948\u594e\u65af\u7279\u9891\u7387\u6307\u793a</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>power_spectrum</code>: \u529f\u7387\u9891\u8c31\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>len</code>: \u529f\u7387\u9891\u8c31\u6570\u7ec4\u957f\u5ea6\u3002</p> </li> <li> <p><code>sample_rate</code>: \u539f\u59cb\u4fe1\u53f7\u7684\u91c7\u6837\u7387\uff08Hz\uff09\uff0c\u7528\u4e8e\u9891\u7387\u8f74\u6807\u7b7e\u3002</p> </li> <li> <p><code>title</code>: \u56fe\u8868\u7684\u53ef\u9009\u6807\u9898\u5b57\u7b26\u4e32\u3002\u4f20\u9012 <code>NULL</code> \u8868\u793a\u65e0\u6807\u9898\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u8f93\u51fa\u683c\u5f0f:</p> <p>\u51fd\u6570\u6253\u5370\uff1a</p> <ul> <li> <p>\u6807\u9898\uff08\u5982\u679c\u63d0\u4f9b\uff09</p> </li> <li> <p>\u5e26\u529f\u7387\u503c\u7684 Y \u8f74\u6807\u7b7e</p> </li> <li> <p>\u7528 '|' \u5b57\u7b26\u7684 ASCII \u6761\u5f62\u56fe</p> </li> <li> <p>\u5e26\u9891\u7387\u6807\u7b7e\uff08Hz\uff09\u7684 X \u8f74</p> </li> <li> <p>\u5305\u542b\u503c\u8303\u56f4\u548c\u5948\u594e\u65af\u7279\u9891\u7387\u7684\u6458\u8981\u884c</p> </li> </ul> <p>\u6ce8\u610f: </p> <p>\u51fd\u6570\u5047\u8bbe\u529f\u7387\u9891\u8c31\u957f\u5ea6\u662f FFT \u957f\u5ea6\u7684\u4e00\u534a\uff08\u5b9e\u4fe1\u53f7\u7684\u5178\u578b\u60c5\u51b5\uff09\u3002\u9891\u7387\u6807\u7b7e\u8ba1\u7b97\u4e3a\uff1a<code>freq = index * sample_rate / (2 * len)</code>\u3002</p>"},{"location":"zh/DSP/SUPPORT/notes/#_5","title":"\u6570\u7ec4\u6253\u5370","text":""},{"location":"zh/DSP/SUPPORT/notes/#tiny_view_array_f32","title":"tiny_view_array_f32","text":"<pre><code>/**\n * @name: tiny_view_array_f32\n * @brief Print array values in a formatted table\n * @param data Input array\n * @param len Length of the array\n * @param name Name/label for the array\n * @param precision Number of decimal places (default: 3)\n * @param items_per_line Number of items per line (default: 8)\n * @return tiny_error_t\n */\ntiny_error_t tiny_view_array_f32(const float *data, int len, const char *name, int precision, int items_per_line);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4ee5\u683c\u5f0f\u5316\u8868\u683c\u6253\u5370\u6570\u7ec4\u503c\uff0c\u53ef\u81ea\u5b9a\u4e49\u7cbe\u5ea6\u548c\u6bcf\u884c\u9879\u76ee\u6570\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u5e26\u7d22\u5f15\u6807\u7b7e\u7684\u683c\u5f0f\u5316\u8868\u683c\u8f93\u51fa</p> </li> <li> <p>\u53ef\u81ea\u5b9a\u4e49\u7cbe\u5ea6\uff08\u5c0f\u6570\u4f4d\u6570\uff09</p> </li> <li> <p>\u53ef\u81ea\u5b9a\u4e49\u6bcf\u884c\u9879\u76ee\u6570</p> </li> <li> <p>\u53ef\u9009\u7684\u6570\u7ec4\u540d\u79f0/\u6807\u7b7e</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>data</code>: \u8f93\u5165\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>len</code>: \u6570\u7ec4\u957f\u5ea6\u3002</p> </li> <li> <p><code>name</code>: \u6570\u7ec4\u7684\u53ef\u9009\u540d\u79f0/\u6807\u7b7e\u3002\u4f20\u9012 <code>NULL</code> \u8868\u793a\u9ed8\u8ba4\u6807\u7b7e\u3002</p> </li> <li> <p><code>precision</code>: \u8981\u663e\u793a\u7684\u5c0f\u6570\u4f4d\u6570\u3002\u5982\u679c\u4e3a\u8d1f\u6570\uff0c\u9ed8\u8ba4\u4e3a 3\u3002</p> </li> <li> <p><code>items_per_line</code>: \u6bcf\u884c\u6253\u5370\u7684\u9879\u76ee\u6570\u3002\u5982\u679c \u2264 0\uff0c\u9ed8\u8ba4\u4e3a 8\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u8f93\u51fa\u683c\u5f0f:</p> <p>\u51fd\u6570\u6253\u5370\uff1a</p> <ul> <li> <p>\u6570\u7ec4\u540d\u79f0\u548c\u957f\u5ea6</p> </li> <li> <p>\u5e26\u7d22\u5f15\u6807\u7b7e\u548c\u503c\u7684\u683c\u5f0f\u5316\u8868\u683c</p> </li> </ul> <p>\u793a\u4f8b\u8f93\u51fa:</p> <pre><code>Test Signal [64 elements]:\n  [  0] 0.000  0.063  0.125  0.188  0.250  0.313  0.375  0.438 \n  [  8] 0.500  0.563  0.625  0.688  0.750  0.813  0.875  0.938 \n  ...\n</code></pre>"},{"location":"zh/DSP/SUPPORT/notes/#_6","title":"\u7edf\u8ba1\u4fe1\u606f","text":""},{"location":"zh/DSP/SUPPORT/notes/#tiny_view_statistics_f32","title":"tiny_view_statistics_f32","text":"<pre><code>/**\n * @name: tiny_view_statistics_f32\n * @brief Print statistical information about a signal\n * @param data Input signal array\n * @param len Length of the signal\n * @param name Name/label for the signal\n * @return tiny_error_t\n */\ntiny_error_t tiny_view_statistics_f32(const float *data, int len, const char *name);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u8ba1\u7b97\u5e76\u6253\u5370\u4fe1\u53f7\u7684\u7edf\u8ba1\u4fe1\u606f\uff0c\u5305\u62ec\u6700\u5c0f\u503c\u3001\u6700\u5927\u503c\u3001\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u65b9\u5dee\u548c\u5cf0\u503c\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u5355\u6b21\u904d\u5386\u8ba1\u7b97\uff08\u9ad8\u6548\uff09</p> </li> <li> <p>\u5168\u9762\u7684\u7edf\u8ba1\u4fe1\u606f\uff1a</p> </li> <li>\u5e26\u7d22\u5f15\u7684\u6700\u5c0f\u503c\u548c\u6700\u5927\u503c</li> <li>\u5cf0\u503c\uff08\u7edd\u5bf9\u6700\u5927\u503c\uff09\u53ca\u7d22\u5f15</li> <li>\u5747\u503c\uff08\u5e73\u5747\u503c\uff09</li> <li>\u6807\u51c6\u5dee</li> <li>\u65b9\u5dee</li> <li> <p>\u8303\u56f4\uff08\u6700\u5927\u503c - \u6700\u5c0f\u503c\uff09</p> </li> <li> <p>\u53ef\u9009\u7684\u4fe1\u53f7\u540d\u79f0/\u6807\u7b7e</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>data</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>len</code>: \u4fe1\u53f7\u6570\u7ec4\u957f\u5ea6\u3002</p> </li> <li> <p><code>name</code>: \u4fe1\u53f7\u7684\u53ef\u9009\u540d\u79f0/\u6807\u7b7e\u3002\u4f20\u9012 <code>NULL</code> \u8868\u793a\u9ed8\u8ba4\u6807\u7b7e\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u8f93\u51fa\u683c\u5f0f:</p> <p>\u51fd\u6570\u6253\u5370\uff1a</p> <ul> <li> <p>\u5e26\u4fe1\u53f7\u540d\u79f0\u7684\u7edf\u8ba1\u4fe1\u606f\u6807\u9898</p> </li> <li> <p>\u683c\u5f0f\u5316\u8868\u683c\u4e2d\u7684\u6240\u6709\u8ba1\u7b97\u7edf\u8ba1\u4fe1\u606f</p> </li> </ul> <p>\u793a\u4f8b\u8f93\u51fa:</p> <pre><code>=== Statistics: Test Signal ===\n  Length:     64 samples\n  Min:        -1.200000 (at index 48)\n  Max:         1.200000 (at index 16)\n  Peak:        1.200000 (at index 16)\n  Mean:        0.000000\n  Std Dev:     0.707107\n  Variance:    0.500000\n  Range:       2.400000\n========================\n</code></pre> <p>\u6570\u5b66\u516c\u5f0f:</p> <ul> <li> <p>\u5747\u503c\uff1a\\( \\mu = \\frac{1}{N} \\sum_{i=0}^{N-1} x[i] \\)</p> </li> <li> <p>\u65b9\u5dee\uff1a\\( \\sigma^2 = \\frac{1}{N} \\sum_{i=0}^{N-1} x[i]^2 - \\mu^2 \\)</p> </li> <li> <p>\u6807\u51c6\u5dee\uff1a\\( \\sigma = \\sqrt{\\sigma^2} \\)</p> </li> <li> <p>\u8303\u56f4\uff1a\\( \\text{range} = \\max(x) - \\min(x) \\)</p> </li> </ul>"},{"location":"zh/DSP/SUPPORT/notes/#_7","title":"\u4f7f\u7528\u6d41\u7a0b","text":""},{"location":"zh/DSP/SUPPORT/notes/#_8","title":"\u5178\u578b\u7684\u53ef\u89c6\u5316\u6d41\u7a0b","text":"<ol> <li> <p>\u53ef\u89c6\u5316\u4fe1\u53f7:    <pre><code>float signal[64];\n// ... \u586b\u5145\u4fe1\u53f7\u6570\u636e ...\ntiny_view_signal_f32(signal, 64, 64, 16, 0, 0, \"\u6211\u7684\u4fe1\u53f7\");\n</code></pre></p> </li> <li> <p>\u6253\u5370\u6570\u7ec4:    <pre><code>tiny_view_array_f32(signal, 64, \"\u4fe1\u53f7\u6570\u636e\", 3, 8);\n</code></pre></p> </li> <li> <p>\u663e\u793a\u7edf\u8ba1\u4fe1\u606f:    <pre><code>tiny_view_statistics_f32(signal, 64, \"\u4fe1\u53f7\");\n</code></pre></p> </li> <li> <p>\u53ef\u89c6\u5316\u9891\u8c31:    <pre><code>float power[128];\n// ... \u8ba1\u7b97\u529f\u7387\u9891\u8c31 ...\ntiny_view_spectrum_f32(power, 128, 1000.0f, \"\u529f\u7387\u9891\u8c31\");\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/SUPPORT/notes/#_9","title":"\u5e94\u7528\u573a\u666f","text":"<p>\u652f\u6301\u6a21\u5757\u9002\u7528\u4e8e\uff1a</p> <ul> <li> <p>\u8c03\u8bd5\uff1a\u5728\u7b97\u6cd5\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u53ef\u89c6\u5316\u4fe1\u53f7</p> </li> <li> <p>\u5206\u6790\uff1a\u5feb\u901f\u7edf\u8ba1\u4fe1\u53f7\u5206\u6790</p> </li> <li> <p>\u6559\u80b2\uff1a\u6f14\u793a\u4fe1\u53f7\u5904\u7406\u6982\u5ff5</p> </li> <li> <p>\u5d4c\u5165\u5f0f\u7cfb\u7edf\uff1a\u5728\u6ca1\u6709\u56fe\u5f62\u663e\u793a\u7684\u60c5\u51b5\u4e0b\u8c03\u8bd5 DSP \u7b97\u6cd5</p> </li> <li> <p>\u6d4b\u8bd5\uff1a\u9a8c\u8bc1\u4fe1\u53f7\u5904\u7406\u7ed3\u679c</p> </li> <li> <p>\u6587\u6863\uff1a\u4e3a\u6587\u6863\u751f\u6210 ASCII \u56fe\u8868</p> </li> </ul>"},{"location":"zh/DSP/SUPPORT/notes/#_10","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li> <p>\u6240\u6709\u53ef\u89c6\u5316\u51fd\u6570\u4f7f\u7528 <code>printf</code> \u8f93\u51fa\u5230 <code>stdout</code></p> </li> <li> <p>ASCII \u56fe\u8868\u8bbe\u8ba1\u7528\u4e8e\u7b49\u5bbd\u5b57\u4f53</p> </li> <li> <p>\u4e3a\u83b7\u5f97\u6700\u4f73\u6548\u679c\uff0c\u4f7f\u7528\u81f3\u5c11 80 \u5b57\u7b26\u5bbd\u5ea6\u7684\u7ec8\u7aef</p> </li> <li> <p>\u4fe1\u53f7\u53ef\u89c6\u5316\u4f7f\u7528\u7ebf\u6027\u63d2\u503c\u4ee5\u83b7\u5f97\u5e73\u6ed1\u56fe\u8868</p> </li> <li> <p>\u9891\u8c31\u53ef\u89c6\u5316\u4f7f\u7528\u9488\u5bf9\u9891\u57df\u6570\u636e\u4f18\u5316\u7684\u6761\u5f62\u56fe</p> </li> </ul>"},{"location":"zh/DSP/SUPPORT/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/SUPPORT/test/#_2","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<pre><code>========== TinyView Test ==========\n\nTest 1: Signal Visualization\n  Input: Sine wave signal (length=64)\n\nTest Signal: 10 Hz Sine Wave\nValue\n  1.07 |                                                                \n  0.93 |                 *****************                              \n  0.80 |            *****                 *****                         \n  0.66 |         ***                           ***                      \n  0.53 |       **                                 **                    \n  0.39 |     **                                     **                  \n  0.26 |   **                                         **                \n  0.12 | **                                             **              \n -0.01 |*                                                 **            \n -0.15 |                                                    *           \n -0.28 |                                                     **         \n -0.42 |                                                       **       \n -0.56 |                                                         **     \n -0.69 |                                                           ***  \n -0.83 |                                                              **\n -0.96 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-0.962, 1.069], Length: 64\n\nTest 2: Array Printing\n  Input: Signal array (length=64)\n\nTest Signal [64 elements]:\n  [  0]   0.000   0.082   0.162   0.241   0.317   0.390   0.459   0.523 \n  [  8]   0.582   0.635   0.683   0.725   0.762   0.793   0.819   0.840 \n  [ 16]   0.857   0.870   0.880   0.887   0.892   0.896   0.898   0.899 \n  [ 24]   0.900   0.900   0.900   0.899   0.898   0.896   0.892   0.887 \n  [ 32]   0.880   0.870   0.857   0.840   0.819   0.793   0.762   0.725 \n  [ 40]   0.683   0.635   0.582   0.523   0.459   0.390   0.317   0.241 \n  [ 48]   0.162   0.082  -0.000  -0.082  -0.162  -0.241  -0.317  -0.390 \n  [ 56]  -0.459  -0.523  -0.582  -0.635  -0.683  -0.725  -0.762  -0.793 \n\nTest 3: Signal Statistics\n  Input: Signal array (length=64)\n\n=== Statistics: Test Signal ===\n  Length:     64 samples\n  Min:        -0.792711 (at index 63)\n  Max:        0.900000 (at index 25)\n  Peak:       0.900000 (at index 25)\n  Mean:       0.414478\n  Std Dev:    0.530688\n  Variance:   0.281630\n  Range:      1.692711\n========================\n\nTest 4: Power Spectrum Visualization\n  Input: Simulated power spectrum (length=128)\n\nPower Spectrum: Peaks at 10 Hz and 30 Hz\nPower\n 82.81 |   |                                                            \n 77.36 |   |                                                            \n 71.90 |   |                                                            \n 66.45 |   |                                                            \n 61.00 |   |                                                            \n 55.54 |   |                                                            \n 50.09 |   |                                                            \n 44.63 |   |    |                                                       \n 39.18 |   |    |                                                       \n 33.72 |   |    |                                                       \n 28.27 |   |    |                                                       \n 22.82 |   |    |                                                       \n 17.36 |   |    |                                                       \n 11.91 |   |    |                                                       \n  6.45 |   ||   ||   ||   ||   ||   ||   ||   ||   ||   ||   ||   ||   |\n  1.00 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n       ----------------------------------------------------------------\n       0.0    31      62      94      125     156     188     219                          (Hz)\nRange: [1.000, 82.812], Nyquist: 500.0 Hz\n\n========================================\n</code></pre> <p>Warning</p> <p>\u6ce8\u610f\uff1a\u53ef\u4ee5\u770b\u5230\u4e32\u53e3\u8f93\u51fa\u7684\u56fe\u7247\u6bd4\u8f83\u7c97\u7cd9\uff0c\u800c\u4e14\u4e5f\u4e0d\u662f\u5341\u5206\u51c6\u786e\uff0c\u4ec5\u53ef\u4ee5\u7528\u4e8e\u5feb\u901f\u67e5\u770b\u6570\u636e\u7684\u6574\u4f53\u8d8b\u52bf\u3002\u5982\u679c\u9700\u8981\u66f4\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf\uff0c\u5efa\u8bae\u4f7f\u7528\u4e13\u4e1a\u7684\u7ed8\u56fe\u5de5\u5177\u3002</p>"},{"location":"zh/DSP/TRANSFORM/DWT/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/TRANSFORM/DWT/notes/","title":"\u8bf4\u660e","text":"<p>\u8bf4\u660e</p> <p>\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\uff08DWT\uff09\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u4fe1\u53f7\u5904\u7406\u6280\u672f\uff0c\u53ef\u5728\u591a\u4e2a\u5206\u8fa8\u7387\u7ea7\u522b\u5c06\u4fe1\u53f7\u5206\u89e3\u4e3a\u4e0d\u540c\u7684\u9891\u7387\u5206\u91cf\u3002\u4e0e\u63d0\u4f9b\u5168\u5c40\u9891\u7387\u4fe1\u606f\u7684 FFT \u4e0d\u540c\uff0cDWT \u63d0\u4f9b\u65f6\u95f4\u548c\u9891\u7387\u7684\u5c40\u90e8\u5316\uff0c\u4f7f\u5176\u975e\u5e38\u9002\u5408\u5206\u6790\u975e\u5e73\u7a33\u4fe1\u53f7\u3001\u53bb\u566a\u3001\u538b\u7f29\u548c\u7279\u5f81\u63d0\u53d6\u3002</p>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#dwt","title":"DWT \u6982\u8ff0","text":""},{"location":"zh/DSP/TRANSFORM/DWT/notes/#_2","title":"\u6570\u5b66\u539f\u7406","text":"<p>\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u4f7f\u7528\u4e00\u5bf9\u6ee4\u6ce2\u5668\u5c06\u4fe1\u53f7\u5206\u89e3\u4e3a\u8fd1\u4f3c\uff08\u4f4e\u9891\uff09\u548c\u7ec6\u8282\uff08\u9ad8\u9891\uff09\u7cfb\u6570\uff1a\u4f4e\u901a\u6ee4\u6ce2\u5668\uff08\u5c3a\u5ea6\u51fd\u6570\uff09\u548c\u9ad8\u901a\u6ee4\u6ce2\u5668\uff08\u5c0f\u6ce2\u51fd\u6570\uff09\u3002</p> <p>\u5355\u7ea7\u5206\u89e3\uff1a</p> \\[ cA[n] = \\sum_{k} x[k] \\cdot h_0[2n - k] \\] \\[ cD[n] = \\sum_{k} x[k] \\cdot h_1[2n - k] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( x[k] \\) \u662f\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\\( h_0 \\) \u662f\u4f4e\u901a\u5206\u89e3\u6ee4\u6ce2\u5668</p> </li> <li> <p>\\( h_1 \\) \u662f\u9ad8\u901a\u5206\u89e3\u6ee4\u6ce2\u5668</p> </li> <li> <p>\\( cA[n] \\) \u662f\u8fd1\u4f3c\u7cfb\u6570\uff08\u4f4e\u9891\uff09</p> </li> <li> <p>\\( cD[n] \\) \u662f\u7ec6\u8282\u7cfb\u6570\uff08\u9ad8\u9891\uff09</p> </li> </ul> <p>\u8f93\u51fa\u957f\u5ea6\uff1a</p> \\[ L_{cA} = L_{cD} = \\left\\lceil \\frac{L_{input}}{2} \\right\\rceil \\] <p>\u91cd\u6784\uff1a</p> \\[ x[n] = \\sum_{k} (cA[k] \\cdot g_0[n - 2k] + cD[k] \\cdot g_1[n - 2k]) \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( g_0 \\) \u662f\u4f4e\u901a\u91cd\u6784\u6ee4\u6ce2\u5668</p> </li> <li> <p>\\( g_1 \\) \u662f\u9ad8\u901a\u91cd\u6784\u6ee4\u6ce2\u5668</p> </li> </ul>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#_3","title":"\u5c0f\u6ce2\u7c7b\u578b","text":"<p>\u5e93\u652f\u6301 Daubechies \u5c0f\u6ce2\uff08DB1 \u5230 DB10\uff09\uff1a</p> <ul> <li>DB1 (Haar)\uff1a\u6700\u7b80\u5355\u7684\u5c0f\u6ce2\uff0c2 \u62bd\u5934\u6ee4\u6ce2\u5668\uff0c\u9002\u5408\u8fb9\u7f18\u68c0\u6d4b</li> <li>DB2\uff1a4 \u62bd\u5934\u6ee4\u6ce2\u5668\uff0c\u9891\u7387\u5206\u8fa8\u7387\u4f18\u4e8e DB1</li> <li>DB3\uff1a6 \u62bd\u5934\u6ee4\u6ce2\u5668\uff0c\u6bd4 DB2 \u66f4\u5e73\u6ed1</li> <li>DB4\uff1a8 \u62bd\u5934\u6ee4\u6ce2\u5668\uff0c\u5e38\u7528\uff0c\u5e73\u8861\u6027\u597d</li> <li>DB5-DB10\uff1a\u66f4\u9ad8\u9636\u5c0f\u6ce2\uff0c\u9891\u7387\u5206\u8fa8\u7387\u66f4\u597d\u4f46\u6ee4\u6ce2\u5668\u66f4\u957f</li> </ul> <p>\u6ee4\u6ce2\u5668\u957f\u5ea6\uff1a</p> \\[ L_{filter} = 2 \\times N \\] <p>\u5176\u4e2d \\( N \\) \u662f\u5c0f\u6ce2\u9636\u6570\uff08DB1: N=1, DB2: N=2, ..., DB10: N=10\uff09\u3002</p>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#dwt_1","title":"\u5355\u7ea7 DWT","text":""},{"location":"zh/DSP/TRANSFORM/DWT/notes/#tiny_dwt_decompose_f32","title":"tiny_dwt_decompose_f32","text":"<pre><code>/**\n * @name tiny_dwt_decompose_f32\n * @brief Perform single-level discrete wavelet decomposition\n * @param input Input signal array\n * @param input_len Length of the input signal\n * @param wavelet Wavelet type (DB1-DB10)\n * @param cA Output array for approximation coefficients\n * @param cD Output array for detail coefficients\n * @param cA_len Output length of approximation coefficients\n * @param cD_len Output length of detail coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_dwt_decompose_f32(const float *input, int input_len,\n                                    tiny_wavelet_type_t wavelet,\n                                    float *cA, float *cD,\n                                    int *cA_len, int *cD_len);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6267\u884c\u5355\u7ea7\u79bb\u6563\u5c0f\u6ce2\u5206\u89e3\uff0c\u5c06\u8f93\u5165\u4fe1\u53f7\u5206\u89e3\u4e3a\u8fd1\u4f3c\uff08\u4f4e\u9891\uff09\u548c\u7ec6\u8282\uff08\u9ad8\u9891\uff09\u7cfb\u6570\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u4f7f\u7528\u5bf9\u79f0\u586b\u5145\u5904\u7406\u8fb9\u754c</p> </li> <li> <p>\u6267\u884c\u4f4e\u901a\u548c\u9ad8\u901a\u6ee4\u6ce2\u5668\u5377\u79ef</p> </li> <li> <p>\u4ee5 2 \u4e3a\u56e0\u5b50\u4e0b\u91c7\u6837\u4ee5\u4fdd\u6301\u4e34\u754c\u91c7\u6837</p> </li> <li> <p>\u652f\u6301\u6240\u6709 Daubechies \u5c0f\u6ce2\uff08DB1-DB10\uff09</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>input_len</code>: \u8f93\u5165\u4fe1\u53f7\u957f\u5ea6\u3002</p> </li> <li> <p><code>wavelet</code>: \u6765\u81ea <code>tiny_wavelet_type_t</code> \u679a\u4e3e\u7684\u5c0f\u6ce2\u7c7b\u578b\uff1a</p> </li> <li> <p><code>TINY_WAVELET_DB1</code> \u5230 <code>TINY_WAVELET_DB10</code></p> </li> <li> <p><code>cA</code>: \u8fd1\u4f3c\u7cfb\u6570\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5e94\u81f3\u5c11\u4e3a <code>(input_len + 1) / 2</code>\u3002</p> </li> <li> <p><code>cD</code>: \u7ec6\u8282\u7cfb\u6570\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5e94\u81f3\u5c11\u4e3a <code>(input_len + 1) / 2</code>\u3002</p> </li> <li> <p><code>cA_len</code>: \u8fd1\u4f3c\u7cfb\u6570\u957f\u5ea6\u7684\u8f93\u51fa\u53d8\u91cf\u6307\u9488\u3002</p> </li> <li> <p><code>cD_len</code>: \u7ec6\u8282\u7cfb\u6570\u957f\u5ea6\u7684\u8f93\u51fa\u53d8\u91cf\u6307\u9488\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u8f93\u51fa\u7cfb\u6570\u6570\u7ec4\u7684\u957f\u5ea6\u7ea6\u4e3a\u8f93\u5165\u4fe1\u53f7\u957f\u5ea6\u7684\u4e00\u534a\u3002\u7531\u4e8e\u5377\u79ef\u64cd\u4f5c\uff0c\u4fe1\u53f7\u8fb9\u7f18\u9644\u8fd1\u53ef\u80fd\u51fa\u73b0\u8fb9\u754c\u6548\u5e94\u3002</p>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#tiny_dwt_reconstruct_f32","title":"tiny_dwt_reconstruct_f32","text":"<pre><code>/**\n * @name tiny_dwt_reconstruct_f32\n * @brief Perform single-level discrete wavelet reconstruction\n * @param cA Approximation coefficients array\n * @param cD Detail coefficients array\n * @param coeff_len Length of coefficient arrays (cA and cD must have same length)\n * @param wavelet Wavelet type (DB1-DB10)\n * @param output Output array for reconstructed signal\n * @param output_len Output length of reconstructed signal\n * @return tiny_error_t\n */\ntiny_error_t tiny_dwt_reconstruct_f32(const float *cA, const float *cD, int coeff_len,\n                                      tiny_wavelet_type_t wavelet,\n                                      float *output, int *output_len);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6267\u884c\u5355\u7ea7\u79bb\u6563\u5c0f\u6ce2\u91cd\u6784\uff0c\u5c06\u8fd1\u4f3c\u548c\u7ec6\u8282\u7cfb\u6570\u7ec4\u5408\u4ee5\u91cd\u5efa\u539f\u59cb\u4fe1\u53f7\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u4ee5 2 \u4e3a\u56e0\u5b50\u4e0a\u91c7\u6837\u7cfb\u6570</p> </li> <li> <p>\u4f7f\u7528\u91cd\u6784\u6ee4\u6ce2\u5668\u6267\u884c\u5377\u79ef</p> </li> <li> <p>\u7ec4\u5408\u4f4e\u901a\u548c\u9ad8\u901a\u91cd\u6784\u7ed3\u679c</p> </li> <li> <p>\u4e2d\u5fc3\u533a\u57df\u5b8c\u7f8e\u91cd\u6784\uff08\u5728\u6570\u503c\u7cbe\u5ea6\u8303\u56f4\u5185\uff09</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>cA</code>: \u8fd1\u4f3c\u7cfb\u6570\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>cD</code>: \u7ec6\u8282\u7cfb\u6570\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>coeff_len</code>: \u4e24\u4e2a\u7cfb\u6570\u6570\u7ec4\u7684\u957f\u5ea6\uff08\u5fc5\u987b\u76f8\u7b49\uff09\u3002</p> </li> <li> <p><code>wavelet</code>: \u7528\u4e8e\u5206\u89e3\u7684\u5c0f\u6ce2\u7c7b\u578b\u3002</p> </li> <li> <p><code>output</code>: \u91cd\u6784\u4fe1\u53f7\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5e94\u81f3\u5c11\u4e3a <code>coeff_len * 2</code>\u3002</p> </li> <li> <p><code>output_len</code>: \u91cd\u6784\u4fe1\u53f7\u957f\u5ea6\u7684\u8f93\u51fa\u53d8\u91cf\u6307\u9488\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u91cd\u6784\u4fe1\u53f7\u957f\u5ea6\u4e3a <code>coeff_len * 2</code>\u3002\u53ef\u80fd\u51fa\u73b0\u8fb9\u754c\u6548\u5e94\uff0c\u5c24\u5176\u662f\u5728\u4fe1\u53f7\u8fb9\u7f18\u9644\u8fd1\u3002\u4e2d\u5fc3\u533a\u57df\u901a\u5e38\u5177\u6709\u975e\u5e38\u9ad8\u7684\u91cd\u6784\u7cbe\u5ea6\u3002</p>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#dwt_2","title":"\u591a\u7ea7 DWT","text":""},{"location":"zh/DSP/TRANSFORM/DWT/notes/#tiny_dwt_multilevel_decompose_f32","title":"tiny_dwt_multilevel_decompose_f32","text":"<pre><code>/**\n * @name tiny_dwt_multilevel_decompose_f32\n * @brief Perform multi-level DWT decomposition\n * @param input Input signal array\n * @param input_len Length of the input signal\n * @param wavelet Wavelet type (DB1-DB10)\n * @param levels Number of decomposition levels\n * @param cA_out Output pointer for final approximation coefficients\n * @param cD_out Output pointer for all detail coefficients (concatenated)\n * @param len_out Output length of final approximation coefficients\n * @return tiny_error_t\n */\ntiny_error_t tiny_dwt_multilevel_decompose_f32(const float *input, int input_len,\n                                               tiny_wavelet_type_t wavelet, int levels,\n                                               float **cA_out, float **cD_out, int *len_out);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6267\u884c\u591a\u7ea7\u79bb\u6563\u5c0f\u6ce2\u5206\u89e3\uff0c\u9012\u5f52\u5206\u89e3\u8fd1\u4f3c\u7cfb\u6570\u4ee5\u521b\u5efa\u4fe1\u53f7\u7684\u5206\u5c42\u8868\u793a\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u9012\u5f52\u5206\u89e3\u8fd1\u4f3c\u7cfb\u6570</p> </li> <li> <p>\u5b58\u50a8\u6240\u6709\u7ea7\u522b\u7684\u6240\u6709\u7ec6\u8282\u7cfb\u6570</p> </li> <li> <p>\u8fd4\u56de\u6700\u7ec8\u8fd1\u4f3c\u548c\u8fde\u63a5\u7684\u7ec6\u8282\u7cfb\u6570</p> </li> <li> <p>\u5185\u5b58\u5728\u5185\u90e8\u5206\u914d\uff0c\u5fc5\u987b\u7531\u8c03\u7528\u8005\u91ca\u653e</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>input_len</code>: \u8f93\u5165\u4fe1\u53f7\u957f\u5ea6\u3002</p> </li> <li> <p><code>wavelet</code>: \u6765\u81ea <code>tiny_wavelet_type_t</code> \u679a\u4e3e\u7684\u5c0f\u6ce2\u7c7b\u578b\u3002</p> </li> <li> <p><code>levels</code>: \u5206\u89e3\u7ea7\u522b\u6570\u3002\u5fc5\u987b\u4e3a\u6b63\u6570\u3002</p> </li> <li> <p><code>cA_out</code>: \u6700\u7ec8\u8fd1\u4f3c\u7cfb\u6570\u7684\u8f93\u51fa\u6307\u9488\u6307\u9488\u3002\u5185\u5b58\u5728\u5185\u90e8\u5206\u914d\u3002</p> </li> <li> <p><code>cD_out</code>: \u6240\u6709\u7ec6\u8282\u7cfb\u6570\u7684\u8f93\u51fa\u6307\u9488\u6307\u9488\uff08\u4ece\u6240\u6709\u7ea7\u522b\u8fde\u63a5\uff09\u3002\u5185\u5b58\u5728\u5185\u90e8\u5206\u914d\u3002</p> </li> <li> <p><code>len_out</code>: \u6700\u7ec8\u8fd1\u4f3c\u7cfb\u6570\u957f\u5ea6\u7684\u8f93\u51fa\u53d8\u91cf\u6307\u9488\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u5185\u5b58\u7ba1\u7406: </p> <p>\u51fd\u6570\u4e3a <code>cA_out</code> \u548c <code>cD_out</code> \u5206\u914d\u5185\u5b58\u3002\u8c03\u7528\u8005\u8d1f\u8d23\u4f7f\u7528 <code>free()</code> \u91ca\u653e\u6b64\u5185\u5b58\u3002</p> <p>\u7cfb\u6570\u7ed3\u6784:</p> <p>\u5bf9\u4e8e N \u7ea7\u5206\u89e3\uff1a - \u7ea7\u522b 1\uff1acA1\uff08\u957f\u5ea6 \u2248 input_len/2\uff09\uff0ccD1\uff08\u957f\u5ea6 \u2248 input_len/2\uff09</p> <ul> <li> <p>\u7ea7\u522b 2\uff1acA2\uff08\u957f\u5ea6 \u2248 input_len/4\uff09\uff0ccD2\uff08\u957f\u5ea6 \u2248 input_len/4\uff09</p> </li> <li> <p>...</p> </li> <li> <p>\u7ea7\u522b N\uff1acAN\uff08\u957f\u5ea6 \u2248 input_len/2^N\uff09\uff0ccDN\uff08\u957f\u5ea6 \u2248 input_len/2^N\uff09</p> </li> </ul> <p><code>cD_out</code> \u6570\u7ec4\u5305\u542b\uff1a\u8fde\u63a5\u7684 [cD1, cD2, ..., cDN]\u3002</p>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#tiny_dwt_multilevel_reconstruct_f32","title":"tiny_dwt_multilevel_reconstruct_f32","text":"<pre><code>/**\n * @name tiny_dwt_multilevel_reconstruct_f32\n * @brief Perform multi-level DWT reconstruction\n * @param cA_init Final approximation coefficients from multi-level decomposition\n * @param cD_all All detail coefficients (concatenated from all levels)\n * @param final_len Length of final approximation coefficients\n * @param wavelet Wavelet type (DB1-DB10)\n * @param levels Number of decomposition levels\n * @param output Output array for reconstructed signal\n * @return tiny_error_t\n */\ntiny_error_t tiny_dwt_multilevel_reconstruct_f32(const float *cA_init, const float *cD_all,\n                                                 int final_len, tiny_wavelet_type_t wavelet, int levels,\n                                                 float *output);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6267\u884c\u591a\u7ea7\u79bb\u6563\u5c0f\u6ce2\u91cd\u6784\uff0c\u4ece\u6700\u7ec8\u8fd1\u4f3c\u548c\u6240\u6709\u7ec6\u8282\u7cfb\u6570\u9012\u5f52\u91cd\u6784\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u4ece\u6700\u7ec8\u8fd1\u4f3c\u5f00\u59cb\u9012\u5f52\u91cd\u6784</p> </li> <li> <p>\u4f7f\u7528\u76f8\u5e94\u7684\u7ec6\u8282\u7cfb\u6570\u91cd\u6784\u6bcf\u4e2a\u7ea7\u522b</p> </li> <li> <p>\u8f93\u51fa\u957f\u5ea6\u5339\u914d\u539f\u59cb\u8f93\u5165\u957f\u5ea6</p> </li> <li> <p>\u8fb9\u754c\u6548\u5e94\u968f\u5206\u89e3\u7ea7\u522b\u7d2f\u79ef</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>cA_init</code>: \u6765\u81ea\u591a\u7ea7\u5206\u89e3\u7684\u6700\u7ec8\u8fd1\u4f3c\u7cfb\u6570\u6307\u9488\u3002</p> </li> <li> <p><code>cD_all</code>: \u4ece\u6240\u6709\u7ea7\u522b\u8fde\u63a5\u7684\u6240\u6709\u7ec6\u8282\u7cfb\u6570\u6307\u9488\u3002</p> </li> <li> <p><code>final_len</code>: \u6700\u7ec8\u8fd1\u4f3c\u7cfb\u6570\u957f\u5ea6\u3002</p> </li> <li> <p><code>wavelet</code>: \u7528\u4e8e\u5206\u89e3\u7684\u5c0f\u6ce2\u7c7b\u578b\u3002</p> </li> <li> <p><code>levels</code>: \u5206\u89e3\u7ea7\u522b\u6570\u3002</p> </li> <li> <p><code>output</code>: \u91cd\u6784\u4fe1\u53f7\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5e94\u81f3\u5c11\u4e3a\u539f\u59cb\u8f93\u5165\u957f\u5ea6\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p><code>cD_all</code> \u6570\u7ec4\u5e94\u6309\u987a\u5e8f\u5305\u542b\u7ec6\u8282\u7cfb\u6570\uff1a[cD_level1, cD_level2, ..., cD_levelN]\u3002\u8fb9\u754c\u6548\u5e94\u968f\u7740\u5206\u89e3\u7ea7\u522b\u7684\u589e\u52a0\u800c\u53d8\u5f97\u66f4\u52a0\u660e\u663e\u3002</p>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#_4","title":"\u7cfb\u6570\u5904\u7406","text":""},{"location":"zh/DSP/TRANSFORM/DWT/notes/#tiny_dwt_coeffs_process","title":"tiny_dwt_coeffs_process","text":"<pre><code>/**\n * @name tiny_dwt_coeffs_process\n * @brief Placeholder for user-defined coefficient processing\n * @param cA Approximation coefficients\n * @param cD Detail coefficients\n * @param cA_len Length of approximation coefficients\n * @param cD_len Length of detail coefficients\n * @param levels Number of decomposition levels\n */\nvoid tiny_dwt_coeffs_process(float *cA, float *cD, int cA_len, int cD_len, int levels);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u7528\u4e8e\u7528\u6237\u5b9a\u4e49\u7cfb\u6570\u5904\u7406\u7684\u5360\u4f4d\u7b26\u51fd\u6570\u3002\u7528\u6237\u53ef\u4ee5\u6269\u5c55\u6b64\u51fd\u6570\u4ee5\u5b9e\u73b0\u53bb\u566a\u3001\u9608\u503c\u5904\u7406\u6216\u5176\u4ed6\u7cfb\u6570\u64cd\u4f5c\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>cA</code>: \u8fd1\u4f3c\u7cfb\u6570\u6307\u9488\uff08\u53ef\u4fee\u6539\uff09\u3002</p> </li> <li> <p><code>cD</code>: \u7ec6\u8282\u7cfb\u6570\u6307\u9488\uff08\u53ef\u4fee\u6539\uff09\u3002</p> </li> <li> <p><code>cA_len</code>: \u8fd1\u4f3c\u7cfb\u6570\u957f\u5ea6\u3002</p> </li> <li> <p><code>cD_len</code>: \u7ec6\u8282\u7cfb\u6570\u957f\u5ea6\u3002</p> </li> <li> <p><code>levels</code>: \u5206\u89e3\u7ea7\u522b\u6570\u3002</p> </li> </ul> <p>\u6ce8\u610f: </p> <p>\u76ee\u524d\u6b64\u51fd\u6570\u4e0d\u6267\u884c\u4efb\u4f55\u64cd\u4f5c\u3002\u7528\u6237\u53ef\u4ee5\u4fee\u6539\u5b83\u4ee5\u5b9e\u73b0\u81ea\u5b9a\u4e49\u5904\u7406\uff0c\u4f8b\u5982\uff1a</p> <ul> <li> <p>\u786c/\u8f6f\u9608\u503c\u5904\u7406\u7528\u4e8e\u53bb\u566a</p> </li> <li> <p>\u7cfb\u6570\u9009\u62e9\u7528\u4e8e\u538b\u7f29</p> </li> <li> <p>\u7279\u5f81\u63d0\u53d6</p> </li> <li> <p>\u5f02\u5e38\u68c0\u6d4b</p> </li> </ul>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#_5","title":"\u4f7f\u7528\u6d41\u7a0b","text":""},{"location":"zh/DSP/TRANSFORM/DWT/notes/#dwt_3","title":"\u5355\u7ea7 DWT \u6d41\u7a0b","text":"<ol> <li> <p>\u5206\u89e3\u4fe1\u53f7:    <pre><code>float input[64];\nfloat cA[32], cD[32];\nint cA_len, cD_len;\ntiny_dwt_decompose_f32(input, 64, TINY_WAVELET_DB4, cA, cD, &amp;cA_len, &amp;cD_len);\n</code></pre></p> </li> <li> <p>\u5904\u7406\u7cfb\u6570\uff08\u53ef\u9009\uff09:    <pre><code>// \u5e94\u7528\u9608\u503c\u5904\u7406\u3001\u53bb\u566a\u7b49\n</code></pre></p> </li> <li> <p>\u91cd\u6784\u4fe1\u53f7:    <pre><code>float output[64];\nint output_len;\ntiny_dwt_reconstruct_f32(cA, cD, cA_len, TINY_WAVELET_DB4, output, &amp;output_len);\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#dwt_4","title":"\u591a\u7ea7 DWT \u6d41\u7a0b","text":"<ol> <li> <p>\u591a\u7ea7\u5206\u89e3:    <pre><code>float *cA, *cD;\nint cA_len;\ntiny_dwt_multilevel_decompose_f32(input, 128, TINY_WAVELET_DB4, 3, &amp;cA, &amp;cD, &amp;cA_len);\n</code></pre></p> </li> <li> <p>\u5904\u7406\u7cfb\u6570\uff08\u53ef\u9009\uff09:    <pre><code>tiny_dwt_coeffs_process(cA, cD, cA_len, 128 - cA_len, 3);\n</code></pre></p> </li> <li> <p>\u591a\u7ea7\u91cd\u6784:    <pre><code>float output[128];\ntiny_dwt_multilevel_reconstruct_f32(cA, cD, cA_len, TINY_WAVELET_DB4, 3, output);\n</code></pre></p> </li> <li> <p>\u91ca\u653e\u5185\u5b58:    <pre><code>free(cA);\nfree(cD);\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#_6","title":"\u5e94\u7528\u573a\u666f","text":"<p>DWT \u5e7f\u6cdb\u5e94\u7528\u4e8e\u5404\u79cd\u5e94\u7528\uff1a</p> <ul> <li>\u4fe1\u53f7\u53bb\u566a\uff1a\u5bf9\u7ec6\u8282\u7cfb\u6570\u8fdb\u884c\u9608\u503c\u5904\u7406\u4ee5\u53bb\u9664\u566a\u58f0</li> <li>\u6570\u636e\u538b\u7f29\uff1a\u4ec5\u5b58\u50a8\u663e\u8457\u7cfb</li> <li>\u7279\u5f81\u63d0\u53d6\uff1a\u5206\u6790\u4e0d\u540c\u5c3a\u5ea6\u7684\u7cfb\u6570</li> <li>\u56fe\u50cf\u5904\u7406\uff1a2D DWT \u7528\u4e8e\u56fe\u50cf\u538b\u7f29\u548c\u5206\u6790</li> <li>\u751f\u7269\u533b\u5b66\u4fe1\u53f7\u5904\u7406\uff1aECG/EEG \u5206\u6790\u3001\u4f2a\u5f71\u53bb\u9664</li> <li>\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\uff1a\u632f\u52a8\u5206\u6790\u3001\u635f\u4f24\u68c0\u6d4b</li> <li>\u65f6\u9891\u5206\u6790\uff1a\u5728\u65f6\u95f4\u548c\u9891\u7387\u4e0a\u5b9a\u4f4d\u4e8b\u4ef6</li> </ul>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#_7","title":"\u8fb9\u754c\u6548\u5e94","text":"<p>DWT \u64cd\u4f5c\u4f7f\u7528\u5bf9\u79f0\u586b\u5145\u6765\u5904\u7406\u4fe1\u53f7\u8fb9\u754c\u3002\u4f46\u662f\uff0c\u4ecd\u53ef\u80fd\u51fa\u73b0\u8fb9\u754c\u6548\u5e94\uff1a</p> <ul> <li>\u5355\u7ea7\uff1a\u8fb9\u754c\u6548\u5e94\u901a\u5e38\u4ece\u6bcf\u4e2a\u8fb9\u7f18\u5ef6\u4f38\u7ea6 filter_length \u4e2a\u6837\u672c</li> <li>\u591a\u7ea7\uff1a\u8fb9\u754c\u6548\u5e94\u7d2f\u79ef\u5e76\u5ef6\u4f38\u7ea6 filter_length \u00d7 levels \u4e2a\u6837\u672c</li> <li>\u4e2d\u5fc3\u533a\u57df\uff1a\u901a\u5e38\u5177\u6709\u975e\u5e38\u9ad8\u7684\u91cd\u6784\u7cbe\u5ea6</li> <li>\u5efa\u8bae\uff1a\u4f7f\u7528\u957f\u5ea6\u5927\u4e8e 2 \u00d7 filter_length \u00d7 levels \u7684\u4fe1\u53f7\u4ee5\u83b7\u5f97\u6700\u4f73\u7ed3\u679c</li> </ul>"},{"location":"zh/DSP/TRANSFORM/DWT/notes/#_8","title":"\u80fd\u91cf\u4fdd\u6301","text":"<p>\u5bf9\u4e8e\u5b8c\u7f8e\u91cd\u6784\u5c0f\u6ce2\uff08\u5982 Daubechies\uff09\uff0c\u80fd\u91cf\u5e94\u8be5\u5927\u81f4\u4fdd\u6301\uff1a</p> \\[ E_{input} \\approx E_{cA} + E_{cD} \\] \\[ E_{output} \\approx E_{input} \\] <p>\u5176\u4e2d\u80fd\u91cf\u8ba1\u7b97\u4e3a\uff1a</p> \\[ E = \\sum_{n} |x[n]|^2 \\] <p>\u8fb9\u754c\u6548\u5e94\u53ef\u80fd\u5bfc\u81f4\u8f7b\u5fae\u7684\u80fd\u91cf\u5dee\u5f02\uff0c\u4f46\u4e2d\u5fc3\u533a\u57df\u5e94\u4fdd\u6301\u51fa\u8272\u7684\u80fd\u91cf\u4fdd\u6301\u3002</p>"},{"location":"zh/DSP/TRANSFORM/DWT/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/TRANSFORM/FFT/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/TRANSFORM/FFT/notes/","title":"\u8bf4\u660e","text":"<p>\u8bf4\u660e</p> <p>\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\u662f\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u57fa\u7840\u7b97\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08DFT\uff09\u3002\u5b83\u5c06\u4fe1\u53f7\u4ece\u65f6\u57df\u8f6c\u6362\u5230\u9891\u57df\uff0c\u5b9e\u73b0\u9891\u7387\u5206\u6790\u3001\u9891\u8c31\u5206\u6790\u548c\u6ee4\u6ce2\u64cd\u4f5c\u3002FFT\u5e7f\u6cdb\u5e94\u7528\u4e8e\u97f3\u9891\u5904\u7406\u3001\u901a\u4fe1\u3001\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u548c\u8bb8\u591a\u5176\u4ed6\u5e94\u7528\u3002</p>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#fft","title":"FFT \u6982\u8ff0","text":""},{"location":"zh/DSP/TRANSFORM/FFT/notes/#_2","title":"\u6570\u5b66\u539f\u7406","text":"<p>\u957f\u5ea6\u4e3a \\( N \\) \u7684\u5e8f\u5217 \\( x[n] \\) \u7684\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08DFT\uff09\u5b9a\u4e49\u4e3a\uff1a</p> \\[ X[k] = \\sum_{n=0}^{N-1} x[n] \\cdot e^{-j \\frac{2\\pi kn}{N}} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( x[n] \\) \u662f\u65f6\u57df\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\\( X[k] \\) \u662f\u9891\u57df\u8f93\u51fa</p> </li> <li> <p>\\( N \\) \u662f\u4fe1\u53f7\u957f\u5ea6\uff08\u5fc5\u987b\u662f2\u7684\u5e42\uff09</p> </li> <li> <p>\\( k \\in [0, N-1] \\) \u662f\u9891\u7387\u7bb1\u7d22\u5f15</p> </li> </ul> <p>\u9891\u7387\u5206\u8fa8\u7387\uff1a</p> \\[ \\Delta f = \\frac{f_s}{N} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( \\Delta f \\) \u662f\u9891\u7387\u5206\u8fa8\u7387\uff08Hz\uff09</p> </li> <li> <p>\\( f_s \\) \u662f\u91c7\u6837\u7387\uff08Hz\uff09</p> </li> <li> <p>\\( N \\) \u662f FFT \u5927\u5c0f</p> </li> </ul> <p>\u7b2c k \u4e2a\u9891\u7387\u7bb1\u7684\u9891\u7387\uff1a</p> \\[ f_k = k \\cdot \\frac{f_s}{N} \\]"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#_3","title":"\u7a97\u51fd\u6570","text":"<p>\u7a97\u51fd\u6570\u5728 FFT \u4e4b\u524d\u5e94\u7528\u4e8e\u4fe1\u53f7\uff0c\u4ee5\u51cf\u5c11\u9891\u8c31\u6cc4\u6f0f\u3002\u5e93\u652f\u6301\u591a\u79cd\u7a97\u7c7b\u578b\uff1a</p> <ul> <li> <p>\u65e0\uff08\u77e9\u5f62\u7a97\uff09\uff1a\u4e0d\u5e94\u7528\u7a97\u51fd\u6570\uff0c\u6700\u5feb\u4f46\u53ef\u80fd\u6709\u9891\u8c31\u6cc4\u6f0f</p> </li> <li> <p>\u6c49\u5b81\u7a97\uff08Hanning\uff09\uff1a\u826f\u597d\u7684\u901a\u7528\u7a97\uff0c\u5e73\u8861\u9891\u7387\u5206\u8fa8\u7387\u548c\u6cc4\u6f0f\u51cf\u5c11</p> </li> <li> <p>\u6c49\u660e\u7a97\uff08Hamming\uff09\uff1a\u4e0e\u6c49\u5b81\u7a97\u7c7b\u4f3c\uff0c\u65c1\u74e3\u6291\u5236\u7a0d\u597d</p> </li> <li> <p>\u5e03\u83b1\u514b\u66fc\u7a97\uff08Blackman\uff09\uff1a\u6700\u4f73\u65c1\u74e3\u6291\u5236\uff0c\u4f46\u4e3b\u74e3\u66f4\u5bbd</p> </li> </ul>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#_4","title":"\u521d\u59cb\u5316\u548c\u53cd\u521d\u59cb\u5316","text":""},{"location":"zh/DSP/TRANSFORM/FFT/notes/#tiny_fft_init","title":"tiny_fft_init","text":"<pre><code>/**\n * @name: tiny_fft_init\n * @brief Initialize FFT tables (required before using FFT functions)\n * @note This function should be called once at startup\n * @param fft_size Maximum FFT size to support (must be power of 2)\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_init(int fft_size);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u521d\u59cb\u5316 FFT \u8868\u5e76\u51c6\u5907\u5e93\u4ee5\u8fdb\u884c FFT \u64cd\u4f5c\u3002\u5728\u4f7f\u7528\u4efb\u4f55 FFT \u64cd\u4f5c\u4e4b\u524d\u5fc5\u987b\u8c03\u7528\u6b64\u51fd\u6570\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u652f\u6301\u5e73\u53f0\u52a0\u901f\uff08ESP32 \u4f7f\u7528\u4f18\u5316\u7684 DSP \u5e93\uff09\u3002</p> </li> <li> <p>\u5728\u4f7f\u7528\u4efb\u4f55 FFT \u51fd\u6570\u4e4b\u524d\u5fc5\u987b\u8c03\u7528\u4e00\u6b21\u3002</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li><code>fft_size</code>: \u652f\u6301\u7684\u6700\u5927 FFT \u5927\u5c0f\u3002\u5fc5\u987b\u662f2\u7684\u5e42\uff08\u4f8b\u5982\uff0c256\u3001512\u30011024\uff09\u3002</li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u91cd\u8981\u8bf4\u660e:</p> <ul> <li> <p>FFT \u5927\u5c0f\u5fc5\u987b\u662f2\u7684\u5e42\u3002</p> </li> <li> <p>\u6b64\u51fd\u6570\u5e94\u5728\u7cfb\u7edf\u542f\u52a8\u65f6\u8c03\u7528\u4e00\u6b21\u3002</p> </li> <li> <p>\u6240\u6709\u540e\u7eed\u7684 FFT \u64cd\u4f5c\u5fc5\u987b\u4f7f\u7528\u5927\u5c0f \u2264 <code>fft_size</code>\u3002</p> </li> </ul>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#tiny_fft_deinit","title":"tiny_fft_deinit","text":"<pre><code>/**\n * @name: tiny_fft_deinit\n * @brief Deinitialize FFT tables and free resources\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_deinit(void);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u53cd\u521d\u59cb\u5316 FFT \u8868\u5e76\u91ca\u653e\u5206\u914d\u7684\u8d44\u6e90\u3002</p> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#fft_1","title":"\u6b63\u5411 FFT","text":""},{"location":"zh/DSP/TRANSFORM/FFT/notes/#tiny_fft_f32","title":"tiny_fft_f32","text":"<pre><code>/**\n * @name: tiny_fft_f32\n * @brief Perform FFT on real-valued input signal\n * @param input Input signal array (real values)\n * @param input_len Length of input signal (must be power of 2)\n * @param output_fft Output FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n *                   Size must be at least input_len * 2\n * @param window Window function to apply before FFT (optional)\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_f32(const float *input, int input_len, float *output_fft, tiny_fft_window_t window);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u5bf9\u5b9e\u503c\u8f93\u5165\u4fe1\u53f7\u6267\u884c\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u5c06\u5176\u4ece\u65f6\u57df\u8f6c\u6362\u5230\u9891\u57df\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u652f\u6301\u5e73\u53f0\u52a0\u901f\u3002</p> </li> <li> <p>\u652f\u6301\u53ef\u9009\u7684\u7a97\u51fd\u6570\u4ee5\u51cf\u5c11\u9891\u8c31\u6cc4\u6f0f\u3002</p> </li> <li> <p>\u8f93\u51fa\u4e3a\u590d\u6570\u683c\u5f0f\uff1a<code>[Re0, Im0, Re1, Im1, ...]</code>\u3002</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\uff08\u5b9e\u6570\u503c\uff09\u3002</p> </li> <li> <p><code>input_len</code>: \u8f93\u5165\u4fe1\u53f7\u957f\u5ea6\u3002\u5fc5\u987b\u662f2\u7684\u5e42\u4e14 \u2264 \u521d\u59cb\u5316\u7684 FFT \u5927\u5c0f\u3002</p> </li> <li> <p><code>output_fft</code>: FFT \u7ed3\u679c\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>input_len * 2</code>\uff08\u590d\u6570\u683c\u5f0f\uff09\u3002</p> </li> <li> <p><code>window</code>: \u5728 FFT \u4e4b\u524d\u5e94\u7528\u7684\u7a97\u51fd\u6570\u7c7b\u578b\u3002\u9009\u9879\uff1a</p> </li> <li><code>TINY_FFT_WINDOW_NONE</code>: \u65e0\u7a97\uff08\u77e9\u5f62\u7a97\uff09</li> <li><code>TINY_FFT_WINDOW_HANNING</code>: \u6c49\u5b81\u7a97</li> <li><code>TINY_FFT_WINDOW_HAMMING</code>: \u6c49\u660e\u7a97</li> <li><code>TINY_FFT_WINDOW_BLACKMAN</code>: \u5e03\u83b1\u514b\u66fc\u7a97</li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u8f93\u51fa\u683c\u5f0f:</p> <p>\u8f93\u51fa\u5b58\u50a8\u4e3a\u4ea4\u9519\u7684\u590d\u6570\u6570\u7ec4\uff1a</p> <ul> <li> <p><code>output_fft[0]</code> = \u7bb10\u7684\u5b9e\u90e8</p> </li> <li> <p><code>output_fft[1]</code> = \u7bb10\u7684\u865a\u90e8</p> </li> <li> <p><code>output_fft[2]</code> = \u7bb11\u7684\u5b9e\u90e8</p> </li> <li> <p><code>output_fft[3]</code> = \u7bb11\u7684\u865a\u90e8</p> </li> <li> <p>...</p> </li> </ul> <p>\u9891\u7387\u7bb1:</p> <ul> <li> <p>\u7bb10\uff1a\u76f4\u6d41\u5206\u91cf\uff080 Hz\uff09</p> </li> <li> <p>\u7bb1k\uff1a\u9891\u7387 = \\( k \\cdot \\frac{f_s}{N} \\) Hz</p> </li> <li> <p>\u7bb1N/2\uff1a\u5948\u594e\u65af\u7279\u9891\u7387\uff08\\( f_s/2 \\) Hz\uff09</p> </li> <li> <p>\u7bb1N/2+1 \u5230 N-1\uff1a\u7bb11 \u5230 N/2-1 \u7684\u955c\u50cf\uff08\u5bf9\u4e8e\u5b9e\u4fe1\u53f7\uff09</p> </li> </ul>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#fft_2","title":"\u9006 FFT","text":""},{"location":"zh/DSP/TRANSFORM/FFT/notes/#tiny_fft_ifft_f32","title":"tiny_fft_ifft_f32","text":"<pre><code>/**\n * @name: tiny_fft_ifft_f32\n * @brief Perform inverse FFT to reconstruct time-domain signal\n * @param input_fft Input FFT array (complex: [Re0, Im0, Re1, Im1, ...])\n * @param fft_len Length of FFT (number of complex points)\n * @param output Output reconstructed signal (real values)\n *               Size must be at least fft_len\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_ifft_f32(const float *input_fft, int fft_len, float *output);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6267\u884c\u9006\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u5c06\u9891\u57df\u4fe1\u53f7\u8f6c\u6362\u56de\u65f6\u57df\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u652f\u6301\u5e73\u53f0\u52a0\u901f\u3002</p> </li> <li> <p>\u4ece FFT \u7ed3\u679c\u91cd\u5efa\u539f\u59cb\u65f6\u57df\u4fe1\u53f7\u3002</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input_fft</code>: \u8f93\u5165 FFT \u6570\u7ec4\u6307\u9488\uff08\u590d\u6570\u683c\u5f0f\uff1a<code>[Re0, Im0, Re1, Im1, ...]</code>\uff09\u3002</p> </li> <li> <p><code>fft_len</code>: FFT \u957f\u5ea6\uff08\u590d\u6570\u70b9\u6570\uff09\u3002\u5fc5\u987b\u662f2\u7684\u5e42\u3002</p> </li> <li> <p><code>output</code>: \u91cd\u5efa\u4fe1\u53f7\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\uff08\u5b9e\u6570\u503c\uff09\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>fft_len</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u91cd\u5efa\u7684\u4fe1\u53f7\u5e94\u4e0e\u539f\u59cb\u8f93\u5165\u4fe1\u53f7\u5339\u914d\uff08\u5728\u6570\u503c\u7cbe\u5ea6\u8303\u56f4\u5185\uff09\uff0c\u5047\u8bbe\u672a\u5bf9 FFT \u7ed3\u679c\u8fdb\u884c\u4fee\u6539\u3002</p>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#_5","title":"\u9891\u8c31\u5206\u6790","text":""},{"location":"zh/DSP/TRANSFORM/FFT/notes/#tiny_fft_magnitude_f32","title":"tiny_fft_magnitude_f32","text":"<pre><code>/**\n * @name: tiny_fft_magnitude_f32\n * @brief Calculate magnitude spectrum from FFT result\n * @param fft_result FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n * @param fft_len Length of FFT (number of complex points)\n * @param magnitude Output magnitude spectrum (real values)\n *                  Size must be at least fft_len\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_magnitude_f32(const float *fft_result, int fft_len, float *magnitude);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4ece FFT \u7ed3\u679c\u8ba1\u7b97\u5e45\u5ea6\u9891\u8c31\u3002\u5e45\u5ea6\u8868\u793a\u6bcf\u4e2a\u9891\u7387\u5206\u91cf\u7684\u632f\u5e45\u3002</p> <p>\u6570\u5b66\u516c\u5f0f:</p> \\[ |X[k]| = \\sqrt{\\text{Re}[X[k]]^2 + \\text{Im}[X[k]]^2} \\] <p>\u53c2\u6570:</p> <ul> <li> <p><code>fft_result</code>: FFT \u7ed3\u679c\u6570\u7ec4\u6307\u9488\uff08\u590d\u6570\u683c\u5f0f\uff09\u3002</p> </li> <li> <p><code>fft_len</code>: FFT \u957f\u5ea6\uff08\u590d\u6570\u70b9\u6570\uff09\u3002</p> </li> <li> <p><code>magnitude</code>: \u5e45\u5ea6\u9891\u8c31\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>fft_len</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#tiny_fft_power_spectrum_f32","title":"tiny_fft_power_spectrum_f32","text":"<pre><code>/**\n * @name: tiny_fft_power_spectrum_f32\n * @brief Calculate power spectrum density (PSD) from FFT result\n * @param fft_result FFT result (complex array: [Re0, Im0, Re1, Im1, ...])\n * @param fft_len Length of FFT (number of complex points)\n * @param power Output power spectrum (real values)\n *              Size must be at least fft_len\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_power_spectrum_f32(const float *fft_result, int fft_len, float *power);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4ece FFT \u7ed3\u679c\u8ba1\u7b97\u529f\u7387\u8c31\u5bc6\u5ea6\uff08PSD\uff09\u3002\u529f\u7387\u9891\u8c31\u8868\u793a\u6bcf\u4e2a\u9891\u7387\u5206\u91cf\u7684\u529f\u7387\uff0c\u5e76\u6309 FFT \u957f\u5ea6\u5f52\u4e00\u5316\u3002</p> <p>\u6570\u5b66\u516c\u5f0f:</p> \\[ P[k] = \\frac{|X[k]|^2}{N} = \\frac{\\text{Re}[X[k]]^2 + \\text{Im}[X[k]]^2}{N} \\] <p>\u53c2\u6570:</p> <ul> <li> <p><code>fft_result</code>: FFT \u7ed3\u679c\u6570\u7ec4\u6307\u9488\uff08\u590d\u6570\u683c\u5f0f\uff09\u3002</p> </li> <li> <p><code>fft_len</code>: FFT \u957f\u5ea6\uff08\u590d\u6570\u70b9\u6570\uff09\u3002</p> </li> <li> <p><code>power</code>: \u529f\u7387\u9891\u8c31\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>fft_len</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#_6","title":"\u9891\u7387\u68c0\u6d4b","text":""},{"location":"zh/DSP/TRANSFORM/FFT/notes/#tiny_fft_find_peak_frequency","title":"tiny_fft_find_peak_frequency","text":"<pre><code>/**\n * @name: tiny_fft_find_peak_frequency\n * @brief Find the frequency with maximum power (useful for structural health monitoring)\n * @param power_spectrum Power spectrum array\n * @param fft_len Length of power spectrum\n * @param sample_rate Sampling rate of the original signal (Hz)\n * @param peak_freq Output peak frequency (Hz)\n * @param peak_power Output peak power value\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_find_peak_frequency(const float *power_spectrum, int fft_len, float sample_rate, float *peak_freq, float *peak_power);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u5728\u529f\u7387\u9891\u8c31\u4e2d\u627e\u5230\u529f\u7387\u6700\u5927\u7684\u9891\u7387\u3002\u4f7f\u7528\u629b\u7269\u7ebf\u63d2\u503c\u4ee5\u63d0\u9ad8\u9891\u7387\u4f30\u8ba1\u7cbe\u5ea6\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u8df3\u8fc7\u76f4\u6d41\u5206\u91cf\uff08\u7bb10\uff09\u3002</p> </li> <li> <p>\u4f7f\u7528\u629b\u7269\u7ebf\u63d2\u503c\u4ee5\u63d0\u9ad8\u9891\u7387\u4f30\u8ba1\u7cbe\u5ea6\u3002</p> </li> <li> <p>\u7528\u4e8e\u68c0\u6d4b\u4fe1\u53f7\u4e2d\u7684\u4e3b\u5bfc\u9891\u7387\u3002</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>power_spectrum</code>: \u529f\u7387\u9891\u8c31\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>fft_len</code>: \u529f\u7387\u9891\u8c31\u957f\u5ea6\u3002</p> </li> <li> <p><code>sample_rate</code>: \u539f\u59cb\u4fe1\u53f7\u7684\u91c7\u6837\u7387\uff08Hz\uff09\u3002</p> </li> <li> <p><code>peak_freq</code>: \u5cf0\u503c\u9891\u7387\u7684\u8f93\u51fa\u53d8\u91cf\u6307\u9488\uff08Hz\uff09\u3002</p> </li> <li> <p><code>peak_power</code>: \u5cf0\u503c\u529f\u7387\u503c\u7684\u8f93\u51fa\u53d8\u91cf\u6307\u9488\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#tiny_fft_find_top_frequencies","title":"tiny_fft_find_top_frequencies","text":"<pre><code>/**\n * @name: tiny_fft_find_top_frequencies\n * @brief Find top N frequencies with highest power\n * @param power_spectrum Power spectrum array\n * @param fft_len Length of power spectrum\n * @param sample_rate Sampling rate of the original signal (Hz)\n * @param top_n Number of top frequencies to find\n * @param frequencies Output array for frequencies (Hz), size must be at least top_n\n * @param powers Output array for power values, size must be at least top_n\n * @return tiny_error_t\n */\ntiny_error_t tiny_fft_find_top_frequencies(const float *power_spectrum, int fft_len, float sample_rate, int top_n, float *frequencies, float *powers);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u5728\u529f\u7387\u9891\u8c31\u4e2d\u627e\u5230\u529f\u7387\u6700\u9ad8\u7684\u524d N \u4e2a\u9891\u7387\u3002\u81ea\u52a8\u68c0\u6d4b\u5c40\u90e8\u5cf0\u503c\u5e76\u5408\u5e76\u9644\u8fd1\u7684\u5cf0\u503c\uff0c\u4ee5\u907f\u514d\u4ece\u540c\u4e00\u9891\u7387\u5cf0\u503c\u9009\u62e9\u591a\u4e2a\u7bb1\u3002</p> <p>\u7279\u70b9:</p> <ul> <li> <p>\u68c0\u6d4b\u529f\u7387\u9891\u8c31\u4e2d\u7684\u5c40\u90e8\u5cf0\u503c\u3002</p> </li> <li> <p>\u5408\u5e76\u9644\u8fd1\u7684\u5cf0\u503c\uff082\u4e2a\u7bb1\u5185\uff09\u4ee5\u907f\u514d\u91cd\u590d\u3002</p> </li> <li> <p>\u4f7f\u7528\u629b\u7269\u7ebf\u63d2\u503c\u4ee5\u63d0\u9ad8\u9891\u7387\u7cbe\u5ea6\u3002</p> </li> <li> <p>\u8fc7\u6ee4\u6389\u4e0d\u663e\u8457\u7684\u5cf0\u503c\uff08\u4f4e\u4e8e\u6700\u5927\u529f\u7387\u76841%\uff09\u3002</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>power_spectrum</code>: \u529f\u7387\u9891\u8c31\u6570\u7ec4\u6307\u9488\u3002</p> </li> <li> <p><code>fft_len</code>: \u529f\u7387\u9891\u8c31\u957f\u5ea6\u3002</p> </li> <li> <p><code>sample_rate</code>: \u539f\u59cb\u4fe1\u53f7\u7684\u91c7\u6837\u7387\uff08Hz\uff09\u3002</p> </li> <li> <p><code>top_n</code>: \u8981\u67e5\u627e\u7684\u524d N \u4e2a\u9891\u7387\u6570\u91cf\u3002</p> </li> <li> <p><code>frequencies</code>: \u9891\u7387\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\uff08Hz\uff09\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>top_n</code>\u3002</p> </li> <li> <p><code>powers</code>: \u529f\u7387\u503c\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>top_n</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u8fd4\u56de\u6210\u529f\u6216\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u5982\u679c\u627e\u5230\u7684\u5cf0\u503c\u5c11\u4e8e <code>top_n</code> \u4e2a\uff0c\u8f93\u51fa\u6570\u7ec4\u4e2d\u5269\u4f59\u6761\u76ee\u5c06\u8bbe\u7f6e\u4e3a\u96f6\u3002</p>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#_7","title":"\u4f7f\u7528\u6d41\u7a0b","text":""},{"location":"zh/DSP/TRANSFORM/FFT/notes/#fft_3","title":"\u5178\u578b\u7684 FFT \u5206\u6790\u6d41\u7a0b","text":"<ol> <li> <p>\u521d\u59cb\u5316 FFT:    <pre><code>tiny_fft_init(256);  // \u521d\u59cb\u5316\u6700\u5927256\u70b9 FFT\n</code></pre></p> </li> <li> <p>\u6267\u884c FFT:    <pre><code>float input[256];\nfloat fft_result[512];  // \u590d\u6570\u8f93\u51fa\uff1a256 * 2\ntiny_fft_f32(input, 256, fft_result, TINY_FFT_WINDOW_HANNING);\n</code></pre></p> </li> <li> <p>\u8ba1\u7b97\u529f\u7387\u9891\u8c31:    <pre><code>float power[256];\ntiny_fft_power_spectrum_f32(fft_result, 256, power);\n</code></pre></p> </li> <li> <p>\u67e5\u627e\u5cf0\u503c\u9891\u7387:    <pre><code>float peak_freq, peak_power;\ntiny_fft_find_peak_frequency(power, 256, 1000.0f, &amp;peak_freq, &amp;peak_power);\n</code></pre></p> </li> <li> <p>\u53cd\u521d\u59cb\u5316\uff08\u5b8c\u6210\u540e\uff09:    <pre><code>tiny_fft_deinit();\n</code></pre></p> </li> </ol>"},{"location":"zh/DSP/TRANSFORM/FFT/notes/#_8","title":"\u5e94\u7528\u573a\u666f","text":"<p>FFT \u5e7f\u6cdb\u5e94\u7528\u4e8e\u5404\u79cd\u5e94\u7528\uff1a</p> <ul> <li> <p>\u97f3\u9891\u5904\u7406\uff1a\u9891\u7387\u5206\u6790\u3001\u5747\u8861\u3001\u97f3\u8c03\u68c0\u6d4b</p> </li> <li> <p>\u901a\u4fe1\uff1a\u4fe1\u53f7\u8c03\u5236\u3001\u89e3\u8c03\u3001\u4fe1\u9053\u5206\u6790</p> </li> <li> <p>\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\uff1a\u632f\u52a8\u5206\u6790\u3001\u5171\u632f\u68c0\u6d4b</p> </li> <li> <p>\u751f\u7269\u533b\u5b66\uff1aECG/EEG \u5206\u6790\u3001\u5fc3\u7387\u68c0\u6d4b</p> </li> <li> <p>\u56fe\u50cf\u5904\u7406\uff1a2D FFT \u7528\u4e8e\u56fe\u50cf\u6ee4\u6ce2\u548c\u5206\u6790</p> </li> <li> <p>\u9891\u8c31\u5206\u6790\uff1a\u8bc6\u522b\u4fe1\u53f7\u4e2d\u7684\u9891\u7387\u5206\u91cf</p> </li> </ul>"},{"location":"zh/DSP/TRANSFORM/FFT/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/TRANSFORM/FFT/test/#_2","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<pre><code>========== TinyFFT Test ==========\n\n1. FFT Initialization:\n  \u2713 FFT initialized (max size: 256)\n\n2. Test Signal Generation:\n  Input: Signal with frequencies 10 Hz and 50 Hz\n  Sample rate: 1000.0 Hz\n  Signal length: 256 samples\n  First 10 samples: 0.000 0.217 0.419 0.592 0.724 0.809 0.844 0.830 0.776 0.690 \n\n3. FFT (No Window):\n  Input: Test signal (length=256)\n  \u2713 FFT completed\n  Output: FFT result (complex, length=256)\n  Magnitude spectrum: First 10 values: 32.216 37.858 81.243 82.696 20.529 9.805 5.459 3.052 1.398 0.332 \n\n4. Peak Frequency Detection:\n  Input: Power spectrum (length=256)\n  Output: Peak frequency = 9.91 Hz (power = 26.714)\n  Expected: ~10 Hz or ~50 Hz (strongest component)\n\n5. Top Frequencies Detection:\n  Input: Power spectrum (length=256)\n  Output: Top 3 frequencies:\n    [1] 9.91 Hz (power = 26.714)\n    [2] 50.77 Hz (power = 14.756)\n    [3] 0.00 Hz (power = 0.000)\n  Expected: ~10 Hz and ~50 Hz should be in top frequencies\n\n6. IFFT (Signal Reconstruction):\n  Input: FFT result (complex, length=256)\n  Output: Reconstructed signal (length=256)\n  First 10 samples: 0.000 0.217 0.419 0.592 0.724 0.809 0.844 0.830 0.776 0.690 \n  Max difference from original: 0.000003\n  \u2713 IFFT reconstruction completed\n\n7. FFT with Hanning Window:\n  Input: Test signal (length=256) with Hanning window\n  Output: Peak frequency = 10.32 Hz (power = 12.407)\n  Note: Window reduces spectral leakage, improving frequency resolution\n\n8. FFT Deinitialization:\n  \u2713 FFT deinitialized\n\n========================================\n</code></pre>"},{"location":"zh/DSP/TRANSFORM/ICA/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/DSP/TRANSFORM/ICA/notes/","title":"\u8bf4\u660e","text":"<p>\u8bf4\u660e</p> <p>\u72ec\u7acb\u6210\u5206\u5206\u6790\uff08ICA\uff09\u662f\u4e00\u79cd\u76f2\u6e90\u5206\u79bb\u6280\u672f\uff0c\u5c06\u6df7\u5408\u4fe1\u53f7\u5206\u79bb\u4e3a\u72ec\u7acb\u7684\u6e90\u6210\u5206\u3002\u5b83\u5047\u8bbe\u89c2\u6d4b\u4fe1\u53f7\u662f\u7edf\u8ba1\u72ec\u7acb\u6e90\u7684\u7ebf\u6027\u6df7\u5408\u3002ICA \u5e7f\u6cdb\u5e94\u7528\u4e8e\u4fe1\u53f7\u5904\u7406\u3001\u795e\u7ecf\u79d1\u5b66\u3001\u56fe\u50cf\u5904\u7406\u548c\u97f3\u9891\u6e90\u5206\u79bb\u5e94\u7528\u3002</p>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#ica","title":"ICA \u6982\u8ff0","text":""},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_2","title":"\u6570\u5b66\u539f\u7406","text":"<p>ICA \u89e3\u51b3\u76f2\u6e90\u5206\u79bb\u95ee\u9898\uff1a</p> \\[ \\mathbf{X} = \\mathbf{A} \\cdot \\mathbf{S} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( \\mathbf{X} \\) \u662f\u89c2\u6d4b\uff08\u6df7\u5408\uff09\u4fe1\u53f7\u77e9\u9635\uff08num_obs \u00d7 num_samples\uff09</p> </li> <li> <p>\\( \\mathbf{A} \\) \u662f\u672a\u77e5\u6df7\u5408\u77e9\u9635\uff08num_obs \u00d7 num_sources\uff09</p> </li> <li> <p>\\( \\mathbf{S} \\) \u662f\u72ec\u7acb\u6e90\u4fe1\u53f7\u77e9\u9635\uff08num_sources \u00d7 num_samples\uff09</p> </li> </ul> <p>\u76ee\u6807\uff1a\u627e\u5230\u89e3\u6df7\u77e9\u9635 \\( \\mathbf{W} \\) \u4f7f\u5f97\uff1a</p> \\[ \\mathbf{S} = \\mathbf{W} \\cdot \\mathbf{X} \\] <p>\u5173\u952e\u5047\u8bbe\uff1a</p> <ol> <li> <p>\u7edf\u8ba1\u72ec\u7acb\u6027\uff1a\u6e90\u4fe1\u53f7\u5728\u7edf\u8ba1\u4e0a\u72ec\u7acb</p> </li> <li> <p>\u975e\u9ad8\u65af\u6027\uff1a\u6700\u591a\u4e00\u4e2a\u6e90\u53ef\u4ee5\u662f\u9ad8\u65af\u5206\u5e03\uff08\u7528\u4e8e\u53ef\u8bc6\u522b\u6027\uff09</p> </li> <li> <p>\u7ebf\u6027\u6df7\u5408\uff1a\u89c2\u6d4b\u662f\u6e90\u7684\u7ebf\u6027\u7ec4\u5408</p> </li> <li> <p>\u65b9\u9635\u6216\u8d85\u5b9a\uff1a\u89c2\u6d4b\u6570\u91cf \u2265 \u6e90\u6570\u91cf</p> </li> </ol>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#ica-vs-pca","title":"ICA vs PCA","text":"<ul> <li>PCA\uff1a\u627e\u5230\u6700\u5927\u65b9\u5dee\u7684\u6b63\u4ea4\u65b9\u5411\uff08\u4e8c\u9636\u7edf\u8ba1\u91cf\uff09</li> <li>ICA\uff1a\u627e\u5230\u7edf\u8ba1\u72ec\u7acb\u7684\u65b9\u5411\uff08\u9ad8\u9636\u7edf\u8ba1\u91cf\uff09</li> <li>PCA\uff1a\u53bb\u76f8\u5173\u6570\u636e\uff08\u53bb\u9664\u7ebf\u6027\u4f9d\u8d56\uff09</li> <li>ICA\uff1a\u5206\u79bb\u72ec\u7acb\u6e90\uff08\u53bb\u9664\u6240\u6709\u4f9d\u8d56\uff09</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_3","title":"\u7b97\u6cd5","text":""},{"location":"zh/DSP/TRANSFORM/ICA/notes/#fastica","title":"FastICA","text":"<p>\u5e93\u5b9e\u73b0\u4e86 FastICA \u7b97\u6cd5\uff0c\u57fa\u4e8e\u6700\u5927\u5316\u975e\u9ad8\u65af\u6027\uff1a</p> <p>\u76ee\u6807\u51fd\u6570\uff1a\u6700\u5927\u5316 \\( \\mathbf{w}^T \\mathbf{x} \\) \u7684\u975e\u9ad8\u65af\u6027</p> <p>\u975e\u7ebf\u6027\u51fd\u6570\uff1a</p> <ul> <li> <p>tanh\uff1a\\( g(u) = \\tanh(u) \\) - \u9002\u7528\u4e8e\u8d85\u9ad8\u65af\u6e90</p> </li> <li> <p>exp\uff1a\\( g(u) = u \\cdot e^{-u^2/2} \\) - \u9002\u7528\u4e8e\u6b21\u9ad8\u65af\u6e90</p> </li> <li> <p>cube\uff1a\\( g(u) = u^3 \\) - \u9002\u7528\u4e8e\u8d85\u9ad8\u65af\u6e90</p> </li> </ul> <p>\u7b97\u6cd5\u6b65\u9aa4\uff1a</p> <ol> <li> <p>\u4e2d\u5fc3\u5316\u6570\u636e\uff1a\\( \\mathbf{x}_c = \\mathbf{x} - \\text{mean}(\\mathbf{x}) \\)</p> </li> <li> <p>\u767d\u5316\u6570\u636e\uff1a\\( \\mathbf{z} = \\mathbf{D}^{-1/2} \\mathbf{E}^T \\mathbf{x}_c \\)</p> </li> <li> <p>\u4f7f\u7528\u5b9a\u70b9\u8fed\u4ee3\u63d0\u53d6\u6210\u5206</p> </li> <li> <p>\u6b63\u4ea4\u5316\u6210\u5206\uff08Gram-Schmidt\uff09</p> </li> </ol>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_4","title":"\u9884\u5904\u7406","text":""},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_5","title":"\u4e2d\u5fc3\u5316","text":"<p>\u4ece\u6bcf\u4e2a\u89c2\u6d4b\u4e2d\u51cf\u53bb\u5747\u503c\uff1a</p> \\[ \\mathbf{x}_c = \\mathbf{x} - \\bar{\\mathbf{x}} \\] <p>\u5176\u4e2d \\( \\bar{\\mathbf{x}} \\) \u662f\u5747\u503c\u5411\u91cf\u3002</p>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_6","title":"\u767d\u5316","text":"<p>\u5c06\u6570\u636e\u53d8\u6362\u4e3a\u5177\u6709\u5355\u4f4d\u65b9\u5dee\u548c\u96f6\u76f8\u5173\uff1a</p> \\[ \\mathbf{z} = \\mathbf{D}^{-1/2} \\mathbf{E}^T \\mathbf{x}_c \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\( \\mathbf{E} \\) \u662f\u534f\u65b9\u5dee\u77e9\u9635\u7684\u7279\u5f81\u5411\u91cf</p> </li> <li> <p>\\( \\mathbf{D} \\) \u662f\u534f\u65b9\u5dee\u77e9\u9635\u7684\u7279\u5f81\u503c</p> </li> </ul> <p>\u767d\u5316\u77e9\u9635\uff1a</p> \\[ \\mathbf{W}_{whiten} = \\mathbf{D}^{-1/2} \\mathbf{E}^T \\]"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_7","title":"\u51fd\u6570","text":""},{"location":"zh/DSP/TRANSFORM/ICA/notes/#tiny_ica_separate_f32","title":"tiny_ica_separate_f32","text":"<pre><code>/**\n * @name tiny_ica_separate_f32\n * @brief Perform ICA separation on mixed signals\n * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n * @param num_obs Number of observations (mixed signals)\n * @param num_samples Number of samples per signal\n * @param num_sources Number of independent sources to extract\n * @param separated_sources Output separated sources (num_sources x num_samples, row-major)\n * @param algorithm ICA algorithm to use (default: TINY_ICA_FASTICA)\n * @param nonlinearity Nonlinearity function for FastICA (default: TINY_ICA_NONLINEARITY_TANH)\n * @param max_iter Maximum number of iterations (default: 100)\n * @param tolerance Convergence tolerance (default: 1e-4)\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_separate_f32(const float *mixed_signals,\n                                   int num_obs,\n                                   int num_samples,\n                                   int num_sources,\n                                   float *separated_sources,\n                                   tiny_ica_algorithm_t algorithm,\n                                   tiny_ica_nonlinearity_t nonlinearity,\n                                   int max_iter,\n                                   float tolerance);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u5728\u4e00\u6b21\u51fd\u6570\u8c03\u7528\u4e2d\u6267\u884c\u5b8c\u6574\u7684 ICA \u5206\u79bb\u3002\u8fd9\u662f ICA \u6700\u7b80\u5355\u7684\u63a5\u53e3\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>mixed_signals</code>: \u8f93\u5165\u6df7\u5408\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\u3002\u6570\u636e\u5e03\u5c40\u4e3a\u884c\u4e3b\u5e8f\uff1a<code>mixed_signals[i * num_samples + j]</code> \u662f\u89c2\u6d4b <code>i</code> \u7684\u6837\u672c <code>j</code>\u3002</p> </li> <li> <p><code>num_obs</code>: \u89c2\u6d4b\u6570\u91cf\uff08\u6df7\u5408\u4fe1\u53f7\uff09\u3002\u5fc5\u987b \u2265 <code>num_sources</code>\u3002</p> </li> <li> <p><code>num_samples</code>: \u6bcf\u4e2a\u4fe1\u53f7\u7684\u6837\u672c\u6570\u3002</p> </li> <li> <p><code>num_sources</code>: \u8981\u63d0\u53d6\u7684\u72ec\u7acb\u6e90\u6570\u91cf\u3002\u5fc5\u987b \u2264 <code>num_obs</code>\u3002</p> </li> <li> <p><code>separated_sources</code>: \u5206\u79bb\u6e90\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\u3002\u6570\u636e\u5e03\u5c40\u4e3a\u884c\u4e3b\u5e8f\uff1a<code>separated_sources[i * num_samples + j]</code> \u662f\u6e90 <code>i</code> \u7684\u6837\u672c <code>j</code>\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>num_sources * num_samples</code>\u3002</p> </li> <li> <p><code>algorithm</code>: ICA \u7b97\u6cd5\u7c7b\u578b\u3002\u76ee\u524d\u4ec5\u652f\u6301 <code>TINY_ICA_FASTICA</code>\u3002</p> </li> <li> <p><code>nonlinearity</code>: FastICA \u7684\u975e\u7ebf\u6027\u51fd\u6570\uff1a</p> </li> <li><code>TINY_ICA_NONLINEARITY_TANH</code>: tanh\uff08\u9ed8\u8ba4\uff0c\u9002\u7528\u4e8e\u8d85\u9ad8\u65af\uff09</li> <li><code>TINY_ICA_NONLINEARITY_EXP</code>: exp(-u\u00b2/2)\uff08\u9002\u7528\u4e8e\u6b21\u9ad8\u65af\uff09</li> <li> <p><code>TINY_ICA_NONLINEARITY_CUBE</code>: u\u00b3\uff08\u9002\u7528\u4e8e\u8d85\u9ad8\u65af\uff09</p> </li> <li> <p><code>max_iter</code>: FastICA \u7684\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u3002\u5982\u679c \u2264 0\uff0c\u9ed8\u8ba4\u503c\u4e3a 100\u3002</p> </li> <li> <p><code>tolerance</code>: \u6536\u655b\u5bb9\u5dee\u3002\u5f53\u53d8\u5316 &lt; tolerance \u65f6\u7b97\u6cd5\u505c\u6b62\u3002\u5982\u679c \u2264 0\uff0c\u9ed8\u8ba4\u503c\u4e3a 1e-4\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u6210\u529f\u65f6\u8fd4\u56de <code>TINY_OK</code>\uff0c\u5931\u8d25\u65f6\u8fd4\u56de\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u5904\u7406\u6b65\u9aa4:</p> <ol> <li>\u4e2d\u5fc3\u5316\u6570\u636e\uff1a\u4ece\u6bcf\u4e2a\u89c2\u6d4b\u4e2d\u51cf\u53bb\u5747\u503c</li> <li>\u767d\u5316\u6570\u636e\uff1a\u4f7f\u7528\u7279\u5f81\u503c\u5206\u89e3\u53bb\u76f8\u5173\u5e76\u5f52\u4e00\u5316\u65b9\u5dee</li> <li>\u63d0\u53d6\u6210\u5206\uff1a\u4f7f\u7528 FastICA \u627e\u5230\u72ec\u7acb\u6210\u5206</li> <li>\u91cd\u6784\u6e90\uff1a\u5c06\u89e3\u6df7\u77e9\u9635\u5e94\u7528\u4e8e\u767d\u5316\u6570\u636e</li> </ol> <p>\u6ce8\u610f: </p> <p>\u6b64\u51fd\u6570\u5728\u5185\u90e8\u6267\u884c\u6240\u6709\u6b65\u9aa4\u3002\u5bf9\u4e8e\u91cd\u590d\u5206\u79bb\uff0c\u4f7f\u7528\u57fa\u4e8e\u7ed3\u6784\u7684 API\uff08<code>tiny_ica_init</code>\u3001<code>tiny_ica_fit</code>\u3001<code>tiny_ica_transform</code>\uff09\u4ee5\u907f\u514d\u91cd\u65b0\u8ba1\u7b97\u767d\u5316\u77e9\u9635\u3002</p>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#tiny_ica_init","title":"tiny_ica_init","text":"<pre><code>/**\n * @name tiny_ica_init\n * @brief Initialize ICA structure for repeated use\n * @param ica Pointer to ICA structure\n * @param num_obs Number of observations (mixed signals)\n * @param num_sources Number of sources to extract\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_init(tiny_ica_t *ica, int num_obs, int num_sources);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u521d\u59cb\u5316 ICA \u7ed3\u6784\u4ee5\u4f9b\u91cd\u590d\u4f7f\u7528\u3002\u4e3a\u6df7\u5408\u77e9\u9635\u3001\u89e3\u6df7\u77e9\u9635\u3001\u767d\u5316\u77e9\u9635\u548c\u5747\u503c\u5411\u91cf\u5206\u914d\u5185\u5b58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>ica</code>: <code>tiny_ica_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>num_obs</code>: \u89c2\u6d4b\u6570\u91cf\uff08\u6df7\u5408\u4fe1\u53f7\uff09\u3002\u5fc5\u987b \u2265 <code>num_sources</code>\u3002</p> </li> <li> <p><code>num_sources</code>: \u8981\u63d0\u53d6\u7684\u6e90\u6570\u91cf\u3002\u5fc5\u987b \u2264 <code>num_obs</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u6210\u529f\u65f6\u8fd4\u56de <code>TINY_OK</code>\uff0c\u5931\u8d25\u65f6\u8fd4\u56de\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u5185\u5b58\u7ba1\u7406: </p> <p>\u51fd\u6570\u5728\u5185\u90e8\u5206\u914d\u5185\u5b58\u3002\u8c03\u7528 <code>tiny_ica_deinit()</code> \u91ca\u653e\u5b83\u3002</p>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#tiny_ica_fit","title":"tiny_ica_fit","text":"<pre><code>/**\n * @name tiny_ica_fit\n * @brief Fit ICA model to mixed signals (learn unmixing matrix)\n * @param ica Pointer to initialized ICA structure\n * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n * @param num_samples Number of samples per signal\n * @param algorithm ICA algorithm to use\n * @param nonlinearity Nonlinearity function for FastICA\n * @param max_iter Maximum number of iterations\n * @param tolerance Convergence tolerance\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_fit(tiny_ica_t *ica,\n                          const float *mixed_signals,\n                          int num_samples,\n                          tiny_ica_algorithm_t algorithm,\n                          tiny_ica_nonlinearity_t nonlinearity,\n                          int max_iter,\n                          float tolerance);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u5c06 ICA \u6a21\u578b\u62df\u5408\u5230\u8bad\u7ec3\u6570\u636e\u3002\u5b66\u4e60\u89e3\u6df7\u77e9\u9635\u548c\u767d\u5316\u77e9\u9635\u3002\u62df\u5408\u540e\uff0c\u4f7f\u7528 <code>tiny_ica_transform()</code> \u5206\u79bb\u65b0\u4fe1\u53f7\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>ica</code>: \u521d\u59cb\u5316\u7684 <code>tiny_ica_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>mixed_signals</code>: \u8f93\u5165\u6df7\u5408\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\uff08\u884c\u4e3b\u5e8f\u5e03\u5c40\uff09\u3002</p> </li> <li> <p><code>num_samples</code>: \u6bcf\u4e2a\u4fe1\u53f7\u7684\u6837\u672c\u6570\u3002</p> </li> <li> <p><code>algorithm</code>: ICA \u7b97\u6cd5\u7c7b\u578b\u3002\u76ee\u524d\u4ec5\u652f\u6301 <code>TINY_ICA_FASTICA</code>\u3002</p> </li> <li> <p><code>nonlinearity</code>: FastICA \u7684\u975e\u7ebf\u6027\u51fd\u6570\u3002</p> </li> <li> <p><code>max_iter</code>: \u6700\u5927\u8fed\u4ee3\u6b21\u6570\u3002\u5982\u679c \u2264 0\uff0c\u9ed8\u8ba4\u503c\u4e3a 100\u3002</p> </li> <li> <p><code>tolerance</code>: \u6536\u655b\u5bb9\u5dee\u3002\u5982\u679c \u2264 0\uff0c\u9ed8\u8ba4\u503c\u4e3a 1e-4\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u6210\u529f\u65f6\u8fd4\u56de <code>TINY_OK</code>\uff0c\u5931\u8d25\u65f6\u8fd4\u56de\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u62df\u5408\u540e\uff0cICA \u7ed3\u6784\u5305\u542b\u5b66\u4e60\u5230\u7684\u89e3\u6df7\u77e9\u9635\u548c\u767d\u5316\u77e9\u9635\u3002\u8fd9\u4e9b\u53ef\u4ee5\u91cd\u590d\u7528\u4e8e\u53d8\u6362\u65b0\u6570\u636e\u3002</p>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#tiny_ica_transform","title":"tiny_ica_transform","text":"<pre><code>/**\n * @name tiny_ica_transform\n * @brief Apply learned ICA model to separate signals\n * @param ica Pointer to fitted ICA structure\n * @param mixed_signals Input mixed signals (num_obs x num_samples, row-major)\n * @param num_samples Number of samples per signal\n * @param separated_sources Output separated sources (num_sources x num_samples, row-major)\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_transform(const tiny_ica_t *ica,\n                                const float *mixed_signals,\n                                int num_samples,\n                                float *separated_sources);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u5c06\u5148\u524d\u62df\u5408\u7684 ICA \u6a21\u578b\u5e94\u7528\u4e8e\u5206\u79bb\u65b0\u4fe1\u53f7\u3002\u6bd4 <code>tiny_ica_separate_f32()</code> \u5feb\u5f97\u591a\uff0c\u56e0\u4e3a\u5b83\u91cd\u7528\u5b66\u4e60\u5230\u7684\u89e3\u6df7\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>ica</code>: \u62df\u5408\u7684 <code>tiny_ica_t</code> \u7ed3\u6784\u6307\u9488\u3002</p> </li> <li> <p><code>mixed_signals</code>: \u8f93\u5165\u6df7\u5408\u4fe1\u53f7\u6570\u7ec4\u6307\u9488\uff08\u884c\u4e3b\u5e8f\u5e03\u5c40\uff09\u3002</p> </li> <li> <p><code>num_samples</code>: \u6bcf\u4e2a\u4fe1\u53f7\u7684\u6837\u672c\u6570\u3002</p> </li> <li> <p><code>separated_sources</code>: \u5206\u79bb\u6e90\u7684\u8f93\u51fa\u6570\u7ec4\u6307\u9488\uff08\u884c\u4e3b\u5e8f\u5e03\u5c40\uff09\u3002\u5927\u5c0f\u5fc5\u987b\u81f3\u5c11\u4e3a <code>num_sources * num_samples</code>\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u6210\u529f\u65f6\u8fd4\u56de <code>TINY_OK</code>\uff0c\u5931\u8d25\u65f6\u8fd4\u56de\u9519\u8bef\u4ee3\u7801\u3002</p> <p>\u6ce8\u610f: </p> <p>\u9700\u8981\u5148\u4f7f\u7528 <code>tiny_ica_fit()</code> \u62df\u5408 <code>ica</code>\u3002\u8f93\u5165\u4fe1\u53f7\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u7684\u5747\u503c\u8fdb\u884c\u4e2d\u5fc3\u5316\u3002</p>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#tiny_ica_deinit","title":"tiny_ica_deinit","text":"<pre><code>/**\n * @name tiny_ica_deinit\n * @brief Deinitialize ICA structure and free memory\n * @param ica Pointer to ICA structure\n * @return tiny_error_t\n */\ntiny_error_t tiny_ica_deinit(tiny_ica_t *ica);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u53d6\u6d88\u521d\u59cb\u5316 ICA \u7ed3\u6784\u5e76\u91ca\u653e\u6240\u6709\u5206\u914d\u7684\u5185\u5b58\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>ica</code>: <code>tiny_ica_t</code> \u7ed3\u6784\u6307\u9488\u3002</li> </ul> <p>\u8fd4\u56de\u503c: </p> <p>\u6210\u529f\u65f6\u8fd4\u56de <code>TINY_OK</code>\uff0c\u5931\u8d25\u65f6\u8fd4\u56de\u9519\u8bef\u4ee3\u7801\u3002</p>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_8","title":"\u4f7f\u7528\u6d41\u7a0b","text":""},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_9","title":"\u7b80\u5355\u4e00\u6b21\u6027\u5206\u79bb","text":"<pre><code>float mixed_signals[2 * 512];  // 2 \u4e2a\u89c2\u6d4b\uff0c\u6bcf\u4e2a 512 \u4e2a\u6837\u672c\nfloat separated_sources[2 * 512];  // 2 \u4e2a\u6e90\uff0c\u6bcf\u4e2a 512 \u4e2a\u6837\u672c\n\n// \u6267\u884c ICA \u5206\u79bb\ntiny_error_t ret = tiny_ica_separate_f32(\n    mixed_signals, 2, 512, 2, separated_sources,\n    TINY_ICA_FASTICA, TINY_ICA_NONLINEARITY_TANH, 100, 1e-4f);\n</code></pre>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#api","title":"\u91cd\u590d\u5206\u79bb\uff08\u7ed3\u6784 API\uff09","text":"<pre><code>tiny_ica_t ica;\n\n// \u521d\u59cb\u5316\ntiny_ica_init(&amp;ica, 2, 2);  // 2 \u4e2a\u89c2\u6d4b\uff0c2 \u4e2a\u6e90\n\n// \u5c06\u6a21\u578b\u62df\u5408\u5230\u8bad\u7ec3\u6570\u636e\ntiny_ica_fit(&amp;ica, training_mixed, 512,\n             TINY_ICA_FASTICA, TINY_ICA_NONLINEARITY_TANH, 100, 1e-4f);\n\n// \u53d8\u6362\u65b0\u6570\u636e\uff08\u53ef\u4ee5\u591a\u6b21\u8c03\u7528\uff09\ntiny_ica_transform(&amp;ica, new_mixed, 512, separated);\n\n// \u6e05\u7406\ntiny_ica_deinit(&amp;ica);\n</code></pre>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_10","title":"\u5e94\u7528\u573a\u666f","text":"<p>ICA \u5e7f\u6cdb\u5e94\u7528\u4e8e\uff1a</p> <ul> <li>\u97f3\u9891\u6e90\u5206\u79bb\uff1a\u4ece\u6df7\u5408\u97f3\u9891\u4e2d\u5206\u79bb\u5355\u4e2a\u4e50\u5668\u6216\u58f0\u97f3</li> <li>\u751f\u7269\u533b\u5b66\u4fe1\u53f7\u5904\u7406\uff1a\u4ece\u4f2a\u5f71\u4e2d\u5206\u79bb EEG/ECG \u4fe1\u53f7</li> <li>\u56fe\u50cf\u5904\u7406\uff1a\u7279\u5f81\u63d0\u53d6\u3001\u53bb\u566a</li> <li>\u901a\u4fe1\uff1a\u76f2\u4fe1\u9053\u5747\u8861</li> <li>\u795e\u7ecf\u79d1\u5b66\uff1a\u5206\u6790\u8111\u4fe1\u53f7\u3001fMRI \u6570\u636e</li> <li>\u4f20\u611f\u5668\u9635\u5217\u5904\u7406\uff1a\u4ece\u591a\u4e2a\u4f20\u611f\u5668\u5206\u79bb\u4fe1\u53f7</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_11","title":"\u4f18\u7f3a\u70b9","text":""},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_12","title":"\u4f18\u70b9","text":"<ul> <li>\u76f2\u5206\u79bb\uff1a\u4e0d\u9700\u8981\u6df7\u5408\u77e9\u9635\u7684\u5148\u9a8c\u77e5\u8bc6</li> <li>\u7edf\u8ba1\u72ec\u7acb\u6027\uff1a\u627e\u5230\u771f\u6b63\u72ec\u7acb\u7684\u6e90</li> <li>\u975e\u9ad8\u65af\u6e90\uff1a\u9002\u7528\u4e8e\u975e\u9ad8\u65af\u4fe1\u53f7</li> <li>\u7075\u6d3b\uff1a\u53ef\u4ee5\u5904\u7406\u4e0d\u540c\u6570\u91cf\u7684\u6e90\u548c\u89c2\u6d4b</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_13","title":"\u7f3a\u70b9","text":"<ul> <li>\u6a21\u7cca\u6027\uff1a\u5206\u79bb\u6e90\u7684\u5c3a\u5ea6\u548c\u7b26\u53f7\u662f\u6a21\u7cca\u7684</li> <li>\u987a\u5e8f\u6a21\u7cca\u6027\uff1a\u5206\u79bb\u6e90\u7684\u987a\u5e8f\u662f\u4efb\u610f\u7684</li> <li>\u975e\u9ad8\u65af\u8981\u6c42\uff1a\u6700\u591a\u4e00\u4e2a\u6e90\u53ef\u4ee5\u662f\u9ad8\u65af\u5206\u5e03</li> <li>\u8ba1\u7b97\u6210\u672c\uff1a\u767d\u5316\u548c\u7279\u5f81\u503c\u5206\u89e3\u53ef\u80fd\u5f88\u6602\u8d35</li> <li>\u6536\u655b\u6027\uff1a\u5bf9\u4e8e\u67d0\u4e9b\u4fe1\u53f7\u7c7b\u578b\u53ef\u80fd\u4e0d\u6536\u655b</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_14","title":"\u8bbe\u8ba1\u8003\u8651","text":""},{"location":"zh/DSP/TRANSFORM/ICA/notes/#vs","title":"\u6e90\u6570\u91cf vs \u89c2\u6d4b\u6570\u91cf","text":"<ul> <li>\u65b9\u9635\u60c5\u51b5\uff08num_obs = num_sources\uff09\uff1a\u6807\u51c6 ICA \u95ee\u9898</li> <li>\u8d85\u5b9a\uff08num_obs &gt; num_sources\uff09\uff1a\u53ef\u4ee5\u9996\u5148\u4f7f\u7528 PCA \u964d\u4f4e\u7ef4\u5ea6</li> <li>\u6b20\u5b9a\uff08num_obs &lt; num_sources\uff09\uff1a\u4e0d\u652f\u6301\uff08\u65e0\u6cd5\u63d0\u53d6\u6bd4\u89c2\u6d4b\u66f4\u591a\u7684\u6e90\uff09</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_15","title":"\u975e\u7ebf\u6027\u9009\u62e9","text":"<ul> <li>tanh\uff1a\u9ed8\u8ba4\u9009\u62e9\uff0c\u9002\u7528\u4e8e\u5927\u591a\u6570\u8d85\u9ad8\u65af\u6e90\uff08\u8bed\u97f3\u3001\u97f3\u4e50\uff09</li> <li>exp\uff1a\u7528\u4e8e\u6b21\u9ad8\u65af\u6e90\uff08\u5747\u5300\u566a\u58f0\u3001\u67d0\u4e9b\u56fe\u50cf\u4fe1\u53f7\uff09</li> <li>cube\uff1a\u8d85\u9ad8\u65af\u6e90\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u66f4\u7b80\u5355\u4f46\u4e0d\u592a\u7a33\u5065</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_16","title":"\u6536\u655b\u53c2\u6570","text":"<ul> <li>max_iter\uff1a\u901a\u5e38 50-200 \u6b21\u8fed\u4ee3\u3002\u56f0\u96be\u60c5\u51b5\u4e0b\u9700\u8981\u66f4\u591a\u8fed\u4ee3\u3002</li> <li>tolerance\uff1a\u901a\u5e38 1e-4 \u5230 1e-6\u3002\u66f4\u5c0f\u7684\u5bb9\u5dee = \u66f4\u51c6\u786e\u4f46\u66f4\u6162\u3002</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_17","title":"\u6570\u636e\u8981\u6c42","text":"<ul> <li>\u6837\u672c\u5927\u5c0f\uff1a\u66f4\u591a\u6837\u672c = \u66f4\u597d\u7684\u5206\u79bb\u8d28\u91cf</li> <li>\u72ec\u7acb\u6027\uff1a\u6e90\u5fc5\u987b\u5728\u7edf\u8ba1\u4e0a\u72ec\u7acb</li> <li>\u975e\u9ad8\u65af\u6027\uff1a\u6700\u591a\u4e00\u4e2a\u6e90\u53ef\u4ee5\u662f\u9ad8\u65af\u5206\u5e03</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/notes/#_18","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>ICA \u53ea\u80fd\u5206\u79bb\u6e90\u5230\u7f29\u653e\u56e0\u5b50\u548c\u6392\u5217\u7684\u7a0b\u5ea6</li> <li>\u5206\u79bb\u6e90\u7684\u987a\u5e8f\u53ef\u80fd\u4e0e\u539f\u59cb\u987a\u5e8f\u4e0d\u5339\u914d</li> <li>\u5f53\u6e90\u5177\u6709\u4e0d\u540c\u7edf\u8ba1\u7279\u6027\u65f6\uff0cICA \u6548\u679c\u6700\u597d</li> <li>\u767d\u5316\u662f ICA \u7684\u5173\u952e\u9884\u5904\u7406\u6b65\u9aa4</li> <li>FastICA \u56e0\u5176\u901f\u5ea6\u548c\u7b80\u5355\u6027\u800c\u6210\u4e3a\u6d41\u884c\u7b97\u6cd5</li> </ul>"},{"location":"zh/DSP/TRANSFORM/ICA/test/","title":"\u6d4b\u8bd5","text":""},{"location":"zh/DSP/TRANSFORM/ICA/test/#_2","title":"\u8f93\u51fa\u7ed3\u679c","text":"<pre><code>========== TinyICA Test ==========\n\n========================================\nSTEP 1: Generating Source Signals\n========================================\nConfiguration:\n  - Number of sources: 2\n  - Number of samples: 512\n  - Sample rate: 1000.0 Hz\n  - Duration: 0.512 seconds\n\nSource Signal Details:\n  Source 1: 10.0 Hz sinusoid (sin(2\u03c0*10.0*t))\n    Statistics: mean=0.0078, std=0.7012, min=-1.0000, max=1.0000\n  Source samples (first 8 and last 8):\n    First 8: 0.0000 0.0628 0.1253 0.1874 0.2487 0.3090 0.3681 0.4258 \n    Last 8:  0.2487 0.3090 0.3681 0.4258 0.4818 0.5358 0.5878 0.6374 \n\nSource 1 (10.0 Hz)\nValue\n  1.20 |                                                                \n  0.98 |   **          **          **           **          **          \n  0.76 |  * *         *  *        *  *         * *         *  *         \n  0.55 | *   *       *   *        *  *        *   *       *   *        *\n  0.33 |*    *       *    *      *    *      *    *       *    *      * \n  0.11 |*     *     *     *      *    *      *     *     *     *      * \n -0.11 |*     *     *     *     *      *    *      *     *     *     *  \n -0.33 |       *   *       *    *      *    *       *   *       *    *  \n -0.55 |       *   *       *   *        *   *       *   *       *   *   \n -0.76 |        * *         *  *        *  *         * *         *  *   \n -0.98 |         **          **          **           **          **    \n -1.20 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.200, 1.200], Length: 512\n\n\n  Source 2: 30.0 Hz sinusoid (sin(2\u03c0*30.0*t))\n    Statistics: mean=0.0162, std=0.7083, min=-1.0000, max=1.0000\n  Source samples (first 8 and last 8):\n    First 8: 0.0000 0.1874 0.3681 0.5358 0.6845 0.8090 0.9048 0.9686 \n    Last 8:  0.6845 0.8090 0.9048 0.9686 0.9980 0.9921 0.9511 0.8763 \n\nSource 2 (30.0 Hz)\nValue\n  1.20 |                                                                \n  0.98 | *   *   *                *   *   *   *   *   *                *\n  0.76 |**  **  **   *   **   *  **  **  **  **  **  **   *   **   *  * \n  0.55 |**  **  **  * * * *  **  **  **  **  **  **  **  * * * *  **  * \n  0.33 |**  * * * * * * * * * * * *  **  **  **  * * * * * * * * * * *  \n  0.11 |* * * * * * * * * * * * * * * *  **  * * * * * * * * * * * * *  \n -0.11 |* * * * * * * * * * * * * * * * *  **  * * * * * * * * * * * *  \n -0.33 |  **  * * * * * * * * * *  **  **  **  **  * * * * * * * * * *  \n -0.55 |  **  **  * * * * * *  **  **  **  **  **  **  * * * * * *  **  \n -0.76 |  **  **  **   *   **   *  **  **  **  **  **  **   *   **   *  \n -0.98 |   *   *   *                *   *   *   *   *   *               \n -1.20 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.200, 1.200], Length: 512\n\n\n========================================\nSTEP 2: Creating Mixing Matrix\n========================================\nMixing Matrix A (num_obs x num_sources = 2 x 2):\n  [0.800  0.300]\n  [0.200  0.700]\n\nMixing Equation:\n  Observation 1 = 0.800 * Source 1 + 0.300 * Source 2\n  Observation 2 = 0.200 * Source 1 + 0.700 * Source 2\n\n========================================\nSTEP 3: Mixing Signals (X = A * S)\n========================================\nProcess: Multiplying mixing matrix by source signals\n\u2713 Mixed 2 sources into 2 observations\n\nMixed Signal Details:\n  Observation 1:\n    Statistics: mean=0.0111, std=0.6025, min=-0.7788, max=0.7788\n  Mixed samples (first 8 and last 8):\n    First 8: 0.0000 0.1064 0.2107 0.3107 0.4043 0.4899 0.5659 0.6312 \n    Last 8:  0.4043 0.4899 0.5659 0.6312 0.6848 0.7263 0.7555 0.7728 \n\nMixed Observation 1\nValue\n  0.93 |                                                                \n  0.76 | **  *        *  *        *  *        **  *        *  *        *\n  0.59 |* * **       * ***       * ** *      * * **       * ***       * \n  0.42 |*  * *      *     *      *    *      *  * *      *     *      * \n  0.25 |*    *      *     *      *    *      *    *      *     *      * \n  0.08 |*     *     *     *     *     *      *     *     *     *     *  \n -0.08 |*     *     *     *     *      *    *      *     *     *     *  \n -0.25 |      *     *     *     *      *    *      *     *     *     *  \n -0.42 |      *    *       *    *      *  * *      *    *       *    *  \n -0.59 |       * ***       * ** *      * ** *       * ***       * ***   \n -0.76 |        *  *        *  *        *  **        *  *        *  *   \n -0.93 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-0.935, 0.935], Length: 512\n\n\n  Observation 2:\n    Statistics: mean=0.0129, std=0.5171, min=-0.8016, max=0.8016\n  Mixed samples (first 8 and last 8):\n    First 8: 0.0000 0.1437 0.2828 0.4126 0.5289 0.6281 0.7070 0.7632 \n    Last 8:  0.5289 0.6281 0.7070 0.7632 0.7950 0.8016 0.7833 0.7409 \n\nMixed Observation 2\nValue\n  0.96 |                                                                \n  0.79 | *   *                    *   *       *   *                    *\n  0.61 |**  **       **  **      **  **      **  **       **  *       * \n  0.44 |**  **   *  * * * *   *  **  **   *  **  **   *  * * * *   *  * \n  0.26 |* * * * **  * * * *  ** * * * *  **  * * **  **  * * * *  ** *  \n  0.09 |* * * * * * * * * * * * * * * *  **  * * * * * * * * * * * * *  \n -0.09 |  **  * * * * * * * * * *  ** *  ** *  **  * * * * * * * * * *  \n -0.26 |  **  * * * * * * * * * *  **  **  **  **  * * * * * * * * * *  \n -0.44 |   *  * * * *  *  * * * *   *  **  **   *  * * * *  *  * * * *  \n -0.61 |      **  **       **  **      **  **      **  **       **  **  \n -0.79 |       *   *                    *   *       *   *               \n -0.96 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-0.962, 0.962], Length: 512\n\n\n========================================\nSTEP 4: ICA Separation (FastICA Algorithm)\n========================================\nAlgorithm: FastICA\nNonlinearity: tanh (for super-Gaussian sources)\nMax iterations: 100\nConvergence tolerance: 1e-4\nProcess:\n  1. Center data (subtract mean)\n  2. Whiten data (decorrelate and normalize variance)\n  3. Extract independent components using FastICA\n  4. Reconstruct separated sources\n\n\u2713 ICA separation completed successfully\n\n========================================\nSTEP 5: Evaluating Separation Quality\n========================================\nSeparated Signal Details:\n\n  Separated Component 1 (matches Source 1):\n    Correlation with original: 0.959623\n    Statistics: mean=-0.0000, std=1.0000, min=-1.2638, max=1.2299\n    Original Source 1: mean=0.0078, std=0.7012, min=-1.0000, max=1.0000\n  Separated samples (first 8 and last 8):\n    First 8: -0.0170 0.1430 0.3001 0.4513 0.5939 0.7256 0.8442 0.9481 \n    Last 8:  0.5939 0.7256 0.8442 0.9481 1.0361 1.1074 1.1620 1.1999 \n\nSeparated Component 1 (matches Source 1)\nValue\n  1.48 |                                                                \n  1.21 |  * **        *  *        ** *         * **        *  *        *\n  0.94 | * * *       * ***       *  * *       * * *       * ***       * \n  0.66 |*    *       *    *      *    *      *    *       *    *      * \n  0.39 |*    *      *     *      *    *      *    *      *     *      * \n  0.12 |*     *     *     *     *     *      *     *     *     *     *  \n -0.15 |*     *     *     *     *      *    *      *     *     *     *  \n -0.43 |      *     *     *     *      *    *      *     *     *     *  \n -0.70 |      *    *       *    *      *    *      *    *       *    *  \n -0.97 |       * * *       * ***       *  * *       * * *       * ***   \n -1.24 |        * **        *  *        ** *         * **        *  *   \n -1.51 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.513, 1.479], Length: 512\n\n\nOriginal Source 1 (for comparison)\nValue\n  1.20 |                                                                \n  0.98 |   **          **          **           **          **          \n  0.76 |  * *         *  *        *  *         * *         *  *         \n  0.55 | *   *       *   *        *  *        *   *       *   *        *\n  0.33 |*    *       *    *      *    *      *    *       *    *      * \n  0.11 |*     *     *     *      *    *      *     *     *     *      * \n -0.11 |*     *     *     *     *      *    *      *     *     *     *  \n -0.33 |       *   *       *    *      *    *       *   *       *    *  \n -0.55 |       *   *       *   *        *   *       *   *       *   *   \n -0.76 |        * *         *  *        *  *         * *         *  *   \n -0.98 |         **          **          **           **          **    \n -1.20 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.200, 1.200], Length: 512\n\n    Normalized RMSE: 0.284173\n    Quality: Excellent\n\n  Separated Component 2 (matches Source 2):\n    Correlation with original: 0.955788\n    Statistics: mean=0.0000, std=1.0000, min=-1.7930, max=1.7557\n    Original Source 2: mean=0.0162, std=0.7083, min=-1.0000, max=1.0000\n  Separated samples (first 8 and last 8):\n    First 8: -0.0186 0.2089 0.4276 0.6288 0.8046 0.9479 1.0530 1.1152 \n    Last 8:  0.8046 0.9479 1.0530 1.1152 1.1316 1.1009 1.0235 0.9014 \n\nSeparated Component 2 (matches Source 2)\nValue\n  2.11 |                                                                \n  1.72 |         *                        *           *                 \n  1.34 |        **           **          **          **           **    \n  0.95 | *   *  * *  *    * * *   *   *  **   *   *  * *  *    * * *   *\n  0.56 |**  **  * * * *  ** * *  **  **  **  **  **  * * * *  ** * *  * \n  0.17 |**  * * * * * * * * * * * *  ** *  * **  * * * * * * * * * * *  \n -0.21 |* * * * * * * * * * * * * * *  **  **  * * * * * * * * * * * *  \n -0.60 |  * * **  * * * * * *  ** * *  **  **  * * **  * * * * * *  **  \n -0.99 |  **   *   *  * *  *    *  **   *   *  **   *   *  * *  *    *  \n -1.37 |  **           **          **          **           **          \n -1.76 |   *                        *           *                       \n -2.15 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-2.148, 2.111], Length: 512\n\n\nOriginal Source 2 (for comparison)\nValue\n  1.20 |                                                                \n  0.98 | *   *   *                *   *   *   *   *   *                *\n  0.76 |**  **  **   *   **   *  **  **  **  **  **  **   *   **   *  * \n  0.55 |**  **  **  * * * *  **  **  **  **  **  **  **  * * * *  **  * \n  0.33 |**  * * * * * * * * * * * *  **  **  **  * * * * * * * * * * *  \n  0.11 |* * * * * * * * * * * * * * * *  **  * * * * * * * * * * * * *  \n -0.11 |* * * * * * * * * * * * * * * * *  **  * * * * * * * * * * * *  \n -0.33 |  **  * * * * * * * * * *  **  **  **  **  * * * * * * * * * *  \n -0.55 |  **  **  * * * * * *  **  **  **  **  **  **  * * * * * *  **  \n -0.76 |  **  **  **   *   **   *  **  **  **  **  **  **   *   **   *  \n -0.98 |   *   *   *                *   *   *   *   *   *               \n -1.20 |                                                                \n       ----------------------------------------------------------------\n       0       8       16      24      32      40      48      56       (Sample Index)\nRange: [-1.200, 1.200], Length: 512\n\n    Normalized RMSE: 0.297362\n    Quality: Excellent\n\n========================================\nSTEP 6: Testing ICA Structure API\n========================================\nThis tests the reusable ICA structure for multiple separations:\n  1. Initialize ICA structure\n  2. Fit model to training data\n  3. Transform new data using learned model\n  4. Compare with direct separation\n\n  \u2713 ICA structure initialized\n  \u2713 ICA model fitted\n  \u2713 ICA transform completed\n  RMSE between direct and structure API: 1.414214\n  \u2713 ICA structure deinitialized\n\n========================================\nSUMMARY: ICA Test Results\n========================================\nTest Configuration:\n  - Sources: 2 independent signals\n  - Observations: 2 mixed signals\n  - Samples: 512 per signal\n  - Sample rate: 1000.0 Hz\n\nSeparation Quality Summary:\n  Component 1 \u2192 Source 1: Correlation = 0.959623 (Excellent)\n  Component 2 \u2192 Source 2: Correlation = 0.955788 (Excellent)\n\nExpected vs Actual:\n  Expected: Separated signals should match original sources\n  Actual: ICA successfully extracted independent components\n  Note: ICA may recover sources with different scale/sign, which is normal\n        (correlation measures similarity regardless of scale)\n\n========== TinyICA Test Complete ==========\n</code></pre>"},{"location":"zh/DSP/USAGE/usage/","title":"\u4f7f\u7528\u8bf4\u660e","text":"<p>\u4f7f\u7528\u8bf4\u660e</p> <p>\u8be5\u6587\u6863\u662f\u5bf9 <code>tiny_dsp</code> \u6a21\u5757\u7684\u4f7f\u7528\u8bf4\u660e\u3002</p>"},{"location":"zh/DSP/USAGE/usage/#tinydsp","title":"\u6574\u4f53\u5f15\u5165TinyDSP","text":"<p>Info</p> <p>\u9002\u7528\u4e8eC\u9879\u76ee\uff0c\u6216\u8005\u7ed3\u6784\u8f83\u4e3a\u7b80\u5355\u7684C++\u9879\u76ee\u3002</p> <pre><code>#include \"tiny_dsp.h\"\n</code></pre>"},{"location":"zh/DSP/USAGE/usage/#tinydsp_1","title":"\u5206\u6a21\u5757\u5f15\u5165TinyDSP","text":"<p>Info</p> <p>\u9002\u7528\u4e8e\u9700\u8981\u7cbe\u786e\u63a7\u5236\u5f15\u5165\u6a21\u5757\u7684\u9879\u76ee\uff0c\u6216\u8005\u590d\u6742\u7684C++\u9879\u76ee\u3002</p> <pre><code>// \u4fe1\u53f7\u5904\u7406\u6a21\u5757 (signal/)\n#include \"tiny_conv.h\"        // \u5377\u79ef\u6a21\u5757\n#include \"tiny_corr.h\"        // \u76f8\u5173\u6a21\u5757\n#include \"tiny_resample.h\"    // \u91cd\u91c7\u6837\u6a21\u5757\n\n// \u6ee4\u6ce2\u5668\u6a21\u5757 (filter/)\n#include \"tiny_fir.h\"         // FIR\u6ee4\u6ce2\u5668\u6a21\u5757\n#include \"tiny_iir.h\"         // IIR\u6ee4\u6ce2\u5668\u6a21\u5757\n\n// \u53d8\u6362\u6a21\u5757 (transform/)\n#include \"tiny_fft.h\"         // \u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\u6a21\u5757\n#include \"tiny_dwt.h\"         // \u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u6a21\u5757\n#include \"tiny_ica.h\"         // \u72ec\u7acb\u6210\u5206\u5206\u6790\u6a21\u5757\n\n// \u652f\u6301\u529f\u80fd\u6a21\u5757 (support/)\n#include \"tiny_view.h\"        // \u4fe1\u53f7\u67e5\u770b/\u652f\u6301\u6a21\u5757\n</code></pre> <p>Tip</p> <p>\u5177\u4f53\u7684\u4f7f\u7528\u65b9\u6cd5\u8bf7\u53c2\u8003\u6d4b\u8bd5\u4ee3\u7801\u3002</p>"},{"location":"zh/MATH/math/","title":"\u6570\u5b66\u8fd0\u7b97","text":"<p>Note</p> <p>\u8be5\u7ec4\u4ef6\u7528\u4e8e \u6570\u5b66\u8fd0\u7b97 \uff0c\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5e93\uff0c\u63d0\u4f9b\u57fa\u672c\u7684\u6570\u5b66\u51fd\u6570\uff0c\u4ee5\u4fbf\u4e8e\u677f\u8f7d\u8ba1\u7b97\u548cAI\u6a21\u578b\u63a8\u7406\u3002\u8be5\u5e93\u8bbe\u8ba1\u4e3a \u8f7b\u91cf\u9ad8\u6548 \uff0c\u9002\u5408\u8fb9\u7f18\u8ba1\u7b97\u5e94\u7528\u3002</p> <p>Note</p> <p>\u8be5\u7ec4\u4ef6\u57fa\u4e8eESP32\u5b98\u65b9\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u5e93 ESP-DSP \u8fdb\u884c\u5c01\u88c5\u548c\u6269\u5c55\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u5c42\u6b21\u7684API\u63a5\u53e3\u3002\u7b80\u5355\u6765\u8bf4\uff0cTinyMath\u5e93\u5bf9\u5e94ESP-DSP\u4e2d\u7684Math, Matrix, DotProduct\u6a21\u5757\uff0cESP-DSP\u4e2d\u7684\u5176\u4f59\u6a21\u5757\u5bf9\u5e94TinyDSP\u5e93\u3002</p>"},{"location":"zh/MATH/math/#_2","title":"\u7ec4\u4ef6\u4f9d\u8d56","text":"<pre><code>set(src_dirs\n    .\n    vec\n    mat\n)\n\nset(include_dirs\n    .\n    include\n    vec\n    mat\n)\n\nset(requires\n    tiny_toolbox\n)\n\nidf_component_register(SRC_DIRS ${src_dirs} INCLUDE_DIRS ${include_dirs} REQUIRES ${requires})\n</code></pre>"},{"location":"zh/MATH/math/#_3","title":"\u67b6\u6784\u4e0e\u529f\u80fd\u76ee\u5f55","text":""},{"location":"zh/MATH/math/#_4","title":"\u4f9d\u8d56\u5173\u7cfb\u793a\u610f\u56fe","text":""},{"location":"zh/MATH/math/#_5","title":"\u4ee3\u7801\u6811","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 include\n    |   \u251c\u2500\u2500 tiny_error_type.h // error type header file\n    |   \u251c\u2500\u2500 tiny_constant.h // constant header file\n    |   \u251c\u2500\u2500 tiny_math_config.h // configuration header file\n    |   \u2514\u2500\u2500 tiny_math.h // main header file, include this file where you want to use the library\n    \u251c\u2500\u2500 vec\n    |   \u251c\u2500\u2500 tiny_vec.h // vector header file\n    |   \u251c\u2500\u2500 tiny_vec.c // vector source file\n    |   \u251c\u2500\u2500 tiny_vec_test.c // vector test file\n    |   \u2514\u2500\u2500 tiny_vec_test.h // vector test header file\n    \u251c\u2500\u2500 mat\n    |   \u251c\u2500\u2500 tiny_mat.h // matrix header file - c\n    |   \u251c\u2500\u2500 tiny_mat.c // matrix source file - c\n    |   \u251c\u2500\u2500 tiny_mat_test.c // matrix test file - c \n    |   \u251c\u2500\u2500 tiny_mat_test.h // matrix test header file - c\n    |   \u251c\u2500\u2500 tiny_matrix.hpp // matrix header file - cpp\n    |   \u251c\u2500\u2500 tiny_matrix.cpp // matrix source file - cpp\n    |   \u251c\u2500\u2500 tiny_matrix_test.cpp // matrix test file - cpp\n    |   \u2514\u2500\u2500 tiny_matrix_test.hpp // matrix test header file - cpp\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/","title":"ESP-DSP \u6570\u5b57\u4fe1\u53f7\u5904\u7406\u5e93","text":"<ul> <li> <p> ESP-DSP</p> <p>\u4e00\u4e2a Espressif DSP \u5e93 (esp-dsp)\uff0c\u5b83\u662f\u4e00\u4e2a\u51fd\u6570\u3001\u6a21\u5757\u548c\u7ec4\u4ef6\u7684\u5e93\uff0c\u63d0\u4f9b\u4e86\u4ee5\u9ad8\u6548\u7684\u65b9\u5f0f\u4f7f\u7528 Espressif \u7684 CPU \u4f5c\u4e3a DSP \u7684\u53ef\u80fd\u6027\u3002</p> <p>  \u5728\u7ebf\u6587\u6863 </p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_1","title":"\u51fd\u6570\u547d\u540d","text":"<p>\u547d\u540d\u7ea6\u5b9a\u9002\u7528\u4e8e\u6240\u6709\u8986\u76d6\u7684\u9886\u57df\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7 dsps \u524d\u7f00\u533a\u5206\u4fe1\u53f7\u5904\u7406\u51fd\u6570\uff0c\u800c\u56fe\u50cf\u548c\u89c6\u9891\u5904\u7406\u51fd\u6570\u5177\u6709 dspi \u524d\u7f00\uff0c\u7279\u5b9a\u4e8e\u5c0f\u77e9\u9635\u64cd\u4f5c\u7684\u51fd\u6570\u5728\u5176\u540d\u79f0\u4e2d\u5177\u6709 dspm \u524d\u7f00\u3002\u5e93\u4e2d\u7684\u51fd\u6570\u540d\u79f0\u5177\u6709\u4ee5\u4e0b\u901a\u7528\u683c\u5f0f\uff1a</p> <pre><code>dsp&lt;data-domain&gt;_&lt;name&gt;_&lt;datatype1&gt;&lt;datatype_ext&gt;_&lt;datatype2&gt;&lt;datatype_ext&gt;[_&lt;descriptor&gt;]&lt;_impl&gt;(&lt;parameters&gt;);\n</code></pre> <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p><code>&lt;data-domain&gt;</code> \u662f\u51fd\u6570\u7684\u57df\uff0c\u4f8b\u5982 <code>s</code> \u8868\u793a\u4fe1\u53f7\u5904\u7406\uff0c<code>i</code> \u8868\u793a\u56fe\u50cf\u5904\u7406\uff0c<code>v</code> \u8868\u793a\u89c6\u9891\u5904\u7406\uff0c<code>m</code> \u8868\u793a\u5c0f\u77e9\u9635\u64cd\u4f5c\u3002</p> </li> <li> <p><code>&lt;name&gt;</code> \u662f\u51fd\u6570\u7684\u540d\u79f0\u3002</p> </li> <li> <p><code>&lt;datatype1&gt;</code> \u662f\u7b2c\u4e00\u4e2a\u8f93\u5165\u53c2\u6570\u7684\u7c7b\u578b\u3002</p> </li> <li> <p><code>&lt;datatype_ext&gt;</code> \u662f\u7b2c\u4e00\u4e2a\u8f93\u5165\u53c2\u6570\u7684\u7c7b\u578b\uff0c\u540e\u7f00\u8868\u793a\u6570\u636e\u7684\u7c7b\u578b\uff0c\u4f8b\u5982 <code>f</code> \u8868\u793a\u6d6e\u70b9\u6570\uff0c<code>i</code> \u8868\u793a\u6574\u6570\uff0c<code>c</code> \u8868\u793a\u590d\u6570\u7b49\u3002</p> </li> <li> <p><code>&lt;datatype2&gt;</code> \u662f\u7b2c\u4e8c\u4e2a\u8f93\u5165\u53c2\u6570\u7684\u7c7b\u578b\u3002</p> </li> <li> <p><code>&lt;descriptor&gt;</code> \u662f\u4e00\u4e2a\u53ef\u9009\u63cf\u8ff0\u7b26\uff0c\u63d0\u4f9b\u6709\u5173\u51fd\u6570\u7684\u9644\u52a0\u4fe1\u606f\u3002</p> </li> <li> <p><code>&lt;impl&gt;</code> \u662f\u4e00\u4e2a\u53ef\u9009\u5b9e\u73b0\u63cf\u8ff0\u7b26\uff0c\u63d0\u4f9b\u6709\u5173\u51fd\u6570\u5b9e\u73b0\u7684\u9644\u52a0\u4fe1\u606f\u3002</p> </li> <li> <p><code>&lt;parameters&gt;</code> \u662f\u51fd\u6570\u7684\u53c2\u6570\u3002</p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_2","title":"\u6570\u636e\u57df","text":"<p>\u6570\u636e\u57df\u662f\u4e00\u4e2a\u5355\u5b57\u7b26\uff0c\u8868\u793a\u7ed9\u5b9a\u51fd\u6570\u6240\u5c5e\u7684\u529f\u80fd\u5b50\u96c6\u3002\u5e93\u8bbe\u8ba1\u4e3a\u652f\u6301\u4ee5\u4e0b\u6570\u636e\u57df\uff1a</p> <ul> <li> <p>s - \u4fe1\u53f7\uff08\u9884\u671f\u6570\u636e\u7c7b\u578b\u4e3a 1D \u4fe1\u53f7\uff09</p> </li> <li> <p>i - \u56fe\u50cf\u548c\u89c6\u9891\uff08\u9884\u671f\u6570\u636e\u7c7b\u578b\u4e3a 2D \u56fe\u50cf\uff09</p> </li> <li> <p>m - \u77e9\u9635\uff08\u9884\u671f\u6570\u636e\u7c7b\u578b\u4e3a\u77e9\u9635\uff09</p> </li> <li> <p>r - \u903c\u771f\u6e32\u67d3\u529f\u80fd\u548c 3D \u6570\u636e\u5904\u7406\uff08\u9884\u671f\u6570\u636e\u7c7b\u578b\u53d6\u51b3\u4e8e\u652f\u6301\u7684\u6e32\u67d3\u6280\u672f\uff09</p> </li> <li> <p>q - \u56fa\u5b9a\u957f\u5ea6\u4fe1\u53f7</p> </li> </ul> <p>\u4f8b\u5982\uff0c\u4ee5 dspi \u5f00\u5934\u7684\u51fd\u6570\u540d\u79f0\u8868\u793a\u76f8\u5e94\u7684\u51fd\u6570\u7528\u4e8e\u56fe\u50cf\u6216\u89c6\u9891\u5904\u7406\u3002</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_3","title":"\u540d\u79f0","text":"<p>\u51fd\u6570\u540d\u79f0\u662f\u51fd\u6570\u5b9e\u9645\u6267\u884c\u7684\u6838\u5fc3\u64cd\u4f5c\u7684\u7f29\u5199\uff0c\u4f8b\u5982 Add\u3001Sqrt\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f1a\u540e\u8ddf\u51fd\u6570\u7279\u5b9a\u7684\u4fee\u9970\u7b26\uff1a= [_modifier]</p> <p>\u5982\u679c\u5b58\u5728\u6b64\u4fee\u9970\u7b26\uff0c\u5219\u8868\u793a\u5bf9\u7ed9\u5b9a\u51fd\u6570\u8fdb\u884c\u4e86\u7ec6\u5fae\u7684\u4fee\u6539\u6216\u53d8\u4f53\u3002</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_4","title":"\u6570\u636e\u7c7b\u578b","text":"<p>\u8be5\u5e93\u652f\u6301\u4e24\u79cd\u4e3b\u8981\u6570\u636e\u7c7b\u578b\uff1a\u7528\u4e8e\u5b9a\u70b9\u8fd0\u7b97\u7684 int16 \u548c\u7528\u4e8e\u6d6e\u70b9\u8fd0\u7b97\u7684 float\u3002\u6570\u636e\u7c7b\u578b\u63cf\u8ff0\u5982\u4e0b\uff1a</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_5","title":"\u6570\u636e\u7c7b\u578b\u540e\u7f00","text":"<ul> <li> <p>s - \u6709\u7b26\u53f7</p> </li> <li> <p>u - \u65e0\u7b26\u53f7</p> </li> <li> <p>f - \u6d6e\u70b9\u6570</p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_6","title":"\u6570\u636e\u7c7b\u578b\u6269\u5c55","text":"<ul> <li>c - \u590d\u6570</li> </ul>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_7","title":"\u6570\u636e\u7c7b\u578b\u6bd4\u7279\u5206\u8fa8\u7387","text":"<ul> <li> <p>16</p> </li> <li> <p>32</p> </li> </ul> <p>\u4f8b\u5982\uff1adsps_mac_sc16 \u5b9a\u4e49\u5c06\u4f7f\u7528 16 \u4f4d\u6709\u7b26\u53f7\u590d\u6570\u6570\u636e\u5bf9 1d \u6570\u7ec4\u8fdb\u884c m\u200b\u200bac \u8fd0\u7b97\u3002</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_8","title":"\u5b9e\u73b0\u65b9\u5f0f\u7c7b\u578b","text":"<p>\u6bcf\u4e2a\u51fd\u6570\u53ef\u4ee5\u9488\u5bf9\u4e0d\u540c\u7684\u5e73\u53f0\u8fdb\u884c\u4e0d\u540c\u7684\u5b9e\u73b0\uff0c\u5e76\u4e14\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u6837\u5f0f\u548c\u8d44\u6e90\u3002\u56e0\u6b64\uff0c\u6bcf\u4e2a\u5b9e\u73b0\u7684\u51fd\u6570\u90fd\u4f1a\u6709\u4e00\u4e2a\u6269\u5c55\u540d &lt;_impl&gt;\uff0c\u7528\u4e8e\u5b9a\u4e49\u5176\u5b9e\u73b0\u7c7b\u578b\u3002\u7528\u6237\u65e0\u9700\u6269\u5c55\u540d\u5373\u53ef\u4f7f\u7528\u901a\u7528\u51fd\u6570\u3002</p>"},{"location":"zh/MATH/ESP-DSP/esp-dsp/#_9","title":"\u5b9e\u73b0\u65b9\u5f0f\u7c7b\u578b\u540e\u7f00","text":"<p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u51fd\u6570\u65e0\u9700\u6269\u5c55\u5373\u53ef\u4f7f\u7528\u3002\u60a8\u53ef\u4ee5\u5728 menuconfig \u4e2d\u9009\u62e9\u201coptimized/ansi\u201d\u9009\u9879\u3002</p> <p>\u5e93\u4e2d\u7684\u6269\u5c55\u5305\u62ec\uff1a</p> <ul> <li> <p>_ansi - \u901a\u7528\u51fd\u6570\uff0c\u5176\u51fd\u6570\u4f53\u4f7f\u7528 ANSI C \u5b9e\u73b0\u3002\u6b64\u5b9e\u73b0\u4e0d\u5305\u542b\u4efb\u4f55\u786c\u4ef6\u4f18\u5316\u3002</p> </li> <li> <p>_ae32 - \u4f7f\u7528 ESP32 \u6c47\u7f16\u5668\u7f16\u5199\uff0c\u5e76\u9488\u5bf9 ESP32 \u8fdb\u884c\u4e86\u4f18\u5316\u3002</p> </li> <li> <p>_aes3 - \u4f7f\u7528 ESP32S3 \u6c47\u7f16\u5668\u7f16\u5199\uff0c\u5e76\u9488\u5bf9 ESP32S3 \u8fdb\u884c\u4e86\u4f18\u5316\u3002</p> </li> <li> <p>_arp4 - \u4f7f\u7528 ESP32P4 \u6c47\u7f16\u5668\u7f16\u5199\uff0c\u5e76\u9488\u5bf9 ESP32P4 \u8fdb\u884c\u4e86\u4f18\u5316\u3002</p> </li> <li> <p>_platform - \u5934\u6587\u4ef6\uff0c\u5176\u4e2d\u5305\u542b\u9488\u5bf9\u4e0d\u540c\u51fd\u6570\u7684\u53ef\u7528 CPU \u6307\u4ee4\u5b9a\u4e49\u3002</p> </li> <li> <p>\u5176\u4ed6 - \u53d6\u51b3\u4e8e\u652f\u6301\u7684 CPU \u6570\u91cf\u3002\u6b64\u5217\u8868\u672a\u6765\u5c06\u4e0d\u65ad\u6269\u5c55\u3002</p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/examples/","title":"ESP-DSP \u6848\u4f8b","text":""},{"location":"zh/MATH/ESP-DSP/examples/#esp-dsp_1","title":"esp-dsp \u793a\u4f8b\u5217\u8868","text":"<p>\u4fe1\u53f7\u5904\u7406 API \u4f7f\u7528 dsps \u524d\u7f00\u3002\u4ee5\u4e0b\u6a21\u5757\u53ef\u7528\uff1a</p> <ul> <li> <p>\u57fa\u7840\u6570\u5b66 - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528\u57fa\u672c\u5411\u91cf\u6570\u5b66\u8fd0\u7b97</p> </li> <li> <p>\u70b9\u79ef - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528\u70b9\u79ef\u51fd\u6570</p> </li> <li> <p>\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362 - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 FFT \u529f\u80fd</p> </li> <li> <p>\u7a97\u53e3 FFT - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528\u7a97\u53e3\u548c FFT \u529f\u80fd</p> </li> <li> <p>\u5b9e\u6570 FFT - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 FFT \u529f\u80fd\u5904\u7406\u5b9e\u6570\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u65e0\u9650\u8109\u51b2\u54cd\u5e94 (IIR) - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 IIR \u6ee4\u6ce2\u5668\u529f\u80fd</p> </li> <li> <p>\u6709\u9650\u8109\u51b2\u54cd\u5e94 (FIR) - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 FIR \u6ee4\u6ce2\u5668\u529f\u80fd</p> </li> <li> <p>\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668 - \u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668 (EKF) \u793a\u4f8b</p> </li> <li> <p>\u77e9\u9635 - \u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Mat \u7c7b\u529f\u80fd</p> </li> </ul>"},{"location":"zh/MATH/ESP-DSP/examples/#_1","title":"\u57fa\u7840\u6570\u5b66","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u4e2d\u7684\u57fa\u672c\u6570\u5b66\u51fd\u6570\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u7528 1024 \u4e2a\u6837\u672c\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u4f7f\u7528\u6807\u51c6 C \u5faa\u73af\u5bf9\u8f93\u5165\u4fe1\u53f7\u52a0\u7a97\u3002</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT \u5e76\u663e\u793a\u7ed3\u679c</p> </li> <li> <p>\u5728\u56fe\u8868\u4e0a\u663e\u793a\u7ed3\u679c</p> </li> <li> <p>\u4f7f\u7528\u57fa\u672c\u6570\u5b66\u51fd\u6570 dsps_mul_f32 \u548c dsps_mulc_f32 \u5bf9\u8f93\u5165\u4fe1\u53f7\u52a0\u7a97\u3002</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT</p> </li> <li> <p>\u5728\u56fe\u8868\u4e0a\u663e\u793a\u7ed3\u679c</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/basic_math/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#_2","title":"\u70b9\u79ef","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u4e2d\u7684 dotprod dsps_dotprod_f32 \u51fd\u6570\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u8f93\u5165\u6570\u7ec4</p> </li> <li> <p>\u8ba1\u7b97\u4e24\u4e2a\u6570\u7ec4\u7684\u70b9\u79ef</p> </li> <li> <p>\u6bd4\u8f83\u7ed3\u679c\u5e76\u8ba1\u7b97\u6267\u884c\u65f6\u95f4\uff08\u4ee5\u5468\u671f\u4e3a\u5355\u4f4d\uff09\u3002</p> </li> </ul> <p>\u66f4\u591a\u8be6\u60c5\uff0c\u8bf7\u53c2\u9605 examples/dotprod/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#fft","title":"FFT","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 ESP-DSP \u5e93\u4e2d\u7684 FFT \u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u7528 1024 \u4e2a\u6837\u672c\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7\uff1a\u7b2c\u4e00\u4e2a 0 dB\uff0c\u7b2c\u4e8c\u4e2a -20 dB</p> </li> <li> <p>\u5c06\u4e24\u4e2a\u4fe1\u53f7\u5408\u5e76\u4e3a\u4e00\u4e2a\u590d\u6570\u8f93\u5165\u4fe1\u53f7\uff0c\u5e76\u5bf9\u8f93\u5165\u4fe1\u53f7\u5bf9\u5e94\u7528\u7a97\u53e3\u3002</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT</p> </li> <li> <p>\u5bf9\u8f93\u51fa\u590d\u6570\u5411\u91cf\u5e94\u7528\u4f4d\u53cd\u8f6c\u64cd\u4f5c</p> </li> <li> <p>\u5c06\u4e00\u4e2a\u590d\u6570 FFT \u8f93\u51fa\u9891\u8c31\u62c6\u5206\u4e3a\u4e24\u4e2a\u5b9e\u6570\u4fe1\u53f7\u9891\u8c31</p> </li> <li> <p>\u5728\u56fe\u8868\u4e0a\u663e\u793a\u7ed3\u679c</p> </li> <li> <p>\u663e\u793a FFT \u7684\u6267\u884c\u65f6\u95f4</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fft/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#fft_1","title":"FFT \u7a97\u53e3","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u4e2d\u7684\u7a97\u53e3\u548c FFT \u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u7528 1024 \u4e2a\u6837\u672c\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u5bf9\u8f93\u5165\u4fe1\u53f7\u5e94\u7528\u7a97\u53e3\u3002</p> </li> <li> <p>\u5bf9 1024 \u4e2a\u590d\u6570\u6837\u672c\u8ba1\u7b97 FFT</p> </li> <li> <p>\u5bf9\u8f93\u51fa\u590d\u6570\u5411\u91cf\u5e94\u7528\u4f4d\u53cd\u8f6c\u64cd\u4f5c</p> </li> <li> <p>\u5c06\u4e00\u4e2a\u590d\u6570 FFT \u8f93\u51fa\u9891\u8c31\u62c6\u5206\u4e3a\u4e24\u4e2a\u5b9e\u6570\u4fe1\u53f7\u9891\u8c31</p> </li> <li> <p>\u5728\u56fe\u8868\u4e0a\u663e\u793a\u7ed3\u679c</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fft_window/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#fft-4-real","title":"FFT 4 Real","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 ESP-DSP \u5e93\u4e2d\u7684 FFT \u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u7528 1024 \u4e2a\u6837\u672c\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7\uff1a\u7b2c\u4e00\u4e2a 0 dB\uff0c\u7b2c\u4e8c\u4e2a -20 dB</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT \u57fa\u6570 2</p> </li> <li> <p>\u8ba1\u7b97 1024 \u4e2a\u590d\u6570\u6837\u672c\u7684 FFT \u57fa\u6570 4</p> </li> <li> <p>\u5bf9\u8f93\u51fa\u590d\u6570\u5411\u91cf\u5e94\u7528\u4f4d\u53cd\u8f6c\u8fd0\u7b97</p> </li> <li> <p>\u7ed8\u56fe\u663e\u793a\u7ed3\u679c</p> </li> <li> <p>\u663e\u793a FFT \u6267\u884c\u65f6\u95f4</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fft4real/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#iir","title":"IIR","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 ESP-DSP \u5e93\u4e2d\u7684 IIR \u6ee4\u6ce2\u5668\u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u5e93</p> </li> <li> <p>\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u663e\u793a Q \u56e0\u5b50\u4e3a 1 \u7684\u4f4e\u901a\u6ee4\u6ce2\u5668 (LPF)</p> </li> <li> <p>\u8ba1\u7b97 IIR \u6ee4\u6ce2\u5668\u7cfb\u6570</p> </li> <li> <p>\u6ee4\u6ce2\u8f93\u5165\u6d4b\u8bd5\u4fe1\u53f7\uff08Delta \u51fd\u6570\uff09</p> </li> <li> <p>\u5728\u56fe\u4e2d\u663e\u793a\u8109\u51b2\u54cd\u5e94</p> </li> <li> <p>\u5728\u56fe\u4e2d\u663e\u793a\u9891\u7387\u54cd\u5e94</p> </li> <li> <p>\u8ba1\u7b97\u6267\u884c\u6027\u80fd</p> </li> <li> <p>\u5bf9\u4e8e Q \u56e0\u5b50\u4e3a 10 \u7684\u4f4e\u901a\u6ee4\u6ce2\u5668\uff0c\u540c\u6837\u5982\u6b64</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fir/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#fir","title":"FIR","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 ESP-DSP \u5e93\u4e2d\u7684 FIR \u6ee4\u6ce2\u5668\u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316 FFT \u5e93</p> </li> <li> <p>\u521d\u59cb\u5316\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u663e\u793a\u8f93\u5165\u4fe1\u53f7</p> </li> <li> <p>\u663e\u793a\u6ee4\u6ce2\u540e\u7684\u4fe1\u53f7</p> </li> </ul> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/fir/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#_3","title":"\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668","text":"<p>\u672c\u793a\u4f8b\u6a21\u62df\u4e86\u5e26\u6709 IMU \u4f20\u611f\u5668\u7684\u7cfb\u7edf\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u5177\u6709 13 \u4e2a\u72b6\u6001\u5411\u91cf\u7684\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668 (EKF) \u6765\u4f30\u8ba1\u9640\u87ba\u4eea\u8bef\u5dee\u5e76\u8ba1\u7b97\u7cfb\u7edf\u59ff\u6001\u3002\u6b64\u5916\uff0c\u672c\u793a\u4f8b\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u5bf9\u77e9\u9635\u548c\u5411\u91cf\u8fdb\u884c\u8fd0\u7b97\u3002</p> <p>\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\uff0c\u5e94\u5c06\u6a21\u62df\u4f20\u611f\u5668\u503c\u66ff\u6362\u4e3a\u5b9e\u9645\u4f20\u611f\u5668\u503c\u3002\u7136\u540e\uff0c\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\uff0c\u5e94\u6267\u884c\u6821\u51c6\u9636\u6bb5\u3002\u6821\u51c6\u9636\u6bb5\u7ed3\u675f\u540e\uff0c\u5e94\u4fdd\u5b58\u72b6\u6001\u5411\u91cf X \u548c\u534f\u65b9\u5dee\u77e9\u9635 P\uff0c\u5e76\u5728\u4e0b\u6b21\u8c03\u7528\u6ee4\u6ce2\u5668\u65f6\u6062\u590d\u3002\u8fd9\u5c06\u8282\u7701\u521d\u59cb\u9636\u6bb5\u7684\u65f6\u95f4\u3002</p> <p>\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 examples/kalman/README.md</p>"},{"location":"zh/MATH/ESP-DSP/examples/#_4","title":"\u77e9\u9635","text":"<p>\u672c\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528 esp-dsp \u5e93\u4e2d\u7684 Mat \u7c7b\u529f\u80fd\u3002\u793a\u4f8b\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li> <p>\u521d\u59cb\u5316\u77e9\u9635 A \u548c \u77e9\u9635 x</p> </li> <li> <p>\u8ba1\u7b97\u77e9\u9635 b\uff1ab = A*x</p> </li> <li> <p>\u4f7f\u7528\u4e0d\u540c\u65b9\u6cd5\u6c42 x1 \u7684\u6839\uff1aA*x1 = b</p> </li> <li> <p>\u6253\u5370\u7ed3\u679c</p> </li> </ul>"},{"location":"zh/MATH/HEADER-FILE/tiny_constants/","title":"\u5e38\u91cf\u5b9a\u4e49","text":"<p>Info</p> <p>\u8be5\u6587\u4ef6\u5305\u542b\u4e86\u4e00\u4e9b\u5e38\u91cf\u7684\u5b9a\u4e49\u7528\u4e8e\u4e0a\u5c42\u8ba1\u7b97\u548c\u5e94\u7528\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bf7\u4ee5\u4ee3\u7801\u4e3a\u51c6\u3002</p> <pre><code>/**\n * @file tiny_constants.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file contains the constants used in the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n// =======================================\n//  Logical Constants\n// =======================================\n#ifndef TRUE\n#define TRUE 1\n#endif\n\n#ifndef FALSE\n#define FALSE 0\n#endif\n\n#ifndef NULL\n#define NULL ((void *)0)\n#endif\n\n// =======================================\n//  Math Constants (float/double safe)\n// =======================================\n#define TINY_PI 3.14159265358979323846f\n#define TINY_TWO_PI 6.28318530717958647692f\n#define TINY_HALF_PI 1.57079632679489661923f\n#define TINY_E 2.71828182845904523536f\n#define TINY_SQRT2 1.41421356237309504880f\n#define TINY_INV_SQRT2 0.70710678118654752440f\n\n#define TINY_DEG2RAD(x) ((x) * TINY_PI / 180.0f)\n#define TINY_RAD2DEG(x) ((x) * 180.0f / TINY_PI)\n\n// =======================================\n//  Bitmask &amp; Bit Manipulation\n// =======================================\n\n// Bitwise operations\n#define TINY_BIT(n) (1U &lt;&lt; (n)) // e.g. TINY_BIT(3) = 0b00001000\n#define TINY_BIT_SET(x, n) ((x) |= TINY_BIT(n))\n#define TINY_BIT_CLEAR(x, n) ((x) &amp;= ~TINY_BIT(n))\n#define TINY_BIT_TOGGLE(x, n) ((x) ^= TINY_BIT(n))\n#define TINY_BIT_CHECK(x, n) (((x) &gt;&gt; (n)) &amp; 0x1U)\n\n// Common bit masks\n#define TINY_MASK_4BIT 0x0FU\n#define TINY_MASK_8BIT 0xFFU\n#define TINY_MASK_16BIT 0xFFFFU\n#define TINY_MASK_32BIT 0xFFFFFFFFU\n\n// =======================================\n//  Fixed-Point Scaling Factors\n// =======================================\n#define TINY_Q7_SCALE 128          // 2^7\n#define TINY_Q15_SCALE 32768       // 2^15\n#define TINY_Q31_SCALE 2147483648U // 2^31\n\n// =======================================\n//  User-Defined Constants (Optional)\n// =======================================\n#define TINY_MATH_MIN_DENOMINATOR 1e-6f         // Minimum denominator for safe division\n#define TINY_MATH_MIN_POSITIVE_INPUT_F32 1e-12f // Minimum positive input for float operations\n#define TINY_MATH_LARGE_VALUE_F32 1e38f         // Large value used to represent infinity-like results (safe for IEEE 754 float, max ~3.4e38)\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/MATH/HEADER-FILE/tiny_error_type/","title":"\u9519\u8bef\u7c7b\u578b\u5b9a\u4e49","text":"<p>Info</p> <p>\u8be5\u6587\u4ef6\u5b9a\u4e49\u4e86\u4e00\u4e9b\u8ba1\u7b97\u4e2d\u5e38\u89c1\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u7528\u4e8e\u8f85\u52a9\u5224\u65ad\u9519\u8bef\u539f\u56e0\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u7b26\uff0c\u8bf7\u4ee5\u4ee3\u7801\u4e3a\u51c6\u3002</p> <pre><code>/**\n * @file tiny_error_type.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-15\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    /* TYPE DEFINITIONS */\n    typedef int tiny_error_t; // Error type for the tiny_math middleware\n\n/* MACROS */\n/* Definitions for error constants. */\n#define TINY_OK 0    /*!&lt; tiny_err_t value indicating success (no error) */\n#define TINY_FAIL -1 /*!&lt; Generic tiny_err_t code indicating failure */\n\n#define TINY_ERR_NO_MEM 0x101           /*!&lt; Out of memory */\n#define TINY_ERR_INVALID_ARG 0x102      /*!&lt; Invalid argument */\n#define TINY_ERR_INVALID_STATE 0x103    /*!&lt; Invalid state */\n#define TINY_ERR_INVALID_SIZE 0x104     /*!&lt; Invalid size */\n#define TINY_ERR_NOT_FOUND 0x105        /*!&lt; Requested resource not found */\n#define TINY_ERR_NOT_SUPPORTED 0x106    /*!&lt; Operation or feature not supported */\n#define TINY_ERR_TIMEOUT 0x107          /*!&lt; Operation timed out */\n#define TINY_ERR_INVALID_RESPONSE 0x108 /*!&lt; Received response was invalid */\n#define TINY_ERR_INVALID_CRC 0x109      /*!&lt; CRC or checksum was invalid */\n#define TINY_ERR_INVALID_VERSION 0x10A  /*!&lt; Version was invalid */\n#define TINY_ERR_INVALID_MAC 0x10B      /*!&lt; MAC address was invalid */\n#define TINY_ERR_NOT_FINISHED 0x10C     /*!&lt; Operation has not fully completed */\n#define TINY_ERR_NOT_ALLOWED 0x10D      /*!&lt; Operation is not allowed */\n\n#define TINY_ERR_WIFI_BASE 0x3000      /*!&lt; Starting number of WiFi error codes */\n#define TINY_ERR_MESH_BASE 0x4000      /*!&lt; Starting number of MESH error codes */\n#define TINY_ERR_FLASH_BASE 0x6000     /*!&lt; Starting number of flash error codes */\n#define TINY_ERR_HW_CRYPTO_BASE 0xc000 /*!&lt; Starting number of HW cryptography module error codes */\n#define TINY_ERR_MEMPROT_BASE 0xd000   /*!&lt; Starting number of Memory Protection API error codes */\n\n#define TINY_ERR_MATH_BASE 0x70000\n#define TINY_ERR_MATH_INVALID_LENGTH (TINY_ERR_MATH_BASE + 1)\n#define TINY_ERR_MATH_INVALID_PARAM (TINY_ERR_MATH_BASE + 2)\n#define TINY_ERR_MATH_PARAM_OUTOFRANGE (TINY_ERR_MATH_BASE + 3)\n#define TINY_ERR_MATH_UNINITIALIZED (TINY_ERR_MATH_BASE + 4)\n#define TINY_ERR_MATH_REINITIALIZED (TINY_ERR_MATH_BASE + 5)\n#define TINY_ERR_MATH_ARRAY_NOT_ALIGNED (TINY_ERR_MATH_BASE + 6)\n#define TINY_ERR_MATH_NULL_POINTER (TINY_ERR_MATH_BASE + 7)\n#define TINY_ERR_MATH_ZERO_DIVISION (TINY_ERR_MATH_BASE + 8)\n#define TINY_ERR_MATH_NEGATIVE_SQRT (TINY_ERR_MATH_BASE + 9)\n\n#define TINY_ERR_DSP_BASE 0x80000\n#define TINY_ERR_DSP_INVALID_LENGTH (TINY_ERR_DSP_BASE + 1)\n#define TINY_ERR_DSP_INVALID_PARAM (TINY_ERR_DSP_BASE + 2)\n#define TINY_ERR_DSP_PARAM_OUTOFRANGE (TINY_ERR_DSP_BASE + 3)\n#define TINY_ERR_DSP_UNINITIALIZED (TINY_ERR_DSP_BASE + 4)\n#define TINY_ERR_DSP_REINITIALIZED (TINY_ERR_DSP_BASE + 5)\n#define TINY_ERR_DSP_ARRAY_NOT_ALIGNED (TINY_ERR_DSP_BASE + 6)\n#define TINY_ERR_DSP_NULL_POINTER (TINY_ERR_DSP_BASE + 7)\n#define TINY_ERR_DSP_ZERO_DIVISION (TINY_ERR_DSP_BASE + 8)\n#define TINY_ERR_DSP_NEGATIVE_SQRT (TINY_ERR_DSP_BASE + 9)\n#define TINY_ERR_DSP_MISMATCH (TINY_ERR_DSP_BASE + 10)\n#define TINY_ERR_DSP_INVALID_MODE (TINY_ERR_DSP_BASE + 11)\n#define TINY_ERR_DSP_MEMORY_ALLOC (TINY_ERR_DSP_BASE + 12)\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/MATH/HEADER-FILE/tiny_math/","title":"TinyMath\u5934\u6587\u4ef6","text":"<p>Info</p> <p>\u8fd9\u662fTinyMath\u5e93\u7684\u4e3b\u5934\u6587\u4ef6\u3002\u5b83\u5305\u542b\u6240\u6709\u5fc5\u8981\u7684\u5934\u6587\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u63a5\u53e3\u6765\u4f7f\u7528\u5e93\u7684\u529f\u80fd\u3002\u5728\u9879\u76ee\u4e2d\u5b8c\u6210\u8be5\u5e93\u7684\u79fb\u690d\u540e\uff0c\u5728\u9700\u8981\u4f7f\u7528\u76f8\u5173\u51fd\u6570\u7684\u5730\u65b9\u63d2\u5165\u8be5\u5934\u6587\u4ef6\u5373\u53ef\u4f7f\u7528\u5e93\u5185\u7684\u6240\u6709\u51fd\u6570\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bf7\u4ee5\u5b9e\u9645\u4ee3\u7801\u4e3a\u51c6\u3002</p> <pre><code>/**\n * @file tiny_math.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-03-26\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n\n// this layer\n#include \"tiny_math_config.h\"\n\n/* SUBMODULES */\n\n// vector operations\n#include \"tiny_vec.h\"\n\n// matrix operations\n#include \"tiny_mat.h\"\n\n// advanced matrix operations\n#ifdef __cplusplus\n\n#include \"tiny_matrix.hpp\"\n\n#endif\n\n/* TEST */ // NOTE: test files are platform specific and should not be included in the library\n\n// vector operations\n#include \"tiny_vec_test.h\"\n\n// matrix operations\n#include \"tiny_mat_test.h\"\n\n// advanced matrix operations\n#ifdef __cplusplus\n\n#include \"tiny_matrix_test.hpp\"\n\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/MATH/HEADER-FILE/tiny_math_config/","title":"TinyMath \u914d\u7f6e","text":"<p>Info</p> <p>\u8fd9\u4e2a\u5934\u6587\u4ef6\u8d77\u5230\u914d\u7f6e\u6574\u4e2aTinyMath\u6a21\u5757\u7684\u4f5c\u7528\uff0c\u6bcf\u4e2a\u5b50\u6a21\u5757\u90fd\u5305\u542b\u4e86\u6b64\u5934\u6587\u4ef6\u3002\u5b83\u5b9a\u4e49\u4e86TinyMath\u7684\u914d\u7f6e\u9009\u9879\u548c\u5b8f\uff0c\u5141\u8bb8\u7528\u6237\u6839\u636e\u9700\u8981\u8fdb\u884c\u81ea\u5b9a\u4e49\u8bbe\u7f6e\u3002\u901a\u8fc7\u4fee\u6539\u8fd9\u4e2a\u5934\u6587\u4ef6\u4e2d\u7684\u914d\u7f6e\u9009\u9879\uff0c\u7528\u6237\u53ef\u4ee5\u8f7b\u677e\u5730\u8c03\u6574TinyMath\u7684\u884c\u4e3a\u548c\u529f\u80fd\uff0c\u4ee5\u6ee1\u8db3\u7279\u5b9a\u7684\u9700\u6c42\u3002\u6587\u6863\u66f4\u65b0\u901f\u5ea6\u8f83\u6162\uff0c\u53ef\u80fd\u4f1a\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bf7\u4ee5\u4ee3\u7801\u4e3a\u51c6\u3002</p> <p>Tip</p> <p>\u8be5\u7ec4\u4ef6\u5185\u5305\u62ec\u9009\u62e9\u5e73\u53f0\u7684\u5b8f\u5b9a\u4e49\uff0c\u7528\u6237\u53ef\u4ee5\u6839\u636e\u9700\u8981\u9009\u62e9\u4e0d\u540c\u7684\u5e73\u53f0\u8fdb\u884c\u7f16\u8bd1\u3002\u5207\u6362\u5230\u5bf9\u5e94\u5e73\u53f0\u7684\u5b8f\u540e\uff0c\u53ef\u4ee5\u5229\u7528\u5e73\u53f0\u52a0\u901f\u7684\u7279\u6027\u6765\u63d0\u5347\u6027\u80fd\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8eESP32\u5e73\u53f0\uff0cTinyMath\u4f1a\u81ea\u52a8\u9009\u62e9ESP32\u7684DSP\u5e93\u8fdb\u884c\u7f16\u8bd1\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6570\u5b66\u8fd0\u7b97\u3002</p> <pre><code>/**\n * @file tiny_math_config.h\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief The configuration file for the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-14\n * @copyright Copyright (c) 2025\n *\n */\n\n#pragma once\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n/* DEPENDENCIES */\n\n// ANSI C\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;math.h&gt;\n#include &lt;stdbool.h&gt;\n#include &lt;stdint.h&gt;\n\n// lower level\n#include \"tiny_toolbox.h\"\n\n// this level\n#include \"tiny_error_type.h\"\n#include \"tiny_constants.h\"\n\n/* PLATFORM SELECTION */\n\n// available platforms\n#define MCU_PLATFORM_GENERIC 0\n#define MCU_PLATFORM_ESP32 1 // here, we utilize the ESP built-in DSP library, it will automatically select the optimized version\n#define MCU_PLATFORM_STM32 2\n#define MCU_PLATFORM_RISCV 3\n\n// choose one platform\n#define MCU_PLATFORM_SELECTED MCU_PLATFORM_ESP32\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/","title":"\u77e9\u9635\u64cd\u4f5c - TINY_MAT","text":"<p>\u5173\u4e8etiny_mat\u5e93</p> <p>tiny_mat\u662f\u4e00\u4e2aC\u8bed\u8a00\u5b9e\u73b0\u7684\u77e9\u9635\u5e93\uff0c\u63d0\u4f9b\u4e86\u57fa\u672c\u7684\u77e9\u9635\u64cd\u4f5c\u51fd\u6570\u3002\u5b83\u652f\u6301\u6d6e\u70b9\u6570\u77e9\u9635\u7684\u52a0\u6cd5\u3001\u51cf\u6cd5\u548c\u4e58\u6cd5\u7b49\u64cd\u4f5c\u3002\u8be5\u5e93\u9002\u7528\u4e8e\u9700\u8981\u8fdb\u884c\u77e9\u9635\u8ba1\u7b97\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u5b9e\u65f6\u5e94\u7528\u3002\u8be5\u5e93\u57fa\u4e8eANSIC C\u6807\u51c6\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u79fb\u690d\u6027\u548c\u6027\u80fd,\u540c\u65f6\u53c8\u652f\u6301\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u8fdb\u884c\u914d\u7f6e\u4ece\u800c\u652f\u6301\u5e73\u53f0\u52a0\u901f\uff08ESP32\uff09\u3002</p> <p>\u5173\u4e8etiny_mat\u5e93\u7684\u4f7f\u7528</p> <p>tiny_mat\u7684\u529f\u80fd\u88abtiny_matrix\u5b8c\u5168\u8986\u76d6\uff0c\u4e5f\u5c31\u662f\u8bf4\u5728tiny_matrix\u4e2d\u7684\u529f\u80fd\u5305\u542b\u4e86tiny_mat\u7684\u6240\u6709\u529f\u80fd\u3002\u5bf9\u4e8e\u7b80\u5355\u7684\u77e9\u9635\u64cd\u4f5c\uff0c\u53ef\u4ee5\u4ec5\u5f15\u5165tiny_mat\u5e93\uff1b\u5bf9\u4e8e\u590d\u6742\u7684\u77e9\u9635\u64cd\u4f5c\uff0c\u5efa\u8bae\u4f7f\u7528tiny_matrix\u5e93\u3002tiny_matrix\u5e93\u662f\u4e00\u4e2aC++\u5b9e\u73b0\u7684\u77e9\u9635\u5e93\uff0c\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u529f\u80fd\u548c\u66f4\u597d\u7684\u6027\u80fd\u3002\u5b83\u652f\u6301\u6d6e\u70b9\u6570\u548c\u6574\u6570\u77e9\u9635\u7684\u52a0\u6cd5\u3001\u51cf\u6cd5\u3001\u4e58\u6cd5\u3001\u8f6c\u7f6e\u3001\u6c42\u9006\u7b49\u64cd\u4f5c\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_1","title":"\u76ee\u5f55","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500Vector\n    \u2514\u2500\u2500Matrix\n        \u251c\u2500\u2500 tiny_mat (c) &lt;---\n        \u2514\u2500\u2500 tiny_matrix (c++)\n</code></pre> <pre><code>// print matrix\nvoid print_matrix(const char *name, const float *mat, int rows, int cols);\n// print matrix padded (row-major)\nvoid print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n// addition\ntiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// subtraction\ntiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\ntiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n// multiplication\ntiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\ntiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\ntiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_2","title":"\u5de5\u5177\u51fd\u6570","text":""},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_3","title":"\u6253\u5370\u77e9\u9635","text":"<pre><code>void print_matrix(const char *name, const float *mat, int rows, int cols);\n</code></pre> <p>\u51fd\u6570: \u4ee5\u884c\u4e3b\u5e8f\u6253\u5370\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>name</code>: \u77e9\u9635\u540d\u79f0\u3002</p> </li> <li> <p><code>mat</code>: \u77e9\u9635\u6570\u636e\u6307\u9488\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u65e0\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_4","title":"\u6253\u5370\u5e26\u586b\u5145\u7684\u77e9\u9635","text":"<pre><code>void print_matrix_padded(const char *name, const float *mat, int rows, int cols, int step);\n</code></pre> <p>\u51fd\u6570: \u4ee5\u884c\u4e3b\u5e8f\u6253\u5370\u5e26\u586b\u5145\u7684\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>name</code>: \u77e9\u9635\u540d\u79f0\u3002</p> </li> <li> <p><code>mat</code>: \u77e9\u9635\u6570\u636e\u6307\u9488\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>step</code>: \u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u65e0\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_5","title":"\u77e9\u9635\u52a0\u6cd5","text":"<pre><code>tiny_error_t tiny_mat_add_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u52a0\u6cd5\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input1</code>: \u8f93\u5165\u77e9\u96351\u3002</p> </li> <li> <p><code>input2</code>: \u8f93\u5165\u77e9\u96352\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd1</code>: \u8f93\u5165\u77e9\u96351\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd2</code>: \u8f93\u5165\u77e9\u96352\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step1</code>: \u8f93\u5165\u77e9\u96351\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step2</code>: \u8f93\u5165\u77e9\u96352\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_6","title":"\u77e9\u9635\u52a0\u5e38\u6570","text":"<pre><code>tiny_error_t tiny_mat_addc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u52a0\u5e38\u6570\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u77e9\u9635\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>C</code>: \u5e38\u6570\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_7","title":"\u77e9\u9635\u51cf\u6cd5","text":"<pre><code>tiny_error_t tiny_mat_sub_f32(const float *input1, const float *input2, float *output, int rows, int cols, int padd1, int padd2, int padd_out, int step1, int step2, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u51cf\u6cd5\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input1</code>: \u8f93\u5165\u77e9\u96351\u3002</p> </li> <li> <p><code>input2</code>: \u8f93\u5165\u77e9\u96352\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd1</code>: \u8f93\u5165\u77e9\u96351\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd2</code>: \u8f93\u5165\u77e9\u96352\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step1</code>: \u8f93\u5165\u77e9\u96351\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step2</code>: \u8f93\u5165\u77e9\u96352\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_8","title":"\u77e9\u9635\u51cf\u5e38\u6570","text":"<pre><code>tiny_error_t tiny_mat_subc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u51cf\u5e38\u6570\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u77e9\u9635\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>C</code>: \u5e38\u6570\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_9","title":"\u77e9\u9635\u4e58\u6cd5","text":"<pre><code>tiny_error_t tiny_mat_mult_f32(const float *A, const float *B, float *C, int m, int n, int k);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u4e58\u6cd5\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>A</code>: \u8f93\u5165\u77e9\u9635A\u3002</p> </li> <li> <p><code>B</code>: \u8f93\u5165\u77e9\u9635B\u3002</p> </li> <li> <p><code>C</code>: \u8f93\u51fa\u77e9\u9635C\u3002</p> </li> <li> <p><code>m</code>: \u77e9\u9635A\u7684\u884c\u6570\u3002</p> </li> <li> <p><code>n</code>: \u77e9\u9635A\u7684\u5217\u6570\u3002</p> </li> <li> <p><code>k</code>: \u77e9\u9635B\u7684\u5217\u6570\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_10","title":"\u6269\u5c55\u77e9\u9635\u4e58\u6cd5","text":"<pre><code>tiny_error_t tiny_mat_mult_ex_f32(const float *A, const float *B, float *C, int A_rows, int A_cols, int B_cols, int A_padding, int B_padding, int C_padding);\n</code></pre> <p>\u51fd\u6570: \u6269\u5c55\u77e9\u9635\u4e58\u6cd5\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>A</code>: \u8f93\u5165\u77e9\u9635A\u3002</p> </li> <li> <p><code>B</code>: \u8f93\u5165\u77e9\u9635B\u3002</p> </li> <li> <p><code>C</code>: \u8f93\u51fa\u77e9\u9635C\u3002</p> </li> <li> <p><code>A_rows</code>: \u77e9\u9635A\u7684\u884c\u6570\u3002</p> </li> <li> <p><code>A_cols</code>: \u77e9\u9635A\u7684\u5217\u6570\u3002</p> </li> <li> <p><code>B_cols</code>: \u77e9\u9635B\u7684\u5217\u6570\u3002</p> </li> <li> <p><code>A_padding</code>: \u77e9\u9635A\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>B_padding</code>: \u77e9\u9635B\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>C_padding</code>: \u77e9\u9635C\u7684\u586b\u5145\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-api/#_11","title":"\u77e9\u9635\u4e58\u5e38\u6570","text":"<pre><code>tiny_error_t tiny_mat_multc_f32(const float *input, float *output, float C, int rows, int cols, int padd_in, int padd_out, int step_in, int step_out);\n</code></pre> <p>\u51fd\u6570: \u77e9\u9635\u4e58\u5e38\u6570\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>input</code>: \u8f93\u5165\u77e9\u9635\u3002</p> </li> <li> <p><code>output</code>: \u8f93\u51fa\u77e9\u9635\u3002</p> </li> <li> <p><code>C</code>: \u5e38\u6570\u3002</p> </li> <li> <p><code>rows</code>: \u77e9\u9635\u884c\u6570\u3002</p> </li> <li> <p><code>cols</code>: \u77e9\u9635\u5217\u6570\u3002</p> </li> <li> <p><code>padd_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>padd_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u586b\u5145\u3002</p> </li> <li> <p><code>step_in</code>: \u8f93\u5165\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> <li> <p><code>step_out</code>: \u8f93\u51fa\u77e9\u9635\u7684\u6b65\u957f\u3002</p> </li> </ul> <p>\u8fd4\u56de: \u9519\u8bef\u7801\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-mat-code/","title":"\u4ee3\u7801","text":""},{"location":"zh/MATH/MATRIX/tiny-mat-test/","title":"TINY_MAT \u6d4b\u8bd5","text":""},{"location":"zh/MATH/MATRIX/tiny-mat-test/#_1","title":"\u6d4b\u8bd5\u4ee3\u7801","text":""},{"location":"zh/MATH/MATRIX/tiny-mat-test/#_2","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<pre><code>============ [tiny_mat_test] ============\n\n================================================================================\nTest Case 1: tiny_mat_add_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1\n\nInput1 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nInput2 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5 \n  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\n          [4.5  5.5  6.5  7.5]  &lt;- Row 1\n          [8.5  9.5 10.5 11.5]  &lt;- Row 2\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.5   3.5   5.5   7.5   9.5  11.5  13.5  15.5  17.5  19.5  21.5  23.5 \n  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\n          [9.5 11.5 13.5 15.5]  &lt;- Row 1\n          [17.5 19.5 21.5 23.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.5   3.5   5.5   7.5   9.5  11.5  13.5  15.5  17.5  19.5  21.5  23.5 \n  Matrix: [1.5  3.5  5.5  7.5]  &lt;- Row 0\n          [9.5 11.5 13.5 15.5]  &lt;- Row 1\n          [17.5 19.5 21.5 23.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 2: tiny_mat_add_f32 - Non-contiguous memory (pad!=0, step&gt;1)\n================================================================================\nParams: rows=2, cols=3, pad1=4, pad2=4, pad_out=4, step1=2, step2=3, step_out=2\nIndex formula: idx = row * (cols + padding) + col * step\n\n[input1 raw len=14]  1.0  0.0  2.0  0.0  3.0  0.0  0.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0 (pad=4, step=2)\n  input1 row0 (stride=7): [0: 1.0 C] [1: 0.0 P] [2: 2.0 C] [3: 0.0 P] [4: 3.0 C] [5: 0.0 P] [6: 0.0 P]\n  input1 row1 (stride=7): [0: 4.0 C] [1: 0.0 P] [2: 5.0 C] [3: 0.0 P] [4: 6.0 C] [5: 0.0 P] [6: 0.0 P]\n\n[input2 raw len=14]  0.5  0.0  0.0  1.5  0.0  0.0  2.5  3.5  0.0  0.0  4.5  0.0  0.0  5.5 (pad=4, step=3)\n  input2 row0 (stride=7): [0: 0.5 C] [1: 0.0 P] [2: 0.0 P] [3: 1.5 C] [4: 0.0 P] [5: 0.0 P] [6: 2.5 C]\n  input2 row1 (stride=7): [0: 3.5 C] [1: 0.0 P] [2: 0.0 P] [3: 4.5 C] [4: 0.0 P] [5: 0.0 P] [6: 5.5 C]\n\nLogical matrices (no padding):\n  input1 row0:  1.0  2.0  3.0\n  input1 row1:  4.0  5.0  6.0\n  input2 row0:  0.5  1.5  2.5\n  input2 row1:  3.5  4.5  5.5\n\n[output raw len=14]  1.5  0.0  3.5  0.0  5.5  0.0  0.0  7.5  0.0  9.5  0.0 11.5  0.0  0.0 (pad_out=4, step_out=2)\n\n  output row0 (stride=7): [0: 1.5 C] [1: 0.0 P] [2: 3.5 C] [3: 0.0 P] [4: 5.5 C] [5: 0.0 P] [6: 0.0 P]\n  output row1 (stride=7): [0: 7.5 C] [1: 0.0 P] [2: 9.5 C] [3: 0.0 P] [4:11.5 C] [5: 0.0 P] [6: 0.0 P]\n\n[expected raw len=14]  1.5  0.0  3.5  0.0  5.5  0.0  0.0  7.5  0.0  9.5  0.0 11.5  0.0  0.0 (pad_out=4, step_out=2)\n\nLogical matrix comparison (expected | actual | diff):\n  row0: [ 1.5 |  1.5 | 0.0e+00] [ 3.5 |  3.5 | 0.0e+00] [ 5.5 |  5.5 | 0.0e+00]\n  row1: [ 7.5 |  7.5 | 0.0e+00] [ 9.5 |  9.5 | 0.0e+00] [11.5 | 11.5 | 0.0e+00]\n\u2713 Test PASSED (all elements match)\n================================================================================\n\n\n================================================================================\nTest Case 3: tiny_mat_addc_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1, C=2.5\n\nInput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nConstant C =   2.5\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5  12.5  13.5  14.5 \n  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\n          [7.5  8.5  9.5 10.5]  &lt;- Row 1\n          [11.5 12.5 13.5 14.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5  12.5  13.5  14.5 \n  Matrix: [3.5  4.5  5.5  6.5]  &lt;- Row 0\n          [7.5  8.5  9.5 10.5]  &lt;- Row 1\n          [11.5 12.5 13.5 14.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 4: tiny_mat_addc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad_in=2, pad_out=2, step_in=2, step_out=2, C=  1.5\nIndex formula: index = row * (cols + padding) + col * step\n\nInput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nConstant C =   1.5\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   2.5  0.0  3.5  0.0  4.5  5.5  0.0  6.5  0.0  7.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   2.5  0.0  3.5  0.0  4.5  5.5  0.0  6.5  0.0  7.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [2.5  X  3.5  X  4.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [5.5  X  6.5  X  7.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 5: tiny_mat_sub_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1\n\nInput1 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nInput2 Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5  10.5  11.5 \n  Matrix: [0.5  1.5  2.5  3.5]  &lt;- Row 0\n          [4.5  5.5  6.5  7.5]  &lt;- Row 1\n          [8.5  9.5 10.5 11.5]  &lt;- Row 2\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 \n  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\n          [0.5  0.5  0.5  0.5]  &lt;- Row 1\n          [0.5  0.5  0.5  0.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 \n  Matrix: [0.5  0.5  0.5  0.5]  &lt;- Row 0\n          [0.5  0.5  0.5  0.5]  &lt;- Row 1\n          [0.5  0.5  0.5  0.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 6: tiny_mat_sub_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad1=2, pad2=1, pad_out=2, step1=2, step2=3, step_out=2\nIndex formula: index = row * (cols + padding) + col * step\n\nInput1 Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nInput2 Memory Layout (16 elements, pad=1, step=3):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] ...\n  Value:   0.5  0.0  0.0  1.5  3.5  0.0  2.5  4.5  0.0  0.0  5.5  0.0 ...\n  Matrix: [0.5  X  X  1.5  X  X  2.5]  &lt;- Row 0 (indices: 0, 3, 6)\n          [3.5  X  X  4.5  X  X  5.5]  &lt;- Row 1 (indices: 4, 7, 10)\n          (X = padding/unused)\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   0.5  0.0  0.5  0.0  0.5  0.5  0.0  0.5  0.0  0.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   0.5  0.0  0.5  0.0  0.5  0.5  0.0  0.5  0.0  0.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [0.5  X  0.5  X  0.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [0.5  X  0.5  X  0.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 7: tiny_mat_subc_f32 - Contiguous Memory Layout (pad=0, step=1)\n================================================================================\nParameters: rows=3, cols=4, pad=0, step=1, C=2.5\n\nInput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nConstant C =   2.5\n\nExpected Output Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:   -1.5  -0.5   0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5 \n  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\n          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\n          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\n\nOutput Memory Layout (12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:   -1.5  -0.5   0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5   8.5   9.5 \n  Matrix: [-1.5 -0.5  0.5  1.5]  &lt;- Row 0\n          [ 2.5  3.5  4.5  5.5]  &lt;- Row 1\n          [ 6.5  7.5  8.5  9.5] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 8: tiny_mat_subc_f32 - Non-Contiguous Memory Layout (pad!=0, step&gt;1)\n================================================================================\nParameters: rows=2, cols=3, pad_in=2, pad_out=2, step_in=2, step_out=2, C=  1.5\nIndex formula: index = row * (cols + padding) + col * step\n\nInput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nConstant C =   1.5\n\nExpected Output Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:  -0.5  0.0  0.5  0.0  1.5  2.5  0.0  3.5  0.0  4.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\nOutput Memory Layout (20 elements, pad=2, step=2):\n  Index:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [10] [11] [12] [13] [14] ...\n  Value:  -0.5  0.0  0.5  0.0  1.5  2.5  0.0  3.5  0.0  4.5  0.0  0.0  0.0  0.0  0.0 ...\n  Matrix: [-0.5  X  0.5  X  1.5]  &lt;- Row 0 (indices: 0, 2, 4)\n          [ 2.5  X  3.5  X  4.5]  &lt;- Row 1 (indices: 5, 7, 9)\n          (X = padding/unused)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 9: tiny_mat_mult_f32 - Basic Matrix Multiplication\n================================================================================\nParameters: m=3, n=4, k=2 (A is 3x4, B is 4x2, C is 3x2)\nNote: This function always uses ESP-DSP on ESP32, standard implementation otherwise\n\nMatrix A Memory Layout (3x4, 12 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2\n\nMatrix B Memory Layout (4x2, 8 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5 \n  Matrix: [0.5  1.5]  &lt;- Row 0\n          [2.5  3.5]  &lt;- Row 1\n          [4.5  5.5]  &lt;- Row 2\n          [6.5  7.5]  &lt;- Row 3\n\nExpected Output Matrix C Memory Layout (3x2, 6 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0\n          [101.0  127.0]  &lt;- Row 1\n          [157.0  199.0] &lt;- Row 2\n  Calculation:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 =  45.0\n    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1] + A[0][3]*B[3][1]\n            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 + 4.0*7.5 =  55.0\n\nOutput Matrix C Memory Layout (3x2, 6 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0\n          [101.0  127.0]  &lt;- Row 1\n          [157.0  199.0] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 10: tiny_mat_mult_f32 - Square Matrix Multiplication\n================================================================================\nParameters: m=3, n=3, k=3 (A is 3x3, B is 3x3, C is 3x3)\nNote: This function always uses ESP-DSP on ESP32, standard implementation otherwise\n\nMatrix A Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0 \n  Matrix: [1.0  2.0  3.0]  &lt;- Row 0\n          [4.0  5.0  6.0]  &lt;- Row 1\n          [7.0  8.0  9.0]  &lt;- Row 2\n\nMatrix B Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    0.5   1.0   1.5   2.0   2.5   3.0   3.5   4.0   4.5 \n  Matrix: [0.5  1.0  1.5]  &lt;- Row 0\n          [2.0  2.5  3.0]  &lt;- Row 1\n          [3.5  4.0  4.5]  &lt;- Row 2\n\nExpected Output Matrix C Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    15.0   18.0   21.0   33.0   40.5   48.0   51.0   63.0   75.0 \n  Matrix: [ 15.0   18.0   21.0]  &lt;- Row 0\n          [ 33.0   40.5   48.0]  &lt;- Row 1\n          [ 51.0   63.0   75.0] &lt;- Row 2\n\nOutput Matrix C Memory Layout (3x3, 9 elements, contiguous):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    15.0   18.0   21.0   33.0   40.5   48.0   51.0   63.0   75.0 \n  Matrix: [ 15.0   18.0   21.0]  &lt;- Row 0\n          [ 33.0   40.5   48.0]  &lt;- Row 1\n          [ 51.0   63.0   75.0] &lt;- Row 2\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 11: tiny_mat_mult_ex_f32 - Contiguous Matrix Multiplication\n================================================================================\nParameters: A_rows=3, A_cols=4, B_cols=2, A_padding=0, B_padding=0, C_padding=0\nMatrix dimensions: A is 3x4, B is 4x2, C is 3x2\nNote: This should use ESP-DSP on ESP32 when all paddings are 0\n\nMatrix A Memory Layout (3x4, 12 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]   [10]  [11]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  11.0  12.0 \n  Matrix: [1.0  2.0  3.0  4.0]  &lt;- Row 0 (indices: 0-3)\n          [5.0  6.0  7.0  8.0]  &lt;- Row 1 (indices: 4-7)\n          [9.0 10.0 11.0 12.0]  &lt;- Row 2 (indices: 8-11)\n  Step size: 4 (A_cols + A_padding = 4 + 0)\n\nMatrix B Memory Layout (4x2, 8 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:    0.5   1.5   2.5   3.5   4.5   5.5   6.5   7.5 \n  Matrix: [0.5  1.5]  &lt;- Row 0 (indices: 0-1)\n          [2.5  3.5]  &lt;- Row 1 (indices: 2-3)\n          [4.5  5.5]  &lt;- Row 2 (indices: 4-5)\n          [6.5  7.5]  &lt;- Row 3 (indices: 6-7)\n  Step size: 2 (B_cols + B_padding = 2 + 0)\n\nExpected Output Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0 (indices: 0-1)\n          [101.0  127.0]  &lt;- Row 1 (indices: 2-3)\n          [157.0  199.0] &lt;- Row 2 (indices: 4-5)\n  Step size: 2 (B_cols + C_padding = 2 + 0)\n  Calculation example:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 + 4.0*6.5 =  45.0\n\nOutput Matrix C Memory Layout (3x2, 6 elements, contiguous, pad=0):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    45.0   55.0  101.0  127.0  157.0  199.0 \n  Matrix: [ 45.0   55.0]  &lt;- Row 0 (indices: 0-1)\n          [101.0  127.0]  &lt;- Row 1 (indices: 2-3)\n          [157.0  199.0] &lt;- Row 2 (indices: 4-5)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 12: tiny_mat_mult_ex_f32 - Padded Matrix Multiplication\n================================================================================\nParameters: A_rows=2, A_cols=3, B_cols=2, A_padding=2, B_padding=1, C_padding=1\nMatrix dimensions: A is 2x3, B is 3x2, C is 2x2\nNote: This should use own implementation when padding is non-zero\n\nMatrix A Memory Layout (2x3, pad=2, step=5, 10 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\n  Value:   1.0  2.0  3.0  0.0  0.0  4.0  5.0  6.0  0.0  0.0 \n  Matrix: [1.0  2.0  3.0  X   X]  &lt;- Row 0 (indices: 0, 1, 2, 3, 4)\n          [4.0  5.0  6.0  X   X]  &lt;- Row 1 (indices: 5, 6, 7, 8, 9)\n          (X = padding/unused)\n  Index calculation: A[i][j] = A[i * 5 + j]\n    Row 0: indices 0, 1, 2 (data), 3, 4 (padding)\n    Row 1: indices 5, 6, 7 (data), 8, 9 (padding)\n\nMatrix B Memory Layout (3x2, pad=1, step=3, 9 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:   0.5  1.5  0.0  2.5  3.5  0.0  4.5  5.5  0.0 \n  Matrix: [0.5  1.5  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [2.5  3.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n          [4.5  5.5  X]  &lt;- Row 2 (indices: 6, 7, 8)\n          (X = padding/unused)\n  Index calculation: B[i][j] = B[i * 3 + j]\n    Row 0: indices 0, 1 (data), 2 (padding)\n    Row 1: indices 3, 4 (data), 5 (padding)\n    Row 2: indices 6, 7 (data), 8 (padding)\n\nExpected Output Matrix C Memory Layout (2x2, pad=1, step=3, 6 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    19.0   25.0    0.0   41.5   56.5    0.0 \n  Matrix: [ 19.0   25.0  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 41.5   56.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n          (X = padding/unused)\n  Index calculation: C[i][j] = C[i * 3 + j]\n  Calculation:\n    C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0]\n            = A[0]*B[0] + A[1]*B[3] + A[2]*B[6]\n            = 1.0*0.5 + 2.0*2.5 + 3.0*4.5 =  19.0\n    C[0][1] = A[0][0]*B[0][1] + A[0][1]*B[1][1] + A[0][2]*B[2][1]\n            = 1.0*1.5 + 2.0*3.5 + 3.0*5.5 =  25.0\n    C[1][0] = A[1][0]*B[0][0] + A[1][1]*B[1][0] + A[1][2]*B[2][0]\n            = 4.0*0.5 + 5.0*2.5 + 6.0*4.5 =  41.5\n    C[1][1] = A[1][0]*B[0][1] + A[1][1]*B[1][1] + A[1][2]*B[2][1]\n            = 4.0*1.5 + 5.0*3.5 + 6.0*5.5 =  56.5\n\nOutput Matrix C Memory Layout (2x2, pad=1, step=3, 6 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]\n  Value:    19.0   25.0    0.0   41.5   56.5    0.0 \n  Matrix: [ 19.0   25.0  X]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 41.5   56.5  X]  &lt;- Row 1 (indices: 3, 4, 5)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 13: tiny_mat_multc_f32 - Contiguous Matrix Multiply Constant\n================================================================================\nParameters: rows=3, cols=3, padd_in=0, padd_out=0, step_in=1, step_out=1\nMatrix dimensions: 3x3\nConstant C: 2.5\nNote: This should use ESP-DSP on ESP32 when all paddings are 0 and all steps are 1\n\nInput Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:    1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0 \n  Matrix: [1.0  2.0  3.0]  &lt;- Row 0 (indices: 0, 1, 2)\n          [4.0  5.0  6.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [7.0  8.0  9.0]  &lt;- Row 2 (indices: 6, 7, 8)\n  Row stride: 3 (cols + padd_in = 3 + 0)\n  Index calculation: input[i][j] = input[i * 3 + j * 1]\n\nExpected Output Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:     2.5    5.0    7.5   10.0   12.5   15.0   17.5   20.0   22.5 \n  Matrix: [  2.5    5.0    7.5]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 10.0   12.5   15.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [ 17.5   20.0   22.5] &lt;- Row 2 (indices: 6, 7, 8)\n  Row stride: 3 (cols + padd_out = 3 + 0)\n  Index calculation: output[i][j] = output[i * 3 + j * 1]\n  Calculation: output[i][j] = input[i][j] * 2.5\n    Example: output[0][0] = input[0][0] * 2.5 = 1.0 * 2.5 = 2.5\n\nOutput Matrix Memory Layout (3x3, 9 elements, contiguous, pad=0, step=1):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]\n  Value:     2.5    5.0    7.5   10.0   12.5   15.0   17.5   20.0   22.5 \n  Matrix: [  2.5    5.0    7.5]  &lt;- Row 0 (indices: 0, 1, 2)\n          [ 10.0   12.5   15.0]  &lt;- Row 1 (indices: 3, 4, 5)\n          [ 17.5   20.0   22.5] &lt;- Row 2 (indices: 6, 7, 8)\n\n\u2713 Test PASSED\n================================================================================\n\n\n================================================================================\nTest Case 14: tiny_mat_multc_f32 - Padded and Strided Matrix Multiply Constant\n================================================================================\nParameters: rows=2, cols=3, padd_in=2, padd_out=1, step_in=2, step_out=1\nMatrix dimensions: 2x3\nConstant C: 3.0\nNote: This should use own implementation when padding is non-zero or step &gt; 1\n\nInput Matrix Memory Layout (2x3, pad=2, step=2, 10 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]   [8]   [9]\n  Value:   1.0  0.0  2.0  0.0  3.0  4.0  0.0  5.0  0.0  6.0 \n  Matrix: [1.0  X  2.0  X  3.0]  &lt;- Row 0 (data indices: 0, 2, 4)\n          [4.0  X  5.0  X  6.0]  &lt;- Row 1 (data indices: 5, 7, 9)\n          (X = unused/padding)\n  Row stride: 5 (cols + padd_in = 3 + 2)\n  Index calculation: input[i][j] = input[i * 5 + j * 2]\n    Row 0: input[0][0]=input[0]=1.0, input[0][1]=input[2]=2.0, input[0][2]=input[4]=3.0\n    Row 1: input[1][0]=input[5]=4.0, input[1][1]=input[7]=5.0, input[1][2]=input[9]=6.0\n\nExpected Output Matrix Memory Layout (2x3, pad=1, step=1, 8 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:     3.0    6.0    9.0    0.0   12.0   15.0   18.0    0.0 \n  Matrix: [  3.0    6.0    9.0  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\n          [ 12.0   15.0   18.0  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\n          (X = padding/unused)\n  Row stride: 4 (cols + padd_out = 3 + 1)\n  Index calculation: output[i][j] = output[i * 4 + j * 1]\n  Calculation: output[i][j] = input[i][j] * 3.0\n    Row 0: output[0][0] = input[0][0] * 3.0 = 1.0 * 3.0 = 3.0 (index 0)\n           output[0][1] = input[0][1] * 3.0 = 2.0 * 3.0 = 6.0 (index 1)\n           output[0][2] = input[0][2] * 3.0 = 3.0 * 3.0 = 9.0 (index 2)\n\nOutput Matrix Memory Layout (2x3, pad=1, step=1, 8 elements):\n  Index:  [0]   [1]   [2]   [3]   [4]   [5]   [6]   [7]\n  Value:     3.0    6.0    9.0    0.0   12.0   15.0   18.0    0.0 \n  Matrix: [  3.0    6.0    9.0  X]  &lt;- Row 0 (indices: 0, 1, 2, 3)\n          [ 12.0   15.0   18.0  X]  &lt;- Row 1 (indices: 4, 5, 6, 7)\n\n\u2713 Test PASSED\n================================================================================\n\n============ [test complete] ============\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/","title":"\u77e9\u9635\u64cd\u4f5c - TINY_MATRIX","text":"<p>TINY_MATRIX\u5e93</p> <ul> <li>\u8be5\u5e93\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u77e9\u9635\u8fd0\u7b97\u5e93\uff0c\u57fa\u4e8eC++\u5b9e\u73b0\uff0c\u63d0\u4f9b\u4e86\u57fa\u672c\u7684\u77e9\u9635\u64cd\u4f5c\u548c\u7ebf\u6027\u4ee3\u6570\u529f\u80fd\u3002</li> <li>\u8be5\u5e93\u7684\u8bbe\u8ba1\u76ee\u6807\u662f\u63d0\u4f9b\u7b80\u5355\u6613\u7528\u7684\u77e9\u9635\u64cd\u4f5c\u63a5\u53e3\uff0c\u9002\u5408\u4e8e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u3002</li> </ul> <p>\u4f7f\u7528\u573a\u666f</p> <p>\u76f8\u5bf9\u4e8eTINY_MAT\u5e93\u800c\u8a00\uff0cTINY_MATRIX\u5e93\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u529f\u80fd\u548c\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\uff0c\u9002\u5408\u4e8e\u9700\u8981\u8fdb\u884c\u590d\u6742\u77e9\u9635\u8fd0\u7b97\u7684\u5e94\u7528\u573a\u666f\u3002\u4f46\u662f\u8bf7\u6ce8\u610f\uff0c\u8be5\u5e93\u57fa\u4e8eC++\u7f16\u5199\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_1","title":"\u51fd\u6570\u5217\u8868","text":"<pre><code>TinyMath\n    \u251c\u2500\u2500Vector\n    \u2514\u2500\u2500Matrix\n        \u251c\u2500\u2500 tiny_mat (c)\n        \u2514\u2500\u2500 tiny_matrix (c++) &lt;---\n</code></pre> <pre><code>/**\n * @file tiny_matrix.hpp\n * @author SHUAIWEN CUI (SHUAIWEN001@e.ntu.edu.sg)\n * @brief This file is the header file for the submodule matrix (advanced matrix operations) of the tiny_math middleware.\n * @version 1.0\n * @date 2025-04-17\n * @note This file is built on top of the mat.h file from the ESP-DSP library.\n *\n */\n\n#pragma once\n\n/* DEPENDENCIES */\n// TinyMath\n#include \"tiny_math_config.h\"\n#include \"tiny_vec.h\"\n#include \"tiny_mat.h\"\n\n// Standard Libraries\n#include &lt;iostream&gt;\n#include &lt;stdint.h&gt;\n\n#if MCU_PLATFORM_SELECTED == MCU_PLATFORM_ESP32\n// ESP32 DSP C++ Matrix library\n#include \"mat.h\"\n#endif\n\n/* STATEMENTS */\nnamespace tiny\n{\n    class Mat\n    {\n    public:\n        // ============================================================================\n        // Matrix Metadata\n        // ============================================================================\n        int row;         //&lt; number of rows\n        int col;         //&lt; number of columns\n        int pad;         //&lt; number of paddings between 2 rows\n        int stride;      //&lt; stride = (number of elements in a row) + padding\n        int element;     //&lt; number of elements = rows * cols\n        int memory;      //&lt; size of the data buffer = rows * stride\n        float *data;     //&lt; pointer to the data buffer\n        float *temp;     //&lt; pointer to the temporary data buffer\n        bool ext_buff;   //&lt; flag indicates that matrix use external buffer\n        bool sub_matrix; //&lt; flag indicates that matrix is a subset of another matrix\n\n        // ============================================================================\n        // Rectangular ROI Structure\n        // ============================================================================\n        /**\n         * @name Region of Interest (ROI) Structure\n         * @brief This is the structure for ROI\n         */\n        struct ROI\n        {\n            int pos_x;  ///&lt; starting column index\n            int pos_y;  ///&lt; starting row index\n            int width;  ///&lt; width of ROI (columns)\n            int height; ///&lt; height of ROI (rows)\n\n            ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n            void resize_roi(int pos_x, int pos_y, int width, int height);\n            int area_roi(void) const;\n        };\n\n        // ============================================================================\n        // Printing Functions\n        // ============================================================================\n        void print_info() const;\n        void print_matrix(bool show_padding) const;\n\n        // ============================================================================\n        // Constructors &amp; Destructor\n        // ============================================================================\n        /**\n         * @brief Allocate memory for the matrix according to the memory required.\n         * @note For ESP32, it will automatically determine if using RAM or PSRAM based on the size of the matrix.\n         * @note This function sets ext_buff to false and allocates memory based on row * stride.\n         *       If allocation fails or parameters are invalid, data will be set to nullptr.\n         */\n        void alloc_mem();\n\n        /**\n         * @brief Default constructor: create a 1x1 matrix with only a zero element.\n         * @note If memory allocation fails, the object will be in an invalid state (data = nullptr).\n         *       Caller should check the data pointer before using the matrix.\n         */\n        Mat();\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows and columns.\n         * @param rows Number of rows\n         * @param cols Number of columns\n         */\n        Mat(int rows, int cols);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and stride.\n         * @param rows Number of rows\n         * @param cols Number of columns\n         * @param stride Stride (number of elements in a row)\n         */\n        Mat(int rows, int cols, int stride);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n         * @param data Pointer to external data buffer\n         * @param rows Number of rows\n         * @param cols Number of columns\n         */\n        Mat(float *data, int rows, int cols);\n\n        /**\n         * @brief Constructor - create a matrix with the specified number of rows, columns and external data.\n         * @param data Pointer to external data buffer\n         * @param rows Number of rows\n         * @param cols Number of columns\n         * @param stride Stride (number of elements in a row)\n         */\n        Mat(float *data, int rows, int cols, int stride);\n\n        /**\n         * @brief Copy constructor - create a matrix with the same properties as the source matrix.\n         * @param src Source matrix\n         */\n        Mat(const Mat &amp;src);\n\n        /**\n         * @brief Destructor - free the memory allocated for the matrix.\n         */\n        ~Mat();\n\n        // ============================================================================\n        // Element Access\n        // ============================================================================\n        inline float &amp;operator()(int row, int col) { return data[row * stride + col]; }\n        inline const float &amp;operator()(int row, int col) const { return data[row * stride + col]; }\n\n        // ============================================================================\n        // Data Manipulation\n        // ============================================================================\n        tiny_error_t copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n        tiny_error_t copy_head(const Mat &amp;src);\n        Mat view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n        Mat view_roi(const Mat::ROI &amp;roi) const;\n        Mat copy_roi(int start_row, int start_col, int height, int width);\n        Mat copy_roi(const Mat::ROI &amp;roi);\n        Mat block(int start_row, int start_col, int block_rows, int block_cols);\n        void swap_rows(int row1, int row2);\n        void swap_cols(int col1, int col2);\n        void clear(void);\n\n        // ============================================================================\n        // Arithmetic Operators\n        // ============================================================================\n        Mat &amp;operator=(const Mat &amp;src);    // Copy assignment\n        Mat &amp;operator+=(const Mat &amp;A);     // Add matrix\n        Mat &amp;operator+=(float C);          // Add constant\n        Mat &amp;operator-=(const Mat &amp;A);     // Subtract matrix\n        Mat &amp;operator-=(float C);          // Subtract constant \n        Mat &amp;operator*=(const Mat &amp;A);     // Multiply matrix\n        Mat &amp;operator*=(float C);          // Multiply constant\n        Mat &amp;operator/=(const Mat &amp;B);     // Divide matrix\n        Mat &amp;operator/=(float C);          // Divide constant\n        Mat operator^(int C);              // Exponentiation\n\n        // ============================================================================\n        // Linear Algebra - Basic Operations\n        // ============================================================================\n        Mat transpose();                   // Transpose matrix\n        float determinant();               // Compute determinant (auto-selects method based on size)\n        float determinant_laplace();        // Compute determinant using Laplace expansion (O(n!), for small matrices)\n        float determinant_lu();            // Compute determinant using LU decomposition (O(n\u00b3), efficient for large matrices)\n        float determinant_gaussian();      // Compute determinant using Gaussian elimination (O(n\u00b3), efficient for large matrices)\n        Mat adjoint();                     // Compute adjoint matrix\n        Mat inverse_adjoint();            // Compute inverse using adjoint method\n        void normalize();                  // Normalize matrix\n        float norm() const;                // Compute matrix norm\n        float dotprod(const Mat &amp;A, const Mat &amp;B);  // Dot product\n\n        // ============================================================================\n        // Linear Algebra - Matrix Utilities\n        // ============================================================================\n        static Mat eye(int size);          // Create identity matrix\n        static Mat ones(int rows, int cols);  // Create matrix filled with ones\n        static Mat ones(int size);         // Create square matrix filled with ones\n        static Mat augment(const Mat &amp;A, const Mat &amp;B);  // Horizontal concatenation [A | B]\n        static Mat vstack(const Mat &amp;A, const Mat &amp;B);   // Vertical concatenation [A; B]\n\n        /**\n         * @brief Gram-Schmidt orthogonalization process\n         * @note Orthogonalizes a set of vectors using the Gram-Schmidt process\n         * @param vectors Input matrix where each column is a vector to be orthogonalized\n         * @param orthogonal_vectors Output matrix for orthogonalized vectors (each column is orthogonal)\n         * @param coefficients Output matrix for projection coefficients (R matrix in QR decomposition)\n         * @param tolerance Minimum norm threshold for linear independence check\n         * @return true if successful, false if input is invalid\n         */\n        static bool gram_schmidt_orthogonalize(const Mat &amp;vectors, Mat &amp;orthogonal_vectors, \n                                               Mat &amp;coefficients, float tolerance = 1e-6f);\n\n        // ============================================================================\n        // Linear Algebra - Matrix Operations\n        // ============================================================================\n        Mat minor(int target_row, int target_col);       // Minor matrix (submatrix after removing row and col)\n        Mat cofactor(int target_row, int target_col);    // Cofactor matrix\n        Mat gaussian_eliminate() const;    // Gaussian elimination\n        Mat row_reduce_from_gaussian();   // Row reduction from Gaussian form\n        Mat inverse_gje();                 // Inverse using Gaussian-Jordan elimination\n\n        // ============================================================================\n        // Linear Algebra - Linear System Solving\n        // ============================================================================\n        Mat solve(const Mat &amp;A, const Mat &amp;b) const;  // Solve Ax = b using Gaussian elimination\n        Mat band_solve(Mat A, Mat b, int k);          // Solve banded system\n        Mat roots(Mat A, Mat y);                      // Alternative solve method\n\n        // ============================================================================\n        // Matrix Decomposition\n        // ============================================================================\n        // Forward declarations (structures defined after class)\n        struct LUDecomposition;\n        struct CholeskyDecomposition;\n        struct QRDecomposition;\n        struct SVDDecomposition;\n\n        // Matrix property checks\n        /**\n         * @brief Check if the matrix is symmetric within a given tolerance.\n         * @param tolerance Maximum allowed difference between A(i,j) and A(j,i) (must be &gt;= 0)\n         * @return true if matrix is symmetric, false otherwise\n         */\n        bool is_symmetric(float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Check if matrix is positive definite using Sylvester's criterion.\n         * @param tolerance Tolerance for numerical checks (must be &gt;= 0)\n         * @param max_minors_to_check Maximum number of leading principal minors to check.\n         *                            - If -1: check all minors (complete Sylvester's criterion)\n         *                            - If &gt; 0: check first max_minors_to_check minors\n         * @return true if matrix is positive definite, false otherwise\n         */\n        bool is_positive_definite(float tolerance = 1e-6f, int max_minors_to_check = -1) const;\n\n        // Decomposition methods\n        LUDecomposition lu_decompose(bool use_pivoting = true) const;\n        CholeskyDecomposition cholesky_decompose() const;\n        QRDecomposition qr_decompose() const;\n        SVDDecomposition svd_decompose(int max_iter = 100, float tolerance = 1e-6f) const;\n\n        // Solve using decomposition (more efficient for multiple RHS)\n        static Mat solve_lu(const LUDecomposition &amp;lu, const Mat &amp;b);\n        static Mat solve_cholesky(const CholeskyDecomposition &amp;chol, const Mat &amp;b);\n        static Mat solve_qr(const QRDecomposition &amp;qr, const Mat &amp;b);  // Least squares solution\n\n        // Pseudo-inverse using SVD (for rank-deficient or non-square matrices)\n        static Mat pseudo_inverse(const SVDDecomposition &amp;svd, float tolerance = 1e-6f);\n\n        // ============================================================================\n        // Eigenvalue &amp; Eigenvector Decomposition\n        // ============================================================================\n        // Forward declarations (structures defined after class)\n        struct EigenPair;\n        struct EigenDecomposition;\n\n        // Single eigenvalue methods (fast, for real-time applications)\n        /**\n         * @brief Compute the dominant (largest magnitude) eigenvalue and eigenvector using power iteration.\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when |\u03bb_k - \u03bb_{k-1}| &lt; tolerance * |\u03bb_k|\n         * @return EigenPair containing the dominant eigenvalue, eigenvector, and status\n         */\n        EigenPair power_iteration(int max_iter = 1000, float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Compute the smallest (minimum magnitude) eigenvalue and eigenvector using inverse power iteration.\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when |\u03bb_k - \u03bb_{k-1}| &lt; tolerance * max(|\u03bb_k|, 1)\n         * @return EigenPair containing the smallest eigenvalue, eigenvector, and status\n         * @note The matrix must be invertible (non-singular) for this method to work.\n         */\n        EigenPair inverse_power_iteration(int max_iter = 1000, float tolerance = 1e-6f) const;\n\n        // Complete eigendecomposition methods\n        /**\n         * @brief Compute complete eigenvalue decomposition using Jacobi method for symmetric matrices.\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when max off-diagonal &lt; tolerance\n         * @param max_iter Maximum number of iterations (must be &gt; 0)\n         * @return EigenDecomposition containing all eigenvalues, eigenvectors, and status\n         * @note Best for symmetric matrices. Matrix should be symmetric for best results.\n         */\n        EigenDecomposition eigendecompose_jacobi(float tolerance = 1e-6f, int max_iter = 100) const;\n\n        /**\n         * @brief Compute complete eigenvalue decomposition using QR algorithm for general matrices.\n         * @param max_iter Maximum number of QR iterations (must be &gt; 0)\n         * @param tolerance Convergence tolerance (must be &gt;= 0). Convergence when subdiagonal &lt; tolerance\n         * @return EigenDecomposition containing eigenvalues, eigenvectors, and status\n         * @note Supports non-symmetric matrices, but may have complex eigenvalues (only real part returned).\n         */\n        EigenDecomposition eigendecompose_qr(int max_iter = 100, float tolerance = 1e-6f) const;\n\n        /**\n         * @brief Automatic eigenvalue decomposition with method selection.\n         * @param tolerance Convergence tolerance (must be &gt;= 0)\n         * @return EigenDecomposition containing eigenvalues, eigenvectors, and status\n         * @note Automatically selects Jacobi method for symmetric matrices, QR algorithm for general matrices.\n         */\n        EigenDecomposition eigendecompose(float tolerance = 1e-6f) const;\n\n    protected:\n\n    private:\n\n    };\n\n    // ============================================================================\n    // Matrix Decomposition Structures\n    // ============================================================================\n    /**\n     * @brief Structure to hold LU decomposition results\n     * @note A = L * U, where L is lower triangular and U is upper triangular\n     */\n    struct Mat::LUDecomposition\n    {\n        Mat L;                 ///&lt; Lower triangular matrix (with unit diagonal)\n        Mat U;                 ///&lt; Upper triangular matrix\n        Mat P;                 ///&lt; Permutation matrix (if pivoting used)\n        bool pivoted;          ///&lt; Whether pivoting was used\n        tiny_error_t status;   ///&lt; Computation status\n\n        LUDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold Cholesky decomposition results\n     * @note A = L * L^T, where L is lower triangular (for symmetric positive definite matrices)\n     */\n    struct Mat::CholeskyDecomposition\n    {\n        Mat L;                 ///&lt; Lower triangular matrix\n        tiny_error_t status;   ///&lt; Computation status\n\n        CholeskyDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold QR decomposition results\n     * @note A = Q * R, where Q is orthogonal and R is upper triangular\n     */\n    struct Mat::QRDecomposition\n    {\n        Mat Q;                 ///&lt; Orthogonal matrix (Q^T * Q = I)\n        Mat R;                 ///&lt; Upper triangular matrix\n        tiny_error_t status;   ///&lt; Computation status\n\n        QRDecomposition();\n    };\n\n    /**\n     * @brief Structure to hold SVD decomposition results\n     * @note A = U * S * V^T, where U and V are orthogonal, S is diagonal (singular values)\n     */\n    struct Mat::SVDDecomposition\n    {\n        Mat U;                 ///&lt; Left singular vectors (orthogonal matrix)\n        Mat S;                 ///&lt; Singular values (diagonal matrix or vector)\n        Mat V;                 ///&lt; Right singular vectors (orthogonal matrix, V^T)\n        int rank;              ///&lt; Numerical rank of the matrix\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        SVDDecomposition();\n    };\n\n    // ============================================================================\n    // Eigenvalue &amp; Eigenvector Decomposition Structures\n    // ============================================================================\n    /**\n     * @brief Structure to hold a single eigenvalue-eigenvector pair\n     * @note Used primarily for power iteration method\n     */\n    struct Mat::EigenPair\n    {\n        float eigenvalue;      ///&lt; Eigenvalue (real part)\n        Mat eigenvector;       ///&lt; Corresponding eigenvector (column vector)\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        EigenPair();\n    };\n\n    /**\n     * @brief Structure to hold complete eigenvalue decomposition results\n     * @note Contains all eigenvalues and eigenvectors\n     */\n    struct Mat::EigenDecomposition\n    {\n        Mat eigenvalues;       ///&lt; Eigenvalues (diagonal matrix or vector)\n        Mat eigenvectors;      ///&lt; Eigenvector matrix (each column is an eigenvector)\n        int iterations;        ///&lt; Number of iterations performed\n        tiny_error_t status;   ///&lt; Computation status\n\n        EigenDecomposition();\n    };\n\n    // ============================================================================\n    // Stream Operators\n    // ============================================================================\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n    std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n    std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n\n    // ============================================================================\n    // Global Arithmetic Operators\n    // ============================================================================\n    Mat operator+(const Mat &amp;A, const Mat &amp;B);\n    Mat operator+(const Mat &amp;A, float C);\n    Mat operator-(const Mat &amp;A, const Mat &amp;B);\n    Mat operator-(const Mat &amp;A, float C);\n    Mat operator*(const Mat &amp;A, const Mat &amp;B);\n    Mat operator*(const Mat &amp;A, float C);\n    Mat operator*(float C, const Mat &amp;A);\n    Mat operator/(const Mat &amp;A, float C);\n    Mat operator/(const Mat &amp;A, const Mat &amp;B);\n    bool operator==(const Mat &amp;A, const Mat &amp;B);\n\n}\n</code></pre>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_2","title":"\u77e9\u9635\u5143\u6570\u636e","text":"<p>\u77e9\u9635\u7ed3\u6784</p> <p>Mat\u7c7b\u4f7f\u7528\u884c\u4e3b\u5e8f\u5b58\u50a8\u5e03\u5c40\uff0c\u652f\u6301\u586b\u5145\u548c\u6b65\u5e45\u3002\u8fd9\u79cd\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u5e76\u4e0eDSP\u5e93\u517c\u5bb9\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_3","title":"\u6838\u5fc3\u7ef4\u5ea6","text":"<ul> <li> <p><code>int row</code> : \u77e9\u9635\u7684\u884c\u6570\u3002</p> </li> <li> <p><code>int col</code> : \u77e9\u9635\u7684\u5217\u6570\u3002</p> </li> <li> <p><code>int element</code> : \u5143\u7d20\u603b\u6570 = \u884c\u6570 \u00d7 \u5217\u6570\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_4","title":"\u5185\u5b58\u5e03\u5c40","text":"<ul> <li> <p><code>int stride</code> : \u6b65\u5e45 = (\u6bcf\u884c\u5143\u7d20\u6570) + \u586b\u5145\u6570\u3002\u6b65\u5e45\u51b3\u5b9a\u4e86\u5728\u5185\u5b58\u4e2d\u79fb\u52a8\u5230\u4e0b\u4e00\u884c\u9700\u8981\u8df3\u8fc7\u7684\u5143\u7d20\u6570\u3002</p> </li> <li> <p><code>int pad</code> : \u4e24\u884c\u4e4b\u95f4\u7684\u586b\u5145\u5143\u7d20\u6570\u3002\u586b\u5145\u7528\u4e8e\u5185\u5b58\u5bf9\u9f50\u548cDSP\u4f18\u5316\u3002</p> </li> <li> <p><code>int memory</code> : \u6570\u636e\u7f13\u51b2\u533a\u5927\u5c0f = \u884c\u6570 \u00d7 \u6b65\u5e45\uff08\u4ee5float\u5143\u7d20\u4e3a\u5355\u4f4d\uff09\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_5","title":"\u6570\u636e\u6307\u9488","text":"<ul> <li> <p><code>float *data</code> : \u6307\u5411\u5305\u542b\u77e9\u9635\u5143\u7d20\u7684\u6570\u636e\u7f13\u51b2\u533a\u7684\u6307\u9488\u3002\u5143\u7d20\u6309\u884c\u4e3b\u5e8f\u5b58\u50a8\uff1a\u4f4d\u7f6e(i, j)\u7684\u5143\u7d20\u4f4d\u4e8e <code>data[i * stride + j]</code>\u3002</p> </li> <li> <p><code>float *temp</code> : \u6307\u5411\u4e34\u65f6\u6570\u636e\u7f13\u51b2\u533a\u7684\u6307\u9488\uff08\u5982\u679c\u5df2\u5206\u914d\uff09\u3002\u67d0\u4e9b\u64cd\u4f5c\u5185\u90e8\u4f7f\u7528\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_6","title":"\u5185\u5b58\u7ba1\u7406\u6807\u5fd7","text":"<ul> <li> <p><code>bool ext_buff</code> : \u6807\u5fd7\u77e9\u9635\u662f\u5426\u4f7f\u7528\u5916\u90e8\u7f13\u51b2\u533a\u3002\u5f53\u4e3a<code>true</code>\u65f6\uff0c\u6790\u6784\u51fd\u6570\u4e0d\u4f1a\u91ca\u653e\u5185\u5b58\uff08\u8c03\u7528\u8005\u8d1f\u8d23\u7ba1\u7406\uff09\u3002</p> </li> <li> <p><code>bool sub_matrix</code> : \u6807\u5fd7\u77e9\u9635\u662f\u5426\u4e3a\u53e6\u4e00\u4e2a\u77e9\u9635\u7684\u5b50\u96c6/\u89c6\u56fe\u3002\u5f53\u4e3a<code>true</code>\u65f6\uff0c\u77e9\u9635\u4e0e\u7236\u77e9\u9635\u5171\u4eab\u6570\u636e\u3002</p> </li> </ul> <p>\u5185\u5b58\u5e03\u5c40\u793a\u4f8b</p> <p>\u5bf9\u4e8e3\u00d74\u77e9\u9635\uff0c\u6b65\u5e45=4\uff08\u65e0\u586b\u5145\uff09\uff1a <pre><code>[a b c d]   \u884c 0: data[0*4+0] \u5230 data[0*4+3]\n[e f g h]   \u884c 1: data[1*4+0] \u5230 data[1*4+3]\n[i j k l]   \u884c 2: data[2*4+0] \u5230 data[2*4+3]\n</code></pre></p> <p>\u5bf9\u4e8e3\u00d74\u77e9\u9635\uff0c\u6b65\u5e45=6\uff08\u586b\u5145=2\uff09\uff1a <pre><code>[a b c d _ _]   \u884c 0: data[0*6+0] \u5230 data[0*6+3]\uff0c\u586b\u5145\u5728 data[0*6+4,5]\n[e f g h _ _]   \u884c 1: data[1*6+0] \u5230 data[1*6+3]\uff0c\u586b\u5145\u5728 data[1*6+4,5]\n[i j k l _ _]   \u884c 2: data[2*6+0] \u5230 data[2*6+3]\uff0c\u586b\u5145\u5728 data[2*6+4,5]\n</code></pre></p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi","title":"ROI \u7ed3\u6784","text":"<p>\u611f\u5174\u8da3\u533a\u57df</p> <p>ROI\uff08\u611f\u5174\u8da3\u533a\u57df\uff09\u7ed3\u6784\u8868\u793a\u77e9\u9635\u7684\u77e9\u5f62\u5b50\u533a\u57df\u3002\u5b83\u4e0e<code>view_roi()</code>\u548c<code>copy_roi()</code>\u51fd\u6570\u4e00\u8d77\u4f7f\u7528\uff0c\u4ee5\u9ad8\u6548\u5730\u63d0\u53d6\u6216\u5f15\u7528\u5b50\u77e9\u9635\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi_1","title":"ROI \u5143\u6570\u636e","text":"<ul> <li> <p><code>int pos_x</code> : \u8d77\u59cb\u5217\u7d22\u5f15\uff08\u5de6\u4e0a\u89d2\u7684x\u5750\u6807\uff09\u3002</p> </li> <li> <p><code>int pos_y</code> : \u8d77\u59cb\u884c\u7d22\u5f15\uff08\u5de6\u4e0a\u89d2\u7684y\u5750\u6807\uff09\u3002</p> </li> <li> <p><code>int width</code> : ROI\u7684\u5bbd\u5ea6\uff08\u5217\u6570\uff09\u3002</p> </li> <li> <p><code>int height</code> : ROI\u7684\u9ad8\u5ea6\uff08\u884c\u6570\uff09\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi_2","title":"ROI \u6784\u9020\u51fd\u6570","text":"<pre><code>Mat::ROI::ROI(int pos_x = 0, int pos_y = 0, int width = 0, int height = 0);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6784\u9020\u4e00\u4e2a ROI \u5bf9\u8c61\uff0c\u9ed8\u8ba4\u503c\u4e3a (0, 0, 0, 0)\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int pos_x</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int pos_y</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int width</code>: ROI \u7684\u5bbd\u5ea6\uff08\u5217\u6570\uff09</p> </li> <li> <p><code>int height</code>: ROI \u7684\u9ad8\u5ea6\uff08\u884c\u6570\uff09</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi_3","title":"ROI \u91cd\u7f6e\u51fd\u6570","text":"<pre><code>void Mat::ROI::resize_roi(int pos_x, int pos_y, int width, int height);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u91cd\u7f6e ROI \u7684\u4f4d\u7f6e\u548c\u5927\u5c0f\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int pos_x</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int pos_y</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int width</code>: ROI \u7684\u5bbd\u5ea6\uff08\u5217\u6570\uff09</p> </li> <li> <p><code>int height</code>: ROI \u7684\u9ad8\u5ea6\uff08\u884c\u6570\uff09</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi_4","title":"ROI \u9762\u79ef\u51fd\u6570","text":"<pre><code>int Mat::ROI::area_roi(void) const;\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u8ba1\u7b97 ROI \u7684\u9762\u79ef\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>\u6574\u6570\u7c7b\u578b ROI \u7684\u9762\u79ef</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_7","title":"\u6253\u5370\u51fd\u6570","text":"<p>\u8c03\u8bd5\u5de5\u5177</p> <p>\u8fd9\u4e9b\u51fd\u6570\u5bf9\u4e8e\u8c03\u8bd5\u548c\u7406\u89e3\u77e9\u9635\u72b6\u6001\u81f3\u5173\u91cd\u8981\u3002\u4f7f\u7528\u5b83\u4eec\u6765\u9a8c\u8bc1\u77e9\u9635\u7ef4\u5ea6\u3001\u5185\u5b58\u5e03\u5c40\u548c\u6570\u636e\u503c\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_8","title":"\u6253\u5370\u77e9\u9635\u4fe1\u606f","text":"<pre><code>void Mat::print_info() const;\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6253\u5370\u5168\u9762\u7684\u77e9\u9635\u4fe1\u606f\uff0c\u5305\u62ec\uff1a</p> <ul> <li> <p>\u7ef4\u5ea6\uff1a\u884c\u6570\u3001\u5217\u6570\u3001\u5143\u7d20\u6570</p> </li> <li> <p>\u5185\u5b58\u5e03\u5c40\uff1a\u586b\u5145\u6570\u3001\u6b65\u5e45\u3001\u5185\u5b58\u5927\u5c0f</p> </li> <li> <p>\u6307\u9488\uff1a\u6570\u636e\u7f13\u51b2\u533a\u5730\u5740\u3001\u4e34\u65f6\u7f13\u51b2\u533a\u5730\u5740</p> </li> <li> <p>\u6807\u5fd7\uff1a\u5916\u90e8\u7f13\u51b2\u533a\u4f7f\u7528\u60c5\u51b5\u3001\u5b50\u77e9\u9635\u72b6\u6001</p> </li> <li> <p>\u8b66\u544a\uff1a\u7ef4\u5ea6\u4e0d\u5339\u914d\u3001\u65e0\u6548\u72b6\u6001</p> </li> </ul> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>void</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u8c03\u8bd5: \u5bf9\u4e8e\u9a8c\u8bc1\u77e9\u9635\u72b6\u6001\u548c\u68c0\u6d4b\u5185\u5b58\u95ee\u9898\u81f3\u5173\u91cd\u8981\u3002</p> </li> <li> <p>\u5185\u5b58\u5206\u6790: \u663e\u793a\u5b9e\u9645\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\u4e0e\u903b\u8f91\u5927\u5c0f\u7684\u5bf9\u6bd4\uff0c\u5e2e\u52a9\u8bc6\u522b\u5185\u5b58\u6548\u7387\u95ee\u9898\u3002</p> </li> <li> <p>\u5b50\u77e9\u9635\u68c0\u6d4b: \u6e05\u695a\u5730\u6307\u793a\u77e9\u9635\u662f\u5426\u4e3a\u89c6\u56fe\uff0c\u8fd9\u4f1a\u5f71\u54cd\u5185\u5b58\u7ba1\u7406\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_9","title":"\u6253\u5370\u77e9\u9635\u5143\u7d20","text":"<pre><code>void Mat::print_matrix(bool show_padding);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u4ee5\u683c\u5f0f\u5316\u8868\u683c\u5f62\u5f0f\u6253\u5370\u77e9\u9635\u5143\u7d20\u3002\u53ef\u9009\u62e9\u663e\u793a\u7531\u89c6\u89c9\u5206\u9694\u7b26\u5206\u9694\u7684\u586b\u5145\u5143\u7d20\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>bool show_padding</code> : \u5982\u679c\u4e3a<code>true</code>\uff0c\u663e\u793a\u586b\u5145\u503c\u5e76\u7528\u5206\u9694\u7b26<code>|</code>\u5206\u9694\u3002\u5982\u679c\u4e3a<code>false</code>\uff0c\u4ec5\u663e\u793a\u5b9e\u9645\u77e9\u9635\u5143\u7d20\u3002</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>void</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u683c\u5f0f\u5316: \u5143\u7d20\u4ee5\u56fa\u5b9a\u5bbd\u5ea6\uff0812\u4e2a\u5b57\u7b26\uff09\u683c\u5f0f\u5316\u4ee5\u4fdd\u6301\u5bf9\u9f50\u3002</p> </li> <li> <p>\u586b\u5145\u53ef\u89c6\u5316: <code>show_padding</code>\u9009\u9879\u6709\u52a9\u4e8e\u7406\u89e3\u5185\u5b58\u5e03\u5c40\u548c\u9a8c\u8bc1\u586b\u5145\u503c\u3002</p> </li> <li> <p>\u5927\u77e9\u9635: \u5bf9\u4e8e\u975e\u5e38\u5927\u7684\u77e9\u9635\uff0c\u8003\u8651\u4f7f\u7528<code>view_roi()</code>\u6253\u5370\u7279\u5b9a\u533a\u57df\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_10","title":"\u6784\u9020\u4e0e\u6790\u6784\u51fd\u6570","text":"<p>\u5185\u5b58\u7ba1\u7406</p> <p>\u6784\u9020\u51fd\u6570\u81ea\u52a8\u5904\u7406\u5185\u5b58\u5206\u914d\u3002\u6790\u6784\u51fd\u6570\u4ec5\u5728\u5185\u5b58\u662f\u5185\u90e8\u5206\u914d\u7684\u60c5\u51b5\u4e0b\u5b89\u5168\u91ca\u653e\u5185\u5b58\uff08\u4e0d\u5305\u62ec\u5916\u90e8\u7f13\u51b2\u533a\u6216\u89c6\u56fe\uff09\u3002\u6784\u9020\u540e\u59cb\u7ec8\u68c0\u67e5<code>data</code>\u6307\u9488\u4ee5\u786e\u4fdd\u5206\u914d\u6210\u529f\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_11","title":"\u5185\u5b58\u5206\u914d","text":"<pre><code>void Mat::alloc_mem();\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6839\u636e\u8ba1\u7b97\u7684\u5185\u5b58\u9700\u6c42\u4e3a\u77e9\u9635\u5206\u914d\u5185\u5b58\u7684\u5185\u90e8\u51fd\u6570\u3002\u8bbe\u7f6e<code>ext_buff = false</code>\u5e76\u5206\u914d<code>row * stride</code>\u4e2afloat\u5143\u7d20\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>void</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u81ea\u52a8\u8c03\u7528: \u7531\u6784\u9020\u51fd\u6570\u81ea\u52a8\u8c03\u7528\u3002\u5f88\u5c11\u9700\u8981\u624b\u52a8\u8c03\u7528\u3002</p> </li> <li> <p>\u5185\u5b58\u8ba1\u7b97: \u5206\u914d<code>row * stride</code>\u4e2a\u5143\u7d20\uff0c\u53ef\u80fd\u5305\u62ec\u586b\u5145\u3002</p> </li> <li> <p>\u9519\u8bef\u5904\u7406: \u5982\u679c\u5206\u914d\u5931\u8d25\uff0c<code>data</code>\u4fdd\u6301\u4e3a<code>nullptr</code>\u3002\u6784\u9020\u540e\u59cb\u7ec8\u68c0\u67e5<code>data</code>\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_12","title":"\u9ed8\u8ba4\u6784\u9020\u51fd\u6570","text":"<pre><code>Mat::Mat();\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u9ed8\u8ba4\u6784\u9020\u51fd\u6570\u521b\u5efa\u4e00\u4e2a1\u00d71\u7684\u96f6\u77e9\u9635\u3002\u8fd9\u5bf9\u4e8e\u521d\u59cb\u5316\u548c\u4f5c\u4e3a\u9519\u8bef\u60c5\u51b5\u7684\u8fd4\u56de\u503c\u5f88\u6709\u7528\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u5728\u67d0\u4e9b\u4e0a\u4e0b\u6587\u4e2d\u521b\u5efa\u77e9\u9635\u8fd0\u7b97\u7684\u6052\u7b49\u5143\u7d20\uff0c\u5c3d\u7ba1\u901a\u5e38\u60a8\u4f1a\u5e0c\u671b\u6307\u5b9a\u7ef4\u5ea6\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u4e00\u4e2a\u5143\u7d20\u4e3a0\u76841\u00d71\u77e9\u9635\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matint-rows-int-cols","title":"\u6784\u9020\u51fd\u6570 - Mat(int rows, int cols)","text":"<pre><code>Mat::Mat(int rows, int cols);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6784\u9020\u51fd\u6570\u521b\u5efa\u5177\u6709\u6307\u5b9a\u7ef4\u5ea6\u7684\u77e9\u9635\u3002\u6240\u6709\u5143\u7d20\u521d\u59cb\u5316\u4e3a\u96f6\u3002\u8fd9\u662f\u6700\u5e38\u7528\u7684\u6784\u9020\u51fd\u6570\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int rows</code> : \u884c\u6570\uff08\u5fc5\u987b &gt; 0\uff09\u3002</p> </li> <li> <p><code>int cols</code> : \u5217\u6570\uff08\u5fc5\u987b &gt; 0\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u4e00\u4e2arows\u00d7cols\u7684\u77e9\u9635\uff0c\u6240\u6709\u5143\u7d20\u521d\u59cb\u5316\u4e3a0\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u96f6\u521d\u59cb\u5316: \u6240\u6709\u5143\u7d20\u4f7f\u7528<code>memset</code>\u8bbe\u7f6e\u4e3a\u96f6\uff0c\u786e\u4fdd\u5e72\u51c0\u7684\u72b6\u6001\u3002</p> </li> <li> <p>\u5185\u5b58\u5e03\u5c40: \u521b\u5efa\u8fde\u7eed\u7684\u5185\u5b58\u5e03\u5c40\uff0c\u65e0\u586b\u5145\uff08stride = cols\uff09\u3002</p> </li> <li> <p>\u9519\u8bef\u5904\u7406: \u5982\u679c\u5185\u5b58\u5206\u914d\u5931\u8d25\uff0c<code>data</code>\u5c06\u4e3a<code>nullptr</code>\u3002\u59cb\u7ec8\u9a8c\u8bc1\u5206\u914d\u6210\u529f\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matint-rows-int-cols-int-stride","title":"\u6784\u9020\u51fd\u6570 - Mat(int rows, int cols, int stride)","text":"<pre><code>Mat::Mat(int rows, int cols, int stride);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6784\u9020\u51fd\u6570\u521b\u5efa\u5177\u6709\u6307\u5b9a\u7ef4\u5ea6\u3001\u5217\u6570\u548c\u6b65\u5e45\u7684\u77e9\u9635\u3002\u5f53\u9700\u8981\u586b\u5145\u4ee5\u8fdb\u884c\u5185\u5b58\u5bf9\u9f50\u6216DSP\u4f18\u5316\u65f6\u5f88\u6709\u7528\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int rows</code> : \u884c\u6570\u3002</p> </li> <li> <p><code>int cols</code> : \u5217\u6570\u3002</p> </li> <li> <p><code>int stride</code> : \u6b65\u5e45\uff08\u5fc5\u987b \u2265 cols\uff09\u3002\u586b\u5145 = stride - cols\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u4e00\u4e2a\u5177\u6709\u6b65\u5e45\u7684rows\u00d7cols\u77e9\u9635\uff0c\u6240\u6709\u5143\u7d20\u521d\u59cb\u5316\u4e3a0\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>DSP\u4f18\u5316: \u67d0\u4e9bDSP\u5e93\u9700\u8981\u5bf9\u9f50\u7684\u5185\u5b58\u3002\u4f7f\u7528\u6b65\u5e45\u786e\u4fdd\u9002\u5f53\u7684\u5bf9\u9f50\u3002</p> </li> <li> <p>\u5185\u5b58\u6548\u7387: \u586b\u5145\u5141\u8bb8\u5728\u5bf9\u9f50\u8fb9\u754c\u4e0a\u8fdb\u884c\u9ad8\u6548\u7684\u5411\u91cf\u5316\u64cd\u4f5c\u3002</p> </li> <li> <p>\u517c\u5bb9\u6027: \u5b9e\u73b0\u4e0e\u4f7f\u7528\u6b65\u5e45\u5185\u5b58\u5e03\u5c40\u7684\u5916\u90e8\u5e93\u7684\u517c\u5bb9\u6027\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matfloat-data-int-rows-int-cols","title":"\u6784\u9020\u51fd\u6570 - Mat(float *data, int rows, int cols)","text":"<pre><code>Mat::Mat(float *data, int rows, int cols);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6784\u9020\u51fd\u6570\u5728\u5916\u90e8\u6570\u636e\u7f13\u51b2\u533a\u4e0a\u521b\u5efa\u77e9\u9635\u89c6\u56fe\u3002\u77e9\u9635\u4e0d\u62e5\u6709\u5185\u5b58\uff1b\u8c03\u7528\u8005\u8d1f\u8d23\u7ba1\u7406\u5b83\u3002\u5bf9\u4e8e\u4e0e\u73b0\u6709\u6570\u636e\u6570\u7ec4\u63a5\u53e3\u5f88\u6709\u7528\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>float *data</code> : \u6307\u5411\u5916\u90e8\u6570\u636e\u7f13\u51b2\u533a\u7684\u6307\u9488\uff08\u5728\u77e9\u9635\u751f\u547d\u5468\u671f\u5185\u5fc5\u987b\u4fdd\u6301\u6709\u6548\uff09\u3002</p> </li> <li> <p><code>int rows</code> : \u884c\u6570\u3002</p> </li> <li> <p><code>int cols</code> : \u5217\u6570\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u4e00\u4e2a<code>ext_buff = true</code>\u7684\u77e9\u9635\u89c6\u56fe\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u96f6\u62f7\u8d1d: \u4e0d\u53d1\u751f\u5185\u5b58\u62f7\u8d1d\uff1b\u77e9\u9635\u76f4\u63a5\u5f15\u7528\u5916\u90e8\u6570\u636e\u3002</p> </li> <li> <p>\u751f\u547d\u5468\u671f\u7ba1\u7406: \u5916\u90e8\u7f13\u51b2\u533a\u5728\u77e9\u9635\u5b58\u5728\u671f\u95f4\u5fc5\u987b\u4fdd\u6301\u6709\u6548\u3002\u6790\u6784\u51fd\u6570\u4e0d\u4f1a\u91ca\u653e\u6b64\u5185\u5b58\u3002</p> </li> <li> <p>\u6570\u636e\u5e03\u5c40: \u5047\u8bbe\u884c\u4e3b\u5e8f\u5e03\u5c40\uff0c\u65e0\u586b\u5145\uff08stride = cols\uff09\u3002</p> </li> <li> <p>\u4f7f\u7528\u573a\u666f: </p> </li> <li> <p>\u5305\u88c5C\u6570\u7ec4</p> </li> <li> <p>\u4e0e\u5176\u4ed6\u5e93\u63a5\u53e3</p> </li> <li> <p>\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u62f7\u8d1d</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matfloat-data-int-rows-int-cols-int-stride","title":"\u6784\u9020\u51fd\u6570 - Mat(float *data, int rows, int cols, int stride)","text":"<pre><code>Mat::Mat(float *data, int rows, int cols, int stride);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6784\u9020\u51fd\u6570\u5728\u5177\u6709\u6307\u5b9a\u6b65\u5e45\u7684\u5916\u90e8\u6570\u636e\u7f13\u51b2\u533a\u4e0a\u521b\u5efa\u77e9\u9635\u89c6\u56fe\u3002\u652f\u6301\u6b65\u5e45\u5185\u5b58\u5e03\u5c40\u4ee5\u5b9e\u73b0DSP\u517c\u5bb9\u6027\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>float *data</code> : \u6307\u5411\u5916\u90e8\u6570\u636e\u7f13\u51b2\u533a\u7684\u6307\u9488\uff08\u5728\u77e9\u9635\u751f\u547d\u5468\u671f\u5185\u5fc5\u987b\u4fdd\u6301\u6709\u6548\uff09\u3002</p> </li> <li> <p><code>int rows</code> : \u884c\u6570\u3002</p> </li> <li> <p><code>int cols</code> : \u5217\u6570\u3002</p> </li> <li> <p><code>int stride</code> : \u6b65\u5e45\uff08\u5fc5\u987b \u2265 cols\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u4e00\u4e2a<code>ext_buff = true</code>\u5e76\u5177\u6709\u6307\u5b9a\u6b65\u5e45\u7684\u77e9\u9635\u89c6\u56fe\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u6b65\u5e45\u5e03\u5c40: \u5bf9\u4e8e\u4f7f\u7528\u6b65\u5e45\u5185\u5b58\u5e03\u5c40\u7684DSP\u5e93\u81f3\u5173\u91cd\u8981\u3002</p> </li> <li> <p>\u5185\u5b58\u5b89\u5168: \u4e0e\u4e0a\u4e00\u4e2a\u6784\u9020\u51fd\u6570\u76f8\u540c\u7684\u751f\u547d\u5468\u671f\u8981\u6c42 - \u5916\u90e8\u7f13\u51b2\u533a\u5fc5\u987b\u4fdd\u6301\u6709\u6548\u3002</p> </li> <li> <p>\u586b\u5145\u652f\u6301: \u53ef\u4ee5\u5904\u7406\u884c\u95f4\u6709\u586b\u5145\u7684\u7f13\u51b2\u533a\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-matconst-mat-src","title":"\u62f7\u8d1d\u6784\u9020\u51fd\u6570 - Mat(const Mat &amp;src)","text":"<pre><code>Mat::Mat(const Mat &amp;src);\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u62f7\u8d1d\u6784\u9020\u51fd\u6570\u4ece\u6e90\u77e9\u9635\u521b\u5efa\u65b0\u77e9\u9635\u3002\u4f7f\u7528\u667a\u80fd\u62f7\u8d1d\u7b56\u7565\uff1a\u5e38\u89c4\u77e9\u9635\u8fdb\u884c\u6df1\u62f7\u8d1d\uff0c\u5b50\u77e9\u9635\u89c6\u56fe\u8fdb\u884c\u6d45\u62f7\u8d1d\u3002</p> <p>\u62f7\u8d1d\u7b56\u7565:</p> <ul> <li> <p>\u5e38\u89c4\u77e9\u9635: \u6df1\u62f7\u8d1d - \u5206\u914d\u65b0\u5185\u5b58\u5e76\u62f7\u8d1d\u6240\u6709\u6570\u636e</p> </li> <li> <p>\u5b50\u77e9\u9635\u89c6\u56fe: \u6d45\u62f7\u8d1d - \u4e0e\u6e90\u5171\u4eab\u6570\u636e\uff08\u521b\u5efa\u53e6\u4e00\u4e2a\u89c6\u56fe\uff09</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;src</code> : \u6e90\u77e9\u9635\u3002</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u6839\u636e\u6e90\u7c7b\u578b\u5177\u6709\u62f7\u8d1d\u6216\u5171\u4eab\u6570\u636e\u7684\u65b0\u77e9\u9635\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u81ea\u52a8\u9009\u62e9: \u6839\u636e\u6e90\u77e9\u9635\u7c7b\u578b\u81ea\u52a8\u9009\u62e9\u6df1\u62f7\u8d1d\u6216\u6d45\u62f7\u8d1d\u3002</p> </li> <li> <p>\u5185\u5b58\u6548\u7387: \u5b50\u77e9\u9635\u89c6\u56fe\u8fdb\u884c\u6d45\u62f7\u8d1d\u4ee5\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5185\u5b58\u5206\u914d\u3002</p> </li> <li> <p>\u72ec\u7acb\u6027: \u6df1\u62f7\u8d1d\u662f\u72ec\u7acb\u7684\uff1b\u4fee\u6539\u4e0d\u4f1a\u5f71\u54cd\u6e90\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_13","title":"\u6790\u6784\u51fd\u6570","text":"<pre><code>Mat::~Mat();\n</code></pre> <p>\u63cf\u8ff0: </p> <p>\u6790\u6784\u51fd\u6570\u5b89\u5168\u5730\u91ca\u653e\u5206\u914d\u7684\u5185\u5b58\u3002\u4ec5\u91ca\u653e\u5185\u90e8\u5206\u914d\u7684\u5185\u5b58\uff08<code>ext_buff = false</code>\uff09\u3002\u5916\u90e8\u7f13\u51b2\u533a\u548c\u89c6\u56fe\u4e0d\u4f1a\u88ab\u91ca\u653e\u3002</p> <p>\u5185\u5b58\u7ba1\u7406:</p> <ul> <li> <p>\u5982\u679c<code>ext_buff = false</code>\uff0c\u91ca\u653e<code>data</code>\u7f13\u51b2\u533a</p> </li> <li> <p>\u5982\u679c\u5df2\u5206\u914d\uff0c\u91ca\u653e<code>temp</code>\u7f13\u51b2\u533a</p> </li> <li> <p>\u5bf9\u5916\u90e8\u7f13\u51b2\u533a\u6216\u89c6\u56fe\u4e0d\u6267\u884c\u4efb\u4f55\u64cd\u4f5c</p> </li> </ul> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>void</p> <p>\u6784\u9020\u51fd\u6570\u548c\u6790\u6784\u51fd\u6570\u89c4\u5219</p> <ul> <li>\u6784\u9020\u51fd\u6570\u51fd\u6570\u5fc5\u987b\u4e0e\u7c7b\u540d\u76f8\u540c\u4e14\u65e0\u8fd4\u56de\u7c7b\u578b</li> <li>C++\u5141\u8bb8\u901a\u8fc7\u66f4\u6539\u53c2\u6570\u6570\u91cf/\u987a\u5e8f\u8fdb\u884c\u51fd\u6570\u91cd\u8f7d</li> <li>\u5f53\u5bf9\u8c61\u8d85\u51fa\u4f5c\u7528\u57df\u65f6\uff0c\u6790\u6784\u51fd\u6570\u4f1a\u81ea\u52a8\u8c03\u7528</li> <li>\u6784\u9020\u540e\u59cb\u7ec8\u68c0\u67e5<code>data != nullptr</code>\u4ee5\u9a8c\u8bc1\u5206\u914d\u6210\u529f</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_14","title":"\u5143\u7d20\u8bbf\u95ee","text":"<p>\u77e9\u9635\u7d22\u5f15</p> <p>Mat\u7c7b\u4f7f\u7528\u8fd0\u7b97\u7b26\u91cd\u8f7d\u63d0\u4f9b\u76f4\u89c2\u7684\u77e9\u9635\u5143\u7d20\u8bbf\u95ee\u3002<code>operator()</code>\u5141\u8bb8\u4f7f\u7528<code>A(i, j)</code>\u8fd9\u6837\u7684\u81ea\u7136\u8bed\u6cd5\uff0c\u800c\u4e0d\u662f<code>A.data[i * stride + j]</code>\u3002\u5b9e\u73b0\u81ea\u52a8\u5904\u7406\u6b65\u5e45\u548c\u586b\u5145\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_15","title":"\u8bbf\u95ee\u77e9\u9635\u5143\u7d20\uff08\u975e\u5e38\u91cf\uff09","text":"<pre><code>inline float &amp;operator()(int row, int col);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4ee5\u8bfb\u5199\u65b9\u5f0f\u8bbf\u95ee\u77e9\u9635\u5143\u7d20\u3002\u8fd4\u56de\u5143\u7d20\u7684\u5f15\u7528\uff0c\u5141\u8bb8\u8bfb\u53d6\u548c\u4fee\u6539\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u4f4d\u7f6e(row, col)\u7684\u5143\u7d20\u8bbf\u95ee\u4e3a<code>data[row * stride + col]</code>\uff0c\u5176\u4e2d\u6b65\u5e45\u8003\u8651\u4e86\u586b\u5145\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li> <p><code>int row</code> : \u884c\u7d22\u5f15\uff08\u57fa\u4e8e0\uff0c\u5fc5\u987b\u5728\u8303\u56f4[0, row-1]\u5185\uff09\u3002</p> </li> <li> <p><code>int col</code> : \u5217\u7d22\u5f15\uff08\u57fa\u4e8e0\uff0c\u5fc5\u987b\u5728\u8303\u56f4[0, col-1]\u5185\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>float&amp;</code> - \u77e9\u9635\u5143\u7d20\u7684\u5f15\u7528\uff0c\u5141\u8bb8\u4fee\u6539\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u8fb9\u754c\u68c0\u67e5: \u4e3a\u4e86\u6027\u80fd\uff0c\u4e0d\u8fdb\u884c\u81ea\u52a8\u8fb9\u754c\u68c0\u67e5\u3002\u786e\u4fdd\u7d22\u5f15\u6709\u6548\u3002</p> </li> <li> <p>\u6b65\u5e45\u5904\u7406: \u81ea\u52a8\u8003\u8651\u6b65\u5e45\uff0c\u56e0\u6b64\u53ef\u4ee5\u6b63\u786e\u5904\u7406\u5e26\u586b\u5145\u7684\u77e9\u9635\u3002</p> </li> <li> <p>\u6027\u80fd: \u5185\u8054\u51fd\u6570\uff0c\u5f00\u9500\u6700\u5c0f\uff0c\u9002\u7528\u4e8e\u7d27\u5bc6\u5faa\u73af\u3002</p> </li> <li> <p>\u793a\u4f8b: <code>A(2, 3) = 5.0f;</code> \u5c06\u7b2c2\u884c\u7b2c3\u5217\u7684\u5143\u7d20\u8bbe\u7f6e\u4e3a5.0\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_16","title":"\u8bbf\u95ee\u77e9\u9635\u5143\u7d20\uff08\u5e38\u91cf\uff09","text":"<pre><code>inline const float &amp;operator()(int row, int col) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4ee5\u53ea\u8bfb\u65b9\u5f0f\u8bbf\u95ee\u77e9\u9635\u5143\u7d20\u3002\u8fd4\u56de\u5e38\u91cf\u5f15\u7528\uff0c\u9632\u6b62\u4fee\u6539\u3002\u5f53\u77e9\u9635\u4e3aconst\u65f6\u4f7f\u7528\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li> <p><code>int row</code> : \u884c\u7d22\u5f15\uff08\u57fa\u4e8e0\uff09\u3002</p> </li> <li> <p><code>int col</code> : \u5217\u7d22\u5f15\uff08\u57fa\u4e8e0\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>const float&amp;</code> - \u77e9\u9635\u5143\u7d20\u7684\u5e38\u91cf\u5f15\u7528\uff08\u53ea\u8bfb\uff09\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u5e38\u91cf\u6b63\u786e\u6027: \u5b9e\u73b0\u6b63\u786e\u7684const-correct\u4ee3\u7801\u3002\u5728const\u6210\u5458\u51fd\u6570\u4e2d\u4f7f\u7528\u6b64\u7248\u672c\u3002</p> </li> <li> <p>\u5b89\u5168\u6027: \u9632\u6b62\u610f\u5916\u4fee\u6539const\u77e9\u9635\u3002</p> </li> </ul> <p>\u8fd0\u7b97\u7b26\u91cd\u8f7d</p> <p>\u8fd9\u4e9b\u51fd\u6570\u91cd\u8f7d\u4e86<code>()</code>\u8fd0\u7b97\u7b26\uff0c\u5b9e\u73b0\u4e86\u81ea\u7136\u7684\u77e9\u9635\u7d22\u5f15\u8bed\u6cd5\uff1a <pre><code>Mat A(3, 4);\nA(1, 2) = 3.14f;        // \u5199\u8bbf\u95ee\nfloat val = A(1, 2);    // \u8bfb\u8bbf\u95ee\nconst Mat&amp; B = A;\nfloat val2 = B(1, 2);   // \u53ea\u8bfb\u8bbf\u95ee\uff08\u4f7f\u7528const\u7248\u672c\uff09\n</code></pre></p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_17","title":"\u6570\u636e\u64cd\u4f5c","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_18","title":"\u590d\u5236\u5176\u4ed6\u77e9\u9635\u5230\u5f53\u524d\u77e9\u9635","text":"<pre><code>tiny_error_t copy_paste(const Mat &amp;src, int row_pos, int col_pos);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u5c06\u6e90\u77e9\u9635\u7684\u5143\u7d20\u590d\u5236\u5230\u5f53\u524d\u77e9\u9635\u7684\u6307\u5b9a\u4f4d\u7f6e\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;src</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>int row_pos</code>: \u76ee\u6807\u77e9\u9635\u7684\u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int col_pos</code>: \u76ee\u6807\u77e9\u9635\u7684\u8d77\u59cb\u5217\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>\u9519\u8bef\u4ee3\u7801</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_19","title":"\u590d\u5236\u77e9\u9635\u5934\u90e8","text":"<pre><code>tiny_error_t copy_head(const Mat &amp;src);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u5c06\u6e90\u77e9\u9635\u7684\u5934\u90e8\u4fe1\u606f\u590d\u5236\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;src</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>\u9519\u8bef\u4ee3\u7801</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_20","title":"\u83b7\u53d6\u5b50\u77e9\u9635\u89c6\u56fe","text":"<pre><code>Mat view_roi(int start_row, int start_col, int roi_rows, int roi_cols) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5b50\u77e9\u9635\u89c6\u56fe\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int start_row</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int start_col</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int roi_rows</code>: \u5b50\u77e9\u9635\u7684\u884c\u6570</p> </li> <li> <p><code>int roi_cols</code>: \u5b50\u77e9\u9635\u7684\u5217\u6570</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>\u5b50\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-roi","title":"\u83b7\u53d6\u5b50\u77e9\u9635\u89c6\u56fe - \u4f7f\u7528 ROI \u7ed3\u6784","text":"<pre><code>Mat view_roi(const Mat::ROI &amp;roi) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5b50\u77e9\u9635\u89c6\u56fe\uff0c\u4f7f\u7528 ROI \u7ed3\u6784\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat::ROI &amp;roi</code>: ROI \u7ed3\u6784\u5bf9\u8c61</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>\u5b50\u77e9\u9635\u5bf9\u8c61</p> <p>\u8b66\u544a</p> <p>\u4e0e ESP-DSP \u4e0d\u540c\uff0cview_roi \u4e0d\u5141\u8bb8\u8bbe\u7f6e\u6b65\u957f\uff0c\u56e0\u4e3a\u5b83\u4f1a\u6839\u636e\u5217\u6570\u548c\u586b\u5145\u6570\u81ea\u52a8\u8ba1\u7b97\u6b65\u957f\u3002\u8be5\u51fd\u6570\u8fd8\u4f1a\u62d2\u7edd\u975e\u6cd5\u8bf7\u6c42\uff0c\u5373\u8d85\u51fa\u8303\u56f4\u7684\u8bf7\u6c42\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_21","title":"\u83b7\u53d6\u5b50\u77e9\u9635\u526f\u672c","text":"<pre><code>Mat copy_roi(int start_row, int start_col, int roi_rows, int roi_cols);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5b50\u77e9\u9635\u526f\u672c\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int start_row</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int start_col</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int roi_rows</code>: \u5b50\u77e9\u9635\u7684\u884c\u6570</p> </li> <li> <p><code>int roi_cols</code>: \u5b50\u77e9\u9635\u7684\u5217\u6570</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>\u5b50\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-roi_1","title":"\u83b7\u53d6\u5b50\u77e9\u9635\u526f\u672c - \u4f7f\u7528 ROI \u7ed3\u6784","text":"<pre><code>Mat copy_roi(const Mat::ROI &amp;roi);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5b50\u77e9\u9635\u526f\u672c\uff0c\u4f7f\u7528 ROI \u7ed3\u6784\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat::ROI &amp;roi</code>: ROI \u7ed3\u6784\u5bf9\u8c61</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>\u5b50\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_22","title":"\u83b7\u53d6\u77e9\u9635\u5757","text":"<pre><code>Mat block(int start_row, int start_col, int block_rows, int block_cols);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u83b7\u53d6\u5f53\u524d\u77e9\u9635\u7684\u5757\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int start_row</code>: \u8d77\u59cb\u884c\u7d22\u5f15</p> </li> <li> <p><code>int start_col</code>: \u8d77\u59cb\u5217\u7d22\u5f15</p> </li> <li> <p><code>int block_rows</code>: \u5757\u7684\u884c\u6570</p> </li> <li> <p><code>int block_cols</code>: \u5757\u7684\u5217\u6570</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>\u5757\u5bf9\u8c61</p> <p>view_roi | copy_roi | block \u4e4b\u95f4\u7684\u533a\u522b</p> <ul> <li> <p><code>view_roi</code> : \u4ece\u8be5\u77e9\u9635\u6d45\u62f7\u8d1d\u5b50\u77e9\u9635 (ROI)\u3002</p> </li> <li> <p><code>copy_roi</code> : \u4ece\u8be5\u77e9\u9635\u6df1\u62f7\u8d1d\u5b50\u77e9\u9635 (ROI)\u3002\u521a\u6027\u62f7\u8d1d\uff0c\u901f\u5ea6\u66f4\u5feb\u3002</p> </li> <li> <p><code>block</code> : \u4ece\u8be5\u77e9\u9635\u6df1\u62f7\u8d1d\u5757\u3002\u67d4\u6027\u62f7\u8d1d\uff0c\u901f\u5ea6\u66f4\u6162\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_23","title":"\u4ea4\u6362\u884c","text":"<pre><code>void Mat::swap_rows(int row1, int row2);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4ea4\u6362\u5f53\u524d\u77e9\u9635\u7684\u4e24\u884c\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int row1</code>: \u7b2c\u4e00\u884c\u7d22\u5f15</p> </li> <li> <p><code>int row2</code>: \u7b2c\u4e8c\u884c\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_24","title":"\u4ea4\u6362\u5217","text":"<pre><code>void Mat::swap_cols(int col1, int col2);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4ea4\u6362\u5f53\u524d\u77e9\u9635\u7684\u4e24\u5217\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int col1</code>: \u7b2c\u4e00\u5217\u7d22\u5f15</p> </li> <li> <p><code>int col2</code>: \u7b2c\u4e8c\u5217\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_25","title":"\u6e05\u9664\u77e9\u9635","text":"<pre><code>void Mat::clear(void);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u901a\u8fc7\u5c06\u6240\u6709\u5143\u7d20\u8bbe\u7f6e\u4e3a\u96f6\u6765\u6e05\u9664\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_26","title":"\u7b97\u672f\u8fd0\u7b97\u7b26","text":"<p>\u5c31\u5730\u64cd\u4f5c</p> <p>\u672c\u8282\u5b9a\u4e49\u4e86\u4f5c\u7528\u4e8e\u5f53\u524d\u77e9\u9635\u672c\u8eab\u7684\u7b97\u672f\u8fd0\u7b97\u7b26\uff08\u5c31\u5730\u64cd\u4f5c\uff09\u3002\u8fd9\u4e9b\u8fd0\u7b97\u7b26\u4fee\u6539\u77e9\u9635\u5e76\u8fd4\u56de\u5176\u5f15\u7528\uff0c\u652f\u6301\u94fe\u5f0f\u64cd\u4f5c\u5982<code>A += B += C</code>\u3002\u8fd9\u4e9b\u8fd0\u7b97\u7b26\u7ecf\u8fc7\u4f18\u5316\u4ee5\u5904\u7406\u586b\u5145\uff0c\u5e76\u5728\u53ef\u7528\u65f6\u4f7f\u7528DSP\u52a0\u901f\u51fd\u6570\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_27","title":"\u62f7\u8d1d\u8d4b\u503c","text":"<pre><code>Mat &amp;operator=(const Mat &amp;src);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u77e9\u9635\u7684\u62f7\u8d1d\u8d4b\u503c\u8fd0\u7b97\u7b26\u3002\u5c06\u6e90\u77e9\u9635\u7684\u5143\u7d20\u590d\u5236\u5230\u5f53\u524d\u77e9\u9635\u3002\u5fc5\u8981\u65f6\u901a\u8fc7\u91cd\u65b0\u5206\u914d\u5185\u5b58\u6765\u5904\u7406\u7ef4\u5ea6\u53d8\u5316\u3002\u4e3a\u9632\u6b62\u610f\u5916\u6570\u636e\u635f\u574f\uff0c\u7981\u6b62\u5bf9\u5b50\u77e9\u9635\u89c6\u56fe\u8fdb\u884c\u8d4b\u503c\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u521b\u5efa\u6e90\u77e9\u9635\u7684\u72ec\u7acb\u526f\u672c\u3002\u4e0e\u62f7\u8d1d\u6784\u9020\u51fd\u6570\u4e0d\u540c\uff0c\u8fd9\u7528\u4e8e\u73b0\u6709\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;src</code> : \u6e90\u77e9\u9635\u3002</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat&amp; - \u5bf9\u5f53\u524d\u77e9\u9635\u7684\u5f15\u7528\uff08\u652f\u6301\u94fe\u5f0f\u64cd\u4f5c\uff09\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u5185\u5b58\u7ba1\u7406: \u5982\u679c\u7ef4\u5ea6\u4e0d\u540c\uff0c\u81ea\u52a8\u91cd\u65b0\u5206\u914d\u5185\u5b58\u3002\u5982\u679c\u5185\u5b58\u662f\u5185\u90e8\u5206\u914d\u7684\uff0c\u91ca\u653e\u65e7\u5185\u5b58\u3002</p> </li> <li> <p>\u5b50\u77e9\u9635\u4fdd\u62a4: \u7981\u6b62\u5bf9\u5b50\u77e9\u9635\u89c6\u56fe\u8fdb\u884c\u8d4b\u503c\uff0c\u4ee5\u9632\u6b62\u610f\u5916\u6570\u636e\u635f\u574f\u3002</p> </li> <li> <p>\u81ea\u8d4b\u503c: \u5b89\u5168\u5904\u7406\u81ea\u8d4b\u503c (A = A)\u3002</p> </li> <li> <p>\u6027\u80fd: \u5bf9\u4e8en\u00d7n\u77e9\u9635\u4e3aO(n\u00b2)\u3002\u5bf9\u4e8e\u5927\u77e9\u9635\uff0c\u8003\u8651\u89c6\u56fe\u662f\u5426\u8db3\u591f\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_28","title":"\u52a0\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat &amp;operator+=(const Mat &amp;A);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u52a0\u6cd5\u8fd0\u7b97\u7b26\uff0c\u5c06\u6e90\u77e9\u9635\u7684\u5143\u7d20\u52a0\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;A</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-","title":"\u52a0\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat &amp;operator+=(float C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u5c06\u5e38\u91cf\u6309\u5143\u7d20\u52a0\u5230\u5f53\u524d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float C</code>: \u8981\u52a0\u7684\u5e38\u91cf</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat&amp; - \u5f53\u524d\u77e9\u9635\u7684\u5f15\u7528</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_29","title":"\u51cf\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat &amp;operator-=(const Mat &amp;A);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4ece\u5f53\u524d\u77e9\u9635\u4e2d\u6309\u5143\u7d20\u51cf\u53bb\u6e90\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;A</code>: \u6e90\u77e9\u9635\u5bf9\u8c61</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat&amp; - \u5f53\u524d\u77e9\u9635\u7684\u5f15\u7528</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_1","title":"\u51cf\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat &amp;operator-=(float C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4ece\u5f53\u524d\u77e9\u9635\u4e2d\u6309\u5143\u7d20\u51cf\u53bb\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float C</code>: \u8981\u51cf\u7684\u5e38\u91cf</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat&amp; - \u5f53\u524d\u77e9\u9635\u7684\u5f15\u7528</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_30","title":"\u77e9\u9635\u4e58\u6cd5","text":"<pre><code>Mat &amp;operator*=(const Mat &amp;A);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u77e9\u9635\u4e58\u6cd5\uff1athis = this * A\u3002\u6267\u884c\u6807\u51c6\u77e9\u9635\u4e58\u6cd5\uff08\u975e\u9010\u5143\u7d20\uff09\u3002\u5f53\u524d\u77e9\u9635\u7684\u5217\u6570\u5fc5\u987b\u7b49\u4e8eA\u7684\u884c\u6570\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u77e9\u9635\u4e58\u6cd5 C = A * B\uff0c\u5176\u4e2d C\u1d62\u2c7c = \u03a3\u2096 A\u1d62\u2096 * B\u2096\u2c7c\u3002\u8fd9\u662f\u6807\u51c6\u77e9\u9635\u4e58\u79ef\uff0c\u4e0d\u662f\u9010\u5143\u7d20\u4e58\u6cd5\u3002</p> <p>\u7ef4\u5ea6\u8981\u6c42:  - \u5f53\u524d\u77e9\u9635: m \u00d7 n</p> <ul> <li> <p>\u77e9\u9635 A: n \u00d7 p</p> </li> <li> <p>\u7ed3\u679c: m \u00d7 p</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;A</code> : \u8981\u4e58\u7684\u77e9\u9635\uff08\u5fc5\u987b\u6709n\u884c\uff0c\u5176\u4e2dn = \u5f53\u524d\u77e9\u9635\u7684\u5217\u6570\uff09\u3002</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat&amp; - \u5bf9\u5f53\u524d\u77e9\u9635\u7684\u5f15\u7528\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u5185\u5b58\u6548\u7387: \u521b\u5efa\u4e34\u65f6\u526f\u672c\u4ee5\u907f\u514d\u5728\u8ba1\u7b97\u671f\u95f4\u8986\u76d6\u6570\u636e\uff0c\u7136\u540e\u66f4\u65b0\u5f53\u524d\u77e9\u9635\u3002</p> </li> <li> <p>\u586b\u5145\u652f\u6301: \u5728\u53ef\u7528\u65f6\u4f7f\u7528\u4e13\u7528DSP\u51fd\u6570\u5904\u7406\u5e26\u586b\u5145\u7684\u77e9\u9635\u3002</p> </li> <li> <p>\u6027\u80fd: \u5bf9\u4e8em\u00d7n * n\u00d7p\u4e58\u6cd5\u4e3aO(mnp)\u3002\u5728ESP32\u5e73\u53f0\u4e0a\u4f7f\u7528\u4f18\u5316\u7684DSP\u51fd\u6570\u3002</p> </li> <li> <p>\u5e38\u89c1\u9519\u8bef: \u8fd9\u662f\u77e9\u9635\u4e58\u6cd5\uff0c\u4e0d\u662f\u9010\u5143\u7d20\u7684\u3002\u5bf9\u4e8e\u9010\u5143\u7d20\uff0c\u4f7f\u7528\u5e26\u6709<code>operator()()</code>\u7684\u5faa\u73af\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_2","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat &amp;operator*=(float C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u4e58\u4ee5\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float C</code>: \u5e38\u91cf\u4e58\u6570</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat&amp; - \u5f53\u524d\u77e9\u9635\u7684\u5f15\u7528</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_31","title":"\u9664\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat &amp;operator/=(const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u9664\u6cd5\uff1athis = this / B</p> <p>\u53c2\u6570:</p> <ul> <li><code>const Mat &amp;B</code>: \u9664\u6570\u77e9\u9635</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat&amp; - \u5f53\u524d\u77e9\u9635\u7684\u5f15\u7528</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_3","title":"\u9664\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat &amp;operator/=(float C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u5c06\u5f53\u524d\u77e9\u9635\u6309\u5143\u7d20\u9664\u4ee5\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float C</code>: \u5e38\u91cf\u9664\u6570</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat&amp; - \u5f53\u524d\u77e9\u9635\u7684\u5f15\u7528</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_32","title":"\u5e42\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator^(int C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u6574\u6570\u5e42\u8fd0\u7b97\u3002\u8fd4\u56de\u4e00\u4e2a\u65b0\u77e9\u9635\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u90fd\u63d0\u5347\u5230\u7ed9\u5b9a\u5e42\u6b21\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>int C</code>: \u6307\u6570\uff08\u6574\u6570\uff09</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u5e42\u8fd0\u7b97\u540e\u7684\u65b0\u77e9\u9635</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_33","title":"\u7ebf\u6027\u4ee3\u6570","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_34","title":"\u8f6c\u7f6e\u77e9\u9635","text":"<pre><code>Mat Mat::transpose();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97\u77e9\u9635\u7684\u8f6c\u7f6e\uff0c\u8fd4\u56de\u65b0\u77e9\u9635\u3002\u77e9\u9635A\u7684\u8f6c\u7f6eA^T \u901a\u8fc7\u4ea4\u6362\u884c\u548c\u5217\u5f97\u5230\uff1a(A^T)\u1d62\u2c7c = A\u2c7c\u1d62\u3002</p> <p>\u6570\u5b66\u539f\u7406: </p> <ul> <li> <p>\u5bf9\u4e8e\u4efb\u4f55\u77e9\u9635A\uff0c(A^T) ^T = A</p> </li> <li> <p>(A + B)^T = A^T + B^T</p> </li> <li> <p>(AB)^T = B^T * A^T</p> </li> <li> <p>\u5bf9\u4e8e\u65b9\u9635\uff0cdet(A) = det(A^T)</p> </li> </ul> <p>\u53c2\u6570:</p> <p>\u65e0\u3002</p> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u8f6c\u7f6e\u540e\u7684\u77e9\u9635 (col \u00d7 row)\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u5185\u5b58\u5e03\u5c40: \u521b\u5efa\u65b0\u77e9\u9635\uff0c\u56e0\u6b64\u5185\u5b58\u4f7f\u7528\u91cf\u6682\u65f6\u7ffb\u500d\u3002\u5bf9\u4e8e\u5927\u77e9\u9635\uff0c\u8003\u8651\u5185\u5b58\u9650\u5236\u3002</p> </li> <li> <p>\u5bf9\u79f0\u77e9\u9635: \u5982\u679cA = A^T\uff0c\u77e9\u9635\u662f\u5bf9\u79f0\u7684\u3002\u4f7f\u7528<code>is_symmetric()</code>\u68c0\u67e5\u3002</p> </li> <li> <p>\u5e94\u7528: </p> </li> <li> <p>\u5185\u79ef: u^T * v</p> </li> <li> <p>\u4e8c\u6b21\u578b: x^T * A * x</p> </li> <li> <p>\u77e9\u9635\u65b9\u7a0b: A^T * A\uff08\u6b63\u89c4\u65b9\u7a0b\uff09</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_35","title":"\u4f59\u5b50\u5f0f\u77e9\u9635","text":"<pre><code>Mat Mat::minor(int row, int col);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u901a\u8fc7\u79fb\u9664\u6307\u5b9a\u7684\u884c\u548c\u5217\u6765\u8ba1\u7b97\u4f59\u5b50\u5f0f\u77e9\u9635\u3002\u4f59\u5b50\u5f0f\u662f\u79fb\u9664\u4e00\u884c\u4e00\u5217\u540e\u5f97\u5230\u7684\u5b50\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int row</code>: \u8981\u79fb\u9664\u7684\u884c\u7d22\u5f15</p> </li> <li> <p><code>int col</code>: \u8981\u79fb\u9664\u7684\u5217\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - (n-1)x(n-1) \u7684\u4f59\u5b50\u5f0f\u77e9\u9635</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_36","title":"\u4ee3\u6570\u4f59\u5b50\u5f0f\u77e9\u9635","text":"<pre><code>Mat Mat::cofactor(int row, int col);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97\u4ee3\u6570\u4f59\u5b50\u5f0f\u77e9\u9635\uff08\u4e0e\u4f59\u5b50\u5f0f\u77e9\u9635\u76f8\u540c\uff09\u3002\u4ee3\u6570\u4f59\u5b50\u5f0f\u77e9\u9635\u4e0e\u4f59\u5b50\u5f0f\u77e9\u9635\u76f8\u540c\u3002\u7b26\u53f7 (-1)^(i+j) \u5728\u8ba1\u7b97\u4ee3\u6570\u4f59\u5b50\u5f0f\u503c\u65f6\u5e94\u7528\uff0c\u800c\u4e0d\u662f\u5e94\u7528\u5230\u77e9\u9635\u5143\u7d20\u672c\u8eab\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int row</code>: \u8981\u79fb\u9664\u7684\u884c\u7d22\u5f15</p> </li> <li> <p><code>int col</code>: \u8981\u79fb\u9664\u7684\u5217\u7d22\u5f15</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - (n-1)x(n-1) \u7684\u4ee3\u6570\u4f59\u5b50\u5f0f\u77e9\u9635\uff08\u4e0e\u4f59\u5b50\u5f0f\u77e9\u9635\u76f8\u540c\uff09</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_37","title":"\u884c\u5217\u5f0f\uff08\u81ea\u52a8\u9009\u62e9\u65b9\u6cd5\uff09","text":"<pre><code>float Mat::determinant();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97\u65b9\u9635\u7684\u884c\u5217\u5f0f\uff0c\u6839\u636e\u77e9\u9635\u5927\u5c0f\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u65b9\u6cd5\u3002\u5bf9\u4e8e\u5c0f\u77e9\u9635\uff08n \u2264 4\uff09\uff0c\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u5c55\u5f00\u6cd5\uff1b\u5bf9\u4e8e\u5927\u77e9\u9635\uff08n &gt; 4\uff09\uff0c\u4f7f\u7528LU\u5206\u89e3\u6cd5\u4ee5\u63d0\u9ad8\u6548\u7387\u3002</p> <p>\u6570\u5b66\u539f\u7406: </p> <p>\u884c\u5217\u5f0f\u662f\u65b9\u9635\u7684\u4e00\u4e2a\u91cd\u8981\u6570\u503c\u7279\u5f81\uff0c\u5177\u6709\u4ee5\u4e0b\u6027\u8d28\uff1a</p> <ul> <li> <p>det(AB) = det(A) * det(B)</p> </li> <li> <p>det(A^T) = det(A)</p> </li> <li> <p>det(A^(-1)) = 1 / det(A)</p> </li> <li> <p>\u5982\u679c\u77e9\u9635\u662f\u5947\u5f02\u7684\uff0cdet(A) = 0</p> </li> </ul> <p>\u65b9\u6cd5\u9009\u62e9:</p> <ul> <li> <p>\u5c0f\u77e9\u9635 (n \u2264 4): \u4f7f\u7528 <code>determinant_laplace()</code> - \u62c9\u666e\u62c9\u65af\u5c55\u5f00\u6cd5\uff0c\u65f6\u95f4\u590d\u6742\u5ea6 O(n!)\uff0c\u5bf9\u5c0f\u77e9\u9635\u66f4\u51c6\u786e</p> </li> <li> <p>\u5927\u77e9\u9635 (n &gt; 4): \u4f7f\u7528 <code>determinant_lu()</code> - LU\u5206\u89e3\u6cd5\uff0c\u65f6\u95f4\u590d\u6742\u5ea6 O(n\u00b3)\uff0c\u6548\u7387\u66f4\u9ad8</p> </li> </ul> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>float - \u884c\u5217\u5f0f\u7684\u503c</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u81ea\u52a8\u9009\u62e9: \u5bf9\u4e8e\u5927\u591a\u6570\u5e94\u7528\uff0c\u76f4\u63a5\u4f7f\u7528 <code>determinant()</code> \u5373\u53ef\uff0c\u51fd\u6570\u4f1a\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u65b9\u6cd5</p> </li> <li> <p>\u6027\u80fd\u4f18\u5316: \u5982\u679c\u9700\u8981\u591a\u6b21\u8ba1\u7b97\u76f8\u540c\u5927\u5c0f\u7684\u77e9\u9635\u884c\u5217\u5f0f\uff0c\u53ef\u4ee5\u8003\u8651\u76f4\u63a5\u8c03\u7528 <code>determinant_lu()</code> \u6216 <code>determinant_gaussian()</code></p> </li> <li> <p>\u7cbe\u5ea6\u8981\u6c42: \u5bf9\u4e8e\u5c0f\u77e9\u9635\uff0c<code>determinant_laplace()</code> \u53ef\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u6570\u503c\u7cbe\u5ea6</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_4","title":"\u884c\u5217\u5f0f - \u62c9\u666e\u62c9\u65af\u5c55\u5f00\u6cd5","text":"<pre><code>float Mat::determinant_laplace();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u5c55\u5f00\uff08\u4f59\u5b50\u5f0f\u5c55\u5f00\uff09\u8ba1\u7b97\u65b9\u9635\u7684\u884c\u5217\u5f0f\u3002\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a O(n!)\uff0c\u4ec5\u9002\u7528\u4e8e\u5c0f\u77e9\u9635\uff08n \u2264 4\uff09\u3002</p> <p>\u6570\u5b66\u539f\u7406: </p> <p>\u62c9\u666e\u62c9\u65af\u5c55\u5f00\u662f\u884c\u5217\u5f0f\u7684\u9012\u5f52\u5b9a\u4e49\u65b9\u6cd5\uff1a</p> <ul> <li> <p>\u5bf9\u4e8e 1\u00d71 \u77e9\u9635: det([a]) = a</p> </li> <li> <p>\u5bf9\u4e8e 2\u00d72 \u77e9\u9635: det([[a,b],[c,d]]) = ad - bc</p> </li> <li> <p>\u5bf9\u4e8e n\u00d7n \u77e9\u9635: det(A) = \u03a3\u2c7c\u208c\u2081\u207f (-1)\u2071\u207a\u02b2 a\u1d62\u2c7c * det(M\u1d62\u2c7c)\uff0c\u5176\u4e2d M\u1d62\u2c7c \u662f\u4f59\u5b50\u5f0f\u77e9\u9635</p> </li> </ul> <p>\u672c\u5b9e\u73b0\u4f7f\u7528\u7b2c\u4e00\u884c\u5c55\u5f00\uff0c\u9012\u5f52\u8ba1\u7b97\u4f59\u5b50\u5f0f\u7684\u884c\u5217\u5f0f\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>float - \u884c\u5217\u5f0f\u7684\u503c</p> <p>\u6027\u80fd\u8b66\u544a</p> <p>\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a O(n!)\uff0c\u4ec5\u9002\u7528\u4e8e\u5c0f\u77e9\u9635\uff08n \u2264 4\uff09\u3002\u5bf9\u4e8e\u5927\u77e9\u9635\uff0c\u8bf7\u4f7f\u7528 <code>determinant_lu()</code> \u6216 <code>determinant_gaussian()</code>\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-lu","title":"\u884c\u5217\u5f0f - LU\u5206\u89e3\u6cd5","text":"<pre><code>float Mat::determinant_lu();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528LU\u5206\u89e3\u8ba1\u7b97\u65b9\u9635\u7684\u884c\u5217\u5f0f\u3002\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a O(n\u00b3)\uff0c\u9002\u7528\u4e8e\u5927\u77e9\u9635\u3002</p> <p>\u6570\u5b66\u539f\u7406: </p> <p>LU\u5206\u89e3\u5c06\u77e9\u9635\u5206\u89e3\u4e3a A = P * L * U\uff0c\u5176\u4e2d\uff1a</p> <ul> <li> <p>P \u662f\u7f6e\u6362\u77e9\u9635\uff08\u5982\u679c\u4f7f\u7528\u4e3b\u5143\uff09</p> </li> <li> <p>L \u662f\u5355\u4f4d\u5bf9\u89d2\u7ebf\u7684\u4e0b\u4e09\u89d2\u77e9\u9635</p> </li> <li> <p>U \u662f\u4e0a\u4e09\u89d2\u77e9\u9635</p> </li> </ul> <p>\u884c\u5217\u5f0f\u8ba1\u7b97\u516c\u5f0f\uff1adet(A) = det(P) * det(L) * det(U)</p> <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>det(P) = (-1)^(\u7f6e\u6362\u7684\u7b26\u53f7)\uff0c\u7531\u884c\u4ea4\u6362\u6b21\u6570\u51b3\u5b9a</p> </li> <li> <p>det(L) = 1\uff08\u56e0\u4e3aL\u662f\u5355\u4f4d\u5bf9\u89d2\u7ebf\u7684\u4e0b\u4e09\u89d2\u77e9\u9635\uff09</p> </li> <li> <p>det(U) = \u220f\u1d62 U\u1d62\u1d62\uff08U\u7684\u5bf9\u89d2\u7ebf\u5143\u7d20\u7684\u4e58\u79ef\uff09</p> </li> </ul> <p>\u7b97\u6cd5\u6b65\u9aa4:</p> <ol> <li>\u6267\u884cLU\u5206\u89e3\uff08\u5e26\u4e3b\u5143\u4ee5\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027\uff09</li> <li>\u8ba1\u7b97\u7f6e\u6362\u77e9\u9635\u7684\u884c\u5217\u5f0f det(P)</li> <li>\u8ba1\u7b97\u4e0a\u4e09\u89d2\u77e9\u9635U\u7684\u5bf9\u89d2\u7ebf\u5143\u7d20\u4e58\u79ef det(U)</li> <li>\u8fd4\u56de det(P) * det(U)</li> </ol> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>float - \u884c\u5217\u5f0f\u7684\u503c\u3002\u5982\u679c\u77e9\u9635\u662f\u5947\u5f02\u7684\u6216\u63a5\u8fd1\u5947\u5f02\u7684\uff0c\u8fd4\u56de 0.0</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u6548\u7387: \u5bf9\u4e8e n &gt; 4 \u7684\u77e9\u9635\uff0c\u6bd4\u62c9\u666e\u62c9\u65af\u5c55\u5f00\u6cd5\u5feb\u5f97\u591a</p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: \u4f7f\u7528\u4e3b\u5143\uff08pivoting\uff09\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027</p> </li> <li> <p>\u5947\u5f02\u77e9\u9635: \u5982\u679c\u77e9\u9635\u662f\u5947\u5f02\u7684\uff0cLU\u5206\u89e3\u4f1a\u5931\u8d25\uff0c\u51fd\u6570\u8fd4\u56de 0.0</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_5","title":"\u884c\u5217\u5f0f - \u9ad8\u65af\u6d88\u5143\u6cd5","text":"<pre><code>float Mat::determinant_gaussian();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u9ad8\u65af\u6d88\u5143\u6cd5\u8ba1\u7b97\u65b9\u9635\u7684\u884c\u5217\u5f0f\u3002\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a O(n\u00b3)\uff0c\u9002\u7528\u4e8e\u5927\u77e9\u9635\u3002</p> <p>\u6570\u5b66\u539f\u7406: </p> <p>\u9ad8\u65af\u6d88\u5143\u6cd5\u5c06\u77e9\u9635\u8f6c\u6362\u4e3a\u4e0a\u4e09\u89d2\u5f62\u5f0f\uff0c\u7136\u540e\u8ba1\u7b97\u5bf9\u89d2\u7ebf\u5143\u7d20\u7684\u4e58\u79ef\u3002\u884c\u5217\u5f0f\u7684\u503c\u7b49\u4e8e\u4e0a\u4e09\u89d2\u77e9\u9635\u5bf9\u89d2\u7ebf\u5143\u7d20\u7684\u4e58\u79ef\uff0c\u5e76\u6839\u636e\u884c\u4ea4\u6362\u6b21\u6570\u8c03\u6574\u7b26\u53f7\u3002</p> <p>\u7b97\u6cd5\u6b65\u9aa4:</p> <ol> <li>\u4f7f\u7528\u90e8\u5206\u4e3b\u5143\u6cd5\u8fdb\u884c\u9ad8\u65af\u6d88\u5143\uff0c\u5c06\u77e9\u9635\u8f6c\u6362\u4e3a\u4e0a\u4e09\u89d2\u5f62\u5f0f</li> <li>\u8ddf\u8e2a\u884c\u4ea4\u6362\u6b21\u6570</li> <li>\u8ba1\u7b97\u4e0a\u4e09\u89d2\u77e9\u9635\u5bf9\u89d2\u7ebf\u5143\u7d20\u7684\u4e58\u79ef</li> <li>\u6839\u636e\u884c\u4ea4\u6362\u6b21\u6570\u8c03\u6574\u7b26\u53f7\uff1a\u6bcf\u6b21\u884c\u4ea4\u6362\u4f7f\u884c\u5217\u5f0f\u4e58\u4ee5 -1</li> </ol> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>float - \u884c\u5217\u5f0f\u7684\u503c\u3002\u5982\u679c\u77e9\u9635\u662f\u5947\u5f02\u7684\uff0c\u8fd4\u56de 0.0</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u6548\u7387: \u5bf9\u4e8e\u5927\u77e9\u9635\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a O(n\u00b3)\uff0c\u4e0eLU\u5206\u89e3\u6cd5\u76f8\u5f53</p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: \u4f7f\u7528\u90e8\u5206\u4e3b\u5143\u6cd5\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027</p> </li> <li> <p>\u5b9e\u73b0\u7b80\u5355: \u76f8\u6bd4LU\u5206\u89e3\uff0c\u5b9e\u73b0\u66f4\u76f4\u89c2\uff0c\u4f46\u529f\u80fd\u8f83\u5c11\uff08\u4e0d\u80fd\u7528\u4e8e\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf\uff09</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_38","title":"\u4f34\u968f\u77e9\u9635","text":"<pre><code>Mat Mat::adjoint();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97\u65b9\u9635\u7684\u4f34\u968f\uff08\u6216\u4f34\u968f\u8f6c\u7f6e\uff09\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u4f34\u968f\u77e9\u9635\u5bf9\u8c61</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_39","title":"\u5f52\u4e00\u5316","text":"<pre><code>void Mat::normalize();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528L2\u8303\u6570\uff08Frobenius\u8303\u6570\uff09\u5f52\u4e00\u5316\u77e9\u9635\u3002\u5f52\u4e00\u5316\u540e\uff0c||Matrix|| = 1\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>void</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_40","title":"\u8303\u6570","text":"<pre><code>float Mat::norm() const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97\u77e9\u9635\u7684Frobenius\u8303\u6570\uff08L2\u8303\u6570\uff09\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>float - \u8ba1\u7b97\u5f97\u5230\u7684\u77e9\u9635\u8303\u6570</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_6","title":"\u77e9\u9635\u6c42\u9006 -- \u57fa\u4e8e\u4f34\u968f\u77e9\u9635","text":"<pre><code>Mat Mat::inverse_adjoint();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u4f34\u968f\u77e9\u9635\u6cd5\u8ba1\u7b97\u65b9\u9635\u7684\u9006\u77e9\u9635\u3002\u5982\u679c\u77e9\u9635\u662f\u5947\u5f02\u7684\uff0c\u8fd4\u56de\u96f6\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u9006\u77e9\u9635\u5bf9\u8c61\u3002\u5982\u679c\u77e9\u9635\u662f\u5947\u5f02\u7684\uff0c\u8fd4\u56de\u96f6\u77e9\u9635</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_41","title":"\u5355\u4f4d\u77e9\u9635","text":"<pre><code>static Mat Mat::eye(int size);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u751f\u6210\u6307\u5b9a\u5927\u5c0f\u7684\u5355\u4f4d\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>int size</code>: \u65b9\u9635\u7684\u7ef4\u5ea6</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u5355\u4f4d\u77e9\u9635 (size x size)</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_42","title":"\u589e\u5e7f\u77e9\u9635\uff08\u6c34\u5e73\u8fde\u63a5\uff09","text":"<pre><code>static Mat Mat::augment(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u901a\u8fc7\u6c34\u5e73\u8fde\u63a5\u4e24\u4e2a\u77e9\u9635\u521b\u5efa\u589e\u5e7f\u77e9\u9635 [A | B]\u3002A\u548cB\u7684\u884c\u6570\u5fc5\u987b\u5339\u914d\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u5de6\u4fa7\u77e9\u9635</p> </li> <li> <p><code>const Mat &amp;B</code>: \u53f3\u4fa7\u77e9\u9635</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u589e\u5e7f\u77e9\u9635 [A B]</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_43","title":"\u5782\u76f4\u5806\u53e0","text":"<pre><code>static Mat Mat::vstack(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u5782\u76f4\u5806\u53e0\u4e24\u4e2a\u77e9\u9635 [A; B]\u3002A\u548cB\u7684\u5217\u6570\u5fc5\u987b\u5339\u914d\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u9876\u90e8\u77e9\u9635</p> </li> <li> <p><code>const Mat &amp;B</code>: \u5e95\u90e8\u77e9\u9635</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u5782\u76f4\u5806\u53e0\u7684\u77e9\u9635 [A; B]</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#gram-schmidt","title":"Gram-Schmidt\u6b63\u4ea4\u5316","text":"<pre><code>static bool Mat::gram_schmidt_orthogonalize(const Mat &amp;vectors, Mat &amp;orthogonal_vectors, \n                                            Mat &amp;coefficients, float tolerance = 1e-6f);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528Gram-Schmidt\u8fc7\u7a0b\u5bf9\u4e00\u7ec4\u5411\u91cf\u8fdb\u884c\u6b63\u4ea4\u5316\u3002\u8fd9\u662f\u4e00\u4e2a\u901a\u7528\u7684\u6b63\u4ea4\u5316\u51fd\u6570\uff0c\u53ef\u91cd\u590d\u7528\u4e8eQR\u5206\u89e3\u548c\u5176\u4ed6\u9700\u8981\u6b63\u4ea4\u57fa\u7684\u5e94\u7528\u3002\u4f7f\u7528\u6539\u8fdb\u7684Gram-Schmidt\u7b97\u6cd5\u548c\u91cd\u65b0\u6b63\u4ea4\u5316\u4ee5\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u7ed9\u5b9a\u4e00\u7ec4\u5411\u91cf {v\u2081, v\u2082, ..., v\u2099}\uff0cGram-Schmidt\u8fc7\u7a0b\u4ea7\u751f\u6b63\u4ea4\u96c6\u5408 {q\u2081, q\u2082, ..., q\u2099}\uff0c\u5176\u4e2d\uff1a</p> <ul> <li> <p>q\u2081 = v\u2081 / ||v\u2081||</p> </li> <li> <p>q\u2c7c = (v\u2c7c - \u03a3\u1d62\u208c\u2081\u02b2\u207b\u00b9\u27e8v\u2c7c, q\u1d62\u27e9q\u1d62) / ||v\u2c7c - \u03a3\u1d62\u208c\u2081\u02b2\u207b\u00b9\u27e8v\u2c7c, q\u1d62\u27e9q\u1d62||</p> </li> </ul> <p>\u6539\u8fdb\u7248\u672c\u7acb\u5373\u51cf\u53bb\u6295\u5f71\uff0c\u8fd9\u63d0\u9ad8\u4e86\u6570\u503c\u7a33\u5b9a\u6027\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;vectors</code> : \u8f93\u5165\u77e9\u9635\uff0c\u5176\u4e2d\u6bcf\u5217\u662f\u8981\u6b63\u4ea4\u5316\u7684\u5411\u91cf (m \u00d7 n)\u3002</p> </li> <li> <p><code>Mat &amp;orthogonal_vectors</code> : \u8f93\u51fa\u77e9\u9635\uff0c\u7528\u4e8e\u6b63\u4ea4\u5316\u5411\u91cf (m \u00d7 n)\uff0c\u6bcf\u5217\u90fd\u662f\u6b63\u4ea4\u4e14\u5f52\u4e00\u5316\u7684\u3002</p> </li> <li> <p><code>Mat &amp;coefficients</code> : \u8f93\u51fa\u77e9\u9635\uff0c\u7528\u4e8e\u6295\u5f71\u7cfb\u6570 (n \u00d7 n\uff0c\u4e0a\u4e09\u89d2)\uff0c\u7c7b\u4f3c\u4e8eQR\u5206\u89e3\u4e2d\u7684R\u77e9\u9635\u3002</p> </li> <li> <p><code>float tolerance</code> : \u7ebf\u6027\u72ec\u7acb\u6027\u68c0\u67e5\u7684\u6700\u5c0f\u8303\u6570\u9608\u503c\uff08\u9ed8\u8ba4\uff1a1e-6\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>bool</code> - \u6210\u529f\u8fd4\u56de<code>true</code>\uff0c\u8f93\u5165\u65e0\u6548\u8fd4\u56de<code>false</code>\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: \u5b9e\u73b0\u4f7f\u7528\u6539\u8fdb\u7684Gram-Schmidt\u548c\u91cd\u65b0\u6b63\u4ea4\u5316\uff0c\u8fd9\u663e\u8457\u63d0\u9ad8\u4e86\u8fd1\u7ebf\u6027\u76f8\u5173\u5411\u91cf\u7684\u7a33\u5b9a\u6027\u3002</p> </li> <li> <p>QR\u5206\u89e3: \u6b64\u51fd\u6570\u7531<code>qr_decompose()</code>\u5185\u90e8\u4f7f\u7528\u3002\u5bf9\u4e8eQR\u5206\u89e3\uff0c\u7cfb\u6570\u77e9\u9635\u5bf9\u5e94\u4e8eR\u77e9\u9635\u3002</p> </li> <li> <p>\u57fa\u6784\u9020: \u7528\u4e8e\u4ece\u4e00\u7ec4\u5411\u91cf\u6784\u9020\u6b63\u4ea4\u57fa\uff0c\u8fd9\u5728\u8bb8\u591a\u7ebf\u6027\u4ee3\u6570\u5e94\u7528\u4e2d\u90fd\u662f\u57fa\u7840\u3002</p> </li> <li> <p>\u6027\u80fd: \u5bf9\u4e8e\u5927\u77e9\u9635\uff0c\u8003\u8651\u8ba1\u7b97\u6210\u672c\u3002\u5bf9\u4e8em\u7ef4\u5411\u91cf\u548cn\u4e2a\u5411\u91cf\uff0c\u590d\u6742\u5ea6\u4e3aO(mn\u00b2)\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#1","title":"\u51681\u77e9\u9635\uff08\u77e9\u5f62\uff09","text":"<pre><code>static Mat Mat::ones(int rows, int cols);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u521b\u5efa\u6307\u5b9a\u5927\u5c0f\u7684\u51681\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int rows</code>: \u884c\u6570</p> </li> <li> <p><code>int cols</code>: \u5217\u6570</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u77e9\u9635 [rows x cols]\uff0c\u6240\u6709\u5143\u7d20 = 1</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#1_1","title":"\u51681\u77e9\u9635\uff08\u65b9\u9635\uff09","text":"<pre><code>static Mat Mat::ones(int size);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u521b\u5efa\u6307\u5b9a\u5927\u5c0f\u7684\u65b9\u9635\uff0c\u6240\u6709\u5143\u7d20\u4e3a1\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>int size</code>: \u65b9\u9635\u7684\u5927\u5c0f\uff08\u884c\u6570 = \u5217\u6570\uff09</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u65b9\u9635 [size x size]\uff0c\u6240\u6709\u5143\u7d20 = 1</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_44","title":"\u9ad8\u65af\u6d88\u5143\u6cd5","text":"<pre><code>Mat Mat::gaussian_eliminate() const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6267\u884c\u9ad8\u65af\u6d88\u5143\u6cd5\uff0c\u5c06\u77e9\u9635\u8f6c\u6362\u4e3a\u884c\u9636\u68af\u5f62\u5f0f\uff08REF\uff09\u3002\u8fd9\u662f\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf\u548c\u8ba1\u7b97\u77e9\u9635\u79e9\u7684\u7b2c\u4e00\u6b65\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u9ad8\u65af\u6d88\u5143\u901a\u8fc7\u521d\u7b49\u884c\u53d8\u6362\u5c06\u77e9\u9635\u8f6c\u6362\u4e3a\u884c\u9636\u68af\u5f62\u5f0f\uff1a</p> <ol> <li> <p>\u884c\u4ea4\u6362: \u4ea4\u6362\u4e24\u884c</p> </li> <li> <p>\u884c\u7f29\u653e: \u5c06\u4e00\u884c\u4e58\u4ee5\u975e\u96f6\u6807\u91cf</p> </li> <li> <p>\u884c\u52a0\u6cd5: \u5c06\u4e00\u884c\u7684\u500d\u6570\u52a0\u5230\u53e6\u4e00\u884c</p> </li> </ol> <p>\u884c\u9636\u68af\u5f62\u5f0f\uff08REF\uff09\u7684\u6027\u8d28:</p> <ul> <li> <p>\u6240\u6709\u96f6\u884c\u5728\u5e95\u90e8</p> </li> <li> <p>\u6bcf\u4e2a\u975e\u96f6\u884c\u7684\u524d\u5bfc\u7cfb\u6570\uff08\u4e3b\u5143\uff09\u4f4d\u4e8e\u4e0a\u4e00\u884c\u4e3b\u5143\u7684\u53f3\u4fa7</p> </li> <li> <p>\u4e3b\u5143\u4e0b\u65b9\u7684\u6240\u6709\u6761\u76ee\u4e3a\u96f6</p> </li> </ul> <p>\u53c2\u6570:</p> <p>\u65e0\u3002</p> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u4e0a\u4e09\u89d2\u77e9\u9635\uff08REF\u5f62\u5f0f\uff09\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3: \u6c42\u89e3Ax = b\u7684\u7b2c\u4e00\u6b65\u3002REF\u4e4b\u540e\uff0c\u4f7f\u7528\u56de\u4ee3\u3002</p> </li> <li> <p>\u79e9\u8ba1\u7b97: \u79e9\u7b49\u4e8eREF\u4e2d\u975e\u96f6\u884c\u7684\u6570\u91cf\u3002</p> </li> <li> <p>\u884c\u5217\u5f0f: \u53ef\u4ee5\u4eceREF\u8ba1\u7b97\u884c\u5217\u5f0f\uff08\u5bf9\u89d2\u5143\u7d20\u7684\u4e58\u79ef\uff0c\u6839\u636e\u884c\u4ea4\u6362\u8fdb\u884c\u8c03\u6574\uff09\u3002</p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: \u5b9e\u73b0\u4f7f\u7528\u90e8\u5206\u4e3b\u5143\u4ee5\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027\u3002</p> </li> <li> <p>\u6027\u80fd: \u5bf9\u4e8en\u00d7n\u77e9\u9635\u4e3aO(n\u00b3)\u3002\u5bf9\u4e8e\u591a\u4e2a\u7cfb\u7edf\uff0c\u4f18\u5148\u4f7f\u7528LU\u5206\u89e3\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_45","title":"\u4ece\u9ad8\u65af\u6d88\u5143\u5230\u884c\u6700\u7b80\u5f62\u5f0f","text":"<pre><code>Mat Mat::row_reduce_from_gaussian();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u5c06\u77e9\u9635\uff08\u5047\u8bbe\u5df2\u4e3a\u884c\u9636\u68af\u5f62\u5f0f\uff09\u8f6c\u6362\u4e3a\u7b80\u5316\u884c\u9636\u68af\u5f62\u5f0f\uff08RREF\uff09\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>Mat - RREF\u5f62\u5f0f\u7684\u77e9\u9635</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_7","title":"\u9ad8\u65af-\u7ea6\u65e6\u6d88\u5143\u6cd5\u6c42\u9006","text":"<pre><code>Mat Mat::inverse_gje();\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u9ad8\u65af-\u7ea6\u65e6\u6d88\u5143\u6cd5\u8ba1\u7b97\u65b9\u9635\u7684\u9006\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <p>void</p> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u5982\u679c\u77e9\u9635\u53ef\u9006\u5219\u8fd4\u56de\u9006\u77e9\u9635\uff0c\u5426\u5219\u8fd4\u56de\u7a7a\u77e9\u9635</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_46","title":"\u70b9\u79ef","text":"<pre><code>float Mat::dotprod(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\uff08Nx1\uff09\u7684\u70b9\u79ef\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u8f93\u5165\u5411\u91cf A (Nx1)</p> </li> <li> <p><code>const Mat &amp;B</code>: \u8f93\u5165\u5411\u91cf B (Nx1)</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>float - \u8ba1\u7b97\u5f97\u5230\u7684\u70b9\u79ef\u503c</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_47","title":"\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4","text":"<pre><code>Mat Mat::solve(const Mat &amp;A, const Mat &amp;b) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u9ad8\u65af\u6d88\u5143\u6cd5\u548c\u56de\u4ee3\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edfAx = b\u3002\u8fd9\u662f\u9002\u7528\u4e8e\u826f\u6761\u4ef6\u7cfb\u7edf\u7684\u76f4\u63a5\u65b9\u6cd5\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u8be5\u65b9\u6cd5\u5305\u62ec\u4e24\u4e2a\u9636\u6bb5\uff1a</p> <ol> <li> <p>\u524d\u5411\u6d88\u5143: \u5c06\u589e\u5e7f\u77e9\u9635[A|b]\u8f6c\u6362\u4e3a\u4e0a\u4e09\u89d2\u5f62\u5f0f</p> </li> <li> <p>\u56de\u4ee3: \u4ece\u4e0b\u5230\u4e0a\u6c42\u89e3Ux = y</p> </li> </ol> <p>\u7b97\u6cd5:</p> <ul> <li> <p>\u521b\u5efa\u589e\u5e7f\u77e9\u9635 [A | b]</p> </li> <li> <p>\u5e94\u7528\u9ad8\u65af\u6d88\u5143\u5f97\u5230 [U | y]\uff0c\u5176\u4e2dU\u662f\u4e0a\u4e09\u89d2\u77e9\u9635</p> </li> <li> <p>\u4f7f\u7528\u56de\u4ee3\u6c42\u89e3Ux = y\uff1ax\u1d62 = (y\u1d62 - \u03a3\u2c7c\u208c\u1d62\u208a\u2081\u207f U\u1d62\u2c7cx\u2c7c) / U\u1d62\u1d62</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code> : \u7cfb\u6570\u77e9\u9635 (N\u00d7N)\uff0c\u5fc5\u987b\u662f\u65b9\u9635\u4e14\u975e\u5947\u5f02\u3002</p> </li> <li> <p><code>const Mat &amp;b</code> : \u53f3\u7aef\u9879\u5411\u91cf (N\u00d71)\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u89e3\u5411\u91cf (N\u00d71)\uff0c\u5305\u542b\u65b9\u7a0bAx = b\u7684\u6839\u3002\u5982\u679c\u7cfb\u7edf\u662f\u5947\u5f02\u7684\u6216\u4e0d\u517c\u5bb9\u7684\uff0c\u8fd4\u56de\u7a7a\u77e9\u9635\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u5355\u4e2a\u7cfb\u7edf: \u5bf9\u4e8e\u6c42\u89e3\u4e00\u4e2a\u7cfb\u7edf\u5f88\u9ad8\u6548\u3002\u5bf9\u4e8e\u5177\u6709\u76f8\u540cA\u7684\u591a\u4e2a\u7cfb\u7edf\uff0c\u4f7f\u7528LU\u5206\u89e3 + <code>solve_lu()</code>\u3002</p> </li> <li> <p>\u6761\u4ef6\u6570: \u5bf9\u4e8e\u75c5\u6001\u77e9\u9635\uff0c\u6027\u80fd\u4f1a\u4e0b\u964d\u3002\u5982\u679c\u7ed3\u679c\u4e0d\u51c6\u786e\uff0c\u68c0\u67e5\u6761\u4ef6\u6570\u3002</p> </li> <li> <p>\u5947\u5f02\u7cfb\u7edf: \u5982\u679cA\u662f\u5947\u5f02\u7684\uff08det(A) = 0\uff09\uff0c\u8fd4\u56de\u7a7a\u77e9\u9635\u3002\u5bf9\u4e8e\u79e9\u4e8f\u7cfb\u7edf\uff0c\u4f7f\u7528SVD + \u4f2a\u9006\u3002</p> </li> <li> <p>\u6027\u80fd: \u6d88\u5143\u4e3aO(n\u00b3)\uff0c\u56de\u4ee3\u4e3aO(n\u00b2)\u3002\u603b\u8ba1O(n\u00b3)\u3002</p> </li> <li> <p>\u66ff\u4ee3\u65b9\u6cd5:</p> </li> <li> <p>\u5bf9\u4e8eSPD\u77e9\u9635\uff1a\u4f7f\u7528Cholesky\u5206\u89e3 + <code>solve_cholesky()</code>\uff08\u66f4\u5feb\uff09</p> </li> <li> <p>\u5bf9\u4e8e\u591a\u4e2a\u53f3\u7aef\u9879\uff1a\u4f7f\u7528LU\u5206\u89e3 + <code>solve_lu()</code>\uff08\u66f4\u9ad8\u6548\uff09</p> </li> <li> <p>\u5bf9\u4e8e\u8d85\u5b9a\u7cfb\u7edf\uff1a\u4f7f\u7528QR\u5206\u89e3 + <code>solve_qr()</code>\uff08\u6700\u5c0f\u4e8c\u4e58\uff09</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_48","title":"\u5e26\u72b6\u77e9\u9635\u6c42\u89e3","text":"<pre><code>Mat Mat::band_solve(Mat A, Mat b, int k);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u4f18\u5316\u7684\u9ad8\u65af\u6d88\u5143\u6cd5\u6c42\u89e3\u5e26\u72b6\u77e9\u9635\u65b9\u7a0b\u7ec4 Ax = b\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>Mat A</code>: \u7cfb\u6570\u77e9\u9635 (NxN) - \u5e26\u72b6\u77e9\u9635</p> </li> <li> <p><code>Mat b</code>: \u7ed3\u679c\u5411\u91cf (Nx1)</p> </li> <li> <p><code>int k</code>: \u77e9\u9635\u7684\u5e26\u5bbd\uff08\u975e\u96f6\u5e26\u7684\u5bbd\u5ea6\uff09</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u89e3\u5411\u91cf (Nx1)\uff0c\u5305\u542b\u65b9\u7a0b Ax = b \u7684\u6839</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_49","title":"\u7ebf\u6027\u7cfb\u7edf\u6c42\u6839","text":"<pre><code>Mat Mat::roots(Mat A, Mat y);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u4e0d\u540c\u65b9\u6cd5\u6c42\u89e3\u77e9\u9635\u3002\u8fd9\u662f 'solve' \u51fd\u6570\u7684\u53e6\u4e00\u79cd\u5b9e\u73b0\uff0c\u539f\u7406\u4e0a\u6ca1\u6709\u533a\u522b\u3002\u6b64\u65b9\u6cd5\u4f7f\u7528\u9ad8\u65af\u6d88\u5143\u6cd5\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf A * x = y\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>Mat A</code>: \u77e9\u9635 [N]x[N]\uff0c\u5305\u542b\u8f93\u5165\u7cfb\u6570</p> </li> <li> <p><code>Mat y</code>: \u5411\u91cf [N]x[1]\uff0c\u5305\u542b\u7ed3\u679c\u503c</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u77e9\u9635 [N]x[1]\uff0c\u5305\u542b\u6839</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_50","title":"\u77e9\u9635\u5c5e\u6027\u4e0e\u5206\u89e3","text":"<p>\u77e9\u9635\u5206\u89e3\u6982\u8ff0</p> <p>\u77e9\u9635\u5206\u89e3\u662f\u6570\u503c\u7ebf\u6027\u4ee3\u6570\u4e2d\u7684\u57fa\u672c\u5de5\u5177\u3002\u5b83\u4eec\u5c06\u77e9\u9635\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u7684\u7ec4\u4ef6\uff0c\u63ed\u793a\u5176\u7ed3\u6784\u5e76\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002\u4e0d\u540c\u7684\u5206\u89e3\u9002\u7528\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u77e9\u9635\u548c\u5e94\u7528\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_51","title":"\u77e9\u9635\u5c5e\u6027\u68c0\u67e5","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_52","title":"\u68c0\u67e5\u5bf9\u79f0\u6027","text":"<pre><code>bool Mat::is_symmetric(float tolerance = 1e-6f) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u68c0\u67e5\u77e9\u9635\u5728\u7ed9\u5b9a\u5bb9\u5dee\u5185\u662f\u5426\u5bf9\u79f0\u3002\u77e9\u9635A\u662f\u5bf9\u79f0\u7684\uff0c\u5982\u679cA = A^T\uff0c\u5373\u5bf9\u4e8e\u6240\u6709i, j\uff0cA(i,j) = A(j,i)\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u5bf9\u4e8e\u5bf9\u79f0\u77e9\u9635\uff0c\u6240\u6709\u7279\u5f81\u503c\u90fd\u662f\u5b9e\u6570\uff0c\u5e76\u4e14\u53ef\u4ee5\u9009\u62e9\u7279\u5f81\u5411\u91cf\u4f7f\u5176\u6b63\u4ea4\u3002\u5bf9\u79f0\u77e9\u9635\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\u90fd\u662f\u57fa\u7840\u7684\uff0c\u7279\u522b\u662f\u5728\u7ed3\u6784\u52a8\u529b\u5b66\u548c\u4f18\u5316\u4e2d\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float tolerance</code> : \u5141\u8bb8\u7684\u6700\u5927\u5dee\u503c |A(i,j) - A(j,i)|\uff08\u9ed8\u8ba4\uff1a1e-6\uff09\u3002</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>bool</code> - \u5982\u679c\u8fd1\u4f3c\u5bf9\u79f0\u8fd4\u56de<code>true</code>\uff0c\u5426\u5219\u8fd4\u56de<code>false</code>\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u7279\u5f81\u5206\u89e3: \u5bf9\u79f0\u77e9\u9635\u53ef\u4ee5\u4f7f\u7528\u66f4\u9ad8\u6548\u548c\u7a33\u5b9a\u7684\u7279\u5f81\u5206\u89e3\u65b9\u6cd5\uff08\u4f8b\u5982Jacobi\u65b9\u6cd5\uff09\u3002</p> </li> <li> <p>Cholesky\u5206\u89e3: \u53ea\u6709\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u53ef\u4ee5\u4f7f\u7528Cholesky\u5206\u89e3\u8fdb\u884c\u5206\u89e3\u3002</p> </li> <li> <p>\u7ed3\u6784\u52a8\u529b\u5b66: \u7ed3\u6784\u5206\u6790\u4e2d\u7684\u521a\u5ea6\u548c\u8d28\u91cf\u77e9\u9635\u901a\u5e38\u662f\u5bf9\u79f0\u7684\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_53","title":"\u68c0\u67e5\u6b63\u5b9a\u6027","text":"<pre><code>bool Mat::is_positive_definite(float tolerance = 1e-6f) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528Sylvester\u51c6\u5219\u68c0\u67e5\u77e9\u9635\u662f\u5426\u6b63\u5b9a\u3002\u5bf9\u79f0\u77e9\u9635A\u662f\u6b63\u5b9a\u7684\uff0c\u5982\u679c\u5bf9\u4e8e\u6240\u6709\u975e\u96f6\u5411\u91cfx\uff0cx^T A x &gt; 0\uff0c\u6216\u8005\u7b49\u4ef7\u5730\uff0c\u6240\u6709\u7279\u5f81\u503c\u90fd\u662f\u6b63\u7684\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>Sylvester\u51c6\u5219\u6307\u51fa\uff0c\u5bf9\u79f0\u77e9\u9635\u662f\u6b63\u5b9a\u7684\u5f53\u4e14\u4ec5\u5f53\u6240\u6709\u524d\u5bfc\u4e3b\u5b50\u5f0f\u90fd\u662f\u6b63\u7684\u3002\u4e3a\u4e86\u6548\u7387\uff0c\u51fd\u6570\u68c0\u67e5\u524d\u51e0\u4e2a\u524d\u5bfc\u4e3b\u5b50\u5f0f\u548c\u5bf9\u89d2\u5143\u7d20\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>float tolerance</code> : \u6570\u503c\u68c0\u67e5\u7684\u5bb9\u5dee\uff08\u9ed8\u8ba4\uff1a1e-6\uff09\u3002</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>bool</code> - \u5982\u679c\u77e9\u9635\u662f\u6b63\u5b9a\u7684\u8fd4\u56de<code>true</code>\uff0c\u5426\u5219\u8fd4\u56de<code>false</code>\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>Cholesky\u5206\u89e3: \u6b63\u5b9a\u77e9\u9635\u53ef\u4ee5\u4f7f\u7528Cholesky\u5206\u89e3\u8fdb\u884c\u5206\u89e3\uff0c\u8fd9\u6bd4LU\u5206\u89e3\u66f4\u5feb\u3001\u66f4\u7a33\u5b9a\u3002</p> </li> <li> <p>\u4f18\u5316: \u6b63\u5b9aHessian\u77e9\u9635\u5728\u4f18\u5316\u95ee\u9898\u4e2d\u8868\u793a\u5c40\u90e8\u6700\u5c0f\u503c\u3002</p> </li> <li> <p>\u7a33\u5b9a\u6027\u5206\u6790: \u5728\u63a7\u5236\u7cfb\u7edf\u4e2d\uff0c\u67d0\u4e9b\u77e9\u9635\u7684\u6b63\u5b9a\u6027\u786e\u4fdd\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_54","title":"\u77e9\u9635\u5206\u89e3\u7ed3\u6784","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#lu","title":"LU\u5206\u89e3\u7ed3\u6784","text":"<pre><code>struct Mat::LUDecomposition\n{\n    Mat L;                 // \u4e0b\u4e09\u89d2\u77e9\u9635\uff08\u5355\u4f4d\u5bf9\u89d2\u7ebf\uff09\n    Mat U;                 // \u4e0a\u4e09\u89d2\u77e9\u9635\n    Mat P;                 // \u7f6e\u6362\u77e9\u9635\uff08\u5982\u679c\u4f7f\u7528\u4e3b\u5143\uff09\n    bool pivoted;          // \u662f\u5426\u4f7f\u7528\u4e3b\u5143\n    tiny_error_t status;   // \u8ba1\u7b97\u72b6\u6001\n\n    LUDecomposition();\n};\n</code></pre> <p>\u63cf\u8ff0:</p> <p>LU\u5206\u89e3\u7ed3\u679c\u7684\u5bb9\u5668\u3002\u5206\u89e3A = P * L * U\uff08\u5e26\u4e3b\u5143\uff09\u6216A = L * U\uff08\u4e0d\u5e26\u4e3b\u5143\uff09\uff0c\u5176\u4e2dL\u662f\u5355\u4f4d\u5bf9\u89d2\u7ebf\u7684\u4e0b\u4e09\u89d2\u77e9\u9635\uff0cU\u662f\u4e0a\u4e09\u89d2\u77e9\u9635\uff0cP\u662f\u7f6e\u6362\u77e9\u9635\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>LU\u5206\u89e3\u5c06\u77e9\u9635\u5206\u89e3\u4e3a\u4e0b\u4e09\u89d2\u548c\u4e0a\u4e09\u89d2\u77e9\u9635\uff0c\u5b9e\u73b0\u7ebf\u6027\u7cfb\u7edf\u7684\u9ad8\u6548\u6c42\u89e3\u3002\u4f7f\u7528\u4e3b\u5143\u65f6\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u5904\u7406\u8fd1\u5947\u5f02\u77e9\u9635\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#cholesky","title":"Cholesky\u5206\u89e3\u7ed3\u6784","text":"<pre><code>struct Mat::CholeskyDecomposition\n{\n    Mat L;                 // \u4e0b\u4e09\u89d2\u77e9\u9635\n    tiny_error_t status;   // \u8ba1\u7b97\u72b6\u6001\n\n    CholeskyDecomposition();\n};\n</code></pre> <p>\u63cf\u8ff0:</p> <p>Cholesky\u5206\u89e3\u7ed3\u679c\u7684\u5bb9\u5668\u3002\u5bf9\u4e8e\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\uff0cA = L * L^T\uff0c\u5176\u4e2dL\u662f\u4e0b\u4e09\u89d2\u77e9\u9635\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>Cholesky\u5206\u89e3\u662f\u7528\u4e8e\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u7684\u4e13\u7528LU\u5206\u89e3\u3002\u5b83\u53ea\u9700\u8981LU\u5206\u89e3\u7684\u4e00\u534a\u5b58\u50a8\u548c\u8ba1\u7b97\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#qr","title":"QR\u5206\u89e3\u7ed3\u6784","text":"<pre><code>struct Mat::QRDecomposition\n{\n    Mat Q;                 // \u6b63\u4ea4\u77e9\u9635 (Q^T * Q = I)\n    Mat R;                 // \u4e0a\u4e09\u89d2\u77e9\u9635\n    tiny_error_t status;   // \u8ba1\u7b97\u72b6\u6001\n\n    QRDecomposition();\n};\n</code></pre> <p>\u63cf\u8ff0:</p> <p>QR\u5206\u89e3\u7ed3\u679c\u7684\u5bb9\u5668\u3002A = Q * R\uff0c\u5176\u4e2dQ\u662f\u6b63\u4ea4\u7684\uff08Q^T * Q = I\uff09\uff0cR\u662f\u4e0a\u4e09\u89d2\u77e9\u9635\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>QR\u5206\u89e3\u5c06\u77e9\u9635\u8868\u793a\u4e3a\u6b63\u4ea4\u77e9\u9635\u548c\u4e0a\u4e09\u89d2\u77e9\u9635\u7684\u4e58\u79ef\u3002\u5b83\u5728\u6570\u503c\u4e0a\u7a33\u5b9a\uff0c\u662f\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u7684\u57fa\u7840\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#svd","title":"SVD\u5206\u89e3\u7ed3\u6784","text":"<pre><code>struct Mat::SVDDecomposition\n{\n    Mat U;                 // \u5de6\u5947\u5f02\u5411\u91cf\uff08\u6b63\u4ea4\u77e9\u9635\uff09\n    Mat S;                 // \u5947\u5f02\u503c\uff08\u5bf9\u89d2\u77e9\u9635\u6216\u5411\u91cf\uff09\n    Mat V;                 // \u53f3\u5947\u5f02\u5411\u91cf\uff08\u6b63\u4ea4\u77e9\u9635\uff0cV^T\uff09\n    int rank;              // \u77e9\u9635\u7684\u6570\u503c\u79e9\n    int iterations;        // \u6267\u884c\u7684\u8fed\u4ee3\u6b21\u6570\n    tiny_error_t status;   // \u8ba1\u7b97\u72b6\u6001\n\n    SVDDecomposition();\n};\n</code></pre> <p>\u63cf\u8ff0:</p> <p>SVD\u5206\u89e3\u7ed3\u679c\u7684\u5bb9\u5668\u3002A = U * S * V^T\uff0c\u5176\u4e2dU\u548cV\u662f\u6b63\u4ea4\u77e9\u9635\uff0cS\u5728\u5bf9\u89d2\u7ebf\u4e0a\u5305\u542b\u5947\u5f02\u503c\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>SVD\u662f\u6700\u901a\u7528\u7684\u77e9\u9635\u5206\u89e3\u3002\u5947\u5f02\u503c\u63ed\u793a\u77e9\u9635\u7684\u79e9\u3001\u6761\u4ef6\u6570\uff0c\u5e76\u80fd\u591f\u8ba1\u7b97\u79e9\u4e8f\u77e9\u9635\u7684\u4f2a\u9006\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_55","title":"\u77e9\u9635\u5206\u89e3\u65b9\u6cd5","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#lu_1","title":"LU\u5206\u89e3","text":"<pre><code>Mat::LUDecomposition Mat::lu_decompose(bool use_pivoting = true) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97LU\u5206\u89e3\uff1aA = P * L * U\uff08\u5e26\u4e3b\u5143\uff09\u6216A = L * U\uff08\u4e0d\u5e26\u4e3b\u5143\uff09\u3002\u5bf9\u4e8e\u6c42\u89e3\u5177\u6709\u76f8\u540c\u7cfb\u6570\u77e9\u9635\u7684\u591a\u4e2a\u7cfb\u7edf\u5f88\u9ad8\u6548\u3002</p> <p>\u6570\u5b66\u539f\u7406: </p> <ul> <li> <p>\u4e0d\u5e26\u4e3b\u5143: A = L * U\uff0c\u5176\u4e2dL\u5177\u6709\u5355\u4f4d\u5bf9\u89d2\u7ebf</p> </li> <li> <p>\u5e26\u4e3b\u5143: P * A = L * U\uff0c\u5176\u4e2dP\u662f\u7f6e\u6362\u77e9\u9635</p> </li> </ul> <p>\u5206\u89e3\u901a\u8fc7\u6c42\u89e3Ly = Pb\uff08\u524d\u5411\u66ff\u6362\uff09\u7136\u540eUx = y\uff08\u540e\u5411\u66ff\u6362\uff09\u6765\u6c42\u89e3Ax = b\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>bool use_pivoting</code> : \u662f\u5426\u4f7f\u7528\u90e8\u5206\u4e3b\u5143\u4ee5\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027\uff08\u9ed8\u8ba4\uff1atrue\uff09\u3002</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>LUDecomposition</code>\uff0c\u5305\u542bL\u3001U\u3001P\u77e9\u9635\u548c\u72b6\u6001\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u591a\u4e2a\u53f3\u7aef\u9879: \u4e00\u65e6\u5206\u89e3\uff0c\u4f7f\u7528<code>solve_lu()</code>\u9ad8\u6548\u6c42\u89e3\u5177\u6709\u4e0d\u540c\u53f3\u7aef\u9879\u7684\u591a\u4e2a\u7cfb\u7edf\u3002</p> </li> <li> <p>\u884c\u5217\u5f0f: det(A) = det(P) * det(L) * det(U) = det(P) * det(U)\uff08\u56e0\u4e3adet(L) = 1\uff09\u3002</p> </li> <li> <p>\u9006\u77e9\u9635: \u53ef\u4ee5\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u5355\u4f4d\u5411\u91cfe\u1d62\u6c42\u89e3LUx = e\u1d62\u6765\u8ba1\u7b97A^(-1)\u3002</p> </li> <li> <p>\u6027\u80fd: \u5206\u89e3\u4e3aO(n\u00b3)\uff0c\u5206\u89e3\u540e\u6bcf\u6b21\u6c42\u89e3\u4e3aO(n\u00b2)\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#cholesky_1","title":"Cholesky\u5206\u89e3","text":"<pre><code>Mat::CholeskyDecomposition Mat::cholesky_decompose() const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u7684Cholesky\u5206\u89e3\uff1aA = L * L^T\u3002\u5bf9\u4e8eSPD\u77e9\u9635\u6bd4LU\u66f4\u5feb\uff0c\u5e38\u7528\u4e8e\u7ed3\u6784\u52a8\u529b\u5b66\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u5bf9\u4e8e\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635A\uff0c\u5b58\u5728\u552f\u4e00\u7684\u5177\u6709\u6b63\u5bf9\u89d2\u5143\u7d20\u7684\u4e0b\u4e09\u89d2\u77e9\u9635L\uff0c\u4f7f\u5f97A = L * L^T\u3002\u8fd9\u672c\u8d28\u4e0a\u662f\u5229\u7528\u5bf9\u79f0\u6027\u7684\u4e13\u7528LU\u5206\u89e3\u3002</p> <p>\u53c2\u6570:</p> <p>\u65e0\uff08\u77e9\u9635\u5fc5\u987b\u662f\u5bf9\u79f0\u6b63\u5b9a\u7684\uff09\u3002</p> <p>\u8fd4\u56de\u503c:</p> <p><code>CholeskyDecomposition</code>\uff0c\u5305\u542bL\u77e9\u9635\u548c\u72b6\u6001\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u6548\u7387: \u9700\u8981\u5927\u7ea6LU\u5206\u89e3\u7684\u4e00\u534a\u8ba1\u7b97\u548c\u5b58\u50a8\u3002</p> </li> <li> <p>\u7a33\u5b9a\u6027: \u5bf9\u4e8e\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u6bd4LU\u66f4\u7a33\u5b9a\u3002</p> </li> <li> <p>\u5e94\u7528: </p> </li> <li> <p>\u7ed3\u6784\u52a8\u529b\u5b66\uff1a\u8d28\u91cf\u548c\u521a\u5ea6\u77e9\u9635\u901a\u5e38\u662fSPD</p> </li> <li> <p>\u4f18\u5316\uff1aNewton\u65b9\u6cd5\u4e2d\u7684Hessian\u77e9\u9635</p> </li> <li> <p>\u7edf\u8ba1\uff1a\u534f\u65b9\u5dee\u77e9\u9635</p> </li> <li> <p>\u9519\u8bef\u5904\u7406: \u5982\u679c\u77e9\u9635\u4e0d\u5bf9\u79f0\u6216\u4e0d\u662f\u6b63\u5b9a\u7684\uff0c\u8fd4\u56de\u9519\u8bef\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#qr_1","title":"QR\u5206\u89e3","text":"<pre><code>Mat::QRDecomposition Mat::qr_decompose() const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97QR\u5206\u89e3\uff1aA = Q * R\uff0c\u5176\u4e2dQ\u662f\u6b63\u4ea4\u7684\uff0cR\u662f\u4e0a\u4e09\u89d2\u7684\u3002\u6570\u503c\u7a33\u5b9a\uff0c\u7528\u4e8e\u6700\u5c0f\u4e8c\u4e58\u548c\u6b63\u4ea4\u5316\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>QR\u5206\u89e3\u5c06\u4efb\u4f55\u77e9\u9635\u8868\u793a\u4e3a\u6b63\u4ea4\u77e9\u9635Q\uff08Q^T * Q = I\uff09\u548c\u4e0a\u4e09\u89d2\u77e9\u9635R\u7684\u4e58\u79ef\u3002\u4f7f\u7528\u6539\u8fdb\u7684Gram-Schmidt\u8fc7\u7a0b\u548c\u91cd\u65b0\u6b63\u4ea4\u5316\u8ba1\u7b97\u5206\u89e3\u3002</p> <p>\u53c2\u6570:</p> <p>\u65e0\u3002</p> <p>\u8fd4\u56de\u503c:</p> <p><code>QRDecomposition</code>\uff0c\u5305\u542bQ\u548cR\u77e9\u9635\u548c\u72b6\u6001\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u6700\u5c0f\u4e8c\u4e58: \u5bf9\u4e8e\u8d85\u5b9a\u7cfb\u7edfAx \u2248 b\uff0c\u6700\u5c0f\u5316||Ax - b||\u2082\u7684\u89e3\u662fx = R^(-1) * Q^T * b\u3002</p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: QR\u5206\u89e3\u5bf9\u4e8e\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u6bd4\u6b63\u89c4\u65b9\u7a0b\u66f4\u7a33\u5b9a\u3002</p> </li> <li> <p>\u7279\u5f81\u5206\u89e3: QR\u7b97\u6cd5\u8fed\u4ee3\u4f7f\u7528QR\u5206\u89e3\u6765\u67e5\u627e\u7279\u5f81\u503c\u3002</p> </li> <li> <p>\u79e9\u63ed\u793a: A\u7684\u79e9\u7b49\u4e8eR\u7684\u975e\u96f6\u5bf9\u89d2\u5143\u7d20\u6570\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#svd_1","title":"SVD\u5206\u89e3","text":"<pre><code>Mat::SVDDecomposition Mat::svd_decompose(int max_iter = 100, float tolerance = 1e-6f) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u8ba1\u7b97\u5947\u5f02\u503c\u5206\u89e3\uff1aA = U * S * V^T\u3002\u6700\u901a\u7528\u7684\u5206\u89e3\uff0c\u7528\u4e8e\u79e9\u4f30\u8ba1\u3001\u4f2a\u9006\u3001\u964d\u7ef4\u3002\u4f7f\u7528\u57fa\u4e8e\u7279\u5f81\u5206\u89e3\u7684\u8fed\u4ee3\u65b9\u6cd5\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>SVD\u5c06\u4efb\u4f55m \u00d7 n\u77e9\u9635A\u5206\u89e3\u4e3a\uff1a - U: m \u00d7 m\u6b63\u4ea4\u77e9\u9635\uff08\u5de6\u5947\u5f02\u5411\u91cf\uff09</p> <ul> <li> <p>S: m \u00d7 n\u5bf9\u89d2\u77e9\u9635\uff08\u5947\u5f02\u503c\u03c3\u2081 \u2265 \u03c3\u2082 \u2265 ... \u2265 \u03c3\u1d63 \u2265 0\uff09</p> </li> <li> <p>V: n \u00d7 n\u6b63\u4ea4\u77e9\u9635\uff08\u53f3\u5947\u5f02\u5411\u91cf\uff09</p> </li> </ul> <p>\u5947\u5f02\u503c\u63ed\u793a\u77e9\u9635\u7684\u57fa\u672c\u5c5e\u6027\uff1a\u79e9\u3001\u6761\u4ef6\u6570\u548c\u6570\u503c\u884c\u4e3a\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int max_iter</code> : \u6700\u5927\u8fed\u4ee3\u6b21\u6570\uff08\u9ed8\u8ba4\uff1a100\uff09\u3002</p> </li> <li> <p><code>float tolerance</code> : \u6536\u655b\u5bb9\u5dee\uff08\u9ed8\u8ba4\uff1a1e-6\uff09\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>SVDDecomposition</code>\uff0c\u5305\u542bU\u3001S\u3001V\u77e9\u9635\u3001\u79e9\u548c\u72b6\u6001\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u79e9\u4f30\u8ba1: \u6570\u503c\u79e9\u662f\u9ad8\u4e8e\u5bb9\u5dee\u9608\u503c\u7684\u5947\u5f02\u503c\u6570\u91cf\u3002</p> </li> <li> <p>\u4f2a\u9006: A\u207a = V * S\u207a * U^T\uff0c\u5176\u4e2dS\u207a\u5bf9\u4e8e\u975e\u96f6\u03c3\u1d62\u67091/\u03c3\u1d62\u3002</p> </li> <li> <p>\u964d\u7ef4: \u622a\u65adSVD\uff08\u4ec5\u4fdd\u7559\u6700\u5927\u5947\u5f02\u503c\uff09\u63d0\u4f9b\u4f4e\u79e9\u8fd1\u4f3c\u3002</p> </li> <li> <p>\u6761\u4ef6\u6570: \u03ba(A) = \u03c3\u2081 / \u03c3\u1d63\uff0c\u5176\u4e2d\u03c3\u1d63\u662f\u6700\u5c0f\u7684\u975e\u96f6\u5947\u5f02\u503c\u3002</p> </li> <li> <p>\u5e94\u7528: </p> </li> <li> <p>\u79e9\u4e8f\u7cfb\u7edf\u7684\u6700\u5c0f\u4e8c\u4e58</p> </li> <li> <p>\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09</p> </li> <li> <p>\u56fe\u50cf\u538b\u7f29</p> </li> <li> <p>\u964d\u566a</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_56","title":"\u4f7f\u7528\u5206\u89e3\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#lu_2","title":"\u4f7f\u7528LU\u5206\u89e3\u6c42\u89e3","text":"<pre><code>static Mat Mat::solve_lu(const LUDecomposition &amp;lu, const Mat &amp;b);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u9884\u8ba1\u7b97\u7684LU\u5206\u89e3\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edfAx = b\u3002\u5f53\u6c42\u89e3\u5177\u6709\u76f8\u540c\u7cfb\u6570\u77e9\u9635\u7684\u591a\u4e2a\u7cfb\u7edf\u65f6\uff0c\u6bd4<code>solve()</code>\u66f4\u9ad8\u6548\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u7ed9\u5b9aA = P * L * U\uff0c\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u6c42\u89e3Ax = b\uff1a 1. \u6c42\u89e3Ly = Pb\uff08\u524d\u5411\u66ff\u6362\uff09 2. \u6c42\u89e3Ux = y\uff08\u540e\u5411\u66ff\u6362\uff09</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const LUDecomposition &amp;lu</code> : \u9884\u8ba1\u7b97\u7684LU\u5206\u89e3\u3002</p> </li> <li> <p><code>const Mat &amp;b</code> : \u53f3\u7aef\u9879\u5411\u91cf (N\u00d71)\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u89e3\u5411\u91cf (N\u00d71)\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u591a\u4e2a\u53f3\u7aef\u9879: \u8ba1\u7b97\u4e00\u6b21LU\u5206\u89e3\u540e\uff0c\u9ad8\u6548\u6c42\u89e3\u591a\u4e2a\u7cfb\u7edf\u3002</p> </li> <li> <p>\u6027\u80fd: \u6bcf\u6b21\u6c42\u89e3O(n\u00b2) vs \u5b8c\u6574\u6c42\u89e3O(n\u00b3)\uff0c\u5bf9\u4e8e\u591a\u4e2a\u53f3\u7aef\u9879\u8282\u7701\u663e\u8457\u3002</p> </li> <li> <p>\u5185\u5b58: \u91cd\u7528\u5206\u89e3\uff0c\u907f\u514d\u91cd\u590d\u8ba1\u7b97\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#cholesky_2","title":"\u4f7f\u7528Cholesky\u5206\u89e3\u6c42\u89e3","text":"<pre><code>static Mat Mat::solve_cholesky(const CholeskyDecomposition &amp;chol, const Mat &amp;b);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u9884\u8ba1\u7b97\u7684Cholesky\u5206\u89e3\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edfAx = b\u3002\u5bf9\u4e8e\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u6bd4LU\u66f4\u9ad8\u6548\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u7ed9\u5b9aA = L * L^T\uff0c\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u6c42\u89e3Ax = b\uff1a 1. \u6c42\u89e3Ly = b\uff08\u524d\u5411\u66ff\u6362\uff09 2. \u6c42\u89e3L^T x = y\uff08\u540e\u5411\u66ff\u6362\uff09</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const CholeskyDecomposition &amp;chol</code> : \u9884\u8ba1\u7b97\u7684Cholesky\u5206\u89e3\u3002</p> </li> <li> <p><code>const Mat &amp;b</code> : \u53f3\u7aef\u9879\u5411\u91cf (N\u00d71)\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u89e3\u5411\u91cf (N\u00d71)\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u6548\u7387: \u5bf9\u4e8eSPD\u77e9\u9635\uff0c\u5728\u5206\u89e3\u548c\u6c42\u89e3\u65b9\u9762\u90fd\u6bd4LU\u66f4\u5feb\u3002</p> </li> <li> <p>\u7a33\u5b9a\u6027: \u5bf9\u4e8eSPD\u77e9\u9635\u5728\u6570\u503c\u4e0a\u66f4\u7a33\u5b9a\u3002</p> </li> <li> <p>\u5e94\u7528: \u7ed3\u6784\u52a8\u529b\u5b66\u3001\u4f18\u5316\u3001\u7edf\u8ba1\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#qr_2","title":"\u4f7f\u7528QR\u5206\u89e3\u6c42\u89e3\uff08\u6700\u5c0f\u4e8c\u4e58\uff09","text":"<pre><code>static Mat Mat::solve_qr(const QRDecomposition &amp;qr, const Mat &amp;b);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528QR\u5206\u89e3\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf\u3002\u4e3a\u8d85\u5b9a\u7cfb\u7edf\uff08\u65b9\u7a0b\u6570\u591a\u4e8e\u672a\u77e5\u6570\uff09\u63d0\u4f9b\u6700\u5c0f\u4e8c\u4e58\u89e3\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u5bf9\u4e8eAx \u2248 b\uff08\u8d85\u5b9a\uff09\uff0c\u6700\u5c0f\u4e8c\u4e58\u89e3\u6700\u5c0f\u5316||Ax - b||\u2082\u3002\u4f7f\u7528A = Q * R\uff1a - x = R^(-1) * Q^T * b</p> <p>\u8fd9\u907f\u514d\u4e86\u6570\u503c\u4e0d\u7a33\u5b9a\u7684\u6b63\u89c4\u65b9\u7a0bA^T * A * x = A^T * b\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const QRDecomposition &amp;qr</code> : \u9884\u8ba1\u7b97\u7684QR\u5206\u89e3\u3002</p> </li> <li> <p><code>const Mat &amp;b</code> : \u53f3\u7aef\u9879\u5411\u91cf (M\u00d71\uff0c\u5176\u4e2dM \u2265 N)\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u6700\u5c0f\u4e8c\u4e58\u89e3\u5411\u91cf (N\u00d71)\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u8d85\u5b9a\u7cfb\u7edf: \u5904\u7406\u65b9\u7a0b\u6570\u591a\u4e8e\u672a\u77e5\u6570\u7684\u60c5\u51b5\u3002</p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: \u6bd4\u76f4\u63a5\u6c42\u89e3\u6b63\u89c4\u65b9\u7a0b\u66f4\u7a33\u5b9a\u3002</p> </li> <li> <p>\u5e94\u7528: </p> </li> <li> <p>\u66f2\u7ebf\u62df\u5408</p> </li> <li> <p>\u6570\u636e\u56de\u5f52</p> </li> <li> <p>\u4fe1\u53f7\u5904\u7406</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_57","title":"\u4f2a\u9006","text":"<pre><code>static Mat Mat::pseudo_inverse(const SVDDecomposition &amp;svd, float tolerance = 1e-6f);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528SVD\u5206\u89e3\u8ba1\u7b97Moore-Penrose\u4f2a\u9006A\u207a\u3002\u9002\u7528\u4e8e\u79e9\u4e8f\u6216\u975e\u65b9\u77e9\u9635\uff0c\u5176\u4e2d\u5e38\u89c4\u9006\u4e0d\u5b58\u5728\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u5bf9\u4e8eA = U * S * V^T\uff0c\u4f2a\u9006\u4e3aA\u207a = V * S\u207a * U^T\uff0c\u5176\u4e2dS\u207a\u5bf9\u4e8e\u5947\u5f02\u503c\u03c3\u1d62 &gt; tolerance\u67091/\u03c3\u1d62\uff0c\u5426\u5219\u4e3a0\u3002</p> <p>\u4f2a\u9006\u7684\u6027\u8d28:</p> <ul> <li> <p>A * A\u207a * A = A</p> </li> <li> <p>A\u207a * A * A\u207a = A\u207a</p> </li> <li> <p>(A * A\u207a)^T = A * A\u207a</p> </li> <li> <p>(A\u207a * A)^T = A\u207a * A</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const SVDDecomposition &amp;svd</code> : \u9884\u8ba1\u7b97\u7684SVD\u5206\u89e3\u3002</p> </li> <li> <p><code>float tolerance</code> : \u5947\u5f02\u503c\u9608\u503c\uff08\u9ed8\u8ba4\uff1a1e-6\uff09\u3002\u4f4e\u4e8e\u6b64\u503c\u7684\u5947\u5f02\u503c\u88ab\u89c6\u4e3a\u96f6\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u4f2a\u9006\u77e9\u9635\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u79e9\u4e8f\u7cfb\u7edf: \u4e3aA\u4e0d\u662f\u6ee1\u79e9\u7684\u7cfb\u7edf\u63d0\u4f9b\u89e3\u3002</p> </li> <li> <p>\u6700\u5c0f\u8303\u6570\u89e3: \u5bf9\u4e8e\u6b20\u5b9a\u7cfb\u7edf\uff0c\u7ed9\u51fa\u5177\u6709\u6700\u5c0f||x||\u2082\u7684\u89e3\u3002</p> </li> <li> <p>\u6700\u5c0f\u4e8c\u4e58: \u5bf9\u4e8e\u8d85\u5b9a\u7cfb\u7edf\uff0c\u7ed9\u51fa\u6700\u5c0f\u4e8c\u4e58\u89e3\u3002</p> </li> <li> <p>\u5e94\u7528:</p> </li> <li> <p>\u63a7\u5236\u7cfb\u7edf</p> </li> <li> <p>\u4fe1\u53f7\u5904\u7406</p> </li> <li> <p>\u673a\u5668\u5b66\u4e60\uff08\u6b63\u5219\u5316\uff09</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_8","title":"\u7ebf\u6027\u4ee3\u6570 - \u7279\u5f81\u503c\u4e0e\u7279\u5f81\u5411\u91cf","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#mateigenpair","title":"\u7ed3\u6784\u4f53\uff1a<code>Mat::EigenPair</code>","text":"<pre><code>Mat::EigenPair::EigenPair();\n// fields:\n// float eigenvalue;      // \u7279\u5f81\u503c\uff08power_iteration \u4e3a\u6700\u5927\u6a21\uff0cinverse_power_iteration \u4e3a\u6700\u5c0f\u6a21\uff09\n// Mat eigenvector;       // \u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\uff08n x 1\uff09\n// int iterations;        // \u8fed\u4ee3\u6b21\u6570\uff08\u82e5\u4e3a\u8fed\u4ee3\u6cd5\u8fd4\u56de\uff09\n// tiny_error_t status;   // \u8ba1\u7b97\u72b6\u6001\uff08TINY_OK / \u9519\u8bef\u7801\uff09\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u7528\u4e8e\u4fdd\u5b58\u5355\u4e00\u7279\u5f81\u503c/\u7279\u5f81\u5411\u91cf\u5bf9\u53ca\u5176\u8ba1\u7b97\u4fe1\u606f\u3002\u5e38\u7531 <code>power_iteration</code> \u6216 <code>inverse_power_iteration</code> \u8fd4\u56de\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#mateigendecomposition","title":"\u7ed3\u6784\u4f53\uff1a<code>Mat::EigenDecomposition</code>","text":"<pre><code>Mat::EigenDecomposition::EigenDecomposition();\n// fields:\n// Mat eigenvalues;    // n x 1 \u77e9\u9635\uff0c\u5b58\u653e\u7279\u5f81\u503c\n// Mat eigenvectors;   // n x n \u77e9\u9635\uff0c\u901a\u5e38\u6bcf\u4e00\u5217\u4e3a\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\n// int iterations;     // \u8fed\u4ee3\u6b21\u6570\uff08\u82e5\u4e3a\u8fed\u4ee3\u6cd5\u8fd4\u56de\uff09\n// tiny_error_t status; // \u8ba1\u7b97\u72b6\u6001\uff08TINY_OK / \u9519\u8bef\u7801\uff09\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u7528\u4e8e\u4fdd\u5b58\u5b8c\u6574\u7684\u7279\u5f81\u503c\u5206\u89e3\u7ed3\u679c\uff0c\u5305\u62ec\u5168\u90e8\u7279\u5f81\u503c\u548c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\u77e9\u9635\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_58","title":"\u5e42\u8fed\u4ee3\uff08\u6c42\u4e3b\u7279\u5f81\u503c/\u5411\u91cf\uff09","text":"<pre><code>Mat::EigenPair Mat::power_iteration(int max_iter, float tolerance) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u5e42\u8fed\u4ee3\u6cd5\u8ba1\u7b97\u77e9\u9635\u7684\u4e3b\u7279\u5f81\u503c\uff08\u7edd\u5bf9\u503c\u6700\u5927\uff09\u53ca\u5bf9\u5e94\u7279\u5f81\u5411\u91cf\u3002\u5feb\u901f\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6SHM\u5e94\u7528\uff0c\u53ef\u5feb\u901f\u8bc6\u522b\u4e3b\u9891\u7387\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u5e42\u8fed\u4ee3\u901a\u8fc7\u8fed\u4ee3\u5730\u5c06\u77e9\u9635\u5e94\u7528\u4e8e\u5411\u91cf\u6765\u627e\u5230\u7edd\u5bf9\u503c\u6700\u5927\u7684\u7279\u5f81\u503c\uff1a</p> <ol> <li> <p>\u4ece\u968f\u673a\u5411\u91cfv\u2080\u5f00\u59cb</p> </li> <li> <p>\u8fed\u4ee3\uff1av\u2096\u208a\u2081 = A * v\u2096 / ||A * v\u2096||</p> </li> <li> <p>\u7279\u5f81\u503c\u4f30\u8ba1\uff1a\u03bb\u2096 = (v\u2096^T * A * v\u2096) / (v\u2096^T * v\u2096) (Rayleigh\u5546)</p> </li> </ol> <p>\u6536\u655b\u6027:</p> <p>\u65b9\u6cd5\u6536\u655b\u5230\u4e3b\u7279\u5f81\u503c\uff0c\u5982\u679c\uff1a</p> <ul> <li> <p>\u4e3b\u7279\u5f81\u503c\u662f\u552f\u4e00\u7684 (|\u03bb\u2081| &gt; |\u03bb\u2082| \u2265 ... \u2265 |\u03bb\u2099|)</p> </li> <li> <p>\u521d\u59cb\u5411\u91cf\u5728\u4e3b\u7279\u5f81\u5411\u91cf\u65b9\u5411\u4e0a\u6709\u975e\u96f6\u5206\u91cf</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int max_iter</code> : \u6700\u5927\u8fed\u4ee3\u6b21\u6570\uff08\u5178\u578b\u9ed8\u8ba4\u503c\uff1a1000\uff09\u3002</p> </li> <li> <p><code>float tolerance</code> : \u6536\u655b\u5bb9\u5dee\uff08\u4f8b\u5982 1e-6\uff09\u3002\u6536\u655b\u6027\u901a\u8fc7 |\u03bb\u2096 - \u03bb\u2096\u208b\u2081| &lt; tolerance * |\u03bb\u2096| \u68c0\u67e5\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>EigenPair</code>\uff0c\u5305\u542b <code>eigenvalue</code>\u3001<code>eigenvector</code>\u3001<code>iterations</code> \u548c <code>status</code>\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u5b9e\u65f6\u5e94\u7528: \u5bf9\u4e8e\u5206\u79bb\u826f\u597d\u7684\u7279\u5f81\u503c\u5feb\u901f\u6536\u655b\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u3002</p> </li> <li> <p>\u521d\u59cb\u5316: \u5b9e\u73b0\u4f7f\u7528\u667a\u80fd\u521d\u59cb\u5316\u7b56\u7565\uff08\u5217\u7edd\u5bf9\u503c\u4e4b\u548c\uff09\u4ee5\u907f\u514d\u6536\u655b\u5230\u8f83\u5c0f\u7684\u7279\u5f81\u503c\u3002</p> </li> <li> <p>\u6536\u655b\u901f\u5ea6: \u6536\u655b\u662f\u7ebf\u6027\u7684\uff0c\u901f\u5ea6\u4e3a |\u03bb\u2082|/|\u03bb\u2081|\u3002\u5f53\u7279\u5f81\u503c\u63a5\u8fd1\u65f6\u8f83\u6162\u3002</p> </li> <li> <p>\u5c40\u9650\u6027: </p> </li> <li> <p>\u53ea\u627e\u5230\u4e00\u4e2a\u7279\u5f81\u503c-\u7279\u5f81\u5411\u91cf\u5bf9</p> </li> <li> <p>\u9700\u8981 |\u03bb\u2081| &gt; |\u03bb\u2082|\uff08\u4e3b\u7279\u5f81\u503c\u5fc5\u987b\u552f\u4e00\uff09</p> </li> <li> <p>\u5982\u679c\u7279\u5f81\u503c\u63a5\u8fd1\uff0c\u53ef\u80fd\u6536\u655b\u7f13\u6162</p> </li> <li> <p>\u5e94\u7528:</p> </li> <li> <p>\u4e3b\u6210\u5206\u5206\u6790\uff08\u7b2c\u4e00\u4e3b\u6210\u5206\uff09</p> </li> <li> <p>PageRank\u7b97\u6cd5</p> </li> <li> <p>\u7ed3\u6784\u52a8\u529b\u5b66\uff08\u57fa\u9891\uff09</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_59","title":"\u53cd\u5e42\u8fed\u4ee3\uff08\u6c42\u6700\u5c0f\u7279\u5f81\u503c/\u5411\u91cf\uff09","text":"<pre><code>Mat::EigenPair Mat::inverse_power_iteration(int max_iter, float tolerance) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528\u53cd\u5e42\u8fed\u4ee3\u6cd5\u8ba1\u7b97\u77e9\u9635\u7684\u6700\u5c0f\uff08\u6700\u5c0f\u6a21\uff09\u7279\u5f81\u503c\u53ca\u5176\u5bf9\u5e94\u7279\u5f81\u5411\u91cf\u3002\u5bf9\u4e8e\u7cfb\u7edf\u8bc6\u522b\u81f3\u5173\u91cd\u8981\u2014\u2014\u5728\u7ed3\u6784\u52a8\u529b\u5b66\u4e2d\u627e\u5230\u57fa\u9891/\u6700\u4f4e\u6a21\u6001\u3002\u8be5\u65b9\u6cd5\u5bf9\u4e8eSHM\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u5176\u4e2d\u6700\u5c0f\u7279\u5f81\u503c\u5bf9\u5e94\u4e8e\u7cfb\u7edf\u7684\u57fa\u672c\u9891\u7387\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>\u53cd\u5e42\u8fed\u4ee3\u5c06\u5e42\u8fed\u4ee3\u5e94\u7528\u4e8eA^(-1)\uff0c \u5176\u7279\u5f81\u503c\u4e3a1/\u03bb\u1d62\u3002\u7531\u4e8e1/\u03bb\u2099\u662fA^(-1) \u7684\u6700\u5927\u7279\u5f81\u503c\uff0c\u8be5\u65b9\u6cd5\u6536\u655b\u5230A\u7684\u6700\u5c0f\u7279\u5f81\u503c\uff1a</p> <ol> <li> <p>\u4ece\u5411\u91cfv\u2080\u5f00\u59cb</p> </li> <li> <p>\u8fed\u4ee3\uff1a\u6c42\u89e3A * y\u2096 = v\u2096\uff0c\u7136\u540ev\u2096\u208a\u2081 = y\u2096 / ||y\u2096||</p> </li> <li> <p>\u7279\u5f81\u503c\u4f30\u8ba1\uff1a\u03bb\u2096 = (v\u2096^T * A * v\u2096) / (v\u2096^T * v\u2096) (Rayleigh\u5546)</p> </li> </ol> <p>\u6536\u655b\u6027:</p> <p>\u6536\u655b\u5230\u6700\u5c0f\u7279\u5f81\u503c\uff0c\u5982\u679c\uff1a</p> <ul> <li> <p>\u6700\u5c0f\u7279\u5f81\u503c\u662f\u552f\u4e00\u7684 (|\u03bb\u2099| &lt; |\u03bb\u2099\u208b\u2081| \u2264 ... \u2264 |\u03bb\u2081|)</p> </li> <li> <p>\u77e9\u9635A\u662f\u53ef\u9006\u7684\uff08\u975e\u5947\u5f02\uff09</p> </li> <li> <p>\u521d\u59cb\u5411\u91cf\u5728\u6700\u5c0f\u7279\u5f81\u5411\u91cf\u65b9\u5411\u4e0a\u6709\u5206\u91cf</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int max_iter</code> : \u6700\u5927\u8fed\u4ee3\u6b21\u6570\uff08\u9ed8\u8ba4\uff1a1000\uff09\u3002</p> </li> <li> <p><code>float tolerance</code> : \u6536\u655b\u5bb9\u5dee\uff08\u9ed8\u8ba4\uff1a1e-6\uff09\u3002\u4f7f\u7528\u76f8\u5bf9\u5bb9\u5dee\uff1a|\u03bb\u2096 - \u03bb\u2096\u208b\u2081| &lt; tolerance * max(|\u03bb\u2096|, 1.0)\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>EigenPair</code>\uff0c\u5305\u542b\u6700\u5c0f\u7279\u5f81\u503c\u3001\u7279\u5f81\u5411\u91cf\u3001\u8fed\u4ee3\u6b21\u6570\u548c\u72b6\u6001\u3002</p> <p>\u7b97\u6cd5\u6b65\u9aa4:</p> <ol> <li> <p>\u521d\u59cb\u5316\u5f52\u4e00\u5316\u7279\u5f81\u5411\u91cfv\uff08\u4f7f\u7528\u4ea4\u66ff\u7b26\u53f7\u4ee5\u907f\u514d\u4e0e\u4e3b\u7279\u5f81\u5411\u91cf\u5bf9\u9f50\uff09</p> </li> <li> <p>\u8fed\u4ee3\uff1a\u4f7f\u7528<code>solve()</code>\u6c42\u89e3A * y = v\uff08\u7b49\u4ef7\u4e8ey = A^(-1) * v\uff09</p> </li> <li> <p>\u5f52\u4e00\u5316y\u5f97\u5230\u65b0\u7684v</p> </li> <li> <p>\u4f7f\u7528Rayleigh\u5546\u8ba1\u7b97\u7279\u5f81\u503c\u4f30\u8ba1\uff1a\u03bb = (v^T * A * v) / (v^T * v)</p> </li> <li> <p>\u4f7f\u7528\u76f8\u5bf9\u5bb9\u5dee\u68c0\u67e5\u6536\u655b\u6027</p> </li> </ol> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u7cfb\u7edf\u8bc6\u522b: \u5bf9\u4e8e\u5728\u7ed3\u6784\u52a8\u529b\u5b66\u4e2d\u67e5\u627e\u57fa\u9891\u81f3\u5173\u91cd\u8981\uff0c\u5176\u4e2d\u6700\u5c0f\u7279\u5f81\u503c\u5bf9\u5e94\u4e8e\u6700\u4f4e\u56fa\u6709\u9891\u7387\u3002</p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: \u5b9e\u73b0\u5305\u62ec\u5bf9\u5947\u5f02\u77e9\u9635\u7684\u68c0\u67e5\uff0c\u5e76\u4f18\u96c5\u5730\u5904\u7406\u8fd1\u5947\u5f02\u60c5\u51b5\u3002</p> </li> <li> <p>\u521d\u59cb\u5316\u7b56\u7565: \u4f7f\u7528\u4ea4\u66ff\u7b26\u53f7\u6a21\u5f0f\u4ee5\u907f\u514d\u6536\u655b\u5230\u8f83\u5927\u7684\u7279\u5f81\u503c\uff0c\u786e\u4fdd\u6536\u655b\u5230\u6700\u5c0f\u7279\u5f81\u503c\u3002</p> </li> <li> <p>\u6027\u80fd: \u6bcf\u6b21\u8fed\u4ee3\u9700\u8981\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf\uff08\u5bf9\u4e8e\u7a20\u5bc6\u77e9\u9635\u4e3aO(n\u00b3)\uff09\uff0c\u4f46\u901a\u5e38\u6bd4\u5e42\u8fed\u4ee3\u6536\u655b\u66f4\u5feb\u3002</p> </li> <li> <p>\u4e0e\u5e42\u8fed\u4ee3\u4e92\u8865: </p> </li> <li> <p>\u5e42\u8fed\u4ee3\uff1a\u627e\u5230\u03bb_max\uff08\u6700\u9ad8\u9891\u7387\uff09</p> </li> <li> <p>\u53cd\u5e42\u8fed\u4ee3\uff1a\u627e\u5230\u03bb_min\uff08\u57fa\u9891\uff09</p> </li> <li> <p>\u4e24\u8005\u4e00\u8d77\u63d0\u4f9b\u7cfb\u7edf\u7684\u9891\u7387\u8303\u56f4</p> </li> <li> <p>\u5e94\u7528:</p> </li> <li> <p>\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\uff08\u57fa\u9891\u68c0\u6d4b\uff09</p> </li> <li> <p>\u6a21\u6001\u5206\u6790\uff08\u6700\u4f4e\u6a21\u6001\u5f62\u72b6\uff09</p> </li> <li> <p>\u7cfb\u7edf\u8bc6\u522b</p> </li> <li> <p>\u7a33\u5b9a\u6027\u5206\u6790\uff08\u6700\u5c0f\u7279\u5f81\u503c\u8868\u793a\u7a33\u5b9a\u6027\u88d5\u5ea6\uff09</p> </li> </ul> <p>\u6ce8\u610f:</p> <ul> <li> <p>\u8981\u6c42\u77e9\u9635\u4e3a\u65b9\u9635\u4e14\u6570\u636e\u6307\u9488\u975e\u7a7a\uff1b\u5426\u5219\u8fd4\u56de\u9519\u8bef\u72b6\u6001\u3002</p> </li> <li> <p>\u77e9\u9635\u5fc5\u987b\u662f\u53ef\u9006\u7684\uff08\u975e\u5947\u5f02\uff09\u624d\u80fd\u4f7f\u6b64\u65b9\u6cd5\u5de5\u4f5c\u3002\u5982\u679c\u77e9\u9635\u662f\u5947\u5f02\u7684\u6216\u63a5\u8fd1\u5947\u5f02\u7684\uff0c\u8be5\u65b9\u6cd5\u5c06\u4f18\u96c5\u5730\u5931\u8d25\u3002</p> </li> <li> <p>\u53cd\u5e42\u8fed\u4ee3\u53ea\u8fd4\u56de\u6700\u5c0f\u7279\u5f81\u503c/\u5411\u91cf\u5bf9\u3002\u82e5\u9700\u5168\u90e8\u7279\u5f81\u503c/\u5411\u91cf\u8bf7\u4f7f\u7528\u4e0b\u9762\u7684\u5206\u89e3\u51fd\u6570\u3002</p> </li> <li> <p>\u8be5\u65b9\u6cd5\u4e0e\u5e42\u8fed\u4ee3\u4e92\u8865\uff1a\u5e42\u8fed\u4ee3\u627e\u5230\u6700\u5927\u7279\u5f81\u503c\uff0c\u800c\u53cd\u5e42\u8fed\u4ee3\u627e\u5230\u6700\u5c0f\u7279\u5f81\u503c\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#jacobi","title":"Jacobi \u7279\u5f81\u5206\u89e3\uff08\u5bf9\u79f0\u77e9\u9635\uff09","text":"<pre><code>Mat::EigenDecomposition Mat::eigendecompose_jacobi(float tolerance, int max_iter) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528Jacobi\u65b9\u6cd5\u8ba1\u7b97\u5b8c\u6574\u7684\u7279\u5f81\u503c\u5206\u89e3\u3002\u63a8\u8350\u7528\u4e8e\u5bf9\u79f0\u77e9\u9635\uff08\u826f\u597d\u7684\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u7ed3\u6784\u52a8\u529b\u5b66\u5e94\u7528\uff09\u3002\u7a33\u5065\u4e14\u51c6\u786e\uff0c\u662f\u7ed3\u6784\u52a8\u529b\u5b66\u77e9\u9635\u7684\u7406\u60f3\u9009\u62e9\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>Jacobi\u65b9\u6cd5\u901a\u8fc7\u4e00\u7cfb\u5217\u6b63\u4ea4\u76f8\u4f3c\u53d8\u6362\uff08Givens\u65cb\u8f6c\uff09\u5bf9\u89d2\u5316\u5bf9\u79f0\u77e9\u9635\uff1a 1. \u627e\u5230\u6700\u5927\u7684\u975e\u5bf9\u89d2\u5143\u7d20a\u209aq 2. \u8ba1\u7b97\u65cb\u8f6c\u89d2\u03b8\u4ee5\u5c06\u8be5\u5143\u7d20\u7f6e\u96f6 3. \u5e94\u7528\u65cb\u8f6c\uff1aA' = J^T * A * J\uff0c\u5176\u4e2dJ\u662f\u65cb\u8f6c\u77e9\u9635 4. \u91cd\u590d\u76f4\u5230\u6240\u6709\u975e\u5bf9\u89d2\u5143\u7d20\u4f4e\u4e8e\u5bb9\u5dee</p> <p>\u6536\u655b\u6027:</p> <p>\u5f53\u6700\u5927\u975e\u5bf9\u89d2\u5143\u7d20\u4f4e\u4e8e\u5bb9\u5dee\u65f6\u65b9\u6cd5\u6536\u655b\u3002\u6bcf\u6b21\u65cb\u8f6c\u5c06\u4e00\u4e2a\u975e\u5bf9\u89d2\u5143\u7d20\u7f6e\u96f6\uff0c\u8fc7\u7a0b\u6301\u7eed\u76f4\u5230\u77e9\u9635\u5bf9\u89d2\u5316\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>float tolerance</code> : \u6536\u655b\u9608\u503c\uff08\u4f8b\u5982 1e-6\uff09\u3002\u5141\u8bb8\u7684\u975e\u5bf9\u89d2\u5143\u7d20\u6700\u5927\u5e45\u5ea6\u3002</p> </li> <li> <p><code>int max_iter</code> : \u6700\u5927\u8fed\u4ee3\u6b21\u6570\uff08\u4f8b\u5982 100\uff09\u3002\u5bf9\u4e8en\u00d7n\u77e9\u9635\uff0c\u901a\u5e38\u9700\u8981O(n\u00b2)\u6b21\u8fed\u4ee3\u6536\u655b\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>EigenDecomposition</code>\uff0c\u5305\u542b <code>eigenvalues</code>\u3001<code>eigenvectors</code>\u3001<code>iterations</code> \u548c <code>status</code>\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u5bf9\u79f0\u77e9\u9635: \u4e13\u4e3a\u5bf9\u79f0\u77e9\u9635\u8bbe\u8ba1\u3002\u5bf9\u4e8e\u975e\u5bf9\u79f0\u77e9\u9635\uff0c\u4f7f\u7528QR\u65b9\u6cd5\u3002</p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: \u5bf9\u4e8e\u5bf9\u79f0\u77e9\u9635\u975e\u5e38\u7a33\u5b9a\uff0c\u5177\u6709\u826f\u597d\u7684\u6b63\u4ea4\u6027\u4fdd\u6301\u3002</p> </li> <li> <p>\u7cbe\u5ea6: \u9ad8\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u9700\u8981\u7cbe\u786e\u7279\u5f81\u503c/\u7279\u5f81\u5411\u91cf\u5bf9\u7684\u5e94\u7528\u3002</p> </li> <li> <p>\u6027\u80fd: \u6bcf\u6b21\u8fed\u4ee3O(n\u00b3)\uff0c\u4f46\u5bf9\u4e8e\u5bf9\u79f0\u77e9\u9635\u901a\u5e38\u6bd4QR\u9700\u8981\u66f4\u5c11\u7684\u8fed\u4ee3\u3002</p> </li> <li> <p>\u5e94\u7528:</p> </li> <li> <p>\u7ed3\u6784\u52a8\u529b\u5b66\uff1a\u521a\u5ea6\u548c\u8d28\u91cf\u77e9\u9635\u662f\u5bf9\u79f0\u7684</p> </li> <li> <p>\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09</p> </li> <li> <p>\u8c31\u805a\u7c7b</p> </li> <li> <p>\u4e8c\u6b21\u578b\u4f18\u5316</p> </li> </ul> <p>\u6ce8\u610f:</p> <p>\u5982\u679c\u77e9\u9635\u4e0d\u662f\u8fd1\u4f3c\u5bf9\u79f0\uff0c\u51fd\u6570\u4f1a\u53d1\u51fa\u8b66\u544a\uff0c\u4f46\u4ecd\u53ef\u80fd\u8fd0\u884c\u3002\u5bf9\u4e8e\u975e\u5bf9\u79f0\u77e9\u9635\uff0c\u63a8\u8350\u4f7f\u7528QR\u65b9\u6cd5\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#qr_3","title":"QR \u7279\u5f81\u5206\u89e3\uff08\u4e00\u822c\u77e9\u9635\uff09","text":"<pre><code>Mat::EigenDecomposition Mat::eigendecompose_qr(int max_iter, float tolerance) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u4f7f\u7528QR\u7b97\u6cd5\u8ba1\u7b97\u7279\u5f81\u503c\u5206\u89e3\u3002\u9002\u7528\u4e8e\u4e00\u822c\uff08\u53ef\u80fd\u975e\u5bf9\u79f0\uff09\u77e9\u9635\u3002\u652f\u6301\u975e\u5bf9\u79f0\u77e9\u9635\uff0c\u4f46\u53ef\u80fd\u4ea7\u751f\u590d\u6570\u7279\u5f81\u503c\uff08\u4ec5\u8fd4\u56de\u5b9e\u90e8\uff09\u3002</p> <p>\u6570\u5b66\u539f\u7406:</p> <p>QR\u7b97\u6cd5\u8fed\u4ee3\u5e94\u7528QR\u5206\u89e3\uff1a</p> <ol> <li> <p>\u4eceA\u2080 = A\u5f00\u59cb</p> </li> <li> <p>\u5bf9\u4e8ek = 0, 1, 2, ...\uff1a \u8ba1\u7b97QR\u5206\u89e3\uff1aA\u2096 = Q\u2096 * R\u2096\uff0c\u7136\u540e\u66f4\u65b0\uff1aA\u2096\u208a\u2081 = R\u2096 * Q\u2096</p> </li> <li> <p>A\u2096\u6536\u655b\u5230\u4e0a\u4e09\u89d2\u5f62\u5f0f\uff08Schur\u5f62\u5f0f\uff09\uff0c\u7279\u5f81\u503c\u5728\u5bf9\u89d2\u7ebf\u4e0a</p> </li> </ol> <p>\u6536\u655b\u6027:</p> <p>\u5f53A\u2096\u8fd1\u4f3c\u4e0a\u4e09\u89d2\uff08\u6b21\u5bf9\u89d2\u5143\u7d20 &lt; \u5bb9\u5dee\uff09\u65f6\u7b97\u6cd5\u6536\u655b\u3002\u7279\u5f81\u503c\u51fa\u73b0\u5728\u5bf9\u89d2\u7ebf\u4e0a\uff0c\u7279\u5f81\u5411\u91cf\u4eceQ\u77e9\u9635\u7d2f\u79ef\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>int max_iter</code> : \u6700\u5927QR\u8fed\u4ee3\u6b21\u6570\uff08\u9ed8\u8ba4\uff1a100\uff09\u3002</p> </li> <li> <p><code>float tolerance</code> : \u6536\u655b\u5bb9\u5dee\uff08\u4f8b\u5982 1e-6\uff09\u3002\u4f7f\u7528\u76f8\u5bf9\u5bb9\u5dee\uff0c\u6bd4\u8f83\u6b21\u5bf9\u89d2\u5143\u7d20\u4e0e\u5bf9\u89d2\u5143\u7d20\u3002</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>EigenDecomposition</code>\uff0c\u5305\u542b\u7279\u5f81\u503c\u3001\u7279\u5f81\u5411\u91cf\u3001\u8fed\u4ee3\u6b21\u6570\u548c\u72b6\u6001\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u4e00\u822c\u77e9\u9635: \u53ef\u4ee5\u5904\u7406\u975e\u5bf9\u79f0\u77e9\u9635\uff0c\u4e0eJacobi\u65b9\u6cd5\u4e0d\u540c\u3002</p> </li> <li> <p>\u590d\u6570\u7279\u5f81\u503c: \u975e\u5bf9\u79f0\u77e9\u9635\u53ef\u80fd\u5177\u6709\u590d\u6570\u7279\u5f81\u503c\uff1b\u5f53\u524d\u5b9e\u73b0\u4ec5\u8fd4\u56de\u5b9e\u90e8\u3002</p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u6027: \u4f7f\u7528\u6539\u8fdb\u7684Gram-Schmidt\u548c\u91cd\u65b0\u6b63\u4ea4\u5316\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002</p> </li> <li> <p>\u6027\u80fd: \u6bcf\u6b21\u8fed\u4ee3O(n\u00b3)\u3002\u53ef\u80fd\u9700\u8981\u591a\u6b21\u8fed\u4ee3\u624d\u80fd\u6536\u655b\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u75c5\u6001\u77e9\u9635\u3002</p> </li> <li> <p>\u6536\u655b\u52a0\u901f: \u5b9e\u73b0\u53ef\u4ee5\u4ece\u79fb\u4f4d\uff08Wilkinson\u79fb\u4f4d\uff09\u4e2d\u53d7\u76ca\u4ee5\u52a0\u5feb\u6536\u655b\uff0c\u4f46\u5f53\u524d\u7248\u672c\u4f7f\u7528\u57fa\u672cQR\u8fed\u4ee3\u3002</p> </li> <li> <p>\u5e94\u7528:</p> </li> <li> <p>\u4e00\u822c\u77e9\u9635\u7279\u5f81\u503c\u95ee\u9898</p> </li> <li> <p>\u52a8\u529b\u7cfb\u7edf\u5206\u6790</p> </li> <li> <p>\u63a7\u5236\u7406\u8bba\uff08\u7cfb\u7edf\u6781\u70b9\uff09</p> </li> </ul> <p>\u6ce8\u610f:</p> <p>QR\u5728\u6b64\u5b9e\u73b0\u4e2d\u4f7f\u7528Gram\u2013Schmidt\u6784\u9020Q/R\uff1b\u5bf9\u4e8e\u75c5\u6001\u77e9\u9635\u53ef\u80fd\u4e0d\u592a\u7a33\u5b9a\u3002\u5bf9\u4e8e\u5bf9\u79f0\u77e9\u9635\uff0c\u7531\u4e8e\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u548c\u7cbe\u5ea6\uff0c\u63a8\u8350\u4f7f\u7528Jacobi\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_60","title":"\u81ea\u52a8\u7279\u5f81\u5206\u89e3\uff08\u6839\u636e\u77e9\u9635\u7279\u6027\u9009\u62e9\u65b9\u6cd5\uff09","text":"<pre><code>Mat::EigenDecomposition Mat::eigendecompose(float tolerance) const;\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u7b80\u4fbf\u63a5\u53e3\uff0c\u4f1a\u5148\u8c03\u7528 <code>is_symmetric(tolerance * 10)</code> \u5224\u65ad\u77e9\u9635\u662f\u5426\u8fd1\u4f3c\u5bf9\u79f0\uff1a</p> <ul> <li> <p>\u82e5\u4e3a\u5bf9\u79f0\uff0c\u4f7f\u7528 <code>eigendecompose_jacobi</code>\uff1b</p> </li> <li> <p>\u5426\u5219\u4f7f\u7528 <code>eigendecompose_qr</code>\u3002</p> </li> </ul> <p>\u53c2\u6570:</p> <ul> <li><code>float tolerance</code>\uff1a\u7528\u4e8e\u5bf9\u79f0\u6027\u68c0\u6d4b\u4e0e\u5206\u89e3\u6536\u655b\u5224\u65ad\uff08\u5efa\u8bae <code>1e-6</code>\uff09\u3002</li> </ul> <p>\u8fd4\u56de\u503c:</p> <p><code>EigenDecomposition</code>\u3002</p> <p>\u4f7f\u7528\u5efa\u8bae:</p> <ul> <li> <p>\u82e5\u660e\u786e\u77e5\u9053\u77e9\u9635\u4e3a\u5bf9\u79f0\u77e9\u9635\uff08\u5982\u521a\u5ea6\u77e9\u9635\u3001\u8d28\u91cf\u77e9\u9635\uff09\uff0c\u76f4\u63a5\u4f7f\u7528 <code>eigendecompose_jacobi</code>\uff1b\u5bf9\u975e\u5bf9\u79f0\u6216\u4e0d\u786e\u5b9a\u60c5\u5f62\uff0c\u53ef\u4f7f\u7528 <code>eigendecompose</code>\u3002</p> </li> <li> <p>\u5bf9\u4e8e\u8f83\u5927\u77e9\u9635\u6216\u5d4c\u5165\u5f0f\u573a\u666f\uff0cJacobi/QR \u8ba1\u7b97\u6210\u672c\u8f83\u9ad8\uff0c\u8bf7\u6743\u8861\u6570\u503c\u7a33\u5b9a\u6027\u4e0e\u6027\u80fd\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_61","title":"\u6d41\u64cd\u4f5c\u7b26","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_62","title":"\u77e9\u9635\u8f93\u51fa\u6d41\u64cd\u4f5c\u7b26","text":"<pre><code>std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat &amp;m);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u77e9\u9635\u7684\u91cd\u8f7d\u8f93\u51fa\u6d41\u64cd\u4f5c\u7b26\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>std::ostream &amp;os</code> : \u8f93\u51fa\u6d41\u3002</p> </li> <li> <p><code>const Mat &amp;m</code> : \u8981\u8f93\u51fa\u7684\u77e9\u9635\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#roi_5","title":"ROI\u8f93\u51fa\u6d41\u64cd\u4f5c\u7b26","text":"<pre><code>std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Mat::ROI &amp;roi);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>ROI\u7ed3\u6784\u4f53\u7684\u91cd\u8f7d\u8f93\u51fa\u6d41\u64cd\u4f5c\u7b26\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>std::ostream &amp;os</code> : \u8f93\u51fa\u6d41\u3002</p> </li> <li> <p><code>const Mat::ROI &amp;roi</code> : ROI\u7ed3\u6784\u3002</p> </li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_63","title":"\u77e9\u9635\u8f93\u5165\u6d41\u64cd\u4f5c\u7b26","text":"<pre><code>std::istream &amp;operator&gt;&gt;(std::istream &amp;is, Mat &amp;m);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u77e9\u9635\u7684\u91cd\u8f7d\u8f93\u5165\u6d41\u64cd\u4f5c\u7b26\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>std::istream &amp;is</code> : \u8f93\u5165\u6d41\u3002</p> </li> <li> <p><code>Mat &amp;m</code> : \u8981\u8f93\u5165\u7684\u77e9\u9635\u3002</p> </li> </ul> <p>Tip</p> <p>\u672c\u8282\u5b9e\u9645\u4e0a\u5728\u663e\u793a\u77e9\u9635\u65b9\u9762\u4e0e\u6253\u5370\u51fd\u6570\u6709\u4e9b\u91cd\u53e0\u3002</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_64","title":"\u5168\u5c40\u7b97\u672f\u8fd0\u7b97\u7b26","text":"<p>\u975e\u4fee\u6539\u64cd\u4f5c</p> <p>\u672c\u8282\u4e2d\u7684\u8fd0\u7b97\u7b26\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u77e9\u9635\u5bf9\u8c61\uff0c\u4f5c\u4e3a\u8fd0\u7b97\u7ed3\u679c\u3002\u539f\u59cb\u77e9\u9635\u4fdd\u6301\u4e0d\u53d8\u3002\u8fd9\u4e9b\u662f\u51fd\u6570\u5f0f\u64cd\u4f5c\uff0c\u4e0d\u4fee\u6539\u5176\u64cd\u4f5c\u6570\uff0c\u4f7f\u5176\u53ef\u4ee5\u5b89\u5168\u5730\u4e0econst\u5f15\u7528\u548c\u4e34\u65f6\u5bf9\u8c61\u4e00\u8d77\u4f7f\u7528\u3002</p> <p>\u4f55\u65f6\u4f7f\u7528</p> <ul> <li>\u4f7f\u7528\u5168\u5c40\u8fd0\u7b97\u7b26 (A + B) \u5f53\u60a8\u60f3\u4fdd\u7559\u539f\u59cb\u77e9\u9635\u65f6</li> <li>\u4f7f\u7528\u6210\u5458\u8fd0\u7b97\u7b26 (A += B) \u5f53\u60a8\u60f3\u5c31\u5730\u4fee\u6539\u77e9\u9635\u65f6\uff08\u66f4\u8282\u7701\u5185\u5b58\uff09</li> </ul>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_65","title":"\u52a0\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator+(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u5c06\u4e24\u4e2a\u77e9\u9635\u76f8\u52a0\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 A+B</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_9","title":"\u52a0\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat operator+(const Mat &amp;A, float C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u5c06\u5e38\u91cf\u52a0\u5230\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u8f93\u5165\u77e9\u9635 A</p> </li> <li> <p><code>float C</code>: \u8f93\u5165\u5e38\u91cf</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 A+C</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_66","title":"\u51cf\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator-(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u5c06\u4e24\u4e2a\u77e9\u9635\u76f8\u51cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 A-B</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_10","title":"\u51cf\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat operator-(const Mat &amp;A, float C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u4ece\u77e9\u9635\u4e2d\u51cf\u53bb\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u8f93\u5165\u77e9\u9635 A</p> </li> <li> <p><code>float C</code>: \u8f93\u5165\u5e38\u91cf</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 A-C</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_67","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator*(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u5c06\u4e24\u4e2a\u77e9\u9635\u76f8\u4e58\uff08\u77e9\u9635\u4e58\u6cd5\uff09\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 A*B</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_11","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf","text":"<pre><code>Mat operator*(const Mat &amp;A, float C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u5c06\u77e9\u9635\u4e58\u4ee5\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u8f93\u5165\u77e9\u9635 A</p> </li> <li> <p><code>float C</code>: \u6d6e\u70b9\u6570\u503c</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 A*C</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_12","title":"\u4e58\u6cd5\u8fd0\u7b97\u7b26 - \u5e38\u91cf\uff08\u5de6\u4fa7\uff09","text":"<pre><code>Mat operator*(float C, const Mat &amp;A);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u5c06\u5e38\u91cf\u4e58\u4ee5\u77e9\u9635\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>float C</code>: \u6d6e\u70b9\u6570\u503c</p> </li> <li> <p><code>const Mat &amp;A</code>: \u8f93\u5165\u77e9\u9635 A</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 C*A</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_68","title":"\u9664\u6cd5\u8fd0\u7b97\u7b26","text":"<pre><code>Mat operator/(const Mat &amp;A, float C);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u5c06\u77e9\u9635\u9664\u4ee5\u5e38\u91cf\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u8f93\u5165\u77e9\u9635 A</p> </li> <li> <p><code>float C</code>: \u6d6e\u70b9\u6570\u503c</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 A/C</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#-_13","title":"\u9664\u6cd5\u8fd0\u7b97\u7b26 - \u77e9\u9635","text":"<pre><code>Mat operator/(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u6309\u5143\u7d20\u5c06\u77e9\u9635 A \u9664\u4ee5\u77e9\u9635 B\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u8f93\u5165\u77e9\u9635 A</p> </li> <li> <p><code>const Mat &amp;B</code>: \u8f93\u5165\u77e9\u9635 B</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>Mat - \u7ed3\u679c\u77e9\u9635 C\uff0c\u5176\u4e2d C[i,j] = A[i,j]/B[i,j]</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-api/#_69","title":"\u7b49\u4e8e\u8fd0\u7b97\u7b26","text":"<pre><code>bool operator==(const Mat &amp;A, const Mat &amp;B);\n</code></pre> <p>\u63cf\u8ff0:</p> <p>\u7b49\u4e8e\u8fd0\u7b97\u7b26\uff0c\u68c0\u67e5\u4e24\u4e2a\u77e9\u9635\u662f\u5426\u76f8\u7b49\u3002</p> <p>\u53c2\u6570:</p> <ul> <li> <p><code>const Mat &amp;A</code>: \u7b2c\u4e00\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> <li> <p><code>const Mat &amp;B</code>: \u7b2c\u4e8c\u4e2a\u77e9\u9635\u5bf9\u8c61</p> </li> </ul> <p>\u8fd4\u56de\u503c:</p> <p>\u5e03\u5c14\u503c\uff0c\u8868\u793a\u4e24\u4e2a\u77e9\u9635\u662f\u5426\u76f8\u7b49</p>"},{"location":"zh/MATH/MATRIX/tiny-matrix-code/","title":"\u4ee3\u7801","text":""},{"location":"zh/MATH/MATRIX/tiny-matrix-test/","title":"\u6d4b\u8bd5","text":"<p>Tip</p> <p>\u4ee5\u4e0b\u7684\u6d4b\u8bd5\u7528\u4ee3\u7801\u548c\u6848\u4f8b\u4e5f\u4f5c\u4e3a\u4f7f\u7528\u6559\u5b66\u6848\u4f8b\u3002</p>"},{"location":"zh/MATH/USAGE/usage/","title":"\u4f7f\u7528\u8bf4\u660e","text":"<p>\u4f7f\u7528\u8bf4\u660e</p> <p>\u8be5\u6587\u6863\u662f\u5bf9 <code>tiny_math</code> \u6a21\u5757\u7684\u4f7f\u7528\u8bf4\u660e\u3002</p>"},{"location":"zh/MATH/USAGE/usage/#tinymath","title":"\u6574\u4f53\u5f15\u5165TinyMath","text":"<p>Info</p> <p>\u9002\u7528\u4e8eC\u9879\u76ee\uff0c\u6216\u8005\u7ed3\u6784\u8f83\u4e3a\u7b80\u5355\u7684C++\u9879\u76ee\u3002</p> <pre><code>#include \"tiny_math.h\"\n</code></pre>"},{"location":"zh/MATH/USAGE/usage/#tinymath_1","title":"\u5206\u6a21\u5757\u5f15\u5165TinyMath","text":"<p>Info</p> <p>\u9002\u7528\u4e8e\u9700\u8981\u7cbe\u786e\u63a7\u5236\u5f15\u5165\u6a21\u5757\u7684\u9879\u76ee\uff0c\u6216\u8005\u590d\u6742\u7684C++\u9879\u76ee\u3002</p> <pre><code>#include \"tiny_vec.h\" // \u5f15\u5165\u5411\u91cf\u6a21\u5757\n#include \"tiny_mat.h\" // \u5f15\u5165\u77e9\u9635\u6a21\u5757\n</code></pre> <pre><code>#include \"tiny_matrix.hpp\" // \u5f15\u5165\u9ad8\u7ea7\u77e9\u9635\u6a21\u5757\n</code></pre> <p>\u6ce8\u610f</p> <ul> <li> <p><code>tiny_vec.h</code> \u548c <code>tiny_mat.h</code> \u662f C \u8bed\u8a00\u7248\u672c\u7684\u5934\u6587\u4ef6\uff0c\u9002\u7528\u4e8e C \u8bed\u8a00\u7f16\u7a0b\u3002</p> </li> <li> <p><code>tiny_matrix.hpp</code> \u662f C++ \u8bed\u8a00\u7248\u672c\u7684\u5934\u6587\u4ef6\uff0c\u9002\u7528\u4e8e C++ \u8bed\u8a00\u7f16\u7a0b\u3002</p> </li> </ul> <p>\u7b80\u5355\u6765\u8bf4\uff0cC\u8bed\u8a00\u9879\u76ee\u53ea\u80fd\u7528 <code>tiny_vec.h</code> \u548c <code>tiny_mat.h</code>\uff0c\u800c C++ \u9879\u76ee\u53ef\u4ee5\u4f7f\u7528 <code>tiny_vec.h</code>\u3001<code>tiny_mat.h</code> \u548c <code>tiny_matrix.hpp</code>\u3002</p> <p>Tip</p> <p>\u5177\u4f53\u7684\u4f7f\u7528\u65b9\u6cd5\u8bf7\u53c2\u8003\u6d4b\u8bd5\u4ee3\u7801\u3002</p>"},{"location":"zh/MATH/VECTOR/api/","title":"\u5411\u91cf\u64cd\u4f5c","text":""},{"location":"zh/MATH/VECTOR/api/#_2","title":"\u76ee\u5f55","text":"<pre><code>// Addition\ntiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Subtraction\ntiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Multiplication\ntiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\ntiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n// Division\ntiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\ntiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\n// Square root\ntiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\ntiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\n// Dot product\ntiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\ntiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n</code></pre>"},{"location":"zh/MATH/VECTOR/api/#_3","title":"\u52a0\u6cd5","text":""},{"location":"zh/MATH/VECTOR/api/#_4","title":"\u4e24\u4e2a\u5411\u91cf\u7684\u52a0\u6cd5","text":"<p><pre><code>tiny_error_t tiny_vec_add_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> \u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u9010\u5143\u7d20\u52a0\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>input2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_5","title":"\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u52a0\u6cd5","text":"<p><pre><code>tiny_error_t tiny_vec_addc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> \u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9010\u5143\u7d20\u52a0\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>C</code>\uff1a\u5e38\u6570\u503c\u3002</li> <li><code>step_in</code>\uff1a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_6","title":"\u51cf\u6cd5","text":""},{"location":"zh/MATH/VECTOR/api/#_7","title":"\u4e24\u4e2a\u5411\u91cf\u7684\u51cf\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_sub_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u9010\u5143\u7d20\u51cf\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>input2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_8","title":"\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u51cf\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_subc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9010\u5143\u7d20\u51cf\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>C</code>\uff1a\u5e38\u6570\u503c\u3002</li> <li><code>step_in</code>\uff1a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_9","title":"\u4e58\u6cd5","text":""},{"location":"zh/MATH/VECTOR/api/#_10","title":"\u4e24\u4e2a\u5411\u91cf\u7684\u4e58\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_mul_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u9010\u5143\u7d20\u4e58\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>input2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_11","title":"\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u4e58\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_mulc_f32(const float *input, float *output, int len, float C, int step_in, int step_out);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9010\u5143\u7d20\u4e58\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>C</code>\uff1a\u5e38\u6570\u503c\u3002</li> <li><code>step_in</code>\uff1a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_12","title":"\u9664\u6cd5","text":""},{"location":"zh/MATH/VECTOR/api/#_13","title":"\u4e24\u4e2a\u5411\u91cf\u7684\u9664\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_div_f32(const float *input1, const float *input2, float *output, int len, int step1, int step2, int step_out, bool allow_divide_by_zero);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u9010\u5143\u7d20\u9664\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>input2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>allow_divide_by_zero</code>\uff1a\u5e03\u5c14\u503c\uff0c\u6307\u793a\u662f\u5426\u5141\u8bb8\u9664\u4ee5\u96f6\u7684\u64cd\u4f5c\u3002</li> </ul>"},{"location":"zh/MATH/VECTOR/api/#_14","title":"\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9664\u6cd5","text":"<pre><code>tiny_error_t tiny_vec_divc_f32(const float *input, float *output, int len, float C, int step_in, int step_out, bool allow_divide_by_zero);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u4e0e\u5e38\u6570\u7684\u9010\u5143\u7d20\u9664\u6cd5\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>C</code>\uff1a\u5e38\u6570\u503c\u3002</li> <li><code>step_in</code>\uff1a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step_out</code>\uff1a\u8f93\u51fa\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>allow_divide_by_zero</code>\uff1a\u5e03\u5c14\u503c\uff0c\u6307\u793a\u662f\u5426\u5141\u8bb8\u9664\u4ee5\u96f6\u7684\u64cd\u4f5c\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_15","title":"\u5e73\u65b9\u6839","text":""},{"location":"zh/MATH/VECTOR/api/#_16","title":"\u5411\u91cf\u7684\u5e73\u65b9\u6839","text":"<pre><code>tiny_error_t tiny_vec_sqrt_f32(const float *input, float *output, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u7684\u9010\u5143\u7d20\u5e73\u65b9\u6839\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_17","title":"\u5411\u91cf\u7684\u5e73\u65b9\u6839\uff08\u5feb\u901f\uff09","text":"<pre><code>tiny_error_t tiny_vec_sqrtf_f32(const float *input, float *output, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u7684\u9010\u5143\u7d20\u5e73\u65b9\u6839\uff08\u5feb\u901f\u7248\u672c\uff09\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_18","title":"\u5411\u91cf\u7684\u5e73\u65b9\u6839\u5012\u6570","text":"<pre><code>tiny_error_t tiny_vec_inv_sqrt_f32(const float *input, float *output, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u7684\u9010\u5143\u7d20\u5e73\u65b9\u6839\u5012\u6570\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_19","title":"\u5411\u91cf\u7684\u5e73\u65b9\u6839\u5012\u6570\uff08\u5feb\u901f\uff09","text":"<pre><code>tiny_error_t tiny_vec_inv_sqrtf_f32(const float *input, float *output, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u5411\u91cf\u7684\u9010\u5143\u7d20\u5e73\u65b9\u6839\u5012\u6570\uff08\u5feb\u901f\u7248\u672c\uff09\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5411\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>output</code>\uff1a\u6307\u5411\u8f93\u51fa\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_20","title":"\u70b9\u79ef","text":""},{"location":"zh/MATH/VECTOR/api/#_21","title":"\u5411\u91cf\u7684\u70b9\u79ef","text":"<pre><code>tiny_error_t tiny_vec_dotprod_f32(const float *src1, const float *src2, float *dest, int len);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u70b9\u79ef\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>src1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>src2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>dest</code>\uff1a\u6307\u5411\u8f93\u51fa\u7ed3\u679c\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/api/#_22","title":"\u5411\u91cf\u7684\u70b9\u79ef\uff08\u5e26\u6b65\u957f\uff09","text":"<pre><code>tiny_error_t tiny_vec_dotprode_f32(const float *src1, const float *src2, float *dest, int len, int step1, int step2);\n</code></pre> <p>\u529f\u80fd\uff1a \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u70b9\u79ef\uff08\u5e26\u6b65\u957f\uff09\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>src1</code>\uff1a\u6307\u5411\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>src2</code>\uff1a\u6307\u5411\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6307\u9488\u3002</li> <li><code>dest</code>\uff1a\u6307\u5411\u8f93\u51fa\u7ed3\u679c\u7684\u6307\u9488\u3002</li> <li><code>len</code>\uff1a\u5411\u91cf\u7684\u957f\u5ea6\u3002</li> <li><code>step1</code>\uff1a\u7b2c\u4e00\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> <li><code>step2</code>\uff1a\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u6b65\u957f\u3002</li> </ul> <p>\u8fd4\u56de\u503c\uff1a \u8fd4\u56de <code>tiny_error_t</code> \u7c7b\u578b\u7684\u9519\u8bef\u7801\uff0c\u8868\u793a\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/MATH/VECTOR/code/","title":"\u4ee3\u7801","text":""},{"location":"zh/MATH/VECTOR/test/","title":"\u5411\u91cf\u64cd\u4f5c\u6d4b\u8bd5","text":"<p>\u5411\u91cf\u64cd\u4f5c\u6d4b\u8bd5</p> <p>\u8be5\u6d4b\u8bd5\u7528\u4e8e\u6d4b\u8bd5\u5411\u91cf\u76f8\u5173\u51fd\u6570\u7684\u6027\u80fd\u3002</p>"},{"location":"zh/MATH/VECTOR/test/#_2","title":"\u6d4b\u8bd5\u4ee3\u7801","text":""},{"location":"zh/MATH/VECTOR/test/#_3","title":"\u6d4b\u8bd5\u7ed3\u679c","text":"<p>\u57fa\u7840C\u8ba1\u7b97\u60c5\u51b5</p> <p></p> <p>ESP-DSP\u52a0\u901f\u60c5\u51b5</p> <p></p> <p>\u53ef\u4ee5\u53d1\u73b0\u5728\u5f00\u542fESP-DSP\u52a0\u901f\u540e\uff0c\u5411\u91cf\u8fd0\u7b97\u7684\u6027\u80fd\u6709\u663e\u8457\u63d0\u5347\u3002</p>"},{"location":"zh/PREREQUISITE/prerequisite/","title":"\u524d\u7f6e\u6761\u4ef6","text":""},{"location":"zh/PREREQUISITE/prerequisite/#_2","title":"\u786c\u4ef6\u4e0e\u8f6f\u4ef6\u8981\u6c42","text":"<p>ESP32S3 \u5f00\u53d1\u677f, \u63a8\u8350\u53c2\u8003\u4ee5\u4e0b\u9879\u76ee:</p> <ul> <li> <p> NexNode</p> <p>  \u4ee3\u7801 </p> <p>  \u6587\u6863 </p> </li> </ul> <p>\u6211\u4eec\u4ee5\u8be5\u9879\u76ee\u4e2d\u7684\u4ee3\u7801\u4e3a\u57fa\u7840\u8fdb\u884c\u8fdb\u4e00\u6b65\u5f00\u53d1\u3002</p>"},{"location":"zh/PREREQUISITE/prerequisite/#_3","title":"\u4f9d\u8d56\u7ec4\u4ef6","text":"<p>\u4e3a\u4e86\u63d0\u5347\u6211\u4eec\u6846\u67b6\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u6211\u4eec\u9996\u5148\u5f15\u5165ESP-DSP\u5e93\u548cESP-DL\u5e93\uff0c\u5b83\u4eec\u5206\u522b\u63d0\u4f9b\u4e86\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u548c\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684\u9ad8\u6548\u5b9e\u73b0\u3002</p> <p>Tip</p> <p>\u6ce8\u610f\u4ee5\u4e0a\u4e24\u4e2a\u5e93\u4f3c\u4e4e\u662f\u7531\u4e0d\u540c\u56e2\u961f\u5f00\u53d1\uff0c\u56e0\u6b64\u4ed6\u4eec\u7684\u5f88\u591a\u529f\u80fd\u6709\u91cd\u53e0\u3002</p> <pre><code>- espressif__esp-dsp\n- espressif__esp-dl\n   - espressif__dl_fft\n   - espressif__esp_new_jpeg\n</code></pre> <p>\u6211\u4eec\u53ef\u4ee5\u5728ESP-REGISTRY\u4e2d\u627e\u5230\u548c\u4e0b\u8f7d\u8fd9\u4e9b\u7ec4\u4ef6\u5230\u9879\u76ee\u4e2d\u3002\u5728\u672c\u9879\u76ee\u4e2d\u6211\u5c06\u4e0b\u8f7d\u7684\u7ec4\u4ef6\u53ca\u5176\u4f9d\u8d56\u7ec4\u4ef6\u79fb\u52a8\u5230\u4e86<code>middleware</code>\u6587\u4ef6\u5939\u4e0b\uff0c\u5e76\u79fb\u9664\u4e86\u914d\u7f6e\u6587\u4ef6\uff0c\u4ece\u800c\u907f\u514d\u7248\u672c\u9501\u5b9a\u548c\u7f51\u7edc\u4f9d\u8d56\u3002</p>"},{"location":"zh/TOOLBOX/toolbox/","title":"\u5de5\u5177\u7bb1","text":"<p>tiny_toolbox</p> <p>\u5de5\u5177\u7bb1tiny_toolbox\u5b9a\u4f4d\u662f\u7528\u4e8e \u5e73\u53f0\u9002\u914d\u4e0e\u4f18\u5316 \u5e76\u63d0\u4f9b \u5404\u79cd\u5b9e\u7528\u5de5\u5177 \u7684\u5e93\uff0c\u670d\u52a1\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u4e0e\u5e94\u7528\u5f00\u53d1\u3002\u6ce8\u610f\uff0c\u4e4b\u6240\u4ee5\u5c06\u9002\u914d\u548c\u5de5\u5177\u653e\u5728\u4e00\u4e2a\u5e93\u91cc\u9762\uff0c\u662f\u56e0\u4e3a\u5f88\u591a\u5de5\u5177\u5e95\u5c42\u5229\u7528\u7684\u662f\u5e73\u53f0\u63d0\u4f9b\u7684\u529f\u80fd\uff0c\u6240\u4ee5\u5c06\u5e73\u53f0\u9002\u914d\u548c\u5404\u7c7b\u5de5\u5177\u653e\u5728\u540c\u4e00\u4e2a\u5e93\u91cc\u9762\uff0c\u4fbf\u4e8e\u4f7f\u7528\u548c\u7ef4\u62a4\u3002</p> <p>Warning</p> <p>\u76ee\u524d\u5f00\u53d1\u4ee5ESP32\u4e3a\u57fa\u7840\uff0c\u5411STM32\u7b49\u5e73\u53f0\u7684\u8fc1\u79fb\u9700\u8981\u5bf9\u9002\u914d\u5c42\u8fdb\u884c\u4e00\u5b9a\u7684\u4fee\u6539\u3002</p>"},{"location":"zh/TOOLBOX/toolbox/#_2","title":"\u67b6\u6784\u4e0e\u529f\u80fd\u76ee\u5f55","text":"<pre><code>    tiny_toolbox\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 tiny_toolbox.h // serves as a directory, integrating all submodules\n    \u251c\u2500\u2500 time\n    \u2502   \u251c\u2500\u2500 tiny_time.h // submodule for time management - header file\n    \u2502   \u251c\u2500\u2500 tiny_time.c // submodule for time management - source file\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"zh/TOOLBOX/toolbox/#_3","title":"\u65f6\u95f4","text":"<ul> <li>\u83b7\u53d6\u8fd0\u884c\u65f6\u95f4\uff1a <code>tiny_get_running_time()</code></li> <li>SNTP\u5bf9\u65f6\uff1a <code>sync_time_with_timezone(\"CST-8\")</code></li> <li>\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\uff1a <code>tiny_get_current_datetime(1)</code></li> </ul> <p>\u5f85\u5f00\u53d1:</p> <ul> <li>\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u672c\u5730\u5bf9\u65f6-\u5fae\u79d2\u7ea7\u522b</li> </ul>"},{"location":"zh/TOOLBOX/toolbox/#_4","title":"\u4ee3\u7801","text":"<p>Tip</p> <p>tiny_toolbox.h \u53ea\u662f\u4f5c\u4e3a\u4e00\u4e2a\u76ee\u5f55\uff0c\u96c6\u6210\u4e86\u6240\u6709\u7684\u5b50\u6a21\u5757\uff0c\u5177\u4f53\u7684\u529f\u80fd\u5728\u5404\u4e2a\u5b50\u6a21\u5757\u4e2d\u5b9e\u73b0\u3002tiny_toolbox.c \u53ea\u662f\u5f62\u5f0f\u4e0a\u7684\u6e90\u6587\u4ef6\uff0c\u6ca1\u6709\u5177\u4f53\u7684\u529f\u80fd\u3002</p>"},{"location":"zh/TOOLBOX/TIME/code/#_1","title":"\u7ed3\u679c","text":"<pre><code>I (25) boot: ESP-IDF v6.0-dev-1833-g758939caec 2nd stage bootloader\nI (25) boot: compile time Nov  4 2025 23:13:16\nI (25) boot: Multicore bootloader\nI (27) boot: chip revision: v0.2\nI (30) boot: efuse block revision: v1.3\nI (33) qio_mode: Enabling default flash chip QIO\nI (38) boot.esp32s3: Boot SPI Speed : 80MHz\nI (41) boot.esp32s3: SPI Mode       : QIO\nI (45) boot.esp32s3: SPI Flash Size : 16MB\nI (49) boot: Enabling RNG early entropy source...\nI (54) boot: Partition Table:\nI (56) boot: ## Label            Usage          Type ST Offset   Length\nI (62) boot:  0 nvs              WiFi data        01 02 00009000 00006000\nI (69) boot:  1 phy_init         RF data          01 01 0000f000 00001000\nI (75) boot:  2 factory          factory app      00 00 00010000 001f0000\nI (82) boot:  3 vfs              Unknown data     01 81 00200000 00a00000\nI (89) boot:  4 storage          Unknown data     01 82 00c00000 00400000\nI (95) boot: End of partition table\nI (98) esp_image: segment 0: paddr=00010020 vaddr=3c0b0020 size=1df80h (122752) map\nI (124) esp_image: segment 1: paddr=0002dfa8 vaddr=3fc99300 size=02070h (  8304) load\nI (126) esp_image: segment 2: paddr=00030020 vaddr=42000020 size=a26fch (665340) map\nI (227) esp_image: segment 3: paddr=000d2724 vaddr=3fc9b370 size=030e0h ( 12512) load\nI (229) esp_image: segment 4: paddr=000d580c vaddr=40374000 size=152ech ( 86764) load\nI (247) esp_image: segment 5: paddr=000eab00 vaddr=50000000 size=00020h (    32) load\nI (256) boot: Loaded app from partition at offset 0x10000\nI (256) boot: Disabling RNG early entropy source...\nI (266) octal_psram: vendor id    : 0x0d (AP)\nI (267) octal_psram: dev id       : 0x02 (generation 3)\nI (267) octal_psram: density      : 0x03 (64 Mbit)\nI (269) octal_psram: good-die     : 0x01 (Pass)\nI (273) octal_psram: Latency      : 0x01 (Fixed)\nI (277) octal_psram: VCC          : 0x01 (3V)\nI (281) octal_psram: SRF          : 0x01 (Fast Refresh)\nI (286) octal_psram: BurstType    : 0x01 (Hybrid Wrap)\nI (291) octal_psram: BurstLen     : 0x01 (32 Byte)\nI (296) octal_psram: Readlatency  : 0x02 (10 cycles@Fixed)\nI (301) octal_psram: DriveStrength: 0x00 (1/1)\nI (306) MSPI Timing: PSRAM timing tuning index: 5\nI (310) esp_psram: Found 8MB PSRAM device\nI (313) esp_psram: Speed: 80MHz\nI (316) cpu_start: Multicore app\nI (752) esp_psram: SPI SRAM memory test OK\nI (760) cpu_start: GPIO 44 and 43 are used as console UART I/O pins\nI (761) cpu_start: Pro cpu start user code\nI (761) cpu_start: cpu freq: 240000000 Hz\nI (762) app_init: Application information:\nI (766) app_init: Project name:     AIoTNode\nI (770) app_init: App version:      0a79117-dirty\nI (775) app_init: Compile time:     Nov  4 2025 23:13:38\nI (780) app_init: ELF file SHA256:  a5e0090b4...\nI (784) app_init: ESP-IDF:          v6.0-dev-1833-g758939caec\nI (789) efuse_init: Min chip rev:     v0.0\nI (793) efuse_init: Max chip rev:     v0.99 \nI (797) efuse_init: Chip rev:         v0.2\nI (801) heap_init: Initializing. RAM available for dynamic allocation:\nI (807) heap_init: At 3FCA2918 len 00046DF8 (283 KiB): RAM\nI (812) heap_init: At 3FCE9710 len 00005724 (21 KiB): RAM\nI (818) heap_init: At 3FCF0000 len 00008000 (32 KiB): DRAM\nI (823) heap_init: At 600FE000 len 00001FE8 (7 KiB): RTCRAM\nI (828) esp_psram: Adding pool of 8192K of PSRAM memory to heap allocator\nI (835) spi_flash: detected chip: boya\nI (838) spi_flash: flash io: qio\nI (841) sleep_gpio: Configure to isolate all GPIO pins in sleep state\nI (847) sleep_gpio: Enable automatic switching of GPIO sleep configuration\nI (854) main_task: Started on CPU0\nI (878) esp_psram: Reserving pool of 32K of internal memory for DMA/internal allocations\nI (878) main_task: Calling app_main()\nI (883) tiny_time_test: ========================================\nI (884) tiny_time_test:   tiny_time Module Test Program\nI (889) tiny_time_test: ========================================\nI (895) tiny_time_test: Initializing WiFi...\nI (900) pp: pp rom version: e7ae62f\nI (902) net80211: net80211 rom version: e7ae62f\nI (907) wifi:wifi driver task: 3fcaf644, prio:23, stack:6656, core=0\nI (915) wifi:wifi firmware version: 14da9b7\nI (916) wifi:wifi certification version: v7.0\nI (920) wifi:config NVS flash: enabled\nI (924) wifi:config nano formatting: disabled\nI (928) wifi:Init data frame dynamic rx buffer num: 32\nI (933) wifi:Init static rx mgmt buffer num: 5\nI (937) wifi:Init management short buffer num: 32\nI (941) wifi:Init dynamic tx buffer num: 32\nI (945) wifi:Init static tx FG buffer num: 2\nI (949) wifi:Init static rx buffer size: 1600\nI (953) wifi:Init static rx buffer num: 10\nI (957) wifi:Init dynamic rx buffer num: 32\nI (961) wifi_init: rx ba win: 6\nI (964) wifi_init: accept mbox: 6\nI (967) wifi_init: tcpip mbox: 32\nI (970) wifi_init: udp mbox: 6\nI (973) wifi_init: tcp mbox: 6\nI (975) wifi_init: tcp tx win: 5760\nI (979) wifi_init: tcp rx win: 5760\nI (982) wifi_init: tcp mss: 1440\nI (985) wifi_init: WiFi IRAM OP enabled\nI (988) wifi_init: WiFi RX IRAM OP enabled\nI (992) NODE-WIFI: Setting WiFi configuration SSID NTUSECURE...\nI (999) phy_init: phy_version 701,f4f1da3a,Mar  3 2025,15:50:10\nI (1037) wifi:mode : sta (cc:ba:97:09:a7:50)\nI (1038) wifi:enable tsf\nI (1039) tiny_time_test: WiFi initialized successfully\nI (1040) tiny_time_test: Waiting for WiFi connection...\nI (1107) wifi:new:&lt;1,0&gt;, old:&lt;1,0&gt;, ap:&lt;255,255&gt;, sta:&lt;1,0&gt;, prof:1, snd_ch_cfg:0x0\nI (1108) wifi:state: init -&gt; auth (0xb0)\nI (1111) wifi:state: auth -&gt; assoc (0x0)\nI (1115) wifi:state: assoc -&gt; run (0x10)\nI (1430) wifi:connected with NTUSECURE, aid = 2, channel 1, BW20, bssid = a8:9d:21:3c:12:b1\nI (1430) wifi:security: WPA2-ENT, phy: bgn, rssi: -66\nI (1432) wifi:pm start, type: 1\n\nI (1435) wifi:dp: 1, bi: 104448, li: 2, scale listen interval from 307200 us to 208896 us\nI (1443) wifi:set rx beacon pti, rx_bcn_pti: 0, bcn_timeout: 25000, mt_pti: 0, mt_time: 10000\nI (1459) wifi:&lt;ba-add&gt;idx:0 (ifx:0, a8:9d:21:3c:12:b1), tid:0, ssn:1200, winSize:64\nI (1488) wifi:AP's beacon interval = 104448 us, DTIM period = 1\nI (2467) esp_netif_handlers: sta ip: 10.91.180.236, mask: 255.255.0.0, gw: 10.91.255.254\nI (2467) tiny_time_test: WiFi connected!\nI (2467) tiny_time_test: \n--- Test 1: Get Running Time ---\nI (2473) tiny_time_test: Running time: 1644833 microseconds\nI (2478) tiny_time_test: Running time: 1.645 seconds\nI (2483) tiny_time_test: \n--- Test 2: Sync Time with Timezone ---\nI (2489) tiny_time_test: Syncing time with timezone CST-8...\nI (2494) NTP_SYNC: Initializing SNTP\nI (2498) NTP_SYNC: Waiting for system time to be set... (1/15)\nI (4503) NTP_SYNC: Waiting for system time to be set... (2/15)\nI (4715) NTP_SYNC: Time synchronized!\nI (6503) NTP_SYNC: System time is set.\nI (6503) NTP_SYNC: Current time: Tue Nov 04 23:15:34 2025\nI (6503) tiny_time_test: Waiting for time synchronization...\nI (11506) tiny_time_test: \n--- Test 3: Get Current DateTime ---\nI (11506) TIME: Current Time: 2025-11-04 23:15:39.003179\nI (11506) tiny_time_test: \n--- Test 4: Measure Time Elapsed ---\nI (11511) tiny_time_test: Time elapsed: 9038406 microseconds\nI (11517) tiny_time_test: Time elapsed: 9.038 seconds\nI (11521) tiny_time_test: \n========================================\nI (11527) tiny_time_test:   Initial Tests Completed\nI (11532) tiny_time_test: ========================================\n\nI (11538) tiny_time_test: \n========================================\nI (11544) tiny_time_test:   Timer Precision Test\nI (11548) tiny_time_test: ========================================\nI (11554) tiny_time_test: Recording 15 timestamps at 2-second intervals...\nI (11561) tiny_time_test: No printing during recording to avoid timing overhead.\n\nI (11568) tiny_time_test: Timer started. Waiting for 15 timestamps...\nI (41674) tiny_time_test: \n========================================\nI (41674) tiny_time_test:   Timer Precision Test Results\nI (41674) tiny_time_test: ========================================\nI (41680) tiny_time_test: Expected interval: 2000000 microseconds (2.000000 seconds)\n\nI (41687) tiny_time_test: Timestamp # 1: 12740383 microseconds (12.740383 seconds) [baseline]\nI (41696) tiny_time_test: Timestamp # 2: 14740381 microseconds (14.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41708) tiny_time_test: Timestamp # 3: 16740383 microseconds (16.740383 seconds) | Interval: 2000002 us (2.000002 s) | Error: 2 us (0.002 ms)\nI (41721) tiny_time_test: Timestamp # 4: 18740383 microseconds (18.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41733) tiny_time_test: Timestamp # 5: 20740383 microseconds (20.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41746) tiny_time_test: Timestamp # 6: 22740383 microseconds (22.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41759) tiny_time_test: Timestamp # 7: 24740382 microseconds (24.740382 seconds) | Interval: 1999999 us (1.999999 s) | Error: -1 us (-0.001 ms)\nI (41771) tiny_time_test: Timestamp # 8: 26740383 microseconds (26.740383 seconds) | Interval: 2000001 us (2.000001 s) | Error: 1 us (0.001 ms)\nI (41784) tiny_time_test: Timestamp # 9: 28740383 microseconds (28.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41797) tiny_time_test: Timestamp #10: 30740383 microseconds (30.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41809) tiny_time_test: Timestamp #11: 32740383 microseconds (32.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41822) tiny_time_test: Timestamp #12: 34740381 microseconds (34.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41834) tiny_time_test: Timestamp #13: 36740383 microseconds (36.740383 seconds) | Interval: 2000002 us (2.000002 s) | Error: 2 us (0.002 ms)\nI (41847) tiny_time_test: Timestamp #14: 38740383 microseconds (38.740383 seconds) | Interval: 2000000 us (2.000000 s) | Error: 0 us (0.000 ms)\nI (41860) tiny_time_test: Timestamp #15: 40740381 microseconds (40.740381 seconds) | Interval: 1999998 us (1.999998 s) | Error: -2 us (-0.002 ms)\nI (41872) tiny_time_test: \n--- Statistics ---\nI (41877) tiny_time_test: Total time: 27999998 microseconds (27.999998 seconds)\nI (41884) tiny_time_test: Expected total: 28000000 microseconds (28.000000 seconds)\nI (41891) tiny_time_test: Total error: -2 microseconds (-0.002 milliseconds)\nI (41898) tiny_time_test: Average interval: 2.000000 seconds (1999999.857 microseconds)\nI (41906) tiny_time_test: \n========================================\nI (41912) tiny_time_test:   Test Complete\nI (41915) tiny_time_test: ========================================\n</code></pre>"},{"location":"zh/TOOLBOX/TIME/log/","title":"LOG","text":"<p>2025-04-10</p> <ul> <li>\u83b7\u53d6\u8fd0\u884c\u65f6\u95f4\uff1a <code>tiny_get_running_time()</code></li> <li>SNTP\u5bf9\u65f6\uff1a <code>sync_time_with_timezone(\"CST-8\")</code></li> <li>\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\uff1a <code>tiny_get_current_datetime(1)</code></li> </ul> <p>\u5f85\u5f00\u53d1:</p> <ul> <li>\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u672c\u5730\u5bf9\u65f6-\u5fae\u79d2\u7ea7\u522b</li> </ul>"},{"location":"zh/TOOLBOX/TIME/notes/","title":"\u65f6\u95f4","text":"<p>\u65f6\u95f4</p> <p>\u65f6\u95f4\u76f8\u5173\u7684\u529f\u80fd\u5bf9\u4e8eMCU\u6765\u8bf4\u975e\u5e38\u91cd\u8981\uff0c\u672c\u8282\u63d0\u4f9b\u4e00\u7cfb\u5217\u65f6\u95f4\u76f8\u5173\u7684\u5b9a\u4e49\u548c\u51fd\u6570\uff0c\u4f9b\u5f00\u53d1\u8005\u4f7f\u7528\u3002</p> <p>MCU\u4e2d\u7684\u65f6\u95f4\u53ef\u4ee5\u5206\u4ee5\u4e0b\u51e0\u79cd\u7c7b\u578b\uff1a</p> <ul> <li> <p>\u8fd0\u884c\u65f6\u95f4\uff1a \u6307\u7684\u662fMCU\u4ece\u4e0a\u7535\u5230\u73b0\u5728\u7684\u65f6\u95f4\u3002</p> </li> <li> <p>\u4e16\u754c\u65f6\u95f4\uff1a \u6307\u7684\u662fMCU\u6240\u5728\u7684\u65f6\u533a\u7684\u65f6\u95f4\u3002\u4e16\u754c\u65f6\u95f4\u53ef\u4ee5\u901a\u8fc7\u6807\u51c6\u7684\u5e74\u6708\u65e5\u65f6\u5206\u79d2\u6765\u8868\u793a\uff0c\u4e5f\u53ef\u4ee5\u8868\u793a\u4e3aUNIX\u65f6\u95f4\u6233\u3002</p> </li> </ul>"},{"location":"zh/TOOLBOX/TIME/notes/#_2","title":"\u8fd0\u884c\u65f6\u95f4","text":"<p>ESP\u6709\u81ea\u5df1\u7684\u83b7\u53d6\u8fd0\u884c\u65f6\u95f4\u7684\u51fd\u6570<code>esp_timer_get_time</code>\uff0c\u4f9d\u8d56\u4e8e<code>esp_timer</code>\u5e93\u3002\u8be5\u51fd\u6570\u8fd4\u56de\u4ece\u4e0a\u7535\u5230\u73b0\u5728\u7684\u65f6\u95f4\uff0c\u5355\u4f4d\u4e3a\u5fae\u79d2\u3002</p> <p>\u4e3a\u4e86\u65b9\u4fbf\u4f7f\u7528\uff0cTinyToolbox\u91cd\u65b0\u5b9a\u4e49\u4e86\u6570\u636e\u7c7b\u578b<code>TinyTimeMark_t</code>\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u51fd\u6570<code>tiny_get_running_time</code>\u6765\u83b7\u53d6\u8fd0\u884c\u65f6\u95f4\u3002\u8be5\u51fd\u6570\u8fd4\u56de\u7684\u65f6\u95f4\u5355\u4f4d\u4e3aint64_t\uff0c\u5176\u957f\u5ea6\u8db3\u591f\u4ee5\u907f\u514d\u6ea2\u51fa\u3002</p> <pre><code>typedef int64_t TinyTimeMark_t;\n</code></pre> <pre><code>/**\n * @brief Get the running time in microseconds\n * @return TinyTimeMark_t\n */\nTinyTimeMark_t tiny_get_running_time(void) { return esp_timer_get_time(); }\n</code></pre> <p>\u4f7f\u7528\u53c2\u8003\uff1a</p> <pre><code>void app_main(void)\n{\n    // Get running time\n    TinyTimeMark_t running_time = tiny_get_running_time();\n    ESP_LOGI(TAG_TIME, \"Running Time: %lld us\", running_time);\n}\n</code></pre>"},{"location":"zh/TOOLBOX/TIME/notes/#_3","title":"\u4e16\u754c\u65f6\u95f4","text":"<p>Warning</p> <p>\u6ce8\u610f\uff0c\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\u9700\u8981\u5efa\u7acb\u5728\u5df2\u7ecf\u8054\u7f51\u7684\u57fa\u7840\u4e0a\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\u7684\u51fd\u6570\u9700\u8981\u5728\u8054\u7f51\u6210\u529f\u540e\u8c03\u7528\u3002</p>"},{"location":"zh/TOOLBOX/TIME/notes/#ntp","title":"NTP\u5bf9\u65f6","text":"<p>NTP\u5bf9\u65f6</p> <p>NTP\uff08Network Time Protocol\uff09\u662f\u7f51\u7edc\u65f6\u95f4\u534f\u8bae\u7684\u7f29\u5199\uff0c\u662f\u4e00\u79cd\u7528\u4e8e\u5728\u8ba1\u7b97\u673a\u7f51\u7edc\u4e2d\u540c\u6b65\u65f6\u95f4\u7684\u534f\u8bae\u3002\u5b83\u53ef\u4ee5\u901a\u8fc7\u4e92\u8054\u7f51\u6216\u5c40\u57df\u7f51\u83b7\u53d6\u51c6\u786e\u7684\u65f6\u95f4\u4fe1\u606f\u3002 NTP\u534f\u8bae\u4f7f\u7528UDP\u534f\u8bae\u8fdb\u884c\u901a\u4fe1\uff0c\u9ed8\u8ba4\u4f7f\u7528123\u7aef\u53e3\u3002NTP\u670d\u52a1\u5668\u4f1a\u5b9a\u671f\u5411\u5ba2\u6237\u7aef\u53d1\u9001\u65f6\u95f4\u4fe1\u606f\uff0c\u5ba2\u6237\u7aef\u6839\u636e\u8fd9\u4e9b\u4fe1\u606f\u6765\u6821\u6b63\u81ea\u5df1\u7684\u7cfb\u7edf\u65f6\u95f4\u3002</p> <pre><code>   Client                      Server\n     |-------------------&gt;      |     T1\uff1a\u8bf7\u6c42\u53d1\u51fa\n     |                          |\n     |         &lt;--------------- |     T2/T3\uff1a\u670d\u52a1\u5668\u6536\u5230 &amp; \u56de\u590d\n     |                          |\n     |-------------------&gt;      |     T4\uff1a\u5ba2\u6237\u7aef\u6536\u5230\u54cd\u5e94\n</code></pre> <p>NTP\u5bf9\u65f6\u539f\u7406</p> <p>NTP\u5bf9\u65f6\u662f\u57fa\u4e8e\u56db\u4e2a\u65f6\u95f4\u6233\uff1a1. \u5ba2\u6237\u7aef\u53d1\u9001\u8bf7\u6c42\u65f6\u7684\u65f6\u95f4\u6233T1 2. \u670d\u52a1\u5668\u63a5\u6536\u5230\u8bf7\u6c42\u65f6\u7684\u65f6\u95f4\u6233T2 3. \u670d\u52a1\u5668\u53d1\u9001\u54cd\u5e94\u65f6\u7684\u65f6\u95f4\u6233T3 4. \u5ba2\u6237\u7aef\u63a5\u6536\u5230\u54cd\u5e94\u65f6\u7684\u65f6\u95f4\u6233T4\u3002\u6839\u636e\u8fd9\u56db\u4e2a\u65f6\u95f4\u6233\uff0c\u53ef\u4ee5\u8ba1\u7b97 \u7f51\u7edc\u5ef6\u8fdf Delay = (T4 - T1) - (T3 - T2)\uff0c\u4ee5\u53ca \u65f6\u95f4\u504f\u79fb Offset = ((T2 - T1) + (T3 - T4)) / 2\u3002</p> <p>ESP32 SNTP\u5bf9\u65f6</p> <p>ESP32\u4e2d\u4f7f\u7528\u7684\u662fSNTP\uff0c\u4e5f\u5c31\u662fSimple Network Time Protocol\u3002SNTP\u662fNTP\u7684\u7b80\u5316\u7248\uff0c\u9002\u7528\u4e8e\u5bf9\u65f6\u95f4\u7cbe\u5ea6\u8981\u6c42\u4e0d\u9ad8\u7684\u573a\u666f\u3002ESP32\u4e2d\u5bf9\u65f6\u4f9d\u8d56\u4e8e<code>esp_sntp</code>\u5e93\u3002SNTP\u7684\u5de5\u4f5c\u539f\u7406\u4e0eNTP\u7c7b\u4f3c\uff0c\u4f46SNTP\u7684\u5b9e\u73b0\u76f8\u5bf9\u7b80\u5355\uff0c\u9002\u5408\u5d4c\u5165\u5f0f\u8bbe\u5907\u4f7f\u7528\u3002\u5176\u7cbe\u5ea6\u901a\u5e38\u5728ms\u7ea7\u522b\uff0c\u9002\u7528\u4e8e\u5927\u591a\u6570\u5e94\u7528\u573a\u666f\u3002</p> <p>\u9996\u5148\u5b9a\u4e49\u4e00\u4e2a\u56de\u8c03\u51fd\u6570\uff0c\u7528\u4e8e\u63a5\u6536\u5bf9\u65f6\u901a\u77e5\uff1a</p> <pre><code>/* WORLD CURRENT TIME - SNTP */\n/**\n * @brief Callback function for time synchronization notification\n * @param tv Pointer to the timeval structure containing the synchronized time\n * @return None\n */\nstatic void time_sync_notification_cb(struct timeval *tv)\n{\n    ESP_LOGI(TAG_SNTP, \"Time synchronized!\");\n}\n</code></pre> <p>\u63a5\u4e0b\u6765\u662fSNTP\u7684\u521d\u59cb\u5316\u51fd\u6570\uff0c\u4e5f\u662f\u5bf9\u65f6\u7684\u6838\u5fc3\u51fd\u6570\uff0c\u901a\u5e38\u5728\u7cfb\u7edf\u521d\u59cb\u5316\u65f6\uff0c\u5b8c\u6210\u8054\u7f51\u540e\u8c03\u7528\u3002\u6ce8\u610f\u5176\u4e2d\u7684\u5bf9\u65f6\u670d\u52a1\u5668\u5730\u5740\u53ef\u4ee5\u6839\u636e\u9700\u8981\u8fdb\u884c\u4fee\u6539\u3002\u5bf9\u65f6\u5b8c\u6210\u540e\uff0cESP32\u4f1a\u5728\u5e95\u5c42\u5bf9\u672c\u673a\u65f6\u95f4\u8fdb\u884c\u8bbe\u7f6e\u3002</p> <pre><code>/**\n * @brief Initialize SNTP\n * @note This function can be called multiple times if needed\n * @return None\n */\nstatic void initialize_sntp(void)\n{\n    ESP_LOGI(TAG_SNTP, \"Initializing SNTP\");\n    esp_sntp_setoperatingmode(SNTP_OPMODE_POLL);\n    esp_sntp_setservername(0, \"pool.ntp.org\"); // NTP server // pool.ntp.org // ntp.aliyun.com\n    esp_sntp_set_time_sync_notification_cb(time_sync_notification_cb);\n    esp_sntp_init();\n}\n</code></pre> <p>\u518d\u63a5\u4e0b\u6765\u662f\u5bf9\u4ee5\u4e0a\u51fd\u6570\u7684\u8fdb\u4e00\u6b65\u5c01\u88c5\uff0c\u5305\u542b\u4e86\u65f6\u533a\u8bbe\u7f6e\u3002\u6ce8\u610f\u4ee5\u4e0b\u51fd\u6570\u4e2d\u5305\u62ec\u4e86\u5bf9RTC\u7684\u8bbe\u7f6e<code>rtc_set_time</code>\uff0c\u4f9d\u8d56\u4e8edriver\u5c42\u7684RTC\u9a71\u52a8\u3002\u6b64\u5904\u4f7f\u7528\u7684\u662f\u6211\u81ea\u5b9a\u4e49\u7684rtc\u9a71\u52a8\uff0c\u82e5\u6ca1\u6709\u76f8\u5173\u529f\u80fd\u53ef\u4ee5\u76f4\u63a5\u6ce8\u91ca\u6389\u3002</p> <pre><code>/**\n * @brief Obtain the current time with timezone\n * @param timezone_str Timezone string (e.g., \"CST-8\" or \"GMT+8\")\n * @note The timezone string format should be compatible with POSIX TZ format\n * (e.g., \"CST-8\", \"GMT+8\")\n * @note To use this function, in application, after internet connection, call\n * sync_time_with_timezone(\"CST-8\")\n * @return None\n */\nvoid sync_time_with_timezone(const char *timezone_str)\n{\n    // Validate input parameter\n    if (timezone_str == NULL)\n    {\n        ESP_LOGE(TAG_SNTP, \"timezone_str is NULL\");\n        return;\n    }\n\n    // Set system timezone\n    if (setenv(\"TZ\", timezone_str, 1) != 0)\n    {\n        ESP_LOGE(TAG_SNTP, \"Failed to set timezone environment variable\");\n        return;\n    }\n    tzset();\n\n    // Initialize SNTP and start time sync\n    initialize_sntp();\n\n    // Wait for system time to be set\n    time_t now = 0;\n    struct tm timeinfo = {0};\n    int retry = 0;\n    const int retry_count = 15;\n\n    while (timeinfo.tm_year &lt; MIN_VALID_YEAR_OFFSET &amp;&amp; ++retry &lt; retry_count)\n    {\n        ESP_LOGI(TAG_SNTP, \"Waiting for system time to be set... (%d/%d)\", retry,\n                 retry_count);\n        vTaskDelay(2000 / portTICK_PERIOD_MS);\n        time(&amp;now);\n        if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n        {\n            ESP_LOGW(TAG_SNTP, \"Failed to convert time to local time\");\n            continue;\n        }\n    }\n\n    if (timeinfo.tm_year &gt;= MIN_VALID_YEAR_OFFSET)\n    {\n        rtc_set_time(timeinfo.tm_year + 1900, timeinfo.tm_mon + 1, timeinfo.tm_mday,\n                     timeinfo.tm_hour, timeinfo.tm_min,\n                     timeinfo.tm_sec); // defined in esp_rtc.c\n        ESP_LOGI(TAG_SNTP, \"System time is set.\");\n    }\n    else\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to sync time.\");\n        return;\n    }\n\n    // Log current local time (using thread-safe formatting)\n    char time_str[64];\n    if (strftime(time_str, sizeof(time_str), \"%a %b %d %H:%M:%S %Y\", &amp;timeinfo) ==\n        0)\n    {\n        ESP_LOGW(TAG_SNTP, \"Failed to format time string\");\n    }\n    else\n    {\n        ESP_LOGI(TAG_SNTP, \"Current time: %s\", time_str);\n    }\n\n    // vTaskDelay(10000 / portTICK_PERIOD_MS); // Wait for 10 second\n    // rtc_get_time(); // uncomment to check the RTC time\n    // ESP_LOGI(TAG_SNTP, \"Current RTC time: %04d-%02d-%02d %02d:%02d:%02d\",\n    //          calendar.year, calendar.month, calendar.date,\n    //          calendar.hour, calendar.min, calendar.sec); // uncomment to check\n    //          the RTC time\n}\n</code></pre>"},{"location":"zh/TOOLBOX/TIME/notes/#_4","title":"\u4e16\u754c\u65f6\u95f4\u83b7\u53d6","text":"<p>\u4e3a\u4e86\u65b9\u4fbf\u4e16\u754c\u65f6\u95f4\u7684\u83b7\u53d6\uff0c\u6211\u4eec\u9996\u5148\u5b9a\u4e49\u4e86\u4e00\u4e2a\u6570\u636e\u7ed3\u6784<code>DateTime_t</code>\uff0c\u7528\u4e8e\u5b58\u50a8\u5e74\u6708\u65e5\u65f6\u5206\u79d2\u7b49\u4fe1\u606f\u3002\u7136\u540e\u5b9a\u4e49\u4e86\u4e00\u4e2a\u51fd\u6570<code>tiny_get_current_datetime</code>\uff0c\u7528\u4e8e\u83b7\u53d6\u5f53\u524d\u7684\u4e16\u754c\u65f6\u95f4\u3002\u8be5\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a<code>DateTime_t</code>\u7ed3\u6784\u4f53\uff0c\u5305\u542b\u4e86\u5f53\u524d\u7684\u5e74\u6708\u65e5\u65f6\u5206\u79d2\u7b49\u4fe1\u606f\u3002\u5728\u4f7f\u7528\u65f6\uff0c\u4f20\u5165\u4e00\u4e2a\u5e03\u5c14\u503c<code>print_flag</code>\uff0c\u7528\u4e8e\u63a7\u5236\u662f\u5426\u6253\u5370\u5f53\u524d\u65f6\u95f4\u3002</p> <pre><code>/**\n * @brief Structure to hold date and time\n */\ntypedef struct TinyDateTime_t\n{\n    int year;\n    int month;\n    int day;\n    int hour;\n    int minute;\n    int second;\n    long microsecond;\n} TinyDateTime_t; \n</code></pre> <pre><code>/* WORLD CURRENT TIME - GET TIME */\n/**\n * @name tiny_get_current_datetime\n * @brief Get the current time as a TinyDateTime_t struct\n * @param print_flag Flag to indicate whether to print the time\n * @return TinyDateTime_t structure containing the current date and time\n */\nTinyDateTime_t tiny_get_current_datetime(bool print_flag)\n{\n    TinyDateTime_t result = {0}; // Initialize to zero\n    struct timeval tv;\n\n    // Get current time (seconds + microseconds)\n    if (gettimeofday(&amp;tv, NULL) != 0)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to get time of day\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    time_t now = tv.tv_sec;\n    struct tm timeinfo;\n    if (localtime_r(&amp;now, &amp;timeinfo) == NULL)\n    {\n        ESP_LOGE(TAG_TIME, \"Failed to convert time to local time\");\n        return result; // Return zero-initialized structure on error\n    }\n\n    result.year = timeinfo.tm_year + 1900;\n    result.month = timeinfo.tm_mon + 1;\n    result.day = timeinfo.tm_mday;\n    result.hour = timeinfo.tm_hour;\n    result.minute = timeinfo.tm_min;\n    result.second = timeinfo.tm_sec;\n    result.microsecond = (int32_t)tv.tv_usec; // Explicit cast for portability\n\n    if (print_flag)\n    {\n        ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06d\",\n                 result.year, result.month, result.day, result.hour, result.minute,\n                 result.second, result.microsecond);\n    }\n\n    return result;\n}\n</code></pre> <p>\u4f7f\u7528\u53c2\u8003\uff1a</p> <pre><code>void app_main(void)\n{\n    // Initialize SNTP and sync time\n    sync_time_with_timezone(\"CST-8\");\n\n    // Get current time\n    TinyDateTime_t current_time = tiny_get_current_datetime(true);\n\n    // Print current time\n    ESP_LOGI(TAG_TIME, \"Current Time: %04d-%02d-%02d %02d:%02d:%02d.%06ld\",\n             current_time.year, current_time.month, current_time.day,\n             current_time.hour, current_time.minute, current_time.second, current_time.microsecond);\n}\n</code></pre> <p>\u4f7f\u7528\u6548\u679c\uff1a</p> <p></p> <p>Danger</p> <p>SNTP\u540c\u6b65\u5230RTC\u4e2d\u7684\u7cbe\u5ea6\u4e3a\u79d2\u7ea7\u522b\uff0c\u56e0\u6b64\u5728\u83b7\u53d6\u4e16\u754c\u65f6\u95f4\u65f6\uff0c\u5fae\u79d2\u90e8\u5206\u53ef\u80fd\u5e76\u4e0d\u51c6\u786e\uff0c\u4ec5\u4f9b\u53c2\u8003\u3002</p>"}]}